### [bt]: This is batchtools v0.9.17
### [bt]: Starting calculation of 1 jobs
### [bt]: Setting working directory to '/content/drive/MyDrive/GitHub/Mater_Thesis_Calibration'
ece.R :
Friedmann_tasks.R :
Functions.R :
ici.R :
mse_feature_effects.R :
PipeOpCalibration_TuningExperiment.R :
PipeOpCalibration.R :
PipeOpCalibrationUnion.R :
### [bt]: Memory measurement disabled
### [bt]: Starting job [batchtools job.id=1416]
### [bt]: Generating problem instance for problem '341ee781c7d79b8f' ...
### [bt]: Applying algorithm 'run_learner' on problem '341ee781c7d79b8f' for job 1416 (seed = 1539) ...
INFO  [16:05:59.026] [mlr3] Applying learner 'xgboost TwP beta' on task 'wdbc' (iter 6/10)
INFO  [16:06:00.227] [bbotk] Starting to optimize 8 parameter(s) with '<OptimizerMbo>' and '<TerminatorEvals> [n_evals=100, k=0]'
INFO  [16:06:11.541] [bbotk] Evaluating 32 configuration(s)
INFO  [16:06:12.241] [mlr3] Running benchmark with 96 resampling iterations
INFO  [16:06:12.543] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -46.29162
[1] 34.7097
[1] -332.3411
[1] -3.779425
[1] -7781.81
[1] -197.6392
[1] -193.5692
[1] 42.30473
[1] -46.7654
[1] 81.10301
INFO  [16:07:37.689] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -25047.27
[1] -954.3409
[1] -1844.763
[1] -51.29554
[1] -36.60334
[1] 33.41173
[1] -96.4113
[1] 7.026981
[1] -114.9531
[1] 21.99444
INFO  [16:08:16.937] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -5676.396
[1] -164.1141
[1] -47.40523
[1] 76.41238
[1] -20.31307
[1] 40.85588
[1] -42.08613
[1] 91.93997
[1] -75.82
[1] 14.22082
INFO  [16:08:58.101] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1617.594
[1] -25.50759
[1] -702.4593
[1] -9.330962
[1] -269.736
[1] 216.3087
[1] -278.3903
[1] 64.76603
[1] -182.5036
[1] 167.0167
INFO  [16:10:07.404] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -450.4013
[1] -6.16437
[1] -4505.218
[1] -82.53944
[1] -243.6254
[1] 209.9294
[1] 7.839493
[1] 322.9586
[1] 9.659095
[1] 446.2219
INFO  [16:11:04.352] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -306.3367
[1] 37.77726
[1] -441.625
[1] -8.679098
[1] -240.6264
[1] 221.9676
[1] -427.7053
[1] 35.3004
[1] -655.9585
[1] -9.079788
INFO  [16:12:21.629] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:13:08.484] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:13:45.716] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:14:17.827] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 18.17298
[1] 839.3691
[1] -769.3841
[1] -13.23637
[1] 29.99371
[1] 1651.351
[1] -340502.2
[1] -7040.083
[1] -155.9966
[1] 471.156
INFO  [16:15:20.829] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -920.5958
[1] -15.37127
[1] 11.56363
[1] 539.207
[1] -698.6998
[1] -12.47894
[1] -1619.405
[1] -27.78908
[1] 16.79722
[1] 815.9134
INFO  [16:16:09.170] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1673.169
[1] 63.13884
[1] -723.1643
[1] -13.48179
[1] -648.1512
[1] 66.12324
[1] 12.09987
[1] 574.8739
[1] -881.7209
[1] 126.1373
INFO  [16:17:16.597] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -511.9888
[1] -9.638064
[1] -33744.75
[1] -604.8938
[1] -1120.742
[1] -18.57478
[1] -204.948
[1] 587.5384
[1] -1620.102
[1] -30.40734
INFO  [16:18:03.453] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -608.5456
[1] -11.72164
[1] -778.7563
[1] -14.1285
[1] 19.11845
[1] 1047.049
[1] -175.1764
[1] 451.0848
[1] 17.34214
[1] 867.5613
INFO  [16:19:08.819] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -711.6567
[1] -13.66113
[1] 12.36931
[1] 615.1722
[1] -766.187
[1] -13.97392
[1] -574.5133
[1] 28.43417
[1] -313.905
[1] 494.7669
INFO  [16:19:53.990] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -30.97712
[1] 215.296
[1] -32.28595
[1] 18.11162
[1] -25.10117
[1] 70.1773
[1] -177.1153
[1] 2.550688
[1] -61.693
[1] 29.50133
INFO  [16:21:08.853] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -165.1234
[1] 39.42927
[1] -75.21543
[1] 0.9468505
[1] -119.9923
[1] 1.124173
[1] -5146.797
[1] -82.38648
[1] -48.56215
[1] 37.68626
INFO  [16:22:31.627] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -49.03103
[1] 41.6892
[1] -442.5736
[1] -4.115566
[1] -76.43048
[1] 16.92088
[1] -56.39516
[1] 38.48912
[1] -34.67661
[1] 32.14379
INFO  [16:23:44.293] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -371.7584
[1] 327.2185
[1] -747.8836
[1] -12.91302
[1] -1252.053
[1] -22.76616
[1] -856.755
[1] -13.43761
[1] 17.40771
[1] 800.7885
INFO  [16:24:23.123] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -334.4917
[1] 166.2617
[1] -383.2643
[1] 264.9495
[1] 29.92694
[1] 1362.824
[1] -867.6162
[1] -14.30317
[1] -167564.2
[1] -3321.642
INFO  [16:25:08.104] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 18.42604
[1] 962.7773
[1] -1627.091
[1] -28.39482
[1] -400.7973
[1] 148.7252
[1] -845.0747
[1] -14.23455
[1] -214.2697
[1] 384.89
INFO  [16:25:42.914] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:26:24.496] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:27:04.255] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:28:04.527] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:29:10.152] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:30:29.963] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:31:09.070] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -95.33071
[1] 108.4543
[1] -185.8164
[1] 192.1072
[1] -168.067
[1] 37.39951
[1] -117.6628
[1] 101.0989
[1] -182.9205
[1] -4.629146
INFO  [16:31:55.697] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -140.5555
[1] 66.50948
[1] -383.6542
[1] -5.932913
[1] -142.2221
[1] 82.20909
[1] -185.9562
[1] 33.0881
[1] -1.916407
[1] 542.3831
INFO  [16:32:51.164] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -266.0261
[1] 56.15414
[1] -231.3882
[1] -5.448769
[1] -119.542
[1] 117.4912
[1] 694.2302
[1] 19224.07
[1] -192.8384
[1] -4.771493
INFO  [16:33:38.300] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -14.24109
[1] 22.86037
[1] -25.98428
[1] 16.72006
[1] -39.18244
[1] 21.43403
[1] -21.79056
[1] 7.790815
[1] -7.954819
[1] 50.29311
INFO  [16:34:28.003] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -48.07462
[1] 403.7861
[1] -29.46063
[1] 16.38655
[1] -119.1996
[1] 19.28846
[1] -20.12053
[1] 46.42924
[1] -15.96153
[1] 32.62242
INFO  [16:35:11.268] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -85.66444
[1] -3.31908
[1] -11.25485
[1] 12.96185
[1] -72.68236
[1] 24.97253
[1] -34.37749
[1] 15.98624
[1] -23.39155
[1] 78.90924
INFO  [16:35:56.416] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -152.5616
[1] 421.432
[1] -454.7075
[1] -9.658095
[1] -420.9314
[1] -6.652063
[1] -284.5944
[1] 271.0425
[1] 7.920555
[1] 398.0631
INFO  [16:36:20.000] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -506.1163
[1] -10.203
[1] -8.009155
[1] 397.803
[1] -1034.845
[1] 12.08297
[1] -118.8565
[1] 289.2983
[1] -451.3753
[1] -8.569375
INFO  [16:36:47.519] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -364.9089
[1] 51.73932
[1] -454.6603
[1] -8.315898
[1] -548.1291
[1] -10.13221
[1] -856.2681
[1] -15.5273
[1] -139.3648
[1] 213.6478
INFO  [16:37:09.956] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:37:42.688] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:38:26.654] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:39:10.132] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -128.8952
[1] 60.78345
[1] -147.1174
[1] 126.3318
[1] -83.61841
[1] 230.3142
[1] -123.8155
[1] 180.4785
[1] -211.821
[1] 40.42046
INFO  [16:40:46.417] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -155.9696
[1] 2.485466
[1] -123133.6
[1] -2216.322
[1] -112.7618
[1] 159.4324
[1] 1587.007
[1] 65729.23
[1] -183.2073
[1] 68.61149
INFO  [16:42:57.422] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -9598.746
[1] -259.8929
[1] -242.5727
[1] -4.976177
[1] -269.1264
[1] 79.1364
[1] 1.568434
[1] 206.7763
[1] -180.46
[1] -4.531582
INFO  [16:44:23.091] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -41.28141
[1] 7.856448
[1] -59.77486
[1] 42.6423
[1] -67.41807
[1] 94.66959
[1] -25.8475
[1] 72.66205
[1] -37.69142
[1] 46.3155
INFO  [16:44:54.724] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -62.61091
[1] 60.89825
[1] -31.57443
[1] 25.83505
[1] -60.92441
[1] 7.685928
[1] -7924.233
[1] -346.2863
[1] -28.75793
[1] 27.96599
INFO  [16:45:22.889] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -11.89158
[1] 110.275
[1] -26.93552
[1] 14.91437
[1] -27.92579
[1] 33.66774
[1] -26.17291
[1] 23.17764
[1] -44.4672
[1] 15.89443
INFO  [16:45:50.671] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 4.241194
[1] 234.1907
[1] -196.8844
[1] 162.3608
[1] 1221.909
[1] 50520.67
[1] -292.1631
[1] -5.215696
[1] -10789.69
[1] -213.3948
INFO  [16:46:43.532] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -35.06894
[1] 428.1369
[1] -149.5995
[1] 266.7485
[1] -446.6532
[1] 70.21689
[1] -188.7452
[1] 75.18381
[1] -46.0291
[1] 199.9228
INFO  [16:47:21.664] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 362.2483
[1] 13452.92
[1] -219.3145
[1] 125.3991
[1] -369.4283
[1] 14.04098
[1] -304.3266
[1] 4.060957
[1] -536.7121
[1] -6.053526
INFO  [16:48:19.576] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 828.5785
[1] 40924.1
[1] -313.7082
[1] 58.19565
[1] 829.8056
[1] 45733.12
[1] -453.4255
[1] -8.526957
[1] -273.7078
[1] 139.5049
INFO  [16:48:42.889] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -95.71417
[1] 315.1212
[1] -547.3165
[1] -10.27369
[1] -363.4863
[1] -7.69583
[1] -120.0874
[1] 441.2878
[1] 21.57006
[1] 1017.643
INFO  [16:49:08.466] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 26.21637
[1] 1527.817
[1] -241.1391
[1] 125.3669
[1] -454.6391
[1] -7.756206
[1] -202.8898
[1] 301.8567
[1] -66.24577
[1] 384.5105
INFO  [16:49:27.206] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 5.00835
[1] 174.717
[1] -45.60474
[1] 143.8881
[1] -360.7717
[1] -5.031743
[1] -37.70996
[1] 1350.402
[1] -198.2876
[1] -4.382826
INFO  [16:50:30.756] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -239.7412
[1] -4.775841
[1] -59.45895
[1] 103.6935
[1] -62.27465
[1] 194.8198
[1] -189.9625
[1] 32.84613
[1] -162.2179
[1] 12.71126
INFO  [16:51:13.774] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -43.68481
[1] 349.3548
[1] -86.47734
[1] 184.35
[1] -62.14212
[1] 62.09896
[1] -211.9005
[1] 24.02437
[1] -203.2191
[1] -4.768993
INFO  [16:52:19.922] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -35.56173
[1] 156.1168
[1] -304.1746
[1] -3.581258
[1] -345.6499
[1] 15.59311
[1] -1966.712
[1] -157.7803
[1] -249.6019
[1] -3.986197
INFO  [16:53:45.605] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -36.48286
[1] 31.02412
[1] -1825.787
[1] -53.80367
[1] -90.20594
[1] 12.4438
[1] -23.22519
[1] 41.1891
[1] -7338.781
[1] -123.2156
INFO  [16:54:56.860] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -45.67656
[1] 36.2666
[1] -329.7012
[1] -3.072627
[1] -26.21834
[1] 32.71768
[1] -72.67344
[1] 33.73422
[1] -25.90684
[1] 23.35653
INFO  [16:55:59.948] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:56:31.147] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:57:13.226] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:57:45.275] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -69.93823
[1] 97.0188
[1] -120.0711
[1] -3.692823
[1] -83.15337
[1] 201.2259
[1] -46.51202
[1] 45.23509
[1] -90.92112
[1] 29.2689
INFO  [16:58:13.735] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -72.37182
[1] 26.35506
[1] -79.74225
[1] 17.85245
[1] -1494.772
[1] 90.17155
[1] -177.5021
[1] 30.68451
[1] -73.1279
[1] 36.84566
INFO  [16:58:44.172] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -3727.935
[1] -93.04691
[1] -82.0977
[1] 30.54927
[1] -52.6578
[1] 40.46511
[1] -27.1428
[1] 39.08997
[1] -75.29898
[1] 9.724715
INFO  [16:59:23.494] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -3631.805
[1] -99.54047
[1] -1318.302
[1] -40.42735
[1] -50.49652
[1] 19.7719
[1] -179.7887
[1] 4.99931
[1] -65.04681
[1] 59.81911
INFO  [17:00:30.770] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -36.70236
[1] 56.96911
[1] -1188.598
[1] -30.60022
[1] -124.3984
[1] 7.033007
[1] -49.8065
[1] 22.37169
[1] -62.35683
[1] 25.07409
INFO  [17:01:18.520] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -211.9234
[1] -3.833979
[1] -26.33042
[1] 41.86015
[1] -48.67345
[1] 29.49938
[1] -26.55051
[1] 285.528
[1] -54.47039
[1] 24.76101
INFO  [17:02:09.743] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 47217.58
[1] 2556729
[1] 50733.18
[1] 2746968
[1] -3311510
[1] -61150.92
[1] -1293736
[1] -23889.08
INFO  [17:03:41.311] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 399231.9
[1] 21618659
[1] -320286.1
[1] -5908.96
[1] 25451.63
[1] 1378144
[1] -306074.9
[1] -5648.551
[1] 17284.18
[1] 935749.6
INFO  [17:04:36.832] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1450390
[1] -26781.77
[1] -1230133
[1] -22713.69
[1] 3016.028
[1] 163108.9
[1] 146362.3
[1] 7925504
INFO  [17:05:34.194] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -3247.324
[1] -110.4755
[1] -971.6702
[1] -29.43766
[1] -98.07481
[1] 17.05845
[1] -60.8373
[1] 48.11151
[1] -196.3911
[1] -3.558096
INFO  [17:06:17.035] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -87.2392
[1] 15.68391
[1] -874.0701
[1] -31.62713
[1] -5854.225
[1] -126.1341
[1] -34.62264
[1] 42.67398
[1] -126.1262
[1] 9.371581
INFO  [17:06:56.784] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -164.9787
[1] -4.179243
[1] -58.0208
[1] 62.21078
[1] -139.7899
[1] -4.115386
[1] -37.95107
[1] 47.00134
[1] -11.90917
[1] 114.7509
INFO  [17:07:36.867] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -22.3203
[1] 32.79087
[1] -147.0174
[1] 8.006421
[1] 289.0342
[1] 8204.791
[1] -70.14679
[1] 14.5381
[1] -2731.596
[1] -52.32735
INFO  [17:08:02.587] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -328.4986
[1] 14.91899
[1] -31.53814
[1] 38.0256
[1] -55.83131
[1] 21.79066
[1] -96.83514
[1] 124.7409
[1] -79.25452
[1] 33.6626
INFO  [17:08:38.436] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -3575.172
[1] -82.52442
[1] -105.3937
[1] 33.58114
[1] -48.96465
[1] 14.5911
[1] -35.18494
[1] 61.61252
[1] -27.30662
[1] 49.41279
INFO  [17:09:07.662] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:10:05.166] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:11:00.062] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:11:47.871] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 57.64135
[1] 3051.079
[1] -4495.328
[1] -84.49292
[1] -4424.414
[1] -80.7768
[1] -2709.565
[1] -49.42426
[1] 57.45148
[1] 3011.651
INFO  [17:13:34.828] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -3528.429
[1] -63.50439
[1] 66.40681
[1] 3486.294
[1] -2916.422
[1] -53.17047
[1] -2808.438
[1] -51.22616
[1] -2905.746
[1] -53.24166
INFO  [17:15:27.847] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -3157.808
[1] -57.90748
[1] -2385.558
[1] -44.13348
[1] 77.8812
[1] 4136.51
[1] -2955.445
[1] -54.6556
[1] -3440.444
[1] -61.80329
INFO  [17:16:26.436] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 37.93059
[1] 1799.491
[1] -3321.957
[1] -54.14115
[1] 41.55882
[1] 2054.593
[1] 556.0336
[1] 27197.77
[1] -1583.248
[1] -25.83903
INFO  [17:16:59.610] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 18.90569
[1] 884.9051
[1] 31.88682
[1] 1494.226
[1] 39.34012
[1] 1854.427
[1] 1468.88
[1] 66591.21
[1] 39.70578
[1] 1950.471
INFO  [17:17:28.485] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 53.91013
[1] 2574.111
[1] -3095.615
[1] -48.05064
[1] -108.5139
[1] 1302.379
[1] 27.62885
[1] 1314.919
[1] -645.3415
[1] 1127.959
INFO  [17:18:00.140] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -32.09092
[1] 32.28582
[1] 541.4796
[1] 7915.689
[1] -7328.65
[1] -138.397
[1] -72.14178
[1] -3.204533
[1] -451.6951
[1] 31.4778
INFO  [17:18:43.824] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 6.120154
[1] 209.7398
[1] -61.60471
[1] 63.47408
[1] -3267.521
[1] -63.64519
[1] -127.9087
[1] 4.636174
[1] -26.16019
[1] 47.77113
INFO  [17:19:37.035] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -39.93971
[1] 37.53986
[1] -55.03714
[1] 14.6213
[1] -25.70222
[1] 27.55644
[1] -91.0187
[1] 72.12951
[1] -57.97856
[1] 6.837617
INFO  [17:20:21.106] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:20:52.138] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:21:25.545] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:21:47.430] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1456.552
[1] -27.23105
[1] -1381.838
[1] -24.78081
[1] 60.96578
[1] 3228.792
[1] 40.11364
[1] 2061.286
[1] 32.64734
[1] 1663.629
INFO  [17:22:26.592] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1857.345
[1] -32.53479
[1] -1886.85
[1] -32.55322
[1] -1489.745
[1] -27.40073
[1] 29.73256
[1] 1523.9
[1] -422.6607
[1] 974.8709
INFO  [17:22:51.752] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1515.742
[1] -26.76696
[1] -17086
[1] -306.2288
[1] 23.12818
[1] 1203.021
[1] 55.1025
[1] 2948.453
[1] -1470.6
[1] -25.63979
INFO  [17:23:32.637] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -54.66927
[1] 95.3581
[1] -78.35383
[1] 47.00893
[1] -189.0156
[1] 61.11735
[1] -108.5693
[1] 16.99739
[1] -209.0608
[1] -3.882242
INFO  [17:24:27.473] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -152.0916
[1] -0.8217022
[1] -92.032
[1] 61.99263
[1] -74.70965
[1] 52.68592
[1] -269.8277
[1] 17.90024
[1] -150.5011
[1] 4.441743
INFO  [17:25:08.491] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -32.72796
[1] 111.9562
[1] -67.89916
[1] 45.69951
[1] -89.07467
[1] -0.8305476
[1] -26.68373
[1] 69.35999
[1] -85.39878
[1] 26.97942
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:25:55.928] [mlr3] Finished benchmark
INFO  [17:25:57.141] [bbotk] Result of batch 1:
INFO  [17:25:57.200] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:25:57.200] [bbotk]            -5.08563955                         0.6807227
INFO  [17:25:57.200] [bbotk]             1.82211614                         0.2307227
INFO  [17:25:57.200] [bbotk]             5.27599378                         0.9057227
INFO  [17:25:57.200] [bbotk]            -1.63176191                         0.4557227
INFO  [17:25:57.200] [bbotk]             0.09517732                         0.5682227
INFO  [17:25:57.200] [bbotk]            -6.81257833                         0.1182227
INFO  [17:25:57.200] [bbotk]            -3.35870073                         0.7932227
INFO  [17:25:57.200] [bbotk]             3.54905496                         0.3432227
INFO  [17:25:57.200] [bbotk]             6.13946319                         0.1744727
INFO  [17:25:57.200] [bbotk]            -0.76829250                         0.6244727
INFO  [17:25:57.200] [bbotk]            -4.22217014                         0.3994727
INFO  [17:25:57.200] [bbotk]             2.68558555                         0.8494727
INFO  [17:25:57.200] [bbotk]             4.41252437                         0.7369727
INFO  [17:25:57.200] [bbotk]            -2.49523132                         0.2869727
INFO  [17:25:57.200] [bbotk]            -5.94910896                         0.9619727
INFO  [17:25:57.200] [bbotk]             0.95864673                         0.5119727
INFO  [17:25:57.200] [bbotk]            -4.65390484                         0.2588477
INFO  [17:25:57.200] [bbotk]             2.25385085                         0.7088477
INFO  [17:25:57.200] [bbotk]            -1.20002720                         0.9338477
INFO  [17:25:57.200] [bbotk]             5.70772849                         0.4838477
INFO  [17:25:57.200] [bbotk]             0.52691203                         0.1463477
INFO  [17:25:57.200] [bbotk]            -6.38084361                         0.5963477
INFO  [17:25:57.200] [bbotk]             3.98078967                         0.8213477
INFO  [17:25:57.200] [bbotk]            -2.92696602                         0.3713477
INFO  [17:25:57.200] [bbotk]            -0.33655779                         0.2025977
INFO  [17:25:57.200] [bbotk]             6.57119790                         0.6525977
INFO  [17:25:57.200] [bbotk]            -3.79043543                         0.8775977
INFO  [17:25:57.200] [bbotk]             3.11732026                         0.4275977
INFO  [17:25:57.200] [bbotk]            -2.06349661                         0.7650977
INFO  [17:25:57.200] [bbotk]             4.84425908                         0.3150977
INFO  [17:25:57.200] [bbotk]            -5.51737425                         0.5400977
INFO  [17:25:57.200] [bbotk]             1.39038144                         0.9900977
INFO  [17:25:57.200] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:25:57.200] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:25:57.200] [bbotk]                         0.7301730          -3.0950051              2.2695412
INFO  [17:25:57.200] [bbotk]                         0.2801731          -7.7001755             -4.6382139
INFO  [17:25:57.200] [bbotk]                         0.9551730          -0.7924200             -1.1843364
INFO  [17:25:57.200] [bbotk]                         0.5051730          -5.3975905              5.7234189
INFO  [17:25:57.200] [bbotk]                         0.3926730          -8.8514680             -6.3651527
INFO  [17:25:57.200] [bbotk]                         0.8426730          -4.2462976              0.5426024
INFO  [17:25:57.200] [bbotk]                         0.1676731          -6.5488830              3.9964800
INFO  [17:25:57.200] [bbotk]                         0.6176730          -1.9437125             -2.9112752
INFO  [17:25:57.200] [bbotk]                         0.4489230          -2.5193588              4.8599494
INFO  [17:25:57.200] [bbotk]                         0.8989230          -7.1245293             -2.0478058
INFO  [17:25:57.200] [bbotk]                         0.2239231          -0.2167737             -5.5016833
INFO  [17:25:57.200] [bbotk]                         0.6739230          -4.8219442              1.4060718
INFO  [17:25:57.200] [bbotk]                         0.1114231          -3.6706514              6.5868883
INFO  [17:25:57.200] [bbotk]                         0.5614230          -8.2758217             -0.3208670
INFO  [17:25:57.200] [bbotk]                         0.3364230          -1.3680663             -3.7747444
INFO  [17:25:57.200] [bbotk]                         0.7864230          -5.9732367              3.1330106
INFO  [17:25:57.200] [bbotk]                         0.4207980          -6.2610599             -2.4795405
INFO  [17:25:57.200] [bbotk]                         0.8707980          -1.6558894              4.4282147
INFO  [17:25:57.200] [bbotk]                         0.6457980          -3.9584745             -5.9334180
INFO  [17:25:57.200] [bbotk]                         0.1957981          -8.5636449              0.9743371
INFO  [17:25:57.200] [bbotk]                         0.7582980          -0.5045969              6.1551536
INFO  [17:25:57.200] [bbotk]                         0.3082981          -5.1097673             -0.7526017
INFO  [17:25:57.200] [bbotk]                         0.5332980          -7.4123524              2.7012759
INFO  [17:25:57.200] [bbotk]                         0.9832980          -2.8071819             -4.2064791
INFO  [17:25:57.200] [bbotk]                         0.1395481          -2.2315357              1.8378065
INFO  [17:25:57.200] [bbotk]                         0.5895480          -6.8367061             -5.0699486
INFO  [17:25:57.200] [bbotk]                         0.8145480          -9.1392912              5.2916842
INFO  [17:25:57.200] [bbotk]                         0.3645480          -4.5341208             -1.6160711
INFO  [17:25:57.200] [bbotk]                         0.4770480          -1.0802431              0.1108677
INFO  [17:25:57.200] [bbotk]                         0.9270480          -5.6854136             -6.7968874
INFO  [17:25:57.200] [bbotk]                         0.7020480          -7.9879987              3.5647453
INFO  [17:25:57.200] [bbotk]                         0.2520481          -3.3828282             -3.3430099
INFO  [17:25:57.200] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:25:57.200] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:25:57.200] [bbotk]                         11                    1672                 0.4428033
INFO  [17:25:57.200] [bbotk]                          1                    4172                 0.8928033
INFO  [17:25:57.200] [bbotk]                          6                     422                 0.6678033
INFO  [17:25:57.200] [bbotk]                         16                    2922                 0.2178033
INFO  [17:25:57.200] [bbotk]                          8                    2297                 0.3303033
INFO  [17:25:57.200] [bbotk]                         18                    4797                 0.7803033
INFO  [17:25:57.200] [bbotk]                         13                    1047                 0.5553033
INFO  [17:25:57.200] [bbotk]                          3                    3547                 0.1053033
INFO  [17:25:57.200] [bbotk]                          9                    3859                 0.9490533
INFO  [17:25:57.200] [bbotk]                         19                    1359                 0.4990533
INFO  [17:25:57.200] [bbotk]                         14                    2609                 0.2740533
INFO  [17:25:57.200] [bbotk]                          4                     109                 0.7240533
INFO  [17:25:57.200] [bbotk]                          2                    1984                 0.3865533
INFO  [17:25:57.200] [bbotk]                         12                    4484                 0.8365533
INFO  [17:25:57.200] [bbotk]                         17                     734                 0.6115533
INFO  [17:25:57.200] [bbotk]                          7                    3234                 0.1615533
INFO  [17:25:57.200] [bbotk]                          6                     265                 0.9209283
INFO  [17:25:57.200] [bbotk]                         16                    2765                 0.4709283
INFO  [17:25:57.200] [bbotk]                          1                    4015                 0.6959283
INFO  [17:25:57.200] [bbotk]                         11                    1515                 0.2459283
INFO  [17:25:57.200] [bbotk]                         14                     890                 0.8084283
INFO  [17:25:57.200] [bbotk]                          4                    3390                 0.3584283
INFO  [17:25:57.200] [bbotk]                         19                    4640                 0.5834283
INFO  [17:25:57.200] [bbotk]                          9                    2140                 0.1334283
INFO  [17:25:57.200] [bbotk]                          5                     578                 0.9771783
INFO  [17:25:57.200] [bbotk]                         15                    3078                 0.5271783
INFO  [17:25:57.200] [bbotk]                         10                    4328                 0.7521783
INFO  [17:25:57.200] [bbotk]                         20                    1828                 0.3021783
INFO  [17:25:57.200] [bbotk]                          7                    3703                 0.4146783
INFO  [17:25:57.200] [bbotk]                         17                    1203                 0.8646783
INFO  [17:25:57.200] [bbotk]                          2                    2453                 0.1896783
INFO  [17:25:57.200] [bbotk]                         12                    4953                 0.6396783
INFO  [17:25:57.200] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:25:57.200] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:25:57.200] [bbotk]      0.02659323        0      0          164.935
INFO  [17:25:57.200] [bbotk]      0.09401286        0      0          202.887
INFO  [17:25:57.200] [bbotk]      0.24573754        0      0          115.300
INFO  [17:25:57.200] [bbotk]      0.17674757        0      0          178.362
INFO  [17:25:57.200] [bbotk]      0.15113515        0      0          156.401
INFO  [17:25:57.200] [bbotk]      0.02482222        0      0          230.094
INFO  [17:25:57.200] [bbotk]      0.16959970        0      0          118.370
INFO  [17:25:57.200] [bbotk]      0.24573754        0      0          140.765
INFO  [17:25:57.200] [bbotk]      0.24573754        0      0          183.391
INFO  [17:25:57.200] [bbotk]      0.05859689        0      0          148.250
INFO  [17:25:57.200] [bbotk]      0.03193273        0      0          136.964
INFO  [17:25:57.200] [bbotk]      0.11859172        0      0           73.118
INFO  [17:25:57.200] [bbotk]      0.24573754        0      0          119.740
INFO  [17:25:57.200] [bbotk]      0.05795222        0      0          312.650
INFO  [17:25:57.200] [bbotk]      0.02498077        0      0           86.502
INFO  [17:25:57.200] [bbotk]      0.07576921        0      0          148.580
INFO  [17:25:57.200] [bbotk]      0.10318984        0      0           67.184
INFO  [17:25:57.200] [bbotk]      0.04524605        0      0          172.380
INFO  [17:25:57.200] [bbotk]      0.02277392        0      0          218.819
INFO  [17:25:57.200] [bbotk]      0.24573754        0      0          104.071
INFO  [17:25:57.200] [bbotk]      0.02864483        0      0           97.900
INFO  [17:25:57.200] [bbotk]      0.02488173        0      0          165.764
INFO  [17:25:57.200] [bbotk]      0.24568801        0      0          203.302
INFO  [17:25:57.200] [bbotk]      0.02676357        0      0          121.446
INFO  [17:25:57.200] [bbotk]      0.02692709        0      0           89.270
INFO  [17:25:57.200] [bbotk]      0.24573754        0      0          159.154
INFO  [17:25:57.200] [bbotk]      0.23191829        0      0          277.901
INFO  [17:25:57.200] [bbotk]      0.21207704        0      0           93.361
INFO  [17:25:57.200] [bbotk]      0.02624591        0      0          140.484
INFO  [17:25:57.200] [bbotk]      0.24573754        0      0           85.740
INFO  [17:25:57.200] [bbotk]      0.21387389        0      0          104.968
INFO  [17:25:57.200] [bbotk]      0.03005727        0      0          133.641
INFO  [17:25:57.200] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:25:57.200] [bbotk]                                 uhash
INFO  [17:25:57.200] [bbotk]  66ea0fa7-1e61-4343-b097-21f7cc2b21ee
INFO  [17:25:57.200] [bbotk]  0a5961cd-f03c-42e9-a169-5e1a1091f59a
INFO  [17:25:57.200] [bbotk]  ac5958b3-7477-489d-93c3-a972921426c5
INFO  [17:25:57.200] [bbotk]  4e10eed9-afdd-4b14-99fa-2b0cf7055ed1
INFO  [17:25:57.200] [bbotk]  221ca2c6-9048-490b-ac58-4d7d8adbceae
INFO  [17:25:57.200] [bbotk]  ad14906f-d6f2-447b-814c-0645cf16c676
INFO  [17:25:57.200] [bbotk]  0ae300cd-2776-45f9-8da0-92639c99f352
INFO  [17:25:57.200] [bbotk]  db483d1f-a365-4f39-b401-a9ec44fedae3
INFO  [17:25:57.200] [bbotk]  d3b6de9d-8870-4b82-8f5b-cfdc17815402
INFO  [17:25:57.200] [bbotk]  4a95acc3-daf0-436b-b054-8c22eb32e2bb
INFO  [17:25:57.200] [bbotk]  37f39bda-20aa-4383-945e-ebf3cb6db599
INFO  [17:25:57.200] [bbotk]  12dfdd1e-4bd7-4d40-872e-1710e0edf7b6
INFO  [17:25:57.200] [bbotk]  8caf88f5-97dd-4ab9-8bc6-849f44c977a3
INFO  [17:25:57.200] [bbotk]  52b62c7f-c3c4-46da-98ee-e59c39ad64f4
INFO  [17:25:57.200] [bbotk]  9a4d4392-b224-45be-8a29-191678eef903
INFO  [17:25:57.200] [bbotk]  461d0d45-4b8a-4b4a-888c-281b7c8274c0
INFO  [17:25:57.200] [bbotk]  ed80492f-c954-4a2d-a650-399d3badc021
INFO  [17:25:57.200] [bbotk]  50d18e04-8475-4810-801f-e8ddfa5fb96e
INFO  [17:25:57.200] [bbotk]  b0504794-ac07-4282-993f-6823bf5a6b9f
INFO  [17:25:57.200] [bbotk]  b0f36e7f-d58a-4f85-8e3e-6d1f40d149de
INFO  [17:25:57.200] [bbotk]  99246588-e6a9-4509-b662-ecbf997dddcc
INFO  [17:25:57.200] [bbotk]  159546c3-b0e8-4ffe-a16c-47ee110a5842
INFO  [17:25:57.200] [bbotk]  80c385e9-5fb6-4af4-9998-7319a9665f72
INFO  [17:25:57.200] [bbotk]  326e9f15-c1de-41b7-9b49-50134ffd803b
INFO  [17:25:57.200] [bbotk]  901d434e-09b1-490a-9083-bff8829cbd71
INFO  [17:25:57.200] [bbotk]  d5116241-16af-48eb-92aa-489265f48d7d
INFO  [17:25:57.200] [bbotk]  a9ead3b3-f81d-4633-8939-62abe8644bbc
INFO  [17:25:57.200] [bbotk]  6475354a-8508-41df-ae61-531f8ec8bbd4
INFO  [17:25:57.200] [bbotk]  c4ba30c0-534d-47be-ae9e-276d6fd29a64
INFO  [17:25:57.200] [bbotk]  f2546654-7217-4f76-a79d-620cb241c916
INFO  [17:25:57.200] [bbotk]  608a56f9-c760-4d4d-9123-ce035acacc8c
INFO  [17:25:57.200] [bbotk]  c42a2260-9bf5-4068-91f3-64d3dbedccdc
INFO  [17:25:57.200] [bbotk]                                 uhash
INFO  [17:26:04.308] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 32 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:26:12.886] [bbotk] Evaluating 1 configuration(s)
INFO  [17:26:13.043] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:26:13.127] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -45.18939
[1] 47.46652
[1] -93.12286
[1] 6.924723
[1] -99.93493
[1] -4.03523
[1] -104.0669
[1] 72.31483
[1] 282.4179
[1] 8215.723
INFO  [17:27:03.661] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -34.4121
[1] 40.04938
[1] -74.30744
[1] 15.29534
[1] -32429.33
[1] -764.9166
[1] -104.2433
[1] -4.059037
[1] -121.7724
[1] 0.3293976
INFO  [17:27:57.149] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -134.7855
[1] 17.44452
[1] -81.32305
[1] 28.06433
[1] -23.84584
[1] 48.98676
[1] -40.5871
[1] 41.60246
[1] -37.11428
[1] 184.3524
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:28:40.784] [mlr3] Finished benchmark
INFO  [17:28:40.986] [bbotk] Result of batch 2:
INFO  [17:28:41.043] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:28:41.043] [bbotk]              0.4939731                           0.64081
INFO  [17:28:41.043] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:28:41.043] [bbotk]                         0.6322502           -2.101045             -0.7124665
INFO  [17:28:41.043] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:28:41.043] [bbotk]                          6                    4661                 0.9011062
INFO  [17:28:41.043] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:28:41.043] [bbotk]  0.04424466 <list[8]>              FALSE     0.02657897        0      0
INFO  [17:28:41.043] [bbotk]  runtime_learners                                uhash
INFO  [17:28:41.043] [bbotk]           147.021 63954537-732f-4cee-b433-6a85383809d8
INFO  [17:28:41.757] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 33 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:28:46.290] [bbotk] Evaluating 1 configuration(s)
INFO  [17:28:46.375] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:28:46.581] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -38.50577
[1] 41.97408
[1] -1907.236
[1] -37.27408
[1] -98.22077
[1] -4.089781
[1] -29.33914
[1] 24.31195
[1] -96.26787
[1] -2.230811
INFO  [17:29:27.311] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -67.34938
[1] 18.53418
[1] -58.65634
[1] 37.13287
[1] -48.46988
[1] 82.50722
[1] -39.00933
[1] 19.27274
[1] -7016.513
[1] -284.3511
INFO  [17:30:12.189] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -27.13942
[1] 26.37784
[1] 72.78379
[1] 1367.997
[1] -59.80727
[1] 9.811257
[1] -4249.461
[1] -155.9972
[1] -137.0656
[1] 10.65482
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:31:02.053] [mlr3] Finished benchmark
INFO  [17:31:02.173] [bbotk] Result of batch 3:
INFO  [17:31:02.190] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:31:02.190] [bbotk]              -5.473485                         0.3936502
INFO  [17:31:02.190] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:31:02.190] [bbotk]                         0.7692772           -1.848482             -0.7677998
INFO  [17:31:02.190] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:31:02.190] [bbotk]                          6                    3985                  0.558736
INFO  [17:31:02.190] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:31:02.190] [bbotk]  0.03659588 <list[8]>              FALSE     0.02279075        0      0
INFO  [17:31:02.190] [bbotk]  runtime_learners                                uhash
INFO  [17:31:02.190] [bbotk]           134.336 839b5d70-481f-42e1-991d-ab2bc3e19c95
INFO  [17:31:03.259] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 34 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:31:08.351] [bbotk] Evaluating 1 configuration(s)
INFO  [17:31:08.667] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:31:08.883] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -54.04183
[1] 39.28591
[1] -1991.816
[1] -53.02554
[1] -108.3618
[1] 9.120559
[1] -223.7976
[1] 6.789382
[1] 31.37178
[1] 718.6434
INFO  [17:31:35.279] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1223.338
[1] -56.73547
[1] -147.2905
[1] 59.40913
[1] -34.49447
[1] 40.9102
[1] -33.2884
[1] 27.21554
[1] -79.27062
[1] 20.18117
INFO  [17:32:07.465] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -38.32991
[1] 34.05191
[1] -35.04215
[1] 28.62744
[1] -193.8343
[1] 25.66068
[1] -50.08793
[1] 2.90664
[1] -625.962
[1] 4.177582
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:32:51.066] [mlr3] Finished benchmark
INFO  [17:32:51.221] [bbotk] Result of batch 4:
INFO  [17:32:51.258] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:32:51.258] [bbotk]              -1.973731                         0.7769126
INFO  [17:32:51.258] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:32:51.258] [bbotk]                         0.3244114           -3.352108              -3.022006
INFO  [17:32:51.258] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:32:51.258] [bbotk]                         14                    3925                 0.5959901
INFO  [17:32:51.258] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:32:51.258] [bbotk]  0.03181275 <list[8]>              FALSE     0.02174124        0      0
INFO  [17:32:51.258] [bbotk]  runtime_learners                                uhash
INFO  [17:32:51.258] [bbotk]            101.08 181fe58a-a05f-46d3-b8c5-7b32b57c856a
INFO  [17:32:51.969] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 35 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:33:01.293] [bbotk] Evaluating 1 configuration(s)
INFO  [17:33:01.635] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:33:01.961] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -48.53889
[1] 18.55337
[1] -73.82371
[1] 36.53705
[1] -136.1637
[1] -3.929698
[1] -35.65967
[1] 115.7106
[1] 41.37798
[1] 889.3254
INFO  [17:33:41.316] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1921.151
[1] -49.06767
[1] -39.60567
[1] 28.44711
[1] -53.24987
[1] 21.123
[1] -68.05229
[1] 28.88545
[1] -101.8484
[1] 23.37636
INFO  [17:34:15.986] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -19.96815
[1] 98.47191
[1] -30.35374
[1] 61.14021
[1] -13.27387
[1] 147.3057
[1] -80.52182
[1] -4.054126
[1] -30.56317
[1] 100.8025
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:35:01.480] [mlr3] Finished benchmark
INFO  [17:35:01.688] [bbotk] Result of batch 5:
INFO  [17:35:01.761] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:35:01.761] [bbotk]               -5.64423                         0.7296983
INFO  [17:35:01.761] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:35:01.761] [bbotk]                           0.13583           -3.094269             -0.6382998
INFO  [17:35:01.761] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:35:01.761] [bbotk]                         20                    2986                 0.3424851
INFO  [17:35:01.761] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:35:01.761] [bbotk]  0.02615619 <list[8]>              FALSE     0.02470805        0      0
INFO  [17:35:01.761] [bbotk]  runtime_learners                                uhash
INFO  [17:35:01.761] [bbotk]           118.192 9a8832a2-9e18-4aba-aea2-832431e3bff7
INFO  [17:35:04.112] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 36 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:35:10.331] [bbotk] Evaluating 1 configuration(s)
INFO  [17:35:10.789] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:35:11.544] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -6.646355e+15
[1] 3.12235e+16
[1] -167.3999
[1] -0.1410789
[1] -71.00502
[1] 18.73661
[1] -37.44039
[1] 308.5913
[1] -106.6024
[1] 14.88134
INFO  [17:35:37.466] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -67.77497
[1] 25.38765
[1] -41.88674
[1] 18.44813
[1] -212.0999
[1] 38.55581
[1] -85.63817
[1] 20.8981
[1] -3263.833
[1] -72.58006
INFO  [17:36:16.534] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -40.39255
[1] 29.37745
[1] -2241.04
[1] -98.09928
[1] -119.2631
[1] 50.56695
[1] -84.4041
[1] -3.867848
[1] -20.46727
[1] 41.20707
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:37:02.631] [mlr3] Finished benchmark
INFO  [17:37:02.803] [bbotk] Result of batch 6:
INFO  [17:37:03.066] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:37:03.066] [bbotk]               -6.46208                         0.6728886
INFO  [17:37:03.066] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:37:03.066] [bbotk]                         0.4447452            -2.94315              -2.114427
INFO  [17:37:03.066] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:37:03.066] [bbotk]                          8                    2250                 0.2901478
INFO  [17:37:03.066] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:37:03.066] [bbotk]  0.02391714 <list[8]>              FALSE      0.0240128        0      0
INFO  [17:37:03.066] [bbotk]  runtime_learners                                uhash
INFO  [17:37:03.066] [bbotk]           110.478 89045b3c-c86a-440b-8b80-859989e96c91
INFO  [17:37:04.907] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 37 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:37:10.375] [bbotk] Evaluating 1 configuration(s)
INFO  [17:37:10.522] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:37:10.596] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -103.6188
[1] 227.4276
[1] -30.45562
[1] 66.99103
[1] -338.4396
[1] -3.145156
[1] -1112.542
[1] -46.46133
[1] -48.46555
[1] 65.70494
INFO  [17:37:34.437] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -6786.492
[1] -238.0065
[1] -137.468
[1] 6.4718
[1] -69.24848
[1] 15.49997
[1] -120.7197
[1] 13.92772
[1] 182.4694
[1] 4883.032
INFO  [17:38:06.335] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -388.9056
[1] 10.87522
[1] -25.43165
[1] 31.76077
[1] -3.864456e+16
[1] -5.900299e+14
[1] -123.3049
[1] 9.231554
[1] -68.96456
[1] 26.24561
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:38:48.053] [mlr3] Finished benchmark
INFO  [17:38:48.240] [bbotk] Result of batch 7:
INFO  [17:38:48.323] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:38:48.323] [bbotk]               0.624509                         0.8795326
INFO  [17:38:48.323] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:38:48.323] [bbotk]                         0.9807622           -1.042411                3.72407
INFO  [17:38:48.323] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:38:48.323] [bbotk]                         13                    1053                  0.627202
INFO  [17:38:48.323] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:38:48.323] [bbotk]  0.02316196 <list[8]>              FALSE     0.02799201        0      0
INFO  [17:38:48.323] [bbotk]  runtime_learners                                uhash
INFO  [17:38:48.323] [bbotk]            96.474 ad71c7f7-3315-4d01-8f38-066f4d115f92
INFO  [17:38:49.212] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 38 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:38:53.473] [bbotk] Evaluating 1 configuration(s)
INFO  [17:38:53.526] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:38:53.625] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -23.80695
[1] 43.79582
[1] -28.69208
[1] 209.773
[1] -21.81102
[1] 159.4496
[1] -30.20334
[1] 21.9582
[1] -4738.498
[1] -4.066035
INFO  [17:39:02.772] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -34.90058
[1] 41.64339
[1] -38.30214
[1] 18.9915
[1] -106.5155
[1] 0.6873848
[1] -79.62856
[1] 1.893793
[1] -50.69165
[1] 29.78231
INFO  [17:39:13.310] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -84.76103
[1] -2.769577
[1] -106.7885
[1] 8.37343
[1] -400.5379
[1] 4.572446
[1] -57.79324
[1] 101.2493
[1] -24.74829
[1] 16.55564
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:39:24.032] [mlr3] Finished benchmark
INFO  [17:39:24.226] [bbotk] Result of batch 8:
INFO  [17:39:24.263] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:39:24.263] [bbotk]              -3.303444                         0.5917921
INFO  [17:39:24.263] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:39:24.263] [bbotk]                         0.3365225           -1.294996              -1.421244
INFO  [17:39:24.263] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:39:24.263] [bbotk]                         13                    1429                 0.9488286
INFO  [17:39:24.263] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:39:24.263] [bbotk]  0.01924825 <list[8]>              FALSE     0.02346175        0      0
INFO  [17:39:24.263] [bbotk]  runtime_learners                                uhash
INFO  [17:39:24.263] [bbotk]            29.761 7e538ea8-862d-458c-9b75-8e5ca76ca6ae
WARN  [17:39:25.072] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:39:25.093] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 39 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:39:30.053] [bbotk] Evaluating 1 configuration(s)
INFO  [17:39:30.168] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:39:30.241] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -24.88375
[1] 33.58135
[1] -43.09416
[1] 10.31475
[1] -26.50287
[1] 17.55683
[1] -27.856
[1] 38.85408
[1] -108.7866
[1] 39.54334
INFO  [17:39:46.999] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -29.01496
[1] 23.52881
[1] -85.38979
[1] 11.0011
[1] -53.0048
[1] 31.89511
[1] -5.231579
[1] 62.15964
[1] -55.02575
[1] -2.574835
INFO  [17:40:01.505] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -93.51359
[1] 10.8905
[1] -24.36452
[1] 39.38679
[1] -38.62986
[1] 22.01245
[1] -22.09003
[1] 29.12309
[1] -61.71966
[1] 18.329
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:40:14.627] [mlr3] Finished benchmark
INFO  [17:40:14.723] [bbotk] Result of batch 9:
INFO  [17:40:14.754] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:40:14.754] [bbotk]              -4.296143                          0.923277
INFO  [17:40:14.754] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:40:14.754] [bbotk]                         0.9784722          -0.6690071              -3.015556
INFO  [17:40:14.754] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:40:14.754] [bbotk]                         17                     248                 0.5462822
INFO  [17:40:14.754] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:40:14.754] [bbotk]  0.01524895 <list[8]>              FALSE     0.02680876        0      0
INFO  [17:40:14.754] [bbotk]  runtime_learners                                uhash
INFO  [17:40:14.754] [bbotk]            43.724 e86d8a88-177a-4daf-bc75-84f853028552
INFO  [17:40:15.406] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 40 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:40:21.206] [bbotk] Evaluating 1 configuration(s)
INFO  [17:40:21.305] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:40:21.356] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -34.25268
[1] 17.46169
[1] -1081.872
[1] -35.34173
[1] -25.88806
[1] 57.44531
[1] -76.3505
[1] 36.99958
[1] -797.7701
[1] -3.47527
INFO  [17:41:01.387] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -56.98663
[1] 93.79809
[1] -70.89302
[1] 27.78991
[1] -55.48171
[1] 17.51858
[1] -27.10257
[1] 61.3363
[1] -23.67388
[1] 21.44412
INFO  [17:41:53.478] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -29.38599
[1] 34.50768
[1] -54.25129
[1] -3.22348
[1] -62.54833
[1] 76.49471
[1] -77.70601
[1] 59.79701
[1] -27.91108
[1] 25.46101
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:42:24.585] [mlr3] Finished benchmark
INFO  [17:42:24.729] [bbotk] Result of batch 10:
INFO  [17:42:24.797] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:42:24.797] [bbotk]              -2.215935                         0.2148171
INFO  [17:42:24.797] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:42:24.797] [bbotk]                         0.6558302           -3.886922              -1.912967
INFO  [17:42:24.797] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:42:24.797] [bbotk]                          1                    4012                 0.9821032
INFO  [17:42:24.797] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:42:24.797] [bbotk]  0.01528465 <list[8]>              FALSE     0.02146639        0      0
INFO  [17:42:24.797] [bbotk]  runtime_learners                                uhash
INFO  [17:42:24.797] [bbotk]           122.048 b865950a-f6dc-4fd8-8523-c0912b36ae11
INFO  [17:42:25.952] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 41 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:42:31.220] [bbotk] Evaluating 1 configuration(s)
INFO  [17:42:31.258] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:42:31.308] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -46.83048
[1] 16.52396
[1] -42.89305
[1] 16.3126
[1] -68.12042
[1] 14.63625
[1] -275.7005
[1] -3.948008
[1] -61.24144
[1] 196.3596
INFO  [17:43:04.317] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1957.383
[1] -38.03804
[1] -48.88127
[1] 131.077
[1] -48.33746
[1] 0.7259956
[1] -276.6334
[1] 20.84953
[1] -55.21515
[1] 19.88735
INFO  [17:43:31.787] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -47.07717
[1] 8.004938
[1] -55.13654
[1] 12.0724
[1] -71.17444
[1] 26.75728
[1] -2.528381e+16
[1] 1.161785e+16
[1] -49.30101
[1] 40.2215
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:43:58.956] [mlr3] Finished benchmark
INFO  [17:43:59.174] [bbotk] Result of batch 11:
INFO  [17:43:59.275] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:43:59.275] [bbotk]              -6.132218                          0.931378
INFO  [17:43:59.275] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:43:59.275] [bbotk]                         0.4175861           -2.153968              0.8022265
INFO  [17:43:59.275] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:43:59.275] [bbotk]                          9                    1525                 0.5882772
INFO  [17:43:59.275] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:43:59.275] [bbotk]  0.01459049 <list[8]>              FALSE     0.02413267        0      0
INFO  [17:43:59.275] [bbotk]  runtime_learners                                uhash
INFO  [17:43:59.275] [bbotk]             86.73 4f5ad56a-7e2f-4eb2-8d4b-f31ce142abbc
INFO  [17:44:00.185] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 42 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:44:05.767] [bbotk] Evaluating 1 configuration(s)
INFO  [17:44:05.968] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:44:06.102] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -68.25495
[1] 9.110584
[1] -39.2052
[1] 35.22132
[1] -94.38263
[1] 161.8752
[1] -435.1159
[1] 99.0704
[1] -1057.775
[1] -34.65778
INFO  [17:44:15.195] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -3349.089
[1] -110.2687
[1] -53.88954
[1] 52.44828
[1] -48.78468
[1] 103.8204
[1] -184.807
[1] 21.7891
[1] -36.74937
[1] 29.21688
INFO  [17:44:27.571] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -126.0664
[1] 25.48086
[1] -6.26003e+15
[1] 5.170975e+16
[1] -12.33965
[1] 129.8453
[1] -73.78869
[1] 25.39142
[1] -80.40386
[1] -1.544098
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:44:37.909] [mlr3] Finished benchmark
INFO  [17:44:38.116] [bbotk] Result of batch 12:
INFO  [17:44:38.167] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:44:38.167] [bbotk]              -1.493605                         0.5575828
INFO  [17:44:38.167] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:44:38.167] [bbotk]                         0.5334799           -2.239562              -3.496492
INFO  [17:44:38.167] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:44:38.167] [bbotk]                          4                      31                 0.8750437
INFO  [17:44:38.167] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:44:38.167] [bbotk]  0.01355496 <list[8]>              FALSE     0.03076146        0      0
INFO  [17:44:38.167] [bbotk]  runtime_learners                                uhash
INFO  [17:44:38.167] [bbotk]            30.609 dcf1eb69-87c5-4d63-96a1-b80a42afd2c4
INFO  [17:44:39.343] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 43 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:44:45.585] [bbotk] Evaluating 1 configuration(s)
INFO  [17:44:45.623] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:44:45.727] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 262.0038
[1] 6920.213
[1] -940.1582
[1] 1.332438
[1] -50.87986
[1] 3.381008
[1] -40.51249
[1] 26.53042
[1] -27.21293
[1] 51.39818
INFO  [17:45:23.868] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -32.76048
[1] 29.056
[1] -39.11464
[1] 19.35929
[1] -38.89038
[1] 22.99731
[1] -180.3191
[1] 28.25618
[1] -61.78024
[1] 34.60866
INFO  [17:46:04.160] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -53.52157
[1] 19.38904
[1] -52.11264
[1] 27.93089
[1] -44.1289
[1] 20.73411
[1] -82.64256
[1] 1.252364
[1] -45.3184
[1] 35.92329
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:46:44.804] [mlr3] Finished benchmark
INFO  [17:46:45.228] [bbotk] Result of batch 13:
INFO  [17:46:45.321] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:46:45.321] [bbotk]              -4.008423                         0.9231714
INFO  [17:46:45.321] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:46:45.321] [bbotk]                         0.5760543           -2.026654               -3.37805
INFO  [17:46:45.321] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:46:45.321] [bbotk]                          6                    2872                 0.6348485
INFO  [17:46:45.321] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:46:45.321] [bbotk]  0.01442142 <list[8]>              FALSE     0.02616305        0      0
INFO  [17:46:45.321] [bbotk]  runtime_learners                                uhash
INFO  [17:46:45.321] [bbotk]            117.82 7f88b70d-9e68-47a0-b3fb-dc6022bd804a
INFO  [17:46:46.518] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 44 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:46:50.584] [bbotk] Evaluating 1 configuration(s)
INFO  [17:46:50.622] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:46:50.725] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -30.18974
[1] 42.98462
[1] -82.35916
[1] 55.73252
[1] 81.89244
[1] 3301.09
[1] -133.9121
[1] -2.065436
[1] -59.56216
[1] 11.04027
INFO  [17:47:32.786] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -185.2145
[1] 6.879768
[1] -44.38434
[1] 74.54881
[1] -70.3985
[1] 4.218187
[1] -28.11682
[1] 22.70418
[1] -81.33579
[1] 17.1758
INFO  [17:48:12.384] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -40.33994
[1] 33.18823
[1] -26.15166
[1] 32.12454
[1] -230.339
[1] -4.091707
[1] -33.73543
[1] 50.72253
[1] -76.97422
[1] -0.95043
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:49:14.684] [mlr3] Finished benchmark
INFO  [17:49:15.009] [bbotk] Result of batch 14:
INFO  [17:49:15.201] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:49:15.201] [bbotk]             -0.6282277                         0.8163487
INFO  [17:49:15.201] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:49:15.201] [bbotk]                         0.5052472           -5.007718               -1.80376
INFO  [17:49:15.201] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:49:15.201] [bbotk]                          3                    4539                 0.9158545
INFO  [17:49:15.201] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:49:15.201] [bbotk]  0.01480621 <list[8]>              FALSE     0.02574677        0      0
INFO  [17:49:15.201] [bbotk]  runtime_learners                                uhash
INFO  [17:49:15.201] [bbotk]           142.978 fb69405b-d5af-4ae6-8691-005abbcdadab
INFO  [17:49:20.112] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 45 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:49:26.099] [bbotk] Evaluating 1 configuration(s)
INFO  [17:49:26.274] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:49:26.525] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -133.8495
[1] -3.447526
[1] -59.21049
[1] 28.97104
[1] -20.40044
[1] 119.6755
[1] -97.06742
[1] 28.75453
[1] -47.7176
[1] 55.31206
INFO  [17:49:43.293] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -106.7039
[1] 42.96978
[1] -128.1018
[1] 33.56692
[1] -80.31185
[1] 31.6486
[1] -4237.709
[1] -66.02969
[1] -81.07351
[1] 3.01462
INFO  [17:49:59.808] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -15.93001
[1] 98.72456
[1] -111.1724
[1] 17.03904
[1] -57.68107
[1] 18.30444
[1] -80.1069
[1] 19.8566
[1] -4362.745
[1] -96.51039
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:50:19.107] [mlr3] Finished benchmark
INFO  [17:50:19.238] [bbotk] Result of batch 15:
INFO  [17:50:19.288] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:50:19.288] [bbotk]               1.260561                         0.7361777
INFO  [17:50:19.288] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:50:19.288] [bbotk]                          0.664928           -2.309888               4.012768
INFO  [17:50:19.288] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:50:19.288] [bbotk]                          8                    2452                 0.9715756
INFO  [17:50:19.288] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:50:19.288] [bbotk]  0.01318821 <list[8]>              FALSE     0.03336315        0      0
INFO  [17:50:19.288] [bbotk]  runtime_learners                                uhash
INFO  [17:50:19.288] [bbotk]            51.754 06bbae6a-ee18-4e6d-a980-348571b62784
INFO  [17:50:20.170] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 46 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:50:25.094] [bbotk] Evaluating 1 configuration(s)
INFO  [17:50:25.129] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:50:25.238] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -71.55592
[1] 6.668255
[1] 492.8177
[1] 15583.7
[1] -42.2435
[1] 60.16978
[1] -154.4221
[1] 27.23054
[1] -253.979
[1] -3.887162
INFO  [17:50:41.254] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -25.29327
[1] 27.381
[1] -91.39026
[1] 20.90341
[1] -1735.525
[1] -82.15853
[1] 106.1644
[1] 2003.941
[1] -69.35007
[1] 8.14423
INFO  [17:51:21.442] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -373.6057
[1] -1.597236
[1] -45.32968
[1] 28.20342
[1] -89.14503
[1] -3.978029
[1] -22.01259
[1] 48.94537
[1] 157.89
[1] 2779.708
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:52:09.227] [mlr3] Finished benchmark
INFO  [17:52:09.560] [bbotk] Result of batch 16:
INFO  [17:52:09.632] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:52:09.632] [bbotk]              -6.525053                         0.4248265
INFO  [17:52:09.632] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:52:09.632] [bbotk]                         0.4093588           -4.056081              -2.795383
INFO  [17:52:09.632] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:52:09.632] [bbotk]                         15                    4386                 0.8717655
INFO  [17:52:09.632] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:52:09.632] [bbotk]  0.01256209 <list[8]>              FALSE     0.02511389        0      0
INFO  [17:52:09.632] [bbotk]  runtime_learners                                uhash
INFO  [17:52:09.632] [bbotk]           100.937 75a59975-aa05-4447-8402-b61c1471533f
INFO  [17:52:12.674] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 47 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:52:28.415] [bbotk] Evaluating 1 configuration(s)
INFO  [17:52:28.689] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:52:28.869] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1094.016
[1] -64.60016
[1] -144.1
[1] -3.951141
[1] -43.40006
[1] 16.02638
[1] -57.53725
[1] 59.75208
[1] -34.55771
[1] 34.7306
INFO  [17:53:39.922] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -87.94541
[1] 25.63419
[1] -902.1523
[1] 36.1524
[1] -47.00049
[1] 13.84285
[1] -34.27704
[1] 23.91391
[1] -54.34119
[1] 25.73849
INFO  [17:54:34.533] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -16.99103
[1] 47.38904
[1] -140.3547
[1] 4.331614
[1] -36.58454
[1] 42.7958
[1] -53.7614
[1] 15.35908
[1] -153.7428
[1] 43.79687
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:55:22.878] [mlr3] Finished benchmark
INFO  [17:55:22.972] [bbotk] Result of batch 17:
INFO  [17:55:23.006] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:55:23.006] [bbotk]              -0.182588                         0.8198415
INFO  [17:55:23.006] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:55:23.006] [bbotk]                           0.95236           -3.447041              -3.479364
INFO  [17:55:23.006] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:55:23.006] [bbotk]                         13                    4007                 0.8356324
INFO  [17:55:23.006] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:55:23.006] [bbotk]  0.01218719 <list[8]>              FALSE     0.02458523        0      0
INFO  [17:55:23.006] [bbotk]  runtime_learners                                uhash
INFO  [17:55:23.006] [bbotk]           173.277 d6d723e3-67f4-4204-990b-92da143bd1f9
INFO  [17:55:24.638] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 48 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:55:33.039] [bbotk] Evaluating 1 configuration(s)
INFO  [17:55:33.265] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:55:33.546] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -61.16067
[1] 35.09514
[1] -84.2516
[1] 6.358238
[1] -1471.549
[1] -52.63589
[1] -49.60587
[1] 23.21512
[1] -457.7425
[1] -3.272123
INFO  [17:56:04.466] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -31.19096
[1] 43.89974
[1] -901.0234
[1] -32.44811
[1] -300.9357
[1] -2.273379
[1] -108.2493
[1] 20.28203
[1] -31.48907
[1] 145.4636
INFO  [17:56:48.416] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -74.48782
[1] 35.72919
[1] -149.7652
[1] 11.37336
[1] -41.56842
[1] 68.84449
[1] -35.95324
[1] 25.13604
[1] -72.60675
[1] 7.259565
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:57:27.225] [mlr3] Finished benchmark
INFO  [17:57:27.384] [bbotk] Result of batch 18:
INFO  [17:57:27.462] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:57:27.462] [bbotk]              -4.981219                         0.5527479
INFO  [17:57:27.462] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:57:27.462] [bbotk]                         0.5560119           -1.446245             0.00577826
INFO  [17:57:27.462] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:57:27.462] [bbotk]                         17                    2786                 0.2379969
INFO  [17:57:27.462] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:57:27.462] [bbotk]  0.01095325 <list[8]>              FALSE     0.02641506        0      0
INFO  [17:57:27.462] [bbotk]  runtime_learners                                uhash
INFO  [17:57:27.462] [bbotk]           112.027 5ca714f3-ed07-4ffa-9c96-ebcc50e7561c
INFO  [17:57:29.219] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 49 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:57:36.534] [bbotk] Evaluating 1 configuration(s)
INFO  [17:57:36.800] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:57:36.955] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -166.3309
[1] -4.054486
[1] -28.9089
[1] 31.97706
[1] -2654.432
[1] -41.92679
[1] -64.16506
[1] 16.03574
[1] -4292.285
[1] -84.57732
INFO  [17:58:11.270] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -6033.142
[1] -168.8706
[1] -88.46935
[1] 10.44605
[1] 41.27912
[1] 1069.219
[1] -62.85715
[1] 22.76204
[1] -53.21208
[1] 8.091487
INFO  [17:58:48.457] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -63.94643
[1] 32.76371
[1] -38.43692
[1] 35.42168
[1] -29.6101
[1] 14.6682
[1] -38.9445
[1] 40.72033
[1] -343.5585
[1] 16.62503
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:59:26.497] [mlr3] Finished benchmark
INFO  [17:59:26.638] [bbotk] Result of batch 19:
INFO  [17:59:26.701] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:59:26.701] [bbotk]              -5.769102                         0.5037934
INFO  [17:59:26.701] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:59:26.701] [bbotk]                         0.7311114           -3.864175              -1.073112
INFO  [17:59:26.701] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:59:26.701] [bbotk]                         18                    2414                  0.658059
INFO  [17:59:26.701] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:59:26.701] [bbotk]  0.01101985 <list[8]>              FALSE     0.02247406        0      0
INFO  [17:59:26.701] [bbotk]  runtime_learners                                uhash
INFO  [17:59:26.701] [bbotk]           107.017 7eb8c698-3ace-42c3-8634-39e86e59ad00
INFO  [17:59:28.164] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 50 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:59:33.635] [bbotk] Evaluating 1 configuration(s)
INFO  [17:59:33.789] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:59:34.130] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -130.1217
[1] 26.75531
[1] -75.75637
[1] 17.02888
[1] -120.2831
[1] -3.946845
[1] -89.98268
[1] 55.14231
[1] -10.86541
[1] 407.5014
INFO  [18:00:11.417] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -23.03058
[1] 36.83382
[1] -118.4371
[1] 20.465
[1] -1732.921
[1] -51.77661
[1] -35.06008
[1] 161.4518
[1] -100.7066
[1] 14.51022
INFO  [18:00:43.246] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -22.04607
[1] 73.48201
[1] -117.8884
[1] -3.264225
[1] -1871.211
[1] -113.4266
[1] -729.6851
[1] 86.80665
[1] -352.812
[1] -1.126068
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:01:24.301] [mlr3] Finished benchmark
INFO  [18:01:24.386] [bbotk] Result of batch 20:
INFO  [18:01:24.409] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:01:24.409] [bbotk]              0.2657409                         0.4465372
INFO  [18:01:24.409] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:01:24.409] [bbotk]                         0.2667063          -0.8507165              0.7997414
INFO  [18:01:24.409] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:01:24.409] [bbotk]                         19                    3263                 0.4095214
INFO  [18:01:24.409] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:01:24.409] [bbotk]  0.00996622 <list[8]>              FALSE      0.0235743        0      0
INFO  [18:01:24.409] [bbotk]  runtime_learners                                uhash
INFO  [18:01:24.409] [bbotk]           109.398 1cdcf511-543a-4406-af7b-2517c72afdac
WARN  [18:01:25.684] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:01:25.730] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 51 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:01:29.138] [bbotk] Evaluating 1 configuration(s)
INFO  [18:01:29.265] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:01:29.336] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -295.1163
[1] -3.824759
[1] -38.76654
[1] 24.68266
[1] -19.4978
[1] 47.8485
[1] -67.75553
[1] 41.72575
[1] -133.7177
[1] -0.08172104
INFO  [18:02:19.350] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -74.50329
[1] 11.18029
[1] -120.7381
[1] 18.24658
[1] -1157.085
[1] -47.96281
[1] -176.1165
[1] 20.25745
[1] -133.1923
[1] 55.86987
INFO  [18:03:09.909] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -42.0037
[1] 37.10163
[1] -1017.061
[1] 67.70977
[1] -75.56636
[1] 11.0518
[1] -39.31663
[1] 18.19395
[1] -20.92207
[1] 55.86732
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:03:56.566] [mlr3] Finished benchmark
INFO  [18:03:56.929] [bbotk] Result of batch 21:
INFO  [18:03:57.160] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:03:57.160] [bbotk]              -6.331295                         0.5773386
INFO  [18:03:57.160] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:03:57.160] [bbotk]                         0.4602273            -3.51525             -0.9256333
INFO  [18:03:57.160] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:03:57.160] [bbotk]                         10                    4613                 0.4986302
INFO  [18:03:57.160] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:03:57.160] [bbotk]  0.01090693 <list[8]>              FALSE     0.02353931        0      0
INFO  [18:03:57.160] [bbotk]  runtime_learners                                uhash
INFO  [18:03:57.160] [bbotk]           146.166 83de206f-f5b9-41b4-8c5a-73bb49fa238f
INFO  [18:03:59.693] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 52 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:04:04.849] [bbotk] Evaluating 1 configuration(s)
INFO  [18:04:05.085] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:04:05.303] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -64.27625
[1] 36.21977
[1] -2.875129e+16
[1] 1.506944e+16
[1] -1065.328
[1] -36.74598
[1] -279.9224
[1] 9.062502
[1] -74.28773
[1] -3.719872
INFO  [18:04:26.311] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -54.54662
[1] 66.49334
[1] -65.67014
[1] 20.21227
[1] -93.61274
[1] 9.241596
[1] -23.60048
[1] 34.26477
[1] -49.25302
[1] 13.51382
INFO  [18:04:47.755] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -32.80039
[1] 23.31528
[1] -46.7345
[1] 11.06215
[1] -65.37087
[1] 19.34438
[1] -32.30179
[1] 24.00456
[1] -305.2406
[1] 93.44978
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:05:04.698] [mlr3] Finished benchmark
INFO  [18:05:04.796] [bbotk] Result of batch 22:
INFO  [18:05:04.976] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:05:04.976] [bbotk]              -5.249095                         0.7127914
INFO  [18:05:04.976] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:05:04.976] [bbotk]                         0.3066313           -1.564261             -0.6708914
INFO  [18:05:04.976] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:05:04.976] [bbotk]                          6                     869                   0.53804
INFO  [18:05:04.976] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:05:04.976] [bbotk]  0.0105246 <list[8]>              FALSE      0.0232354        0      0
INFO  [18:05:04.976] [bbotk]  runtime_learners                                uhash
INFO  [18:05:04.976] [bbotk]            58.635 af115d78-ada6-4d2c-becf-0c7b16fa8e92
INFO  [18:05:09.121] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 53 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:05:17.597] [bbotk] Evaluating 1 configuration(s)
INFO  [18:05:17.831] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:05:18.156] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -24.21464
[1] 63.01597
[1] -39.64448
[1] 77.41258
[1] -404.4594
[1] -3.932043
[1] -35.76285
[1] 13.76377
[1] -208.0687
[1] 6.957922
INFO  [18:06:16.447] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -40.09558
[1] 29.21533
[1] 34.91011
[1] 821.9856
[1] -2790.42
[1] -92.38021
[1] -52.29252
[1] 15.20953
[1] -99.11298
[1] 15.4569
INFO  [18:06:56.979] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -37.23355
[1] 12.98655
[1] -105.776
[1] 34.9242
[1] -40.03384
[1] 18.18295
[1] -56.25499
[1] 35.45926
[1] -32.40832
[1] 32.73393
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:07:43.063] [mlr3] Finished benchmark
INFO  [18:07:43.163] [bbotk] Result of batch 23:
INFO  [18:07:43.236] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:07:43.236] [bbotk]             -0.9872115                          0.170199
INFO  [18:07:43.236] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:07:43.236] [bbotk]                         0.3426765           -1.485421               -3.87837
INFO  [18:07:43.236] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:07:43.236] [bbotk]                         10                    4877                 0.7822311
INFO  [18:07:43.236] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:07:43.236] [bbotk]  0.01039817 <list[8]>              FALSE     0.02315671        0      0
INFO  [18:07:43.236] [bbotk]  runtime_learners                                uhash
INFO  [18:07:43.236] [bbotk]           143.874 4041d684-2a18-42c5-a14e-1bf9ed3bf114
INFO  [18:07:44.207] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 54 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:07:49.993] [bbotk] Evaluating 1 configuration(s)
INFO  [18:07:50.034] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:07:50.061] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -201.4566
[1] 48.12461
[1] -185.9326
[1] -0.6100148
[1] -56.46507
[1] 8.425455
[1] -105.4827
[1] 42.30599
[1] -79.7851
[1] -3.994363
INFO  [18:08:36.209] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -97.67259
[1] -2.944542
[1] -1.63329e+16
[1] 1.397418e+16
[1] -1123.491
[1] -76.2646
[1] -45.73992
[1] 22.2126
[1] -280.2171
[1] 13.30974
INFO  [18:09:05.848] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -40.29083
[1] 63.77476
[1] -275.685
[1] 29.66364
[1] -882.9042
[1] -28.29923
[1] -70.63684
[1] 32.16053
[1] -5793.367
[1] -247.5031
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:09:52.296] [mlr3] Finished benchmark
INFO  [18:09:52.453] [bbotk] Result of batch 24:
INFO  [18:09:52.473] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:09:52.473] [bbotk]               -2.75894                         0.2200723
INFO  [18:09:52.473] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:09:52.473] [bbotk]                         0.8569329           -2.162521              -1.868925
INFO  [18:09:52.473] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:09:52.473] [bbotk]                         10                    3239                 0.6124371
INFO  [18:09:52.473] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:09:52.473] [bbotk]  0.0105174 <list[8]>              FALSE     0.02206115        0      0
INFO  [18:09:52.473] [bbotk]  runtime_learners                                uhash
INFO  [18:09:52.473] [bbotk]           120.214 d896784e-a15e-4f6f-88f7-b70f73e9ac84
INFO  [18:09:54.014] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 55 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:10:00.804] [bbotk] Evaluating 1 configuration(s)
INFO  [18:10:01.093] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:10:01.299] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -230.8668
[1] -1.792886
[1] -68.2119
[1] 38.93901
[1] -110.6812
[1] 11.87976
[1] -56.83479
[1] 18.6558
[1] -7338.957
[1] -117.6309
INFO  [18:10:55.231] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -51.8531
[1] 37.74722
[1] -114.6005
[1] 5.55284
[1] -66.81227
[1] 21.49145
[1] -91.714
[1] 8.882949
[1] -60.91572
[1] 40.25358
INFO  [18:11:23.596] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -74.2401
[1] 18.64601
[1] -40.99575
[1] 10.51408
[1] 39.95691
[1] 1391.499
[1] -64.25718
[1] 6.406954
[1] -12.56513
[1] 68.27445
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:12:03.718] [mlr3] Finished benchmark
INFO  [18:12:03.911] [bbotk] Result of batch 25:
INFO  [18:12:03.970] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:12:03.970] [bbotk]              -1.845329                         0.1808592
INFO  [18:12:03.970] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:12:03.970] [bbotk]                         0.9606044           -5.586577              -4.649724
INFO  [18:12:03.970] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:12:03.970] [bbotk]                         12                    4245                  0.860056
INFO  [18:12:03.970] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:12:03.970] [bbotk]  0.01148357 <list[8]>              FALSE     0.02450038        0      0
INFO  [18:12:03.970] [bbotk]  runtime_learners                                uhash
INFO  [18:12:03.970] [bbotk]           121.474 65f2a75f-f378-4073-a4d7-89dd0b43939d
WARN  [18:12:06.936] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:12:07.093] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 56 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:12:12.731] [bbotk] Evaluating 1 configuration(s)
INFO  [18:12:12.918] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:12:13.082] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -83.12995
[1] 113.6887
[1] 128.707
[1] 5955.656
[1] -193.4508
[1] 4.535929
[1] -50.20095
[1] 21.5913
[1] -89.48327
[1] 91.94539
INFO  [18:12:41.252] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -45.66299
[1] 43.48886
[1] -91.3504
[1] 3.190798
[1] -192.0438
[1] 9.526089
[1] -94.37963
[1] 75.40401
[1] -157.7252
[1] 17.88458
INFO  [18:13:00.422] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -242.7577
[1] 9.724111
[1] -22.01565
[1] 32.05326
[1] -352.9205
[1] -18.73671
[1] -117.1199
[1] 2.424005
[1] -3981.44
[1] -88.5963
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:13:33.075] [mlr3] Finished benchmark
INFO  [18:13:33.565] [bbotk] Result of batch 26:
INFO  [18:13:33.653] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:13:33.653] [bbotk]              -6.140972                         0.2046379
INFO  [18:13:33.653] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:13:33.653] [bbotk]                         0.7692962           -2.862403               2.452582
INFO  [18:13:33.653] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:13:33.653] [bbotk]                         14                     545                 0.8946483
INFO  [18:13:33.653] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:13:33.653] [bbotk]  0.008764196 <list[8]>              FALSE     0.02666224        0      0
INFO  [18:13:33.653] [bbotk]  runtime_learners                                uhash
INFO  [18:13:33.653] [bbotk]            77.647 2f496018-2cb7-4818-a3f1-9a2e2b4d85c3
INFO  [18:13:35.661] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 57 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:13:43.209] [bbotk] Evaluating 1 configuration(s)
INFO  [18:13:43.452] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:13:43.735] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -147.9168
[1] 23.32933
[1] -703.0233
[1] 2.970253
[1] -9057.955
[1] -571.2082
[1] -82.25504
[1] -2.3465
[1] -67.73602
[1] 6.20998
INFO  [18:14:01.351] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -4734.399
[1] -149.3542
[1] -31.03195
[1] 35.67998
[1] -33.34743
[1] 27.19477
[1] -99.528
[1] 15.63991
[1] -44.80741
[1] 20.54726
INFO  [18:14:20.907] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -39.40734
[1] 23.04241
[1] -70.95598
[1] 31.34527
[1] -153.6511
[1] 84.13196
[1] -46.19969
[1] 17.66663
[1] -111.4596
[1] -3.526234
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:14:40.960] [mlr3] Finished benchmark
INFO  [18:14:41.102] [bbotk] Result of batch 27:
INFO  [18:14:41.146] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:14:41.146] [bbotk]               -2.58591                         0.8143344
INFO  [18:14:41.146] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:14:41.146] [bbotk]                         0.5216737           -1.458702              -5.994581
INFO  [18:14:41.146] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:14:41.146] [bbotk]                          8                    3517                  0.382596
INFO  [18:14:41.146] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:14:41.146] [bbotk]  0.008651212 <list[8]>              FALSE     0.02775567        0      0
INFO  [18:14:41.146] [bbotk]  runtime_learners                                uhash
INFO  [18:14:41.146] [bbotk]            56.555 93d9ea4a-a1d7-4727-ab35-89b3b39231ca
INFO  [18:14:43.270] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 58 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:14:49.151] [bbotk] Evaluating 1 configuration(s)
INFO  [18:14:49.250] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:14:49.328] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -71.70109
[1] 9.23813
[1] -494.5238
[1] -3.813263
[1] -39.92932
[1] 36.65822
[1] -20.91881
[1] 29.86275
[1] -2.071346e+16
[1] 1.992434e+16
INFO  [18:15:41.823] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -90.54235
[1] 11.47458
[1] -34.98415
[1] 29.99447
[1] -69.96466
[1] 15.00267
[1] -43.69805
[1] 29.81542
[1] -31.13974
[1] 56.26933
INFO  [18:16:21.660] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -64.45031
[1] 77.37387
[1] -438.4203
[1] 6.709672
[1] -173.6677
[1] 3.210568
[1] -23.38905
[1] 68.50014
[1] 52.28783
[1] 1182.05
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:17:10.840] [mlr3] Finished benchmark
INFO  [18:17:11.235] [bbotk] Result of batch 28:
INFO  [18:17:11.488] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:17:11.488] [bbotk]              -1.065168                         0.8846716
INFO  [18:17:11.488] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:17:11.488] [bbotk]                         0.1671391           -1.880501               -1.62644
INFO  [18:17:11.488] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:17:11.488] [bbotk]                          7                    4908                   0.79476
INFO  [18:17:11.488] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:17:11.488] [bbotk]  0.00853397 <list[8]>              FALSE     0.02354085        0      0
INFO  [18:17:11.488] [bbotk]  runtime_learners                                uhash
INFO  [18:17:11.488] [bbotk]           140.685 a344d409-5b9b-492d-8e3e-f1228d28c54b
INFO  [18:17:13.856] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 59 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:17:21.713] [bbotk] Evaluating 1 configuration(s)
INFO  [18:17:22.036] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:17:22.271] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -167.0409
[1] -0.8270698
[1] -78.90734
[1] 156.8911
[1] -62.62943
[1] 31.00144
[1] -155.1306
[1] -3.998877
[1] -5021.741
[1] -204.7766
INFO  [18:18:08.632] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -58.557
[1] 36.19771
[1] -38.72865
[1] 16.97736
[1] -75.17413
[1] 22.51267
[1] -60.15708
[1] 58.22398
[1] -3511.302
[1] -105.2441
INFO  [18:18:57.466] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -3137.634
[1] -64.07196
[1] -74.26891
[1] 22.93709
[1] -16.35245
[1] 55.89116
[1] -53.63949
[1] 12.95741
[1] -30.12325
[1] 40.04762
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:19:49.148] [mlr3] Finished benchmark
INFO  [18:19:49.537] [bbotk] Result of batch 29:
INFO  [18:19:49.646] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:19:49.646] [bbotk]             -0.6301851                         0.3936194
INFO  [18:19:49.646] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:19:49.646] [bbotk]                         0.4836241           -3.845949              -2.285582
INFO  [18:19:49.646] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:19:49.646] [bbotk]                          6                    4379                 0.8529823
INFO  [18:19:49.646] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:19:49.646] [bbotk]  0.007876099 <list[8]>              FALSE     0.02357838        0      0
INFO  [18:19:49.646] [bbotk]  runtime_learners                                uhash
INFO  [18:19:49.646] [bbotk]           145.751 434b3dc0-498b-455a-9023-978f19e15cb8
INFO  [18:19:52.455] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 60 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:19:59.270] [bbotk] Evaluating 1 configuration(s)
INFO  [18:19:59.614] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:20:00.276] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -88.74936
[1] 42.45606
[1] -27.00918
[1] 79.30607
[1] -96.08146
[1] -2.041636
[1] -169.2505
[1] 10.4141
[1] -51.91752
[1] 24.82076
INFO  [18:20:33.481] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 34.24464
[1] 1074.324
[1] -33.4147
[1] 12.26279
[1] -120.7551
[1] 15.73554
[1] -37.8713
[1] 370.5822
[1] -47.97178
[1] 62.53074
INFO  [18:20:55.702] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -42.10302
[1] 45.03457
[1] -39.29977
[1] 22.95716
[1] -33.02919
[1] 49.82581
[1] -191.7096
[1] 10.08512
[1] -73.95193
[1] 19.91102
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:21:27.559] [mlr3] Finished benchmark
INFO  [18:21:27.742] [bbotk] Result of batch 30:
INFO  [18:21:27.815] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:21:27.815] [bbotk]              -1.222369                         0.1381127
INFO  [18:21:27.815] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:21:27.815] [bbotk]                         0.7063006          -0.7267392            -0.03581717
INFO  [18:21:27.815] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:21:27.815] [bbotk]                         16                    1983                 0.9011418
INFO  [18:21:27.815] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:21:27.815] [bbotk]  0.007905863 <list[8]>              FALSE     0.02328917        0      0
INFO  [18:21:27.815] [bbotk]  runtime_learners                                uhash
INFO  [18:21:27.815] [bbotk]            85.478 f7972c33-2c05-4eda-b8d2-d95dd5257169
INFO  [18:21:28.998] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 61 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:21:35.407] [bbotk] Evaluating 1 configuration(s)
INFO  [18:21:35.617] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:21:35.734] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -39.67397
[1] 189.9347
[1] -112.647
[1] 15.52357
[1] -265.4835
[1] 4.135534
[1] -42.23146
[1] 28.75367
[1] -35.88179
[1] 27.3959
INFO  [18:22:10.318] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -101.5749
[1] 15.10063
[1] -54.33279
[1] 16.85561
[1] -49.76901
[1] 15.24311
[1] -50.25835
[1] 47.62748
[1] -67.83044
[1] 51.55431
INFO  [18:22:45.953] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -101.2124
[1] 9.044303
[1] -30.09148
[1] 12.15039
[1] -40.33628
[1] 22.27279
[1] -123.1683
[1] 36.94348
[1] -869.6237
[1] -40.87784
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:23:15.880] [mlr3] Finished benchmark
INFO  [18:23:16.112] [bbotk] Result of batch 31:
INFO  [18:23:16.134] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:23:16.134] [bbotk]              -6.564211                         0.1517021
INFO  [18:23:16.134] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:23:16.134] [bbotk]                         0.6770434           -3.536844               1.066558
INFO  [18:23:16.134] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:23:16.134] [bbotk]                          4                    3290                 0.8378545
INFO  [18:23:16.134] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:23:16.134] [bbotk]  0.00864569 <list[8]>              FALSE     0.02341175        0      0
INFO  [18:23:16.134] [bbotk]  runtime_learners                                uhash
INFO  [18:23:16.134] [bbotk]            98.476 ffaafe64-a983-4484-b7de-78509beee7f4
INFO  [18:23:17.997] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 62 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:23:25.135] [bbotk] Evaluating 1 configuration(s)
INFO  [18:23:25.381] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:23:25.641] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -57.58376
[1] 10.85889
[1] -64.47169
[1] 46.41381
[1] -7394.136
[1] -203.5336
[1] -42.77881
[1] 30.53614
[1] -117.9159
[1] 76.38383
INFO  [18:23:52.166] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -67.28739
[1] 53.4206
[1] -70.65063
[1] 16.74275
[1] -45.58028
[1] 29.35656
[1] -23.11189
[1] 48.34122
[1] -64.78385
[1] 43.13272
INFO  [18:24:40.374] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -73.30152
[1] 61.84701
[1] -49.85238
[1] 56.23697
[1] 71.35048
[1] 2135.852
[1] -87.57317
[1] -1.329864
[1] -63.74134
[1] 1.043506
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:25:25.594] [mlr3] Finished benchmark
INFO  [18:25:25.812] [bbotk] Result of batch 32:
INFO  [18:25:25.915] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:25:25.915] [bbotk]              0.5300944                         0.9437445
INFO  [18:25:25.915] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:25:25.915] [bbotk]                         0.2528526           -2.868862              -3.262513
INFO  [18:25:25.915] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:25:25.915] [bbotk]                         13                    3884                 0.8786652
INFO  [18:25:25.915] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:25:25.915] [bbotk]  0.007592903 <list[8]>              FALSE     0.02555302        0      0
INFO  [18:25:25.915] [bbotk]  runtime_learners                                uhash
INFO  [18:25:25.915] [bbotk]           119.472 8abfa168-d6ca-4d29-9ee2-f60f01a0a4f5
INFO  [18:25:28.583] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 63 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:25:37.180] [bbotk] Evaluating 1 configuration(s)
INFO  [18:25:37.422] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:25:37.644] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -35.64102
[1] 76.8762
[1] -112.9913
[1] 2.390936
[1] -322.7911
[1] 56.87861
[1] -246.3143
[1] 17.95703
[1] -123.0556
[1] 65.42815
INFO  [18:25:55.960] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -74.38527
[1] 13.45445
[1] -217.3059
[1] 15.0228
[1] 118.877
[1] 5282.612
[1] -122.6166
[1] 10.69237
[1] -50.25051
[1] 55.13207
INFO  [18:26:18.927] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -162.1063
[1] 18.79158
[1] -33.26304
[1] 30.86077
[1] -1364.673
[1] -39.20833
[1] -26.91221
[1] 98.80499
[1] -54.4527
[1] 24.12545
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:26:46.246] [mlr3] Finished benchmark
INFO  [18:26:46.983] [bbotk] Result of batch 33:
INFO  [18:26:47.154] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:26:47.154] [bbotk]              -6.859584                         0.1744254
INFO  [18:26:47.154] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:26:47.154] [bbotk]                         0.1019725           -4.961978              -1.974082
INFO  [18:26:47.154] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:26:47.154] [bbotk]                          9                    2507                 0.4028034
INFO  [18:26:47.154] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:26:47.154] [bbotk]  0.008687321 <list[8]>              FALSE     0.02458741        0      0
INFO  [18:26:47.154] [bbotk]  runtime_learners                                uhash
INFO  [18:26:47.154] [bbotk]            67.512 412ecab9-003f-400e-af40-6ef82272d765
INFO  [18:26:50.290] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 64 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:26:56.407] [bbotk] Evaluating 1 configuration(s)
INFO  [18:26:56.619] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:26:56.841] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 9.692767
[1] 1621.333
[1] -41.97291
[1] 127.3547
[1] -160.2144
[1] 19.20076
[1] -1237.492
[1] -81.25075
[1] -57.92686
[1] -2.897114
INFO  [18:27:51.659] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -59.92919
[1] 43.17135
[1] -1866.609
[1] -45.43698
[1] -54.33094
[1] 11.92692
[1] -2676.998
[1] -42.28657
[1] -31.19907
[1] 33.3403
INFO  [18:28:49.638] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -28.24538
[1] 41.05568
[1] -43.18194
[1] 3.218426
[1] -25287.22
[1] -874.1176
[1] -2562.661
[1] -70.82854
[1] -19.18016
[1] 27.6408
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:29:21.144] [mlr3] Finished benchmark
INFO  [18:29:21.419] [bbotk] Result of batch 34:
INFO  [18:29:21.458] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:29:21.458] [bbotk]               -2.26947                         0.9100836
INFO  [18:29:21.458] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:29:21.458] [bbotk]                          0.782098           -4.152223              -3.215926
INFO  [18:29:21.458] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:29:21.458] [bbotk]                          1                    4895                 0.5631322
INFO  [18:29:21.458] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:29:21.458] [bbotk]  0.008223189 <list[8]>              FALSE     0.02462793        0      0
INFO  [18:29:21.458] [bbotk]  runtime_learners                                uhash
INFO  [18:29:21.458] [bbotk]           142.214 59ea7e10-7c18-484f-9ced-f4f7a7ef851f
INFO  [18:29:22.660] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 65 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:29:29.676] [bbotk] Evaluating 1 configuration(s)
INFO  [18:29:29.963] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:29:30.346] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -144.8683
[1] 126.3416
[1] -144.5648
[1] -3.446851
[1] -367.5246
[1] -3.278269
[1] -58.84072
[1] 65.96133
[1] -35.95062
[1] 71.08989
INFO  [18:29:43.764] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -258.8735
[1] -3.150253
[1] -155.5972
[1] -2.859785
[1] -58.68921
[1] 32.81245
[1] -161.606
[1] 45.71884
[1] -15.86056
[1] 87.31991
INFO  [18:29:57.902] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -102.1275
[1] 17.22012
[1] -99.42766
[1] 91.04466
[1] -73.07446
[1] 52.01555
[1] -94.10088
[1] 11.66221
[1] 1.855254
[1] 102.7441
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:30:15.311] [mlr3] Finished benchmark
INFO  [18:30:15.441] [bbotk] Result of batch 35:
INFO  [18:30:15.465] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:30:15.465] [bbotk]              -1.109759                         0.2097144
INFO  [18:30:15.465] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:30:15.465] [bbotk]                         0.2238143          -0.2569095               1.196424
INFO  [18:30:15.465] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:30:15.465] [bbotk]                         12                       4                 0.6158549
INFO  [18:30:15.465] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:30:15.465] [bbotk]  0.007294318 <list[8]>              FALSE     0.05421243        0      0
INFO  [18:30:15.465] [bbotk]  runtime_learners                                uhash
INFO  [18:30:15.465] [bbotk]            44.657 2f2a26d4-638c-4cd8-b549-d981e685d6b9
INFO  [18:30:18.126] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 66 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:30:24.833] [bbotk] Evaluating 1 configuration(s)
INFO  [18:30:25.364] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:30:25.590] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -47.64382
[1] 45.47351
[1] -122.2832
[1] -1.549214
[1] -4178.129
[1] -83.66257
[1] -112.8021
[1] 29.36587
[1] -90.73428
[1] 9.574585
INFO  [18:31:10.686] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -83.09968
[1] 43.29124
[1] -126.8692
[1] -4.073449
[1] -117.1138
[1] 94.63695
[1] -198.3131
[1] 28.87115
[1] -77.56274
[1] 88.48717
INFO  [18:31:42.853] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -83.69702
[1] 2.944044
[1] -190.581
[1] -3.83786
[1] -188.9701
[1] 35.62417
[1] -30.32537
[1] 42.54445
[1] -66.47303
[1] 12.56901
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:32:29.859] [mlr3] Finished benchmark
INFO  [18:32:29.990] [bbotk] Result of batch 36:
INFO  [18:32:30.028] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:32:30.028] [bbotk]               0.575287                         0.2787348
INFO  [18:32:30.028] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:32:30.028] [bbotk]                         0.7463999          -0.9885776               1.726022
INFO  [18:32:30.028] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:32:30.028] [bbotk]                         19                    4509                 0.9366858
INFO  [18:32:30.028] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:32:30.028] [bbotk]  0.01044984 <list[8]>              FALSE     0.02711731        0      0
INFO  [18:32:30.028] [bbotk]  runtime_learners                                uhash
INFO  [18:32:30.028] [bbotk]           123.492 5fa61cac-ca35-41ba-9cd1-67ee52387023
INFO  [18:32:31.443] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 67 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:32:35.375] [bbotk] Evaluating 1 configuration(s)
INFO  [18:32:35.411] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:32:35.452] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -140.2606
[1] 65.98177
[1] -16.25541
[1] 31.68379
[1] -33.95217
[1] 29.66645
[1] -374.9289
[1] -26.79082
[1] -74.17673
[1] -3.666705
INFO  [18:33:06.531] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -199.8552
[1] 10.13505
[1] -80.24088
[1] 118.3959
[1] -164.6009
[1] 24.31684
[1] -58.27196
[1] 19.07796
[1] -67.091
[1] 182.9199
INFO  [18:34:08.886] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -75.479
[1] 21.65981
[1] -68.72196
[1] -3.6014
[1] -963.8416
[1] -73.92127
[1] -39.16368
[1] 69.26949
[1] -38.81307
[1] 16.55918
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:34:53.549] [mlr3] Finished benchmark
INFO  [18:34:54.643] [bbotk] Result of batch 37:
INFO  [18:34:54.897] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:34:54.897] [bbotk]              -2.077173                         0.6434971
INFO  [18:34:54.897] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:34:54.897] [bbotk]                         0.8228809           -1.348839              -2.739131
INFO  [18:34:54.897] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:34:54.897] [bbotk]                         10                    3464                 0.7165121
INFO  [18:34:54.897] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:34:54.897] [bbotk]  0.008340508 <list[8]>              FALSE     0.02418807        0      0
INFO  [18:34:54.897] [bbotk]  runtime_learners                                uhash
INFO  [18:34:54.897] [bbotk]           136.777 9d4e051f-77a2-44c8-a91d-dfe66cc6d06b
INFO  [18:34:56.930] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 68 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:35:04.071] [bbotk] Evaluating 1 configuration(s)
INFO  [18:35:04.138] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:35:04.335] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -63.19427
[1] 42.46794
[1] -157.3418
[1] 25.89235
[1] -179.5833
[1] 40.34001
[1] -4546.509
[1] -99.62846
[1] -183.1237
[1] 18.06567
INFO  [18:35:44.031] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -4317.891
[1] -155.2275
[1] -78.84079
[1] 56.10515
[1] -103.8827
[1] 29.57147
[1] -1825.867
[1] -36.31991
[1] -73.77923
[1] 18.81032
INFO  [18:36:44.584] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -40.03704
[1] 118.4929
[1] -52.44075
[1] 40.31776
[1] -56.62019
[1] 29.46427
[1] -120.7617
[1] 21.72577
[1] -46.72267
[1] 105.2031
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:37:44.069] [mlr3] Finished benchmark
INFO  [18:37:44.220] [bbotk] Result of batch 38:
INFO  [18:37:44.251] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:37:44.251] [bbotk]              0.9626226                         0.9684085
INFO  [18:37:44.251] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:37:44.251] [bbotk]                         0.4434826          -0.4385329               4.675629
INFO  [18:37:44.251] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:37:44.251] [bbotk]                         17                    4477                  0.349345
INFO  [18:37:44.251] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:37:44.251] [bbotk]  0.007252658 <list[8]>              FALSE      0.0317158        0      0
INFO  [18:37:44.251] [bbotk]  runtime_learners                                uhash
INFO  [18:37:44.251] [bbotk]           158.755 b9e61bc7-782f-4b79-91ed-5c528dd98d6e
INFO  [18:37:46.171] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 69 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:37:53.863] [bbotk] Evaluating 1 configuration(s)
INFO  [18:37:54.053] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:37:54.212] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -81.14617
[1] 86.7465
[1] -135.6772
[1] 18.7644
[1] -158.1222
[1] -3.87868
[1] -2340.66
[1] -35.61813
[1] -23.40527
[1] 24.45321
INFO  [18:38:34.900] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -526.7908
[1] -18.70533
[1] -7271.872
[1] -228.8975
[1] -411.5486
[1] 4.9422
[1] -99.97318
[1] 22.03978
[1] -150.1074
[1] 17.9987
INFO  [18:39:04.230] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -44.56023
[1] -0.0006987356
[1] -2319.83
[1] -90.96981
[1] 23.48884
[1] 585.7518
[1] -1165.813
[1] 27.88171
[1] -27.61213
[1] 39.69374
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:39:38.195] [mlr3] Finished benchmark
INFO  [18:39:38.332] [bbotk] Result of batch 39:
INFO  [18:39:38.453] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:39:38.453] [bbotk]              -5.322465                         0.6368419
INFO  [18:39:38.453] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:39:38.453] [bbotk]                         0.8550884           -2.508633              -0.442293
INFO  [18:39:38.453] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:39:38.453] [bbotk]                          6                    2246                 0.5448728
INFO  [18:39:38.453] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:39:38.453] [bbotk]  0.006890616 <list[8]>              FALSE     0.02522682        0      0
INFO  [18:39:38.453] [bbotk]  runtime_learners                                uhash
INFO  [18:39:38.453] [bbotk]           102.359 61dd2500-b9eb-4d76-9186-ace481cf6f9a
WARN  [18:39:43.201] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:39:43.227] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 70 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:39:51.618] [bbotk] Evaluating 1 configuration(s)
INFO  [18:39:51.697] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:39:51.774] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -5382.936
[1] -140.8265
[1] -60.70142
[1] 34.56962
[1] -35.63991
[1] 21.28733
[1] -156.3161
[1] 8.345191
[1] -73.80401
[1] 2.692982
INFO  [18:40:36.770] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1752.228
[1] -84.22475
[1] -176.2988
[1] 1.504325
[1] -53.40815
[1] 24.28563
[1] -23.70195
[1] 51.60991
[1] -24.72487
[1] 40.49178
INFO  [18:41:28.498] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -209.0212
[1] 282.8329
[1] -9.250243
[1] 43.83933
[1] -31.68082
[1] 4.009847
[1] -1621.469
[1] -62.2619
[1] -46.12755
[1] 34.10094
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:42:06.652] [mlr3] Finished benchmark
INFO  [18:42:06.914] [bbotk] Result of batch 40:
INFO  [18:42:07.001] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:42:07.001] [bbotk]              -4.602426                         0.2721008
INFO  [18:42:07.001] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:42:07.001] [bbotk]                         0.4922534           -1.299926               1.733403
INFO  [18:42:07.001] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:42:07.001] [bbotk]                         10                    4349                 0.9864063
INFO  [18:42:07.001] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:42:07.001] [bbotk]  0.008223078 <list[8]>              FALSE     0.02378252        0      0
INFO  [18:42:07.001] [bbotk]  runtime_learners                                uhash
INFO  [18:42:07.001] [bbotk]           134.013 d10988a3-0924-446b-b031-c82ae5eac122
INFO  [18:42:09.267] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 71 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:42:18.982] [bbotk] Evaluating 1 configuration(s)
INFO  [18:42:19.256] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:42:19.391] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -10824.76
[1] -300.2376
[1] -70.26371
[1] 31.77848
[1] -75.82872
[1] 112.6406
[1] -715.1487
[1] -3.090277
[1] -1437.239
[1] -37.39661
INFO  [18:42:47.504] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -178.7053
[1] 36.34588
[1] -54.32824
[1] 28.53557
[1] -124.0795
[1] 9.905672
[1] -59.15595
[1] 21.58701
[1] -38.06917
[1] 23.73022
INFO  [18:43:21.350] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -60.04144
[1] 3.363482
[1] -361.348
[1] 15.98905
[1] -23.98411
[1] 52.26701
[1] -33.68242
[1] 28.45768
[1] -74.31949
[1] 26.58448
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:44:07.538] [mlr3] Finished benchmark
INFO  [18:44:07.698] [bbotk] Result of batch 41:
INFO  [18:44:08.047] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:44:08.047] [bbotk]              -1.060456                         0.1324197
INFO  [18:44:08.047] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:44:08.047] [bbotk]                         0.6350229           -1.820198              -1.634199
INFO  [18:44:08.047] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:44:08.047] [bbotk]                          2                    2873                 0.8056591
INFO  [18:44:08.047] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:44:08.047] [bbotk]  0.006385974 <list[8]>              FALSE     0.02103257        0      0
INFO  [18:44:08.047] [bbotk]  runtime_learners                                uhash
INFO  [18:44:08.047] [bbotk]           106.984 25d6cc59-bfb5-4d2d-95d0-0a61b5649b96
INFO  [18:44:11.125] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 72 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:44:17.735] [bbotk] Evaluating 1 configuration(s)
INFO  [18:44:18.078] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:44:18.288] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -740.4809
[1] -27.10569
[1] -85.57981
[1] 1.660077
[1] -18.83684
[1] 49.43591
[1] -101.5465
[1] 29.58961
[1] -69.91365
[1] 26.37064
INFO  [18:44:58.378] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -87.25965
[1] 13.87303
[1] -28.43094
[1] 31.86007
[1] -1746.461
[1] -49.53484
[1] -272.928
[1] 4.666173
[1] -696.4906
[1] -37.26411
INFO  [18:45:42.671] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -96.29149
[1] 1.648055
[1] -21.75715
[1] 38.60948
[1] -27.52202
[1] 36.01039
[1] -44.5632
[1] 27.34749
[1] -105.6
[1] 15.43058
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:46:15.671] [mlr3] Finished benchmark
INFO  [18:46:16.590] [bbotk] Result of batch 42:
INFO  [18:46:16.681] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:46:16.681] [bbotk]              -5.775043                         0.4393577
INFO  [18:46:16.681] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:46:16.681] [bbotk]                         0.1862682           -3.086478              0.4105715
INFO  [18:46:16.681] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:46:16.681] [bbotk]                         13                    3038                 0.6763677
INFO  [18:46:16.681] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:46:16.681] [bbotk]  0.007002275 <list[8]>              FALSE     0.02276844        0      0
INFO  [18:46:16.681] [bbotk]  runtime_learners                                uhash
INFO  [18:46:16.681] [bbotk]            116.62 623451db-5944-4bbd-8535-a0ca68efdd80
INFO  [18:46:19.448] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 73 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:46:26.130] [bbotk] Evaluating 1 configuration(s)
INFO  [18:46:26.427] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:46:26.667] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -125.1506
[1] -3.681996
[1] -62.84436
[1] 47.248
[1] -117.0938
[1] 54.32362
[1] -55.18891
[1] 109.6067
[1] -85.56756
[1] 19.1111
INFO  [18:47:08.187] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -81.56661
[1] 26.9929
[1] -160.1754
[1] 94.97096
[1] -136.3145
[1] 8.299898
[1] -80.29915
[1] 26.09944
[1] -37.21834
[1] 205.5523
INFO  [18:47:53.842] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -43.24774
[1] 38.16883
[1] -22.08203
[1] 55.07318
[1] -1234.083
[1] -49.15246
[1] -149.7252
[1] -3.915105
[1] -135.2622
[1] 20.76107
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:48:41.349] [mlr3] Finished benchmark
INFO  [18:48:41.581] [bbotk] Result of batch 43:
INFO  [18:48:41.659] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:48:41.659] [bbotk]              0.5591569                         0.9994701
INFO  [18:48:41.659] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:48:41.659] [bbotk]                         0.4596114           -1.997841              0.3415833
INFO  [18:48:41.659] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:48:41.659] [bbotk]                         12                    4834                 0.3073668
INFO  [18:48:41.659] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:48:41.659] [bbotk]  0.007091005 <list[8]>              FALSE     0.02573976        0      0
INFO  [18:48:41.659] [bbotk]  runtime_learners                                uhash
INFO  [18:48:41.659] [bbotk]           133.829 88e6adbf-e56f-449d-b2b2-22a5f2dadeda
WARN  [18:48:44.048] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:48:44.114] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 74 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:48:55.621] [bbotk] Evaluating 1 configuration(s)
INFO  [18:48:55.764] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:48:55.945] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1189.775
[1] -32.91582
[1] -51.19918
[1] 30.79206
[1] -90.47808
[1] 15.11315
[1] -56.08668
[1] 42.70805
[1] 60.35095
[1] 1671.306
INFO  [18:49:33.364] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -123.1282
[1] 56.65275
[1] -32.43603
[1] 15.16553
[1] -41.49532
[1] 51.14133
[1] -49.20872
[1] 48.23723
[1] -833.0187
[1] -42.58619
INFO  [18:50:09.513] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -3364.923
[1] -83.528
[1] -79.50953
[1] 11.42759
[1] -201.6685
[1] 8.178311
[1] -33.53062
[1] 64.12776
[1] -25.74867
[1] 45.43091
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:50:54.802] [mlr3] Finished benchmark
INFO  [18:50:55.705] [bbotk] Result of batch 44:
INFO  [18:50:55.747] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:50:55.747] [bbotk]              -2.436556                         0.2870292
INFO  [18:50:55.747] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:50:55.747] [bbotk]                         0.2409783           -3.217746              -5.044285
INFO  [18:50:55.747] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:50:55.747] [bbotk]                          5                    4812                 0.5404607
INFO  [18:50:55.747] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:50:55.747] [bbotk]  0.006476068 <list[8]>              FALSE     0.02281692        0      0
INFO  [18:50:55.747] [bbotk]  runtime_learners                                uhash
INFO  [18:50:55.747] [bbotk]           117.072 ff160f05-4627-43a0-b7dc-3aca4dba94b9
INFO  [18:51:00.362] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 75 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:51:13.188] [bbotk] Evaluating 1 configuration(s)
INFO  [18:51:13.370] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:51:13.478] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -85.01684
[1] 34.56863
[1] -223.6909
[1] -3.887235
[1] -52.42981
[1] 45.13846
[1] 301.3778
[1] 9183.632
[1] -117.5522
[1] -4.138534
INFO  [18:51:44.598] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -83.76338
[1] 37.55844
[1] -357.2838
[1] 25.73803
[1] -119.7603
[1] -4.593621
[1] -91.93532
[1] -4.31204
[1] -84.00715
[1] 55.54006
INFO  [18:52:20.708] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -36.88548
[1] 56.80657
[1] -213.0716
[1] 6.854239
[1] -49.09733
[1] 24.82547
[1] -99.44517
[1] 124.9369
[1] -10.27346
[1] 105.4605
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:52:57.498] [mlr3] Finished benchmark
INFO  [18:52:57.630] [bbotk] Result of batch 45:
INFO  [18:52:57.646] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:52:57.646] [bbotk]              0.6742148                         0.2466198
INFO  [18:52:57.646] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:52:57.646] [bbotk]                         0.8490962           -1.517883               2.111134
INFO  [18:52:57.646] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:52:57.646] [bbotk]                         19                    2050                 0.5700747
INFO  [18:52:57.646] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:52:57.646] [bbotk]  0.006532121 <list[8]>              FALSE     0.02865193        0      0
INFO  [18:52:57.646] [bbotk]  runtime_learners                                uhash
INFO  [18:52:57.646] [bbotk]           103.051 4dae87a9-20d5-46e6-ac8a-b60cebd87882
WARN  [18:53:00.357] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:53:00.375] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 76 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:53:07.714] [bbotk] Evaluating 1 configuration(s)
INFO  [18:53:07.990] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:53:08.134] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -62.38463
[1] 67.67149
[1] -147.9872
[1] 6.484898
[1] -64.50365
[1] 175.7293
[1] -1762.99
[1] -47.83986
[1] -48.82509
[1] 38.66179
INFO  [18:53:29.935] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -45.18738
[1] 61.68013
[1] -114.3435
[1] 7.993346
[1] -117.939
[1] 17.58011
[1] -66.00063
[1] 80.72491
[1] -71.29185
[1] 79.65256
INFO  [18:54:08.108] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -15.61035
[1] 111.0671
[1] -68.84039
[1] 9.905368
[1] -48.23888
[1] 23.55451
[1] -3.919528e+16
[1] 7.99527e+15
[1] -59.38192
[1] 65.3093
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:54:44.154] [mlr3] Finished benchmark
INFO  [18:54:45.222] [bbotk] Result of batch 46:
INFO  [18:54:45.326] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:54:45.326] [bbotk]              -6.216326                         0.8603797
INFO  [18:54:45.326] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:54:45.326] [bbotk]                         0.2098659           -4.388958              -4.810865
INFO  [18:54:45.326] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:54:45.326] [bbotk]                          9                    2534                   0.21649
INFO  [18:54:45.326] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:54:45.326] [bbotk]  0.006314776 <list[8]>              FALSE     0.02420524        0      0
INFO  [18:54:45.326] [bbotk]  runtime_learners                                uhash
INFO  [18:54:45.326] [bbotk]            95.701 7baaa531-8051-4ecb-a9e2-23cfcee6ae9c
INFO  [18:54:50.142] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 77 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:55:15.351] [bbotk] Evaluating 1 configuration(s)
INFO  [18:55:15.765] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:55:15.955] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -2581.884
[1] -105.1544
[1] -237.3795
[1] 73.9094
[1] -50.88773
[1] 16.37319
[1] -381.6596
[1] -4.007517
[1] -66.54025
[1] 59.8081
INFO  [18:55:48.210] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 24.01626
[1] 300.6614
[1] -1724.508
[1] -61.36898
[1] -98.7418
[1] 31.05877
[1] -85.88238
[1] 13.81434
[1] -108.101
[1] 6.928825
INFO  [18:56:12.849] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -23.60745
[1] 32.6581
[1] -1023.36
[1] -29.76813
[1] -23.97956
[1] 38.69754
[1] -44.34379
[1] 41.93609
[1] -195.6483
[1] -3.822561
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:56:39.801] [mlr3] Finished benchmark
INFO  [18:56:40.014] [bbotk] Result of batch 47:
INFO  [18:56:40.051] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:56:40.051] [bbotk]              -6.714749                         0.9200082
INFO  [18:56:40.051] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:56:40.051] [bbotk]                         0.1414723           -4.325687              -2.598069
INFO  [18:56:40.051] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:56:40.051] [bbotk]                         10                    1579                 0.4364551
INFO  [18:56:40.051] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:56:40.051] [bbotk]  0.006393512 <list[8]>              FALSE     0.02483152        0      0
INFO  [18:56:40.051] [bbotk]  runtime_learners                                uhash
INFO  [18:56:40.051] [bbotk]            83.063 9f000b43-1a7d-48bc-95a1-087a561167a1
INFO  [18:56:47.661] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 78 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:56:59.973] [bbotk] Evaluating 1 configuration(s)
INFO  [18:57:00.228] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:57:00.266] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -185.7737
[1] 47.6789
[1] -23.70163
[1] 62.87636
[1] -92.1903
[1] 211.2559
[1] -20.08605
[1] 148.7132
[1] -72.71245
[1] -3.33986
INFO  [18:57:15.874] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -52.6602
[1] 41.56415
[1] -45.3356
[1] 15.43037
[1] -103.7142
[1] 6.432537
[1] -93.34334
[1] 11.0192
[1] -63.29203
[1] 28.26976
INFO  [18:57:34.216] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2.223961e+16
[1] 4.526676e+16
[1] -59.45524
[1] 45.91115
[1] -32.92074
[1] 22.09189
[1] -132.0961
[1] -4.156703
[1] -157.975
[1] 130.3246
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:57:50.092] [mlr3] Finished benchmark
INFO  [18:57:50.175] [bbotk] Result of batch 48:
INFO  [18:57:50.185] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:57:50.185] [bbotk]              -5.019936                         0.9199873
INFO  [18:57:50.185] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:57:50.185] [bbotk]                         0.8160566           -2.035061               1.830016
INFO  [18:57:50.185] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:57:50.185] [bbotk]                         20                     102                 0.8912163
INFO  [18:57:50.185] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:57:50.185] [bbotk]  0.008322895 <list[8]>              FALSE     0.02718607        0      0
INFO  [18:57:50.185] [bbotk]  runtime_learners                                uhash
INFO  [18:57:50.185] [bbotk]            49.452 eba3346a-74b9-49b1-8a88-e43f807d501b
INFO  [18:57:57.779] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 79 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:58:07.063] [bbotk] Evaluating 1 configuration(s)
INFO  [18:58:07.154] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:58:07.250] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -159.0565
[1] 11.67694
[1] -52.10905
[1] 50.94522
[1] -117.3227
[1] 47.69505
[1] -1932.938
[1] -55.73415
[1] -59.20054
[1] 14.48855
INFO  [18:58:34.763] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -731.7531
[1] -30.49924
[1] -117.3821
[1] 25.4444
[1] -49.1197
[1] 83.57048
[1] -60.13519
[1] 28.85767
[1] -110.2837
[1] -4.14747
INFO  [18:58:56.448] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 113.667
[1] 3281.155
[1] -253.981
[1] -3.604553
[1] -64.40721
[1] 29.07381
[1] 4.108151
[1] 70.151
[1] -76.1619
[1] -4.343298
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:59:21.975] [mlr3] Finished benchmark
INFO  [18:59:22.157] [bbotk] Result of batch 49:
INFO  [18:59:22.180] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:59:22.180] [bbotk]              -4.146202                         0.9494687
INFO  [18:59:22.180] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:59:22.180] [bbotk]                         0.5295954           -2.613104              -6.047337
INFO  [18:59:22.180] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:59:22.180] [bbotk]                         15                     701                  0.186451
INFO  [18:59:22.180] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:59:22.180] [bbotk]  0.006399151 <list[8]>              FALSE     0.02640793        0      0
INFO  [18:59:22.180] [bbotk]  runtime_learners                                uhash
INFO  [18:59:22.180] [bbotk]            74.163 b0ffafb8-f7c9-417c-82c5-5fddbe0076cd
WARN  [18:59:25.955] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:59:25.968] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 80 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:59:32.128] [bbotk] Evaluating 1 configuration(s)
INFO  [18:59:32.294] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:59:32.385] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -41.84707
[1] 35.16138
[1] -63.89211
[1] 34.63857
[1] -24.98448
[1] 29.64151
[1] -1912.172
[1] -85.79695
[1] -83.17233
[1] 15.17741
INFO  [19:00:26.294] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -67.55704
[1] 21.84504
[1] -1877.417
[1] -95.13441
[1] 41.34349
[1] 1718.593
[1] -48.99452
[1] 31.87478
[1] -30.37234
[1] 22.17369
INFO  [19:01:15.687] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -56.64242
[1] 3.011335
[1] -44.16902
[1] 7.994638
[1] -64.15909
[1] 59.88424
[1] -36.7142
[1] 67.95186
[1] -58.40125
[1] 120.3291
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:01:59.349] [mlr3] Finished benchmark
INFO  [19:02:00.381] [bbotk] Result of batch 50:
INFO  [19:02:00.522] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:02:00.522] [bbotk]              -2.428955                         0.1970277
INFO  [19:02:00.522] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:02:00.522] [bbotk]                         0.3941259           -1.647546               -0.20791
INFO  [19:02:00.522] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:02:00.522] [bbotk]                          5                    4020                  0.954621
INFO  [19:02:00.522] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:02:00.522] [bbotk]  0.006064961 <list[8]>              FALSE     0.02209046        0      0
INFO  [19:02:00.522] [bbotk]  runtime_learners                                uhash
INFO  [19:02:00.522] [bbotk]           146.722 790de0be-f674-4128-889d-94f940771a86
INFO  [19:02:24.732] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 81 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:02:54.391] [bbotk] Evaluating 1 configuration(s)
INFO  [19:02:54.592] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:02:54.623] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -39.35342
[1] 22.03012
[1] -26.45842
[1] 53.48374
[1] -1959.812
[1] -50.83971
[1] -58.62483
[1] 9.53518
[1] -286.8159
[1] -3.839281
INFO  [19:03:49.379] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -49.73096
[1] 30.83035
[1] -1528.087
[1] -37.27011
[1] -226.5559
[1] 18.00109
[1] -59.41586
[1] 50.46476
[1] -62.97259
[1] 25.87841
INFO  [19:04:39.294] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -55.72791
[1] 45.60983
[1] -107.342
[1] 30.63904
[1] -36.91843
[1] 98.84979
[1] -61.3244
[1] -0.3824238
[1] -43.65058
[1] 19.13358
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:05:19.432] [mlr3] Finished benchmark
INFO  [19:05:19.573] [bbotk] Result of batch 51:
INFO  [19:05:19.631] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:05:19.631] [bbotk]             -0.2757484                         0.2544698
INFO  [19:05:19.631] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:05:19.631] [bbotk]                         0.1043273           -1.262773              0.1358416
INFO  [19:05:19.631] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:05:19.631] [bbotk]                         11                    3480                 0.9498626
INFO  [19:05:19.631] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:05:19.631] [bbotk]  0.00611852 <list[8]>              FALSE     0.02513244        0      0
INFO  [19:05:19.631] [bbotk]  runtime_learners                                uhash
INFO  [19:05:19.631] [bbotk]           144.465 65697578-1c6d-4db0-b5e6-8c57ebb95c20
INFO  [19:05:25.443] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 82 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:05:33.545] [bbotk] Evaluating 1 configuration(s)
INFO  [19:05:33.604] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:05:33.631] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -35.47791
[1] 20.67448
[1] -48.62834
[1] 38.81728
[1] -103.3651
[1] 8.22715
[1] -42.22226
[1] 34.38648
[1] -31.54117
[1] 59.69692
INFO  [19:06:15.161] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -54.53216
[1] 36.72921
[1] -55.79485
[1] 16.73236
[1] -72.70482
[1] 22.83696
[1] -567.9837
[1] -35.76372
[1] -55.1241
[1] 37.73227
INFO  [19:06:53.768] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -47.88964
[1] 43.49047
[1] -38.40181
[1] 16.79632
[1] -41.7488
[1] 69.65933
[1] -234.2191
[1] 0.861263
[1] -56.44224
[1] 13.39809
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:07:51.823] [mlr3] Finished benchmark
INFO  [19:07:51.901] [bbotk] Result of batch 52:
INFO  [19:07:51.920] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:07:51.920] [bbotk]             -0.4471149                         0.5671587
INFO  [19:07:51.920] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:07:51.920] [bbotk]                         0.5722706           -1.590483               -3.07432
INFO  [19:07:51.920] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:07:51.920] [bbotk]                         17                    4942                 0.6149998
INFO  [19:07:51.920] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:07:51.920] [bbotk]  0.005132008 <list[8]>              FALSE     0.02287514        0      0
INFO  [19:07:51.920] [bbotk]  runtime_learners                                uhash
INFO  [19:07:51.920] [bbotk]           138.021 a96acbdc-146c-4a36-90db-c96ae039a637
INFO  [19:07:59.819] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 83 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:08:05.475] [bbotk] Evaluating 1 configuration(s)
INFO  [19:08:05.493] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:08:05.520] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -25.83077
[1] 30.5258
[1] -30.70483
[1] 22.66188
[1] -4187.628
[1] -112.3679
[1] -43.28185
[1] 33.15794
[1] -45.52534
[1] 116.9951
INFO  [19:08:36.502] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -35.35447
[1] 45.92964
[1] -35.91639
[1] 83.32442
[1] -55.49113
[1] 13.38973
[1] -61.92639
[1] 18.61593
[1] -118.1092
[1] 0.3632633
INFO  [19:09:34.629] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -58.90991
[1] 17.78233
[1] 107.2061
[1] 3721.628
[1] -246.3787
[1] 9.527418
[1] -35.05386
[1] 16.37259
[1] -2672.562
[1] -67.53719
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:10:49.374] [mlr3] Finished benchmark
INFO  [19:10:49.831] [bbotk] Result of batch 53:
INFO  [19:10:49.840] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:10:49.840] [bbotk]              -2.585248                         0.3935023
INFO  [19:10:49.840] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:10:49.840] [bbotk]                         0.7699955           -3.684288              -4.058077
INFO  [19:10:49.840] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:10:49.840] [bbotk]                         19                    4590                 0.9661511
INFO  [19:10:49.840] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:10:49.840] [bbotk]  0.005622348 <list[8]>              FALSE      0.0268555        0      0
INFO  [19:10:49.840] [bbotk]  runtime_learners                                uhash
INFO  [19:10:49.840] [bbotk]           163.186 d661eccc-f46f-47c5-862b-b96b8386496d
INFO  [19:10:51.291] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 84 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:11:00.790] [bbotk] Evaluating 1 configuration(s)
INFO  [19:11:00.867] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:11:00.883] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -77.37775
[1] 25.55643
[1] -35.43741
[1] 27.03451
[1] -1044.039
[1] 4.927836
[1] -43.31645
[1] 113.5112
[1] -924.7111
[1] -62.72812
INFO  [19:11:39.691] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -59.97712
[1] 24.2774
[1] -65.20848
[1] 26.74041
[1] -145.4379
[1] -0.3941728
[1] -48.21006
[1] 44.42324
[1] -386.7015
[1] 34.00596
INFO  [19:12:21.131] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -70.13913
[1] 48.9811
[1] -63.17314
[1] 6.180556
[1] -51.87248
[1] 6.653693
[1] -30.35366
[1] 25.61464
[1] 65.98061
[1] 1752.571
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:12:55.620] [mlr3] Finished benchmark
INFO  [19:12:55.858] [bbotk] Result of batch 54:
INFO  [19:12:55.878] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:12:55.878] [bbotk]              -4.820761                         0.2074451
INFO  [19:12:55.878] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:12:55.878] [bbotk]                         0.7855488           -1.175621                1.86513
INFO  [19:12:55.878] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:12:55.878] [bbotk]                          7                    1740                 0.7763293
INFO  [19:12:55.878] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:12:55.878] [bbotk]  0.006501503 <list[8]>              FALSE     0.02415309        0      0
INFO  [19:12:55.878] [bbotk]  runtime_learners                                uhash
INFO  [19:12:55.878] [bbotk]           114.401 c8a7dfba-935c-4d5a-b175-ae713a719571
INFO  [19:13:01.333] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 85 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:13:10.666] [bbotk] Evaluating 1 configuration(s)
INFO  [19:13:10.918] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:13:10.992] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -304.7669
[1] -3.382286
[1] -122.3104
[1] 69.48802
[1] -82.8636
[1] 64.42731
[1] -206.236
[1] 76.8141
[1] -80.987
[1] 16.43519
INFO  [19:13:49.937] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -44.9477
[1] 20.76677
[1] -71.40099
[1] 34.14009
[1] -1481.144
[1] -53.2542
[1] -181.7084
[1] 72.49582
[1] -71.09698
[1] 112.3115
INFO  [19:14:32.456] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -63.76304
[1] 38.39695
[1] -147.621
[1] -3.393741
[1] -28.44539
[1] 73.71178
[1] -32.25568
[1] 32.59424
[1] -42.10803
[1] 38.3453
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:15:13.091] [mlr3] Finished benchmark
INFO  [19:15:13.919] [bbotk] Result of batch 55:
INFO  [19:15:14.005] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:15:14.005] [bbotk]              -6.460469                         0.3979249
INFO  [19:15:14.005] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:15:14.005] [bbotk]                         0.5525418           -4.368053              -1.497386
INFO  [19:15:14.005] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:15:14.005] [bbotk]                         12                    3220                 0.2455986
INFO  [19:15:14.005] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:15:14.005] [bbotk]  0.004845716 <list[8]>              FALSE     0.02503342        0      0
INFO  [19:15:14.005] [bbotk]  runtime_learners                                uhash
INFO  [19:15:14.005] [bbotk]           121.666 146cbeac-83f1-40be-9152-68106deb12b0
WARN  [19:15:15.770] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:15:15.846] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 86 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:15:24.783] [bbotk] Evaluating 1 configuration(s)
INFO  [19:15:24.857] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:15:24.906] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -618.8931
[1] -54.30708
[1] -248.3904
[1] -4.030256
[1] -39.43998
[1] 50.68021
[1] -68.85907
[1] 12.36977
[1] -77.50048
[1] 15.27417
INFO  [19:15:58.191] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -53.58736
[1] 27.37797
[1] -845.9851
[1] -29.93217
[1] -135.3432
[1] 1.073158
[1] -55.77281
[1] 19.38376
[1] -174.1145
[1] 24.49823
INFO  [19:16:30.033] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -31.04865
[1] 33.80031
[1] -35.48591
[1] 37.96848
[1] -147.9736
[1] 6.456898
[1] -107.8066
[1] -3.070743
[1] -51.05161
[1] 6.771482
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:17:11.856] [mlr3] Finished benchmark
INFO  [19:17:12.707] [bbotk] Result of batch 56:
INFO  [19:17:12.775] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:17:12.775] [bbotk]              -2.179908                         0.7345443
INFO  [19:17:12.775] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:17:12.775] [bbotk]                         0.9177007            -3.31323              -1.516959
INFO  [19:17:12.775] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:17:12.775] [bbotk]                         11                     792                 0.7917429
INFO  [19:17:12.775] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:17:12.775] [bbotk]  0.007726866 <list[8]>              FALSE     0.02487602        0      0
INFO  [19:17:12.775] [bbotk]  runtime_learners                                uhash
INFO  [19:17:12.775] [bbotk]           106.205 cadbb695-ae4f-42fe-b91d-1cbfd1a50c5c
INFO  [19:17:19.808] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 87 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:17:49.985] [bbotk] Evaluating 1 configuration(s)
INFO  [19:17:50.129] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:17:50.179] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -72.06474
[1] 70.16118
[1] -211.6006
[1] -3.254324
[1] -20.44353
[1] 40.17194
[1] -98.57914
[1] 13.01415
[1] -92.8455
[1] 52.21334
INFO  [19:18:21.770] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1818.688
[1] -66.49774
[1] -59.70658
[1] 20.54862
[1] -1347.252
[1] -57.38683
[1] -93.46135
[1] 38.2999
[1] -71.45881
[1] 7.890277
INFO  [19:19:23.486] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -29.32607
[1] 64.23967
[1] -19.8084
[1] 20.83409
[1] -50.64727
[1] 26.64319
[1] -34.77029
[1] 37.72224
[1] -110.4166
[1] 25.30662
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:20:15.227] [mlr3] Finished benchmark
INFO  [19:20:15.304] [bbotk] Result of batch 57:
INFO  [19:20:15.370] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:20:15.370] [bbotk]               -5.94956                         0.1340081
INFO  [19:20:15.370] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:20:15.370] [bbotk]                         0.9157514             -2.2497                2.64127
INFO  [19:20:15.370] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:20:15.370] [bbotk]                         16                    3875                 0.9223679
INFO  [19:20:15.370] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:20:15.370] [bbotk]  0.004794491 <list[8]>              FALSE     0.02272584        0      0
INFO  [19:20:15.370] [bbotk]  runtime_learners                                uhash
INFO  [19:20:15.370] [bbotk]           144.709 34783271-ef66-4a11-937e-0dba021413d1
INFO  [19:20:18.640] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 88 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:20:28.874] [bbotk] Evaluating 1 configuration(s)
INFO  [19:20:29.445] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:20:29.671] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -42.22334
[1] 122.1345
[1] -154.1698
[1] 33.36672
[1] -31.62048
[1] 23.24796
[1] -59.45914
[1] 20.72639
[1] -154.3452
[1] -3.952123
INFO  [19:21:29.041] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -149.0711
[1] -1.344439
[1] -3882.789
[1] -88.644
[1] -387.4272
[1] 38.96265
[1] -57.18168
[1] 24.34543
[1] -99.19808
[1] 4.843493
INFO  [19:22:06.954] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -11485.18
[1] -139.9136
[1] -43.68049
[1] 19.68384
[1] -9129.952
[1] -127.851
[1] -35.86299
[1] 15.81112
[1] -351.1989
[1] 14.30061
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:22:37.495] [mlr3] Finished benchmark
INFO  [19:22:38.145] [bbotk] Result of batch 58:
INFO  [19:22:38.181] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:22:38.181] [bbotk]             -0.3943408                          0.775779
INFO  [19:22:38.181] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:22:38.181] [bbotk]                          0.681087           -3.273816             -0.8997746
INFO  [19:22:38.181] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:22:38.181] [bbotk]                          2                    1567                 0.7592441
INFO  [19:22:38.181] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:22:38.181] [bbotk]  0.004969752 <list[8]>              FALSE     0.02449574        0      0
INFO  [19:22:38.181] [bbotk]  runtime_learners                                uhash
INFO  [19:22:38.181] [bbotk]           127.603 308c8ffd-20e6-4b69-8e35-7698811ce334
WARN  [19:22:41.220] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:22:41.270] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 89 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:22:52.694] [bbotk] Evaluating 1 configuration(s)
INFO  [19:22:52.719] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:22:52.734] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -73.83604
[1] 12.51035
[1] -1.860907e+16
[1] 1.435488e+16
[1] -130.2989
[1] 8.187782
[1] -25.60267
[1] 74.67325
[1] -43.51753
[1] 35.42288
INFO  [19:24:00.289] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -229.6475
[1] 16.4961
[1] -1882.549
[1] -56.95181
[1] -267.6879
[1] 28.1945
[1] -47.97353
[1] 30.83306
[1] -4407.188
[1] -109.0853
INFO  [19:24:49.921] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -66.80155
[1] 9.914272
[1] -27.20749
[1] 154.7756
[1] -30.00764
[1] 49.01765
[1] -332.9706
[1] 84.8403
[1] -43.33381
[1] 33.21069
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:26:07.967] [mlr3] Finished benchmark
INFO  [19:26:09.110] [bbotk] Result of batch 59:
INFO  [19:26:09.682] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:26:09.682] [bbotk]              -6.303268                         0.2734814
INFO  [19:26:09.682] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:26:09.682] [bbotk]                         0.1433292           -3.761693             -0.6106609
INFO  [19:26:09.682] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:26:09.682] [bbotk]                          1                    4837                 0.4648541
INFO  [19:26:09.682] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:26:09.682] [bbotk]  0.004898173 <list[8]>              FALSE     0.02419469        0      0
INFO  [19:26:09.682] [bbotk]  runtime_learners                                uhash
INFO  [19:26:09.682] [bbotk]           195.004 7d92398c-449f-45b0-b134-9fe4eba77b8e
INFO  [19:26:20.004] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 90 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:26:30.498] [bbotk] Evaluating 1 configuration(s)
INFO  [19:26:30.538] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:26:30.552] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -192.4543
[1] 71.46008
[1] -30.8035
[1] 22.97817
[1] -6044.298
[1] -286.7291
[1] -118.9612
[1] -3.176205
[1] -26.21324
[1] 41.61499
INFO  [19:27:16.209] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -52.4589
[1] 63.04233
[1] -175.5048
[1] 25.52026
[1] -62.91328
[1] 81.9482
[1] -39.50258
[1] 16.83383
[1] -62.93475
[1] 6.725035
INFO  [19:27:44.634] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -6124.929
[1] -286.4326
[1] -1714.281
[1] 7.269385
[1] -14.34936
[1] 31.97874
[1] 107.7822
[1] 3103.103
[1] -9.624977
[1] 74.64334
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:28:18.310] [mlr3] Finished benchmark
INFO  [19:28:18.389] [bbotk] Result of batch 60:
INFO  [19:28:18.409] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:28:18.409] [bbotk]               -4.31481                         0.1445661
INFO  [19:28:18.409] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:28:18.409] [bbotk]                         0.7077389           -1.977011               -4.79952
INFO  [19:28:18.409] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:28:18.409] [bbotk]                         19                    1940                  0.803673
INFO  [19:28:18.409] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:28:18.409] [bbotk]  0.004236652 <list[8]>              FALSE     0.02646537        0      0
INFO  [19:28:18.409] [bbotk]  runtime_learners                                uhash
INFO  [19:28:18.409] [bbotk]            107.35 506f6eca-f2ee-40b6-b9e6-86e301b3dc55
INFO  [19:28:26.280] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 91 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:28:40.868] [bbotk] Evaluating 1 configuration(s)
INFO  [19:28:41.350] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:28:41.531] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -23.71977
[1] 15.56908
[1] -12.84201
[1] 54.21402
[1] 33.90781
[1] 817.8792
[1] -106.6092
[1] 4.002445
[1] -36.89669
[1] 30.17175
INFO  [19:30:47.528] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -30.43848
[1] 35.69965
[1] -72.46197
[1] 134.2992
[1] -59.53582
[1] 6.657958
[1] -34.00292
[1] 25.0165
[1] -92.10168
[1] -3.634887
INFO  [19:32:16.617] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -37.59617
[1] 3.5834
[1] 69.16746
[1] 2188.224
[1] -62.80121
[1] 11.19189
[1] -50.80697
[1] 8.417738
[1] -48.79795
[1] 47.22381
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:34:21.535] [mlr3] Finished benchmark
INFO  [19:34:21.986] [bbotk] Result of batch 61:
INFO  [19:34:21.996] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:34:21.996] [bbotk]              -1.442331                         0.8433698
INFO  [19:34:21.996] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:34:21.996] [bbotk]                         0.9265038           -5.482781              -4.111664
INFO  [19:34:21.996] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:34:21.996] [bbotk]                         13                    4800                 0.9815874
INFO  [19:34:21.996] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:34:21.996] [bbotk]  0.00410206 <list[8]>              FALSE     0.02938987        0      0
INFO  [19:34:21.996] [bbotk]  runtime_learners                                uhash
INFO  [19:34:21.996] [bbotk]           339.494 168c25a5-1dbc-4bfa-87a7-c4398820760e
INFO  [19:34:25.449] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 92 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:34:48.947] [bbotk] Evaluating 1 configuration(s)
INFO  [19:34:49.106] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:34:49.144] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -26919.81
[1] -1100.484
[1] -66.49766
[1] 22.06878
[1] -116.0918
[1] 95.51155
[1] -54.30087
[1] 45.36741
[1] -52.97898
[1] 31.19029
INFO  [19:35:54.763] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -93.4668
[1] 34.66793
[1] -68.21898
[1] 264.3391
[1] -83.94699
[1] 5.417392
[1] -66.22514
[1] 83.00277
[1] -25.07486
[1] 139.4503
INFO  [19:37:03.574] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -16.5725
[1] 61.06412
[1] -58.87617
[1] 28.44752
[1] -85.114
[1] -3.294056
[1] -144.786
[1] 83.01305
[1] -1123.116
[1] -30.70794
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:38:12.153] [mlr3] Finished benchmark
INFO  [19:38:12.272] [bbotk] Result of batch 62:
INFO  [19:38:12.279] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:38:12.279] [bbotk]               1.000162                         0.5949488
INFO  [19:38:12.279] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:38:12.279] [bbotk]                         0.9867872          -0.5952646               4.322827
INFO  [19:38:12.279] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:38:12.279] [bbotk]                         17                    2228                 0.7518832
INFO  [19:38:12.279] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:38:12.279] [bbotk]  0.004897015 <list[8]>              FALSE     0.02702498        0      0
INFO  [19:38:12.279] [bbotk]  runtime_learners                                uhash
INFO  [19:38:12.279] [bbotk]           202.325 a22ae5a3-1932-43eb-b2eb-50e54ac2d371
INFO  [19:38:33.038] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 93 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:38:54.609] [bbotk] Evaluating 1 configuration(s)
INFO  [19:38:55.186] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:38:55.353] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -192.8294
[1] 0.4924936
[1] -99.56045
[1] 17.95825
[1] -20.31487
[1] 76.69249
[1] -51.38137
[1] 33.54204
[1] -51.49153
[1] 150.5693
INFO  [19:39:49.332] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -3031.373
[1] -89.01118
[1] -42.65005
[1] 15.45157
[1] -1.98317e+16
[1] 2.272582e+16
[1] -20.35179
[1] 100.9004
[1] -36.0021
[1] 28.61515
INFO  [19:40:55.606] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -18.4666
[1] 42.21236
[1] -25.52175
[1] 14.14525
[1] -41.60292
[1] 16.80997
[1] -19.7963
[1] 174.1263
[1] -44.77168
[1] 39.20446
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:41:31.693] [mlr3] Finished benchmark
INFO  [19:41:32.813] [bbotk] Result of batch 63:
INFO  [19:41:32.823] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:41:32.823] [bbotk]               -5.99554                         0.1963956
INFO  [19:41:32.823] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:41:32.823] [bbotk]                         0.7983025          -0.2564927              -4.778326
INFO  [19:41:32.823] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:41:32.823] [bbotk]                          6                    2769                 0.8274733
INFO  [19:41:32.823] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:41:32.823] [bbotk]  0.004096263 <list[8]>              FALSE     0.02655366        0      0
INFO  [19:41:32.823] [bbotk]  runtime_learners                                uhash
INFO  [19:41:32.823] [bbotk]            155.75 77aaf1c5-186b-4ae6-aa09-82ea207c2a1d
INFO  [19:41:39.970] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 94 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:42:01.559] [bbotk] Evaluating 1 configuration(s)
INFO  [19:42:02.116] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:42:02.178] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -100.5375
[1] -4.05747
[1] -79.76991
[1] 12.35423
[1] -229.3314
[1] -3.768955
[1] -41.59567
[1] 33.22781
[1] -94.45694
[1] 29.44349
INFO  [19:43:12.851] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -37.96954
[1] 36.93475
[1] -143.4705
[1] 35.56647
[1] -45.33222
[1] 43.22306
[1] 27.63266
[1] 579.7256
[1] -66.15305
[1] 5.67822
INFO  [19:44:21.304] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -885.9696
[1] -3.976333
[1] -91.05723
[1] 7.186265
[1] -29.30744
[1] 93.29441
[1] -19.0278
[1] 37.06682
[1] -31.14399
[1] 85.44147
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:45:06.298] [mlr3] Finished benchmark
INFO  [19:45:07.354] [bbotk] Result of batch 64:
INFO  [19:45:07.575] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:45:07.575] [bbotk]              -1.218512                         0.2835259
INFO  [19:45:07.575] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:45:07.575] [bbotk]                          0.661163           -2.494426              -2.080714
INFO  [19:45:07.575] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:45:07.575] [bbotk]                          9                    4114                 0.8674934
INFO  [19:45:07.575] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:45:07.575] [bbotk]  0.004086741 <list[8]>              FALSE     0.02299358        0      0
INFO  [19:45:07.575] [bbotk]  runtime_learners                                uhash
INFO  [19:45:07.575] [bbotk]           183.521 f29bbc72-9b10-48b0-9d59-16aee05f6c8e
INFO  [19:45:21.896] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 95 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:45:34.716] [bbotk] Evaluating 1 configuration(s)
INFO  [19:45:35.172] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:45:35.508] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -163.711
[1] -4.182485
[1] -31.55037
[1] 26.33213
[1] -65.21678
[1] 348.7552
[1] -60.48878
[1] 206.6344
[1] -25.52311
[1] 47.87527
INFO  [19:46:06.361] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1289.414
[1] -30.03176
[1] -37.05674
[1] 47.47329
[1] -86.25387
[1] 5.170652
[1] -43.38106
[1] 19.64434
[1] -71.22815
[1] 29.81751
INFO  [19:46:34.365] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -24.81643
[1] 31.26045
[1] -16.37111
[1] 53.24163
[1] -51.4803
[1] 26.51709
[1] -280.8413
[1] 10.31464
[1] -40.0935
[1] 35.83685
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:47:05.993] [mlr3] Finished benchmark
INFO  [19:47:06.067] [bbotk] Result of batch 65:
INFO  [19:47:06.076] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:47:06.076] [bbotk]              -3.610747                         0.8340218
INFO  [19:47:06.076] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:47:06.076] [bbotk]                         0.7706131           -2.157401              -1.937031
INFO  [19:47:06.076] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:47:06.076] [bbotk]                         20                     614                  0.439914
INFO  [19:47:06.076] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:47:06.076] [bbotk]  0.005053148 <list[8]>              FALSE     0.02581175        0      0
INFO  [19:47:06.076] [bbotk]  runtime_learners                                uhash
INFO  [19:47:06.076] [bbotk]            89.803 122f01c2-75e3-4c1a-aa7d-c28c60d3160b
INFO  [19:47:09.553] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 96 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:47:52.099] [bbotk] Evaluating 1 configuration(s)
INFO  [19:47:52.511] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:47:52.756] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -68.87936
[1] 20.32475
[1] -27.15856
[1] 14.39069
[1] -47.19215
[1] -2.390373
[1] -31.63374
[1] 16.16679
[1] 43.98009
[1] 1213.012
INFO  [19:48:51.373] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -62.39872
[1] 12.56191
[1] -27.41221
[1] 38.26825
[1] -4183.143
[1] -207.8431
[1] -123.984
[1] 5.495588
[1] -18.18977
[1] 44.63854
INFO  [19:49:30.716] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -33.05244
[1] 14.91676
[1] -38.94812
[1] 23.87674
[1] -57.14105
[1] 7.703767
[1] -37.63783
[1] 10.68565
[1] -30.83273
[1] 43.55871
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:50:13.576] [mlr3] Finished benchmark
INFO  [19:50:14.685] [bbotk] Result of batch 66:
INFO  [19:50:14.785] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:50:14.785] [bbotk]              -4.638915                          0.408415
INFO  [19:50:14.785] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:50:14.785] [bbotk]                         0.9012052         -0.06242748              -1.566231
INFO  [19:50:14.785] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:50:14.785] [bbotk]                         19                    2541                    0.9461
INFO  [19:50:14.785] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:50:14.785] [bbotk]  0.004335959 <list[8]>              FALSE     0.02847569        0      0
INFO  [19:50:14.785] [bbotk]  runtime_learners                                uhash
INFO  [19:50:14.785] [bbotk]           140.369 5cc7d73a-fc2b-48ac-b681-fb33e876696e
INFO  [19:50:35.037] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 97 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:50:47.350] [bbotk] Evaluating 1 configuration(s)
INFO  [19:50:47.713] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:50:47.946] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -263.4796
[1] -3.362829
[1] -35.86287
[1] 67.05332
[1] -34.22589
[1] 15.06739
[1] -60.33844
[1] 24.72859
[1] -80.38387
[1] 88.6984
INFO  [19:52:07.002] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -100.0446
[1] 34.36421
[1] -95.5073
[1] 3.113846
[1] -92.66903
[1] 16.67092
[1] 44.72432
[1] 1002.248
[1] -36.97299
[1] 46.65797
INFO  [19:53:03.980] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 313.4853
[1] 9004.089
[1] -56.54169
[1] 26.73109
[1] -43.60164
[1] 127.4269
[1] -83.30105
[1] 6.840139
[1] -3535.342
[1] -242.9752
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:54:20.014] [mlr3] Finished benchmark
INFO  [19:54:20.095] [bbotk] Result of batch 67:
INFO  [19:54:20.102] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:54:20.102] [bbotk]              -2.396916                         0.9278389
INFO  [19:54:20.102] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:54:20.102] [bbotk]                         0.1638127            -3.91605              -4.236337
INFO  [19:54:20.102] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:54:20.102] [bbotk]                          7                    3673                 0.7316648
INFO  [19:54:20.102] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:54:20.102] [bbotk]  0.00411469 <list[8]>              FALSE       0.023074        0      0
INFO  [19:54:20.102] [bbotk]  runtime_learners                                uhash
INFO  [19:54:20.102] [bbotk]           211.113 2f19e51f-9557-4043-b85b-3815c713cf9b
WARN  [19:54:32.408] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:54:32.413] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 98 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:54:51.345] [bbotk] Evaluating 1 configuration(s)
INFO  [19:54:51.401] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:54:51.442] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -34.78383
[1] 52.12306
[1] -112.6845
[1] -3.842164
[1] -138.0591
[1] 4.332806
[1] -32.54655
[1] 57.24583
[1] -71.76567
[1] 49.02052
INFO  [19:55:19.936] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -15212.18
[1] -365.5177
[1] -149.9655
[1] 12.96591
[1] -96.05991
[1] 2.847685
[1] -39.25309
[1] 35.61788
[1] -72.00633
[1] 28.69744
INFO  [19:55:41.831] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -37.44339
[1] 32.51041
[1] -366.342
[1] 3.045763
[1] -166.1584
[1] 22.77972
[1] -70.8985
[1] 25.39776
[1] -54.45351
[1] 82.36276
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:56:08.832] [mlr3] Finished benchmark
INFO  [19:56:09.053] [bbotk] Result of batch 68:
INFO  [19:56:09.106] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:56:09.106] [bbotk]             0.09177975                         0.1378081
INFO  [19:56:09.106] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:56:09.106] [bbotk]                         0.9779152           -2.347887               2.068942
INFO  [19:56:09.106] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:56:09.106] [bbotk]                          2                     553                 0.7490338
INFO  [19:56:09.106] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:56:09.106] [bbotk]  0.003209355 <list[8]>              FALSE     0.02673637        0      0
INFO  [19:56:09.106] [bbotk]  runtime_learners                                uhash
INFO  [19:56:09.106] [bbotk]            77.083 3ee11d15-6e41-4205-813c-29eca9036e0c
INFO  [19:56:12.685] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 99 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:56:31.808] [bbotk] Evaluating 1 configuration(s)
INFO  [19:56:31.896] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:56:31.929] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -45.05403
[1] 41.97886
[1] -181.7005
[1] 20.17823
[1] -117.5084
[1] -3.860659
[1] -34.66667
[1] 137.857
[1] -2285.748
[1] -68.96307
INFO  [19:58:11.157] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -23.95689
[1] 68.35915
[1] -142.1995
[1] -2.282477
[1] -49.8122
[1] 32.82845
[1] -52.18511
[1] 27.24163
[1] -1518.391
[1] -66.31057
INFO  [19:59:59.827] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -54.50114
[1] 196.898
[1] -57.24063
[1] 9.165462
[1] -115.3328
[1] 22.64004
[1] -54.05051
[1] 43.14194
[1] -78.47609
[1] 18.31312
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:01:35.175] [mlr3] Finished benchmark
INFO  [20:01:35.471] [bbotk] Result of batch 69:
INFO  [20:01:35.498] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:01:35.498] [bbotk]              0.7649161                          0.839468
INFO  [20:01:35.498] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:01:35.498] [bbotk]                         0.9972347           -4.849544              -2.127373
INFO  [20:01:35.498] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:01:35.498] [bbotk]                          2                    3065                 0.6745301
INFO  [20:01:35.498] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:01:35.498] [bbotk]  0.003634509 <list[8]>              FALSE     0.02814204        0      0
INFO  [20:01:35.498] [bbotk]  runtime_learners                                uhash
INFO  [20:01:35.498] [bbotk]           302.825 9106f6d6-3bc2-477a-864e-7bacb5615da1
INFO  [20:01:56.303] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 100 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:01:56.474] [bbotk] Finished optimizing after 100 evaluation(s)
INFO  [20:01:56.481] [bbotk] Result:
INFO  [20:01:56.518] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:01:56.518] [bbotk]                  <num>                             <num>
INFO  [20:01:56.518] [bbotk]              -1.060456                         0.1324197
INFO  [20:01:56.518] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:01:56.518] [bbotk]                             <num>               <num>                  <num>
INFO  [20:01:56.518] [bbotk]                         0.6350229           -1.820198              -1.634199
INFO  [20:01:56.518] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:01:56.518] [bbotk]                      <int>                   <int>                     <num>
INFO  [20:01:56.518] [bbotk]                          2                    2873                 0.8056591
INFO  [20:01:56.518] [bbotk]  learner_param_vals  x_domain classif.bbrier
INFO  [20:01:56.518] [bbotk]              <list>    <list>          <num>
INFO  [20:01:56.518] [bbotk]          <list[10]> <list[8]>     0.02103257
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] -177.6215
[1] 58.05209
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] -191.6607
[1] 12.46914
[1] -89.8834
[1] 8.769182
[1] -43.43206
[1] 27.66609
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] -119.6952
[1] 64.78804

### [bt]: Job terminated successfully [batchtools job.id=1416]
### [bt]: Calculation finished!
