### [bt]: This is batchtools v0.9.17
### [bt]: Starting calculation of 1 jobs
### [bt]: Setting working directory to '/content/drive/MyDrive/GitHub/Mater_Thesis_Calibration'
ece.R :
Friedmann_tasks.R :
Functions.R :
ici.R :
mse_feature_effects.R :
PipeOpCalibration_TuningExperiment.R :
PipeOpCalibration.R :
PipeOpCalibrationUnion.R :
### [bt]: Memory measurement disabled
### [bt]: Starting job [batchtools job.id=1419]
### [bt]: Generating problem instance for problem '341ee781c7d79b8f' ...
### [bt]: Applying algorithm 'run_learner' on problem '341ee781c7d79b8f' for job 1419 (seed = 1542) ...
INFO  [16:06:33.252] [mlr3] Applying learner 'xgboost TwP beta' on task 'wdbc' (iter 9/10)
INFO  [16:06:34.144] [bbotk] Starting to optimize 8 parameter(s) with '<OptimizerMbo>' and '<TerminatorEvals> [n_evals=100, k=0]'
INFO  [16:06:41.832] [bbotk] Evaluating 32 configuration(s)
INFO  [16:06:42.121] [mlr3] Running benchmark with 96 resampling iterations
INFO  [16:06:42.162] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -5226.133
[1] -104.191
[1] -285.9458
[1] -3.556738
[1] -82.88483
[1] 118.3353
[1] -137.3029
[1] -1.693134
[1] -77.03831
[1] 125.7465
INFO  [16:07:59.876] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -158.6107
[1] 28.39504
[1] -217.2727
[1] 28.24666
[1] -196.007
[1] 66.259
[1] -291.1759
[1] 2.179013
[1] -175.3777
[1] 12.78655
INFO  [16:09:00.859] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -88.35185
[1] 130.4383
[1] 9.195228
[1] 249.6705
[1] -142.4695
[1] 90.2687
[1] -117.5943
[1] 30.4059
[1] -5947.746
[1] -109.353
INFO  [16:10:25.232] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -8009.064
[1] -146.4627
[1] 104.7566
[1] 5639.941
[1] -5450.067
[1] -101.6788
[1] -4263.327
[1] -78.57727
[1] -4336.267
[1] -79.79269
INFO  [16:10:55.376] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 75.64866
[1] 4034.182
[1] -5048.062
[1] -92.71664
[1] 128.5404
[1] 6949.245
[1] -607114.7
[1] -11452.35
[1] 138.7411
[1] 7467.057
INFO  [16:11:20.812] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -4385.723
[1] -80.37436
[1] -7470.081
[1] -139.1482
[1] 136.3791
[1] 7305.7
[1] 93.46228
[1] 5053.87
[1] -7321.617
[1] -132.5979
INFO  [16:11:47.138] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:12:16.800] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:12:51.676] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:13:46.551] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -64.65562
[1] 10.72054
[1] -126.6418
[1] 7.573911
[1] -19.42876
[1] 43.13118
[1] -78.24369
[1] 5.596455
[1] -1747.962
[1] -58.66809
INFO  [16:15:03.796] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -118.2323
[1] -4.131554
[1] -94.74792
[1] 27.98459
[1] -3.319843e+15
[1] 2.515967e+16
[1] -38.99762
[1] 17.60298
[1] -31.35241
[1] 38.20485
INFO  [16:16:57.039] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -137.0902
[1] 18.57154
[1] -1526.295
[1] -4.284246
[1] -191.6077
[1] -3.861487
[1] -481.109
[1] -31.09642
[1] -46.7424
[1] 25.59245
INFO  [16:17:53.914] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -73.82092
[1] 25.83291
[1] -167.1208
[1] 48.32084
[1] -41.36063
[1] 115.8412
[1] -45.01714
[1] 140.9844
[1] -98.44099
[1] 29.92084
INFO  [16:18:33.830] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 49.79821
[1] 1361.455
[1] -165.0253
[1] 2.614543
[1] -150.3906
[1] 66.53116
[1] -33.68059
[1] 56.85412
[1] -97.20675
[1] 95.36486
INFO  [16:19:05.841] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -130.9258
[1] 47.23545
[1] -133.4229
[1] 51.04834
[1] -35.69654
[1] 53.39516
[1] -134.5852
[1] 67.82912
[1] 68.15776
[1] 2612.312
INFO  [16:19:46.925] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -44.24102
[1] 156.5571
[1] -1015.989
[1] 24.30946
[1] -7110.334
[1] -207.6842
[1] -5649.926
[1] -242.3349
[1] -108.0179
[1] 19.83548
INFO  [16:21:07.437] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -4.003071
[1] 144.1938
[1] -135.4867
[1] 13.02187
[1] -44.78819
[1] 456.6594
[1] -20.59445
[1] 127.0188
[1] -196.7432
[1] -4.512573
INFO  [16:22:53.575] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -48.38711
[1] 81.11515
[1] -80.42078
[1] 36.03945
[1] -211.5572
[1] 59.15515
[1] -60.79229
[1] 168.0883
[1] -17422.36
[1] -303.3705
INFO  [16:24:44.007] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:25:51.555] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:27:06.153] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:28:14.287] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -39.58108
[1] 112.1214
[1] -22.72346
[1] 46.34948
[1] 64.61442
[1] 1468.671
[1] -47.95622
[1] -3.890357
[1] -33.93519
[1] 17.60361
INFO  [16:29:00.036] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -32.21483
[1] 15.52726
[1] -23.32485
[1] 32.56012
[1] -390.0546
[1] -0.6257163
[1] -47.47009
[1] 9.683139
[1] 49.7464
[1] 1269.506
INFO  [16:29:48.741] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1340.494
[1] -31.79366
[1] -38.52746
[1] 38.23063
[1] -78.84518
[1] 29.59217
[1] -43.38269
[1] 2.107134
[1] -60.01443
[1] 39.20341
INFO  [16:30:37.702] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -49.26343
[1] 42.85518
[1] -138.1259
[1] 7.97964
[1] -113.7709
[1] -3.846087
[1] -76.87086
[1] 33.60264
[1] -4833.328
[1] -100.4912
INFO  [16:31:14.887] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -141.7784
[1] -3.145246
[1] -2080.199
[1] -50.86047
[1] -135.8621
[1] 21.21226
[1] -59.8021
[1] 28.17546
[1] -37.45258
[1] 64.68278
INFO  [16:31:38.276] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -52.38243
[1] 76.99271
[1] -140.4747
[1] -3.956357
[1] -171.6431
[1] 13.85862
[1] -32.00184
[1] 81.44352
[1] -37.56831
[1] 44.3346
INFO  [16:32:03.920] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:33:00.225] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:33:53.695] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:35:01.815] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -189.4662
[1] -3.729716
[1] -156.2781
[1] 101.2531
[1] 10.86563
[1] 515.1073
[1] 5.617896
[1] 235.4731
[1] 4.965531
[1] 222.9309
INFO  [16:35:43.643] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -483.3
[1] -5.526904
[1] -367.9329
[1] -5.888939
[1] -166.5597
[1] 79.91095
[1] -487.494
[1] -6.345556
[1] -72.16696
[1] 224.6027
INFO  [16:36:27.105] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -205.8041
[1] -3.887274
[1] -146.9869
[1] 101.0426
[1] -107.3739
[1] 178.7346
[1] -71.2252
[1] 162.3743
[1] -189.4675
[1] 105.7575
INFO  [16:37:16.022] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -224.0694
[1] -4.482455
[1] -90.32011
[1] 37.33571
[1] -228.1169
[1] 106.892
[1] -31.24023
[1] 145.7978
[1] -14.41534
[1] 198.675
INFO  [16:38:22.270] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1470.05
[1] -23.46768
[1] -85.65046
[1] 108.5715
[1] -111.0986
[1] 41.50704
[1] -309.9839
[1] -4.103424
[1] -73.56174
[1] 91.22008
INFO  [16:40:02.060] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -111.2079
[1] 104.9153
[1] -172.7878
[1] 10.85963
[1] -44.65882
[1] 141.9296
[1] 12.18757
[1] 542.9657
[1] -67.79495
[1] 82.62967
INFO  [16:41:05.539] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:41:33.875] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:42:04.913] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:42:45.558] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -126.0712
[1] 21.18882
[1] -44.2443
[1] 16.01803
[1] -83.32281
[1] 13.32046
[1] -42.62234
[1] 97.36034
[1] -69.81405
[1] 50.35226
INFO  [16:43:34.118] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -513.0454
[1] 23.59712
[1] -107.3557
[1] -3.211341
[1] -11.90815
[1] 167.287
[1] -2775.385
[1] -88.1858
[1] -35.08452
[1] 12.40826
INFO  [16:44:37.915] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -35.29651
[1] 61.75581
[1] -3.22402e+16
[1] 5.357095e+15
[1] -45.9988
[1] 50.26527
[1] -197.1617
[1] -3.940726
[1] -231.8655
[1] 17.95727
INFO  [16:45:43.451] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -70.52788
[1] 191.9609
[1] -155.4958
[1] 87.08586
[1] -256.7235
[1] -4.818215
[1] -51.76914
[1] 84.95262
[1] -49.13746
[1] 157.9325
INFO  [16:46:43.890] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -125.8178
[1] 164.8848
[1] -121.1027
[1] 28.357
[1] 4.88829
[1] 219.5166
[1] -236.9796
[1] -5.041482
[1] -48.20722
[1] 154.3748
INFO  [16:47:32.706] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -69.2904
[1] 98.08179
[1] -363.1294
[1] -6.023124
[1] -515.276
[1] -6.244617
[1] -81.72622
[1] 97.8166
[1] -114.5043
[1] 133.4447
INFO  [16:48:23.955] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -54.72623
[1] 28.71362
[1] -105.4712
[1] 36.0529
[1] -45.81079
[1] 57.02172
[1] -72.02296
[1] 101.3868
[1] -61.50945
[1] 76.21807
INFO  [16:49:41.413] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -3157.361
[1] -84.53288
[1] -19.29067
[1] 83.45517
[1] -52.13072
[1] 29.83877
[1] -42.36611
[1] 112.9362
[1] -39.73923
[1] 28.44127
INFO  [16:50:48.561] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -14474.17
[1] -340.2605
[1] -76.18382
[1] 91.29602
[1] -26.12003
[1] 44.00859
[1] -1.245989e+16
[1] 3.665687e+16
[1] -81.07644
[1] 1.027966
INFO  [16:51:31.058] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -33.65713
[1] 11.87754
[1] -2.464079e+16
[1] 3.263335e+16
[1] -55.49572
[1] 37.54764
[1] -106.7494
[1] 32.07461
[1] -3.215706
[1] 374.9137
INFO  [16:52:27.751] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -233.5524
[1] 19.94031
[1] -280.4052
[1] 45.82778
[1] -27.31165
[1] 81.41476
[1] -75.75079
[1] 13.36111
[1] -55.72271
[1] 8.483069
INFO  [16:53:12.438] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -64.2469
[1] 9.064949
[1] -159.275
[1] -3.959674
[1] 1.786941
[1] 117.8582
[1] 49.60223
[1] 1619.632
[1] -27.30332
[1] 31.6807
INFO  [16:53:50.320] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:54:13.083] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:54:31.090] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:54:49.326] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:55:27.209] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:56:07.172] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:56:49.864] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -47.91169
[1] 48.96681
[1] -30.94795
[1] 30.31537
[1] -162.5992
[1] -3.944638
[1] -44.29279
[1] 25.79354
[1] -3330.191
[1] -88.34023
INFO  [16:57:53.535] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -34.15397
[1] 89.45729
[1] -170.8915
[1] 83.65204
[1] -109.2396
[1] -4.748245
[1] -199.5577
[1] -4.139142
[1] -102.5144
[1] 30.5355
INFO  [16:58:43.259] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -50.43424
[1] 49.7212
[1] -61.67427
[1] 45.33062
[1] -32.31916
[1] 40.96475
[1] -205.0242
[1] -3.990171
[1] -34.29762
[1] 55.61017
INFO  [16:59:47.182] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 119.1239
[1] 4242.561
[1] -87.66136
[1] 28.71197
[1] -89.96107
[1] 16.00074
[1] -52.63477
[1] 79.09335
[1] -112.2288
[1] 46.38279
INFO  [17:00:11.032] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -97.53118
[1] 16.03855
[1] -37.49858
[1] 235.7121
[1] -163.4267
[1] -3.87373
[1] -40.48799
[1] 81.39421
[1] -25658.57
[1] -442.9678
INFO  [17:00:37.495] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -104.9286
[1] 33.91633
[1] -61.26673
[1] 45.27011
[1] -266.9672
[1] 161.701
[1] -129.7829
[1] 21.44535
[1] 57.69232
[1] 2216.906
INFO  [17:01:01.699] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -385.6882
[1] 282.9863
[1] 42.30187
[1] 2371.433
[1] 219.0592
[1] 10758.15
[1] -754.6807
[1] -12.49367
[1] -1023.433
[1] -20.27524
INFO  [17:02:08.758] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 31.06768
[1] 1716.431
[1] -854.3248
[1] -14.97476
[1] -1306.268
[1] 108.5168
[1] -155.0052
[1] 471.3094
[1] 14.786
[1] 722.5991
INFO  [17:03:29.423] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -250.3922
[1] 563.4371
[1] -298.8176
[1] 398.2261
[1] 14.47604
[1] 731.2312
[1] -1148.842
[1] -18.71636
[1] -1166.521
[1] -22.58886
INFO  [17:04:25.486] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:05:17.636] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:05:55.667] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:06:45.365] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -95.34612
[1] 60.72592
[1] -68.34101
[1] 21.62862
[1] -37.51173
[1] 70.97375
[1] -43.78254
[1] 46.43471
[1] -104.7268
[1] -3.825637
INFO  [17:08:08.670] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -43.36775
[1] 120.6439
[1] -134.6849
[1] -4.105776
[1] -286.3829
[1] 11.77485
[1] -38.69704
[1] 110.8877
[1] -246.8612
[1] -3.377619
INFO  [17:09:24.902] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -90.81816
[1] -3.7384
[1] -2180.853
[1] -72.11743
[1] -14.93989
[1] 68.1701
[1] -60.64066
[1] 41.33568
[1] -34.39188
[1] 33.72164
INFO  [17:10:50.246] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 1896.959
[1] 102601.6
[1] 1317.751
[1] 71260.43
[1] -42968.44
[1] -792.2903
[1] -43622.13
[1] -804.8048
[1] -45410.93
[1] -837.5261
INFO  [17:11:22.188] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -53259.11
[1] -981.5661
[1] 999.5237
[1] 54044.22
[1] -55504.08
[1] -1024.278
[1] 1310.852
[1] 70733.19
[1] -38994.78
[1] -718.4651
INFO  [17:11:47.712] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 814.9938
[1] 44083.29
[1] -3870146
[1] -71353.89
[1] 1148.872
[1] 62051.85
[1] 755.9913
[1] 40863.49
[1] 892.4943
[1] 48189.65
INFO  [17:12:10.989] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:13:07.596] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:13:55.781] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:14:24.404] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 79.1389
[1] 1633.505
[1] -167.7992
[1] 17.92145
[1] -39.61287
[1] 33.6956
[1] -52.48332
[1] 16.04377
[1] -983.3006
[1] -35.72466
INFO  [17:15:39.806] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -146.208
[1] -0.5707775
[1] -429.0628
[1] 682.9686
[1] -37.27554
[1] 83.83341
[1] -24.64939
[1] 21.2826
[1] -20.73481
[1] 154.589
INFO  [17:16:29.028] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -221.8567
[1] -0.3932274
[1] -28.32898
[1] 44.45317
[1] 362.9917
[1] 5235.062
[1] -140.4916
[1] 18.46884
[1] -36.45999
[1] 13.03354
INFO  [17:17:20.118] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -153.9278
[1] -3.89516
[1] -74.88798
[1] 32.28726
[1] -37.8103
[1] 75.99788
[1] -1599.081
[1] -70.65983
[1] -57.73669
[1] 46.1579
INFO  [17:18:16.135] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -14.52427
[1] 79.20454
[1] -74.12733
[1] 13.09454
[1] -21869.19
[1] -414.6741
[1] -53.60254
[1] 108.4433
[1] -155.8663
[1] -3.369429
INFO  [17:18:57.853] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1643.534
[1] -36.15553
[1] -228.292
[1] 83.28499
[1] -148.7594
[1] -4.025574
[1] -51.72482
[1] 65.10033
[1] -62.20252
[1] 40.01074
INFO  [17:19:54.215] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -23.41262
[1] 17.86196
[1] -24.54727
[1] 29.35426
[1] -586.6351
[1] 10.58126
[1] -3467.902
[1] -74.37259
[1] -16.44012
[1] 31.6618
INFO  [17:20:29.679] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -37.38056
[1] 14.45159
[1] -8404.085
[1] -650.7675
[1] -203.9686
[1] 17.57841
[1] -836.1166
[1] -45.05343
[1] -18.04246
[1] 45.21897
INFO  [17:20:59.968] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -20.96868
[1] 32.06181
[1] -84.81113
[1] 20.39239
[1] -173.4647
[1] 11.92572
[1] -1778.211
[1] -139.2762
[1] -3880.29
[1] -103.4283
INFO  [17:21:44.553] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -237.9005
[1] 117.3112
[1] -356.2684
[1] 85.2036
[1] -113.7336
[1] 121.9513
[1] -527.1745
[1] -6.173162
[1] -194.0565
[1] -3.38868
INFO  [17:22:26.996] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -92.74671
[1] 101.8524
[1] -156.1007
[1] 122.0301
[1] 0.6373358
[1] 201.629
[1] -233.368
[1] 16.74591
[1] -287.042
[1] -5.454429
INFO  [17:23:18.941] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 6.518167
[1] 215.949
[1] -265.0846
[1] 56.09129
[1] -318.9179
[1] -5.454972
[1] -297.3315
[1] 28.16576
[1] -120.4239
[1] 98.29009
INFO  [17:24:01.074] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:24:23.723] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:24:45.879] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:25:06.688] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -364.6271
[1] 474.9795
[1] 22.17196
[1] 1017.132
[1] -590.1893
[1] -9.618914
[1] 12.64565
[1] 632.6212
[1] -871.8621
[1] -16.812
INFO  [17:25:36.627] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -553.1008
[1] 252.9052
[1] -41843.27
[1] -638.683
[1] -679.6789
[1] -10.88797
[1] 10.0323
[1] 502.3172
[1] -795.3014
[1] -11.81534
INFO  [17:26:10.140] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 20.13228
[1] 905.9837
[1] -1128.093
[1] -17.01934
[1] -485.3814
[1] 128.905
[1] -1129.056
[1] -20.22371
[1] -856.5399
[1] -14.2065
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:27:06.336] [mlr3] Finished benchmark
INFO  [17:27:07.551] [bbotk] Result of batch 1:
INFO  [17:27:07.678] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:27:07.678] [bbotk]              2.0253317                         0.9160216
INFO  [17:27:07.678] [bbotk]             -4.8824233                         0.4660216
INFO  [17:27:07.678] [bbotk]              5.4792094                         0.2410216
INFO  [17:27:07.678] [bbotk]             -1.4285459                         0.6910216
INFO  [17:27:07.678] [bbotk]              0.2983929                         0.3535216
INFO  [17:27:07.678] [bbotk]             -6.6093622                         0.8035216
INFO  [17:27:07.678] [bbotk]              3.7522705                         0.5785216
INFO  [17:27:07.678] [bbotk]             -3.1554847                         0.1285216
INFO  [17:27:07.678] [bbotk]             -0.5650765                         0.4097716
INFO  [17:27:07.678] [bbotk]              6.3426788                         0.8597716
INFO  [17:27:07.678] [bbotk]              2.8888011                         0.1847716
INFO  [17:27:07.678] [bbotk]             -4.0189539                         0.6347716
INFO  [17:27:07.678] [bbotk]              4.6157400                         0.5222716
INFO  [17:27:07.678] [bbotk]             -2.2920153                         0.9722716
INFO  [17:27:07.678] [bbotk]             -5.7458928                         0.2972716
INFO  [17:27:07.678] [bbotk]              1.1618623                         0.7472716
INFO  [17:27:07.678] [bbotk]             -3.5872192                         0.1566466
INFO  [17:27:07.678] [bbotk]              3.3205358                         0.6066466
INFO  [17:27:07.678] [bbotk]              6.7744135                         0.3816466
INFO  [17:27:07.678] [bbotk]             -0.1333418                         0.8316466
INFO  [17:27:07.678] [bbotk]             -5.3141581                         0.7191466
INFO  [17:27:07.678] [bbotk]              1.5935970                         0.2691466
INFO  [17:27:07.678] [bbotk]              5.0474747                         0.9441466
INFO  [17:27:07.678] [bbotk]             -1.8602806                         0.4941466
INFO  [17:27:07.678] [bbotk]             -2.7237500                         0.5503966
INFO  [17:27:07.678] [bbotk]              4.1840052                         0.1003966
INFO  [17:27:07.678] [bbotk]             -6.1776275                         0.3253966
INFO  [17:27:07.678] [bbotk]              0.7301276                         0.7753966
INFO  [17:27:07.678] [bbotk]             -4.4506886                         0.8878966
INFO  [17:27:07.678] [bbotk]              2.4570664                         0.4378966
INFO  [17:27:07.678] [bbotk]              5.9109441                         0.6628966
INFO  [17:27:07.678] [bbotk]             -0.9968112                         0.2128966
INFO  [17:27:07.678] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:27:07.678] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:27:07.678] [bbotk]                         0.7210973         -4.04432164              6.2250257
INFO  [17:27:07.678] [bbotk]                         0.2710973         -8.64949169             -0.6827292
INFO  [17:27:07.678] [bbotk]                         0.4960973         -6.34690646              2.7711481
INFO  [17:27:07.678] [bbotk]                         0.9460973         -1.74173655             -4.1366068
INFO  [17:27:07.678] [bbotk]                         0.8335973         -2.89302910              4.4980869
INFO  [17:27:07.678] [bbotk]                         0.3835973         -7.49819915             -2.4096680
INFO  [17:27:07.678] [bbotk]                         0.1585973         -5.19561392              1.0442092
INFO  [17:27:07.678] [bbotk]                         0.6085973         -0.59044400             -5.8635456
INFO  [17:27:07.678] [bbotk]                         0.4398473         -3.46867537              0.1807398
INFO  [17:27:07.678] [bbotk]                         0.8898473         -8.07384542             -6.7270151
INFO  [17:27:07.678] [bbotk]                         0.2148473         -1.16609028             -3.2731374
INFO  [17:27:07.678] [bbotk]                         0.6648473         -5.77126019              3.6346175
INFO  [17:27:07.678] [bbotk]                         0.5523473         -6.92255287             -5.0000762
INFO  [17:27:07.678] [bbotk]                         0.1023473         -2.31738282              1.9076786
INFO  [17:27:07.678] [bbotk]                         0.7773473         -4.61996764              5.3615563
INFO  [17:27:07.678] [bbotk]                         0.3273473         -0.01479773             -1.5461986
INFO  [17:27:07.678] [bbotk]                         0.3554723         -3.18085223             -3.7048721
INFO  [17:27:07.678] [bbotk]                         0.8054723         -7.78602228              3.2028828
INFO  [17:27:07.678] [bbotk]                         0.1304723         -0.87826714              6.6567604
INFO  [17:27:07.678] [bbotk]                         0.5804723         -5.48343705             -0.2509945
INFO  [17:27:07.678] [bbotk]                         0.2429723         -4.33214478             -5.4318109
INFO  [17:27:07.678] [bbotk]                         0.6929723         -8.93731483              1.4759439
INFO  [17:27:07.678] [bbotk]                         0.4679723         -2.02955969              4.9298216
INFO  [17:27:07.678] [bbotk]                         0.9179723         -6.63472960             -1.9779333
INFO  [17:27:07.678] [bbotk]                         0.5242223         -8.36166856              5.7932910
INFO  [17:27:07.678] [bbotk]                         0.9742223         -3.75649851             -1.1144639
INFO  [17:27:07.678] [bbotk]                         0.7492223         -1.45391341              2.3394134
INFO  [17:27:07.678] [bbotk]                         0.2992223         -6.05908333             -4.5683415
INFO  [17:27:07.678] [bbotk]                         0.8617223         -0.30262087              0.6124745
INFO  [17:27:07.678] [bbotk]                         0.4117223         -4.90779078             -6.2952804
INFO  [17:27:07.678] [bbotk]                         0.6367223         -2.60520596             -2.8414027
INFO  [17:27:07.678] [bbotk]                         0.1867223         -7.21037601              4.0663522
INFO  [17:27:07.678] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:27:07.678] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:27:07.678] [bbotk]                          3                    2749                 0.9795556
INFO  [17:27:07.678] [bbotk]                         13                     249                 0.5295556
INFO  [17:27:07.678] [bbotk]                          8                    1499                 0.7545556
INFO  [17:27:07.678] [bbotk]                         18                    3999                 0.3045556
INFO  [17:27:07.678] [bbotk]                          6                     874                 0.4170556
INFO  [17:27:07.678] [bbotk]                         16                    3374                 0.8670556
INFO  [17:27:07.678] [bbotk]                          1                    4624                 0.1920556
INFO  [17:27:07.678] [bbotk]                         11                    2124                 0.6420556
INFO  [17:27:07.678] [bbotk]                         17                     562                 0.4733056
INFO  [17:27:07.678] [bbotk]                          7                    3062                 0.9233056
INFO  [17:27:07.678] [bbotk]                          2                    1812                 0.6983056
INFO  [17:27:07.678] [bbotk]                         12                    4312                 0.2483056
INFO  [17:27:07.678] [bbotk]                          4                    1187                 0.3608056
INFO  [17:27:07.678] [bbotk]                         14                    3687                 0.8108056
INFO  [17:27:07.678] [bbotk]                         19                    2437                 0.5858056
INFO  [17:27:07.678] [bbotk]                          9                    4937                 0.1358056
INFO  [17:27:07.678] [bbotk]                          8                    2593                 0.6701806
INFO  [17:27:07.678] [bbotk]                         18                      93                 0.2201806
INFO  [17:27:07.678] [bbotk]                         13                    3843                 0.4451806
INFO  [17:27:07.678] [bbotk]                          3                    1343                 0.8951806
INFO  [17:27:07.678] [bbotk]                          5                     718                 0.1076806
INFO  [17:27:07.678] [bbotk]                         15                    3218                 0.5576806
INFO  [17:27:07.678] [bbotk]                         20                    1968                 0.7826806
INFO  [17:27:07.678] [bbotk]                         10                    4468                 0.3326806
INFO  [17:27:07.678] [bbotk]                          6                    1031                 0.1639306
INFO  [17:27:07.678] [bbotk]                         16                    3531                 0.6139306
INFO  [17:27:07.678] [bbotk]                          1                    4781                 0.3889306
INFO  [17:27:07.678] [bbotk]                         11                    2281                 0.8389306
INFO  [17:27:07.678] [bbotk]                          9                    1656                 0.9514306
INFO  [17:27:07.678] [bbotk]                         19                    4156                 0.5014306
INFO  [17:27:07.678] [bbotk]                         14                     406                 0.2764306
INFO  [17:27:07.678] [bbotk]                          4                    2906                 0.7264306
INFO  [17:27:07.678] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:27:07.678] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:27:07.678] [bbotk]      0.04007260        0      0          222.293
INFO  [17:27:07.678] [bbotk]      0.20716605        0      0           80.929
INFO  [17:27:07.678] [bbotk]      0.23338645        0      0          118.971
INFO  [17:27:07.678] [bbotk]      0.02346304        0      0          246.174
INFO  [17:27:07.678] [bbotk]      0.03675733        0      0          111.954
INFO  [17:27:07.678] [bbotk]      0.03050478        0      0          296.857
INFO  [17:27:07.678] [bbotk]      0.23338645        0      0          208.030
INFO  [17:27:07.678] [bbotk]      0.02620259        0      0          141.112
INFO  [17:27:07.678] [bbotk]      0.02736743        0      0           85.486
INFO  [17:27:07.678] [bbotk]      0.23338645        0      0          176.011
INFO  [17:27:07.678] [bbotk]      0.04844151        0      0          133.407
INFO  [17:27:07.678] [bbotk]      0.04036687        0      0          228.894
INFO  [17:27:07.678] [bbotk]      0.23338645        0      0           99.662
INFO  [17:27:07.678] [bbotk]      0.02592862        0      0          177.354
INFO  [17:27:07.678] [bbotk]      0.04034087        0      0          159.863
INFO  [17:27:07.678] [bbotk]      0.03550200        0      0          186.305
INFO  [17:27:07.678] [bbotk]      0.02673996        0      0          138.478
INFO  [17:27:07.678] [bbotk]      0.23338645        0      0           58.682
INFO  [17:27:07.678] [bbotk]      0.23338645        0      0          119.961
INFO  [17:27:07.678] [bbotk]      0.03108913        0      0          175.893
INFO  [17:27:07.678] [bbotk]      0.03535396        0      0           73.949
INFO  [17:27:07.678] [bbotk]      0.08525102        0      0          202.822
INFO  [17:27:07.678] [bbotk]      0.23338645        0      0          139.424
INFO  [17:27:07.678] [bbotk]      0.02798840        0      0          243.577
INFO  [17:27:07.678] [bbotk]      0.23131549        0      0           79.788
INFO  [17:27:07.678] [bbotk]      0.23338645        0      0          132.868
INFO  [17:27:07.678] [bbotk]      0.02702166        0      0          175.462
INFO  [17:27:07.678] [bbotk]      0.03229537        0      0          153.727
INFO  [17:27:07.678] [bbotk]      0.02654003        0      0          110.131
INFO  [17:27:07.678] [bbotk]      0.04111921        0      0          136.176
INFO  [17:27:07.678] [bbotk]      0.23338645        0      0           64.802
INFO  [17:27:07.678] [bbotk]      0.08469157        0      0          108.489
INFO  [17:27:07.678] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:27:07.678] [bbotk]                                 uhash
INFO  [17:27:07.678] [bbotk]  0a7347a5-4fac-47a0-9607-840cb30fb21e
INFO  [17:27:07.678] [bbotk]  abafc602-9a00-4345-ab89-dfb70921c383
INFO  [17:27:07.678] [bbotk]  506b1b41-78dc-4ea3-bfb3-6abfa651a3ba
INFO  [17:27:07.678] [bbotk]  10959977-959c-4e93-8d26-d294757bd6e0
INFO  [17:27:07.678] [bbotk]  244ab32b-0c05-451b-a6c7-12f228bd0ddc
INFO  [17:27:07.678] [bbotk]  02c078ba-28dd-4493-8279-1fb36289d58d
INFO  [17:27:07.678] [bbotk]  458634a4-6041-4624-8114-f12849381d53
INFO  [17:27:07.678] [bbotk]  155cc742-4385-414b-b7d0-9395376bad96
INFO  [17:27:07.678] [bbotk]  b5237d84-6a0e-45a7-b69d-3f8a7ec01698
INFO  [17:27:07.678] [bbotk]  4bca3892-6de3-4032-ad6b-1a32b0b15ebc
INFO  [17:27:07.678] [bbotk]  7783035c-232d-4a16-975e-47bd521666b6
INFO  [17:27:07.678] [bbotk]  a77467d7-fb0f-4015-a330-6b7c00dfed0e
INFO  [17:27:07.678] [bbotk]  91b5f6be-2312-4894-86d0-aeb4c4688d51
INFO  [17:27:07.678] [bbotk]  d9acda39-7c18-4ed9-97b5-b00e1d7a9db3
INFO  [17:27:07.678] [bbotk]  03b921b0-758b-49b6-b273-8c26abf22a58
INFO  [17:27:07.678] [bbotk]  90d259cd-b634-46db-9059-da30c492a720
INFO  [17:27:07.678] [bbotk]  499bd9fc-6ef3-40ab-b2d5-fe6443d8e715
INFO  [17:27:07.678] [bbotk]  f2fa93ad-d7d5-4375-9f61-628b2ca7e69d
INFO  [17:27:07.678] [bbotk]  cdf510a4-8c25-4ad4-ba64-5cda4e499553
INFO  [17:27:07.678] [bbotk]  8d73cd55-3c8f-4287-9374-9794fc03c939
INFO  [17:27:07.678] [bbotk]  f0205484-fa30-4ab9-8798-aa3fd5557a94
INFO  [17:27:07.678] [bbotk]  9c23c667-3111-4bfe-94f5-f03ace60d42d
INFO  [17:27:07.678] [bbotk]  a2568704-2f92-4873-b41c-88a456f8b0ae
INFO  [17:27:07.678] [bbotk]  9e7a9d05-e96e-4b41-a5a5-c687b0bba822
INFO  [17:27:07.678] [bbotk]  fb42f75f-3056-421f-bfcd-e5e12c9ba8d3
INFO  [17:27:07.678] [bbotk]  eb66f637-e949-4be7-9d71-5293b102df99
INFO  [17:27:07.678] [bbotk]  dbe2c1e5-0ec5-4cb8-be34-ccba5f668ad2
INFO  [17:27:07.678] [bbotk]  6b9da1f6-9e6f-40d9-8b7f-34c90b131d94
INFO  [17:27:07.678] [bbotk]  a84fadb8-3482-4f58-b4b8-7d9a5cfebcfc
INFO  [17:27:07.678] [bbotk]  b8d48e31-cf0d-48bb-a632-a238507ee6a7
INFO  [17:27:07.678] [bbotk]  c54beefa-f552-4090-800e-98e1d8463ae0
INFO  [17:27:07.678] [bbotk]  ff7eb0c4-37bc-4af8-bc16-f52ef16e72b3
INFO  [17:27:07.678] [bbotk]                                 uhash
WARN  [17:27:15.002] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:27:15.044] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 32 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:27:23.537] [bbotk] Evaluating 1 configuration(s)
INFO  [17:27:24.038] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:27:24.317] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -37.97357
[1] 46.51634
[1] -73.99905
[1] 476.1264
[1] -62.91703
[1] 22.86188
[1] -74.53576
[1] 37.57004
[1] -74.19782
[1] 113.2028
INFO  [17:28:15.059] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -29.3078
[1] 35.08393
[1] -4120.066
[1] -43.46409
[1] -201.9587
[1] -4.685972
[1] -134.4285
[1] 51.60567
[1] -147.5823
[1] -3.746979
INFO  [17:28:49.186] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -85.81381
[1] 40.6129
[1] -3538.769
[1] -62.915
[1] -16.78635
[1] 60.73464
[1] -63.84469
[1] 44.65301
[1] -230.8446
[1] -4.191013
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:29:34.925] [mlr3] Finished benchmark
INFO  [17:29:35.049] [bbotk] Result of batch 2:
INFO  [17:29:35.117] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:29:35.117] [bbotk]              0.9746035                         0.1169751
INFO  [17:29:35.117] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:29:35.117] [bbotk]                         0.6945611           -3.164349              -6.133455
INFO  [17:29:35.117] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:29:35.117] [bbotk]                         14                    4135                 0.9176603
INFO  [17:29:35.117] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:29:35.117] [bbotk]  0.04590353 <list[8]>              FALSE     0.02882525        0      0
INFO  [17:29:35.117] [bbotk]  runtime_learners                                uhash
INFO  [17:29:35.117] [bbotk]           129.835 3be0ced9-6caa-4efc-90a6-e599b0bc7e2c
INFO  [17:29:35.796] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 33 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:29:42.336] [bbotk] Evaluating 1 configuration(s)
INFO  [17:29:43.162] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:29:43.874] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1.597063e+16
[1] 1.561448e+16
[1] -74.8483
[1] 6.788832
[1] -64.32573
[1] -4.026368
[1] 62.06906
[1] 1086.779
[1] -6731.032
[1] -209.7295
INFO  [17:30:25.163] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -294.8072
[1] 7.814763
[1] -80.7939
[1] 20.5109
[1] -56.27655
[1] 63.64826
[1] -58.09024
[1] 54.4596
[1] -145.915
[1] -3.823444
INFO  [17:31:09.471] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1184.007
[1] -28.47072
[1] -73.56375
[1] 10.51208
[1] -46.26786
[1] 21.9728
[1] -23.0542
[1] 48.24193
[1] -2198.701
[1] -37.11398
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:32:01.840] [mlr3] Finished benchmark
INFO  [17:32:02.028] [bbotk] Result of batch 3:
INFO  [17:32:02.072] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:32:02.072] [bbotk]              -5.154978                         0.9977313
INFO  [17:32:02.072] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:32:02.072] [bbotk]                         0.6438831           -3.771119              -4.081651
INFO  [17:32:02.072] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:32:02.072] [bbotk]                         11                    3465                 0.4953005
INFO  [17:32:02.072] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:32:02.072] [bbotk]  0.03817824 <list[8]>              FALSE     0.02668148        0      0
INFO  [17:32:02.072] [bbotk]  runtime_learners                                uhash
INFO  [17:32:02.072] [bbotk]           134.977 319ede13-c39d-441d-b996-8fe40f348ad3
INFO  [17:32:03.406] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 34 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:32:11.788] [bbotk] Evaluating 1 configuration(s)
INFO  [17:32:11.939] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:32:12.274] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -63.97701
[1] 20.53486
[1] -47.78697
[1] 16.51737
[1] -34.18114
[1] 71.32563
[1] -792.3804
[1] -30.87306
[1] -54.11886
[1] 45.07106
INFO  [17:32:32.443] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -35.50205
[1] 77.42197
[1] -50.13086
[1] 13.85412
[1] -66.30014
[1] 55.52807
[1] -529.3957
[1] -4.064195
[1] -298.2421
[1] -3.973658
INFO  [17:33:26.620] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -125.4
[1] -3.999515
[1] -626.3357
[1] -4.069292
[1] -30.98765
[1] 40.17938
[1] -124.7203
[1] 130.6721
[1] -106.5317
[1] 26.73757
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:34:24.730] [mlr3] Finished benchmark
INFO  [17:34:24.853] [bbotk] Result of batch 4:
INFO  [17:34:24.892] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:34:24.892] [bbotk]              -1.660745                         0.5253407
INFO  [17:34:24.892] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:34:24.892] [bbotk]                         0.7143392            -4.34595              -3.120728
INFO  [17:34:24.892] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:34:24.892] [bbotk]                          5                    4124                 0.7414001
INFO  [17:34:24.892] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:34:24.892] [bbotk]  0.02732497 <list[8]>              FALSE     0.02344896        0      0
INFO  [17:34:24.892] [bbotk]  runtime_learners                                uhash
INFO  [17:34:24.892] [bbotk]           131.395 458c4477-80c7-434f-ae2a-2aabe573293a
INFO  [17:34:25.525] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 35 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:34:33.440] [bbotk] Evaluating 1 configuration(s)
INFO  [17:34:33.751] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:34:33.987] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -71.53972
[1] 79.36228
[1] -94.33366
[1] 87.72411
[1] -60.67841
[1] 38.02461
[1] -79.61483
[1] 39.35527
[1] -117.9532
[1] 87.68231
INFO  [17:35:04.664] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -125.057
[1] 26.03979
[1] -58.29288
[1] 45.94463
[1] -90.4588
[1] 88.05743
[1] -3611.912
[1] -50.71688
[1] -187.2317
[1] -4.189429
INFO  [17:35:31.038] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -251.8932
[1] 68.71771
[1] -54.40735
[1] 83.15956
[1] -89.82264
[1] 54.13633
[1] -331.5388
[1] -4.040992
[1] -5774.127
[1] -102.6469
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:35:55.514] [mlr3] Finished benchmark
INFO  [17:35:55.660] [bbotk] Result of batch 5:
INFO  [17:35:55.729] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:35:55.729] [bbotk]               1.808552                         0.5038955
INFO  [17:35:55.729] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:35:55.729] [bbotk]                         0.2579959           -1.582676              -6.308549
INFO  [17:35:55.729] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:35:55.729] [bbotk]                          8                    2266                 0.6243645
INFO  [17:35:55.729] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:35:55.729] [bbotk]  0.02616396 <list[8]>              FALSE     0.03742664        0      0
INFO  [17:35:55.729] [bbotk]  runtime_learners                                uhash
INFO  [17:35:55.729] [bbotk]            80.085 e21c78ec-c4b4-4bcb-9e8e-dc7dab4a1c6f
INFO  [17:35:56.725] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 36 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:36:03.229] [bbotk] Evaluating 1 configuration(s)
INFO  [17:36:03.474] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:36:03.670] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -129.4939
[1] 15.98832
[1] -112.5544
[1] -4.06173
[1] -256.1692
[1] 20.44459
[1] -72.25544
[1] 67.64487
[1] -63.95136
[1] 44.11749
INFO  [17:37:06.622] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -145.1523
[1] -4.153615
[1] -0.6548782
[1] 183.3088
[1] -128.1572
[1] 2.312398
[1] -7240.095
[1] -163.8028
[1] -54.22656
[1] 34.05722
INFO  [17:38:37.461] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -29244.45
[1] -618.4836
[1] -69.03341
[1] 461.562
[1] -39.38669
[1] 38.89908
[1] -211.9482
[1] -3.880881
[1] -194.6196
[1] 56.26471
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:39:19.859] [mlr3] Finished benchmark
INFO  [17:39:20.149] [bbotk] Result of batch 6:
INFO  [17:39:20.215] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:39:20.215] [bbotk]             -0.5501635                         0.8304886
INFO  [17:39:20.215] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:39:20.215] [bbotk]                         0.5911853           -4.925842               1.914662
INFO  [17:39:20.215] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:39:20.215] [bbotk]                         14                    4962                 0.2984839
INFO  [17:39:20.215] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:39:20.215] [bbotk]  0.0296965 <list[8]>              FALSE     0.02747825        0      0
INFO  [17:39:20.215] [bbotk]  runtime_learners                                uhash
INFO  [17:39:20.215] [bbotk]           194.774 dbde528a-518b-46d4-8d4a-477be6e32a21
INFO  [17:39:21.694] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 37 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:39:27.675] [bbotk] Evaluating 1 configuration(s)
INFO  [17:39:27.836] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:39:28.081] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -46.64666
[1] 77.18584
[1] -129.0544
[1] 18.78216
[1] -75.85309
[1] 77.81617
[1] -44.38852
[1] 111.182
[1] -106.5079
[1] 17.43826
INFO  [17:40:23.373] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -8.983944
[1] 103.4747
[1] -41.09312
[1] 72.8404
[1] -82.05589
[1] 39.36573
[1] -59.03404
[1] 12.63131
[1] -1457.543
[1] -37.05175
INFO  [17:41:11.511] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -29.53917
[1] 38.65927
[1] 40.86602
[1] 948.5444
[1] -254.3768
[1] -4.283388
[1] -13334.09
[1] -334.6051
[1] -36.05985
[1] 12.29012
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:42:19.050] [mlr3] Finished benchmark
INFO  [17:42:19.170] [bbotk] Result of batch 7:
INFO  [17:42:19.224] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:42:19.224] [bbotk]              -6.427075                          0.633612
INFO  [17:42:19.224] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:42:19.224] [bbotk]                         0.2707773           -4.700072              -4.241021
INFO  [17:42:19.224] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:42:19.224] [bbotk]                         12                    4885                  0.394797
INFO  [17:42:19.224] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:42:19.224] [bbotk]  0.0248582 <list[8]>              FALSE     0.02383523        0      0
INFO  [17:42:19.224] [bbotk]  runtime_learners                                uhash
INFO  [17:42:19.224] [bbotk]           169.936 a93444c6-5bad-4b83-b609-7f72c0d389d5
INFO  [17:42:21.852] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 38 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:42:30.201] [bbotk] Evaluating 1 configuration(s)
INFO  [17:42:30.253] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:42:30.357] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -96.35284
[1] 20.05321
[1] -72.36258
[1] 34.16045
[1] -32.3789
[1] 35.46804
[1] -2247.112
[1] -124.802
[1] -55.6966
[1] 12.17771
INFO  [17:42:57.023] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -59.91661
[1] 9.892341
[1] -73.78554
[1] 58.81015
[1] -4542.911
[1] -89.75794
[1] -167.2806
[1] -2.587482
[1] -22.42167
[1] 63.52583
INFO  [17:43:27.223] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -164.7519
[1] 0.9260227
[1] -34.61622
[1] 63.39761
[1] -93.2249
[1] 21.17796
[1] -3268.723
[1] -145.1106
[1] -33.31939
[1] 109.2783
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:43:54.501] [mlr3] Finished benchmark
INFO  [17:43:54.708] [bbotk] Result of batch 8:
INFO  [17:43:54.806] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:43:54.806] [bbotk]              -6.240549                         0.5136398
INFO  [17:43:54.806] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:43:54.806] [bbotk]                         0.1992473           -2.113129              -4.345955
INFO  [17:43:54.806] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:43:54.806] [bbotk]                          5                    2226                 0.5590178
INFO  [17:43:54.806] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:43:54.806] [bbotk]  0.02456407 <list[8]>              FALSE     0.02749857        0      0
INFO  [17:43:54.806] [bbotk]  runtime_learners                                uhash
INFO  [17:43:54.806] [bbotk]            83.157 a534132c-8938-4447-81bf-9dd02ba6615d
INFO  [17:43:56.221] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 39 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:44:03.883] [bbotk] Evaluating 1 configuration(s)
INFO  [17:44:04.087] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:44:04.166] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -62.91068
[1] 12.86422
[1] -1651.14
[1] -56.51586
[1] 50.33002
[1] 1707.742
[1] -29.94795
[1] 40.05811
[1] -35.06855
[1] 64.21062
INFO  [17:44:33.874] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -4630.466
[1] -76.72372
[1] -1930.343
[1] -58.80312
[1] -2156.259
[1] -106.3492
[1] -111.908
[1] 6.830612
[1] -24.99875
[1] 18.30458
INFO  [17:45:08.696] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -113.8875
[1] 10.41821
[1] -27.80364
[1] 85.39391
[1] -69.6981
[1] -3.554125
[1] -85.71322
[1] 28.62889
[1] -65.9116
[1] 414.4261
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:46:01.501] [mlr3] Finished benchmark
INFO  [17:46:01.749] [bbotk] Result of batch 9:
INFO  [17:46:01.968] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:46:01.968] [bbotk]              -3.618265                          0.296242
INFO  [17:46:01.968] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:46:01.968] [bbotk]                         0.6122417           -1.864311               2.217424
INFO  [17:46:01.968] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:46:01.968] [bbotk]                         12                    4346                 0.3179314
INFO  [17:46:01.968] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:46:01.968] [bbotk]  0.0184098 <list[8]>              FALSE     0.02539587        0      0
INFO  [17:46:01.968] [bbotk]  runtime_learners                                uhash
INFO  [17:46:01.968] [bbotk]           114.874 88970c47-3245-44e3-b9cc-47fb71317631
INFO  [17:46:03.671] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 40 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:46:10.742] [bbotk] Evaluating 1 configuration(s)
INFO  [17:46:11.024] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:46:11.172] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -91.35255
[1] 31.51188
[1] -80.31921
[1] 28.76437
[1] -159.1413
[1] 8.534608
[1] -28.24459
[1] 59.08336
[1] -216.4407
[1] 111.2663
INFO  [17:46:53.823] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -243.5114
[1] -4.198672
[1] -26.28437
[1] 225.1726
[1] -124.9116
[1] 86.77568
[1] -106.5675
[1] 171.8948
[1] -116.5578
[1] -3.968654
INFO  [17:47:35.263] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -55.25293
[1] 24.12715
[1] -164.0825
[1] 89.56255
[1] -119.7617
[1] 47.88743
[1] -45.4173
[1] 79.90962
[1] -48.46579
[1] 54.45767
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:48:18.628] [mlr3] Finished benchmark
INFO  [17:48:18.847] [bbotk] Result of batch 10:
INFO  [17:48:18.927] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:48:18.927] [bbotk]              0.9135715                         0.3529902
INFO  [17:48:18.927] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:48:18.927] [bbotk]                           0.45533           -4.678507              -2.958839
INFO  [17:48:18.927] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:48:18.927] [bbotk]                         18                    3980                 0.6896997
INFO  [17:48:18.927] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:48:18.927] [bbotk]  0.01849123 <list[8]>              FALSE     0.02926915        0      0
INFO  [17:48:18.927] [bbotk]  runtime_learners                                uhash
INFO  [17:48:18.927] [bbotk]           127.098 e1e1efa3-4bfe-453c-a53d-42b90657da1b
INFO  [17:48:20.339] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 41 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:48:26.897] [bbotk] Evaluating 1 configuration(s)
INFO  [17:48:27.097] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:48:27.317] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -201.5543
[1] 13.87335
[1] -85.39805
[1] 5.168149
[1] -45.90987
[1] 133.7809
[1] -1206.424
[1] -31.5892
[1] -67.18279
[1] 56.07706
INFO  [17:49:16.186] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -18.71601
[1] 75.57659
[1] -101.7738
[1] 45.03478
[1] -106.04
[1] -3.070905
[1] -67.87456
[1] 9.107677
[1] -49.5173
[1] 63.51294
INFO  [17:49:54.591] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -111.8187
[1] 5.916788
[1] -3377.02
[1] -51.78174
[1] -3064.483
[1] -60.21551
[1] -93.91211
[1] 19.79879
[1] -56.61106
[1] 20.2516
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:50:34.057] [mlr3] Finished benchmark
INFO  [17:50:34.205] [bbotk] Result of batch 11:
INFO  [17:50:34.334] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:50:34.334] [bbotk]              -2.632399                         0.8196788
INFO  [17:50:34.334] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:50:34.334] [bbotk]                         0.7587611           -4.308009              -6.179531
INFO  [17:50:34.334] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:50:34.334] [bbotk]                         18                    4962                 0.2786026
INFO  [17:50:34.334] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:50:34.334] [bbotk]  0.01897477 <list[8]>              FALSE     0.02585274        0      0
INFO  [17:50:34.334] [bbotk]  runtime_learners                                uhash
INFO  [17:50:34.334] [bbotk]           125.582 348647ca-b731-4f39-a457-210cc6b40dbf
INFO  [17:50:36.834] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 42 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:50:43.417] [bbotk] Evaluating 1 configuration(s)
INFO  [17:50:43.646] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:50:43.804] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -30.84103
[1] 41.88019
[1] -63.00144
[1] 73.13153
[1] -51.6714
[1] 16.67453
[1] -5.801948
[1] 95.70397
[1] -37.74057
[1] 86.46827
INFO  [17:51:12.230] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1917.081
[1] -37.16754
[1] -45.39211
[1] 11.71479
[1] -3.103967
[1] 65.67754
[1] -69.9876
[1] 47.91089
[1] -16.0437
[1] 254.6832
INFO  [17:51:42.950] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -29.96247
[1] 32.39467
[1] -103.3045
[1] 53.93451
[1] -61.47913
[1] 1.799607
[1] -155.0687
[1] 30.88898
[1] -964.4095
[1] -2.120606
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:52:04.854] [mlr3] Finished benchmark
INFO  [17:52:05.282] [bbotk] Result of batch 12:
INFO  [17:52:05.528] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:52:05.528] [bbotk]              -4.563077                         0.3216654
INFO  [17:52:05.528] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:52:05.528] [bbotk]                         0.3351047            -1.57095              -3.104869
INFO  [17:52:05.528] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:52:05.528] [bbotk]                          1                    1653                 0.1442122
INFO  [17:52:05.528] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:52:05.528] [bbotk]  0.01593163 <list[8]>              FALSE     0.02773197        0      0
INFO  [17:52:05.528] [bbotk]  runtime_learners                                uhash
INFO  [17:52:05.528] [bbotk]            79.498 725f5562-b4a4-46c4-b83f-46d230888faa
INFO  [17:52:08.181] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 43 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:52:20.851] [bbotk] Evaluating 1 configuration(s)
INFO  [17:52:21.334] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:52:22.122] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -90.91931
[1] 23.61942
[1] -90.33366
[1] 14.29266
[1] -3.738574e+16
[1] -6.448854e+14
[1] -51.09866
[1] 35.09054
[1] -50.81027
[1] 45.33904
INFO  [17:52:41.801] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -19.43805
[1] 78.733
[1] -31.37132
[1] 55.36758
[1] -128.8237
[1] 7.801806
[1] -64.59228
[1] 54.08025
[1] -89.19951
[1] -4.050725
INFO  [17:53:06.836] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -89.90437
[1] 12.60252
[1] -2395.624
[1] -44.41259
[1] -49.54275
[1] 42.84478
[1] -62.07444
[1] 47.91427
[1] -37.99162
[1] 28.05775
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:53:36.801] [mlr3] Finished benchmark
INFO  [17:53:36.997] [bbotk] Result of batch 13:
INFO  [17:53:37.048] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:53:37.048] [bbotk]             -0.4486326                         0.7988159
INFO  [17:53:37.048] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:53:37.048] [bbotk]                         0.5813011           -1.481795               -1.20918
INFO  [17:53:37.048] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:53:37.048] [bbotk]                          9                     881                 0.9934557
INFO  [17:53:37.048] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:53:37.048] [bbotk]  0.01648265 <list[8]>              FALSE     0.02762787        0      0
INFO  [17:53:37.048] [bbotk]  runtime_learners                                uhash
INFO  [17:53:37.048] [bbotk]            73.064 a907100c-9ac7-4b19-a06e-e976a18c13e7
INFO  [17:53:38.925] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 44 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:53:45.636] [bbotk] Evaluating 1 configuration(s)
INFO  [17:53:45.802] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:53:46.076] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -67.10293
[1] 9.384857
[1] -36.13663
[1] 44.05211
[1] -27.93706
[1] 21.2085
[1] -37.94803
[1] 71.23456
[1] -42.62108
[1] 34.97629
INFO  [17:54:35.014] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -31.07886
[1] 80.10156
[1] -45.87113
[1] 17.25147
[1] -136.972
[1] -3.352263
[1] -1767.524
[1] -34.33683
[1] -50.62629
[1] 13.15459
INFO  [17:55:38.054] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -19764.34
[1] -610.1764
[1] -857.9367
[1] -28.78663
[1] -92.38465
[1] 6.472133
[1] -191.8368
[1] 7.304272
[1] -39.16741
[1] 22.96495
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:56:34.409] [mlr3] Finished benchmark
INFO  [17:56:34.898] [bbotk] Result of batch 14:
INFO  [17:56:34.992] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:56:34.992] [bbotk]               -6.40025                         0.7950467
INFO  [17:56:34.992] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:56:34.992] [bbotk]                         0.8749902           -5.351241            0.004884086
INFO  [17:56:34.992] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:56:34.992] [bbotk]                          2                    4029                 0.8651147
INFO  [17:56:34.992] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:56:34.992] [bbotk]  0.01732611 <list[8]>              FALSE     0.02715215        0      0
INFO  [17:56:34.992] [bbotk]  runtime_learners                                uhash
INFO  [17:56:34.992] [bbotk]           167.532 bf3664d2-1bec-4cfd-ae56-30dbf4e1f0c4
INFO  [17:56:36.773] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 45 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:56:43.416] [bbotk] Evaluating 1 configuration(s)
INFO  [17:56:43.483] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:56:43.516] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -57.41589
[1] 14.94768
[1] -46.09437
[1] 46.81545
[1] -48.66831
[1] 20.21089
[1] -43.57137
[1] 37.40346
[1] -53.71194
[1] 62.96665
INFO  [17:57:08.661] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -155.3766
[1] 37.97197
[1] -65.7435
[1] -4.066078
[1] -1698.11
[1] -59.13829
[1] 61.62719
[1] 1613.934
[1] -37.18482
[1] 13.91186
INFO  [17:57:55.612] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -12.57531
[1] 85.08726
[1] -68.30815
[1] 13.63072
[1] -96.30783
[1] 9.517
[1] -42.78384
[1] 42.14785
[1] -40.41369
[1] 57.06908
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:58:53.192] [mlr3] Finished benchmark
INFO  [17:58:53.410] [bbotk] Result of batch 15:
INFO  [17:58:53.483] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:58:53.483] [bbotk]              -1.161726                          0.372731
INFO  [17:58:53.483] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:58:53.483] [bbotk]                         0.8855738           -4.454681              -2.517789
INFO  [17:58:53.483] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:58:53.483] [bbotk]                         14                    4768                 0.6006067
INFO  [17:58:53.483] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:58:53.483] [bbotk]  0.01691129 <list[8]>              FALSE     0.02510669        0      0
INFO  [17:58:53.483] [bbotk]  runtime_learners                                uhash
INFO  [17:58:53.483] [bbotk]           128.129 1321e049-63d2-438c-9891-338fcd52d11c
INFO  [17:58:55.983] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 46 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:59:03.628] [bbotk] Evaluating 1 configuration(s)
INFO  [17:59:04.219] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:59:04.491] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1701.961
[1] -85.05611
[1] -38.65869
[1] 59.73079
[1] -39.86781
[1] 13.7991
[1] -6360.876
[1] -139.121
[1] -67.16422
[1] 79.32433
INFO  [17:59:46.695] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -19.56383
[1] 142.1047
[1] -72.30911
[1] 14.6538
[1] -17.86946
[1] 230.1293
[1] -1487.964
[1] -59.20533
[1] -277.0192
[1] -3.084039
INFO  [18:00:27.597] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -53.87205
[1] 16.22907
[1] -48.4245
[1] 70.01178
[1] -2.582927e+16
[1] 5.579971e+15
[1] -1423.729
[1] -32.5032
[1] -83.68503
[1] 16.91144
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:01:04.571] [mlr3] Finished benchmark
INFO  [18:01:04.725] [bbotk] Result of batch 16:
INFO  [18:01:04.768] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:01:04.768] [bbotk]             -0.2550074                         0.9792375
INFO  [18:01:04.768] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:01:04.768] [bbotk]                         0.7191739           -3.862328              -6.209031
INFO  [18:01:04.768] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:01:04.768] [bbotk]                         11                    2770                 0.5646259
INFO  [18:01:04.768] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:01:04.768] [bbotk]  0.01335923 <list[8]>              FALSE     0.02507627        0      0
INFO  [18:01:04.768] [bbotk]  runtime_learners                                uhash
INFO  [18:01:04.768] [bbotk]           118.979 bef40761-9f37-44d9-ab5e-f772d0a29a8f
WARN  [18:01:07.505] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:01:07.541] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 47 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:01:13.159] [bbotk] Evaluating 1 configuration(s)
INFO  [18:01:13.267] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:01:13.318] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -52.42505
[1] 59.16179
[1] -100.5776
[1] 3.300956
[1] -5063.978
[1] -126.8773
[1] -279.8795
[1] 30.83279
[1] -127.9732
[1] -3.992473
INFO  [18:02:17.959] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -103.5137
[1] 133.4851
[1] 151.219
[1] 4232.165
[1] -77.67867
[1] 22.45512
[1] -56.15968
[1] 35.49639
[1] -108.8566
[1] 96.95478
INFO  [18:03:13.977] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -88.50821
[1] 88.28958
[1] -185.0323
[1] 1.588681
[1] -174.1144
[1] 51.12947
[1] -47.76109
[1] 114.6615
[1] -74.76786
[1] 8.593562
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:04:20.797] [mlr3] Finished benchmark
INFO  [18:04:20.957] [bbotk] Result of batch 17:
INFO  [18:04:21.004] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:04:21.004] [bbotk]               1.844856                         0.8644825
INFO  [18:04:21.004] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:04:21.004] [bbotk]                         0.9260752           -4.237647              -6.272496
INFO  [18:04:21.004] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:04:21.004] [bbotk]                         15                    4073                 0.9752322
INFO  [18:04:21.004] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:04:21.004] [bbotk]  0.01248957 <list[8]>              FALSE     0.03484995        0      0
INFO  [18:04:21.004] [bbotk]  runtime_learners                                uhash
INFO  [18:04:21.004] [bbotk]           186.777 3d25de71-126b-4d83-80fe-026815c5bc14
INFO  [18:04:22.742] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 48 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:04:29.457] [bbotk] Evaluating 1 configuration(s)
INFO  [18:04:29.644] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:04:29.829] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -301.69
[1] 926.0709
[1] -52.37247
[1] 54.12517
[1] -102.0268
[1] 17.56289
[1] -100.7844
[1] 113.8868
[1] -42.76269
[1] 39.49179
INFO  [18:04:58.598] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -42.47661
[1] 60.45254
[1] -164.0649
[1] -1.214076
[1] -215.7219
[1] -2.165476
[1] -88.71441
[1] 4.496486
[1] -4789.896
[1] -119.709
INFO  [18:05:33.627] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -11.63676
[1] 152.4393
[1] -306.7552
[1] 2.332427
[1] -76.43096
[1] 122.9482
[1] -99.96225
[1] 12.02832
[1] -106.3369
[1] 82.15268
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:06:04.365] [mlr3] Finished benchmark
INFO  [18:06:04.462] [bbotk] Result of batch 18:
INFO  [18:06:04.603] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:06:04.603] [bbotk]              -6.828394                         0.8007366
INFO  [18:06:04.603] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:06:04.603] [bbotk]                         0.7803811           -3.995381               1.074917
INFO  [18:06:04.603] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:06:04.603] [bbotk]                          9                    2576                 0.1524194
INFO  [18:06:04.603] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:06:04.603] [bbotk]  0.01221817 <list[8]>              FALSE     0.02838335        0      0
INFO  [18:06:04.603] [bbotk]  runtime_learners                                uhash
INFO  [18:06:04.603] [bbotk]            93.159 a6f11816-59b8-41ae-a088-958c99d00c0d
INFO  [18:06:07.042] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 49 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:06:17.248] [bbotk] Evaluating 1 configuration(s)
INFO  [18:06:17.504] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:06:17.836] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -251.3604
[1] 44.36016
[1] -321.3488
[1] 220.2009
[1] -1694.164
[1] -38.16626
[1] -98.53668
[1] 94.06665
[1] -53.87325
[1] 11.03033
INFO  [18:06:52.708] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -167.9596
[1] 65.03508
[1] -113.218
[1] 0.4375657
[1] -45.22005
[1] 43.03718
[1] -71.83356
[1] 45.9157
[1] -2866.505
[1] -55.65619
INFO  [18:07:29.720] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 36.20121
[1] 1005.29
[1] -43.53966
[1] 22.09873
[1] -77.63951
[1] 3.015122
[1] -264.8309
[1] 0.4288825
[1] -63.08642
[1] 89.46473
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:08:09.678] [mlr3] Finished benchmark
INFO  [18:08:09.889] [bbotk] Result of batch 19:
INFO  [18:08:09.924] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:08:09.924] [bbotk]              -6.048779                         0.2688695
INFO  [18:08:09.924] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:08:09.924] [bbotk]                         0.2859763           -4.534984              0.8867788
INFO  [18:08:09.924] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:08:09.924] [bbotk]                          1                    4193                 0.2984052
INFO  [18:08:09.924] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:08:09.924] [bbotk]  0.0112953 <list[8]>              FALSE     0.02626105        0      0
INFO  [18:08:09.924] [bbotk]  runtime_learners                                uhash
INFO  [18:08:09.924] [bbotk]           110.665 334f795b-aeed-44eb-8273-46c296b630f9
INFO  [18:08:10.831] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 50 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:08:17.070] [bbotk] Evaluating 1 configuration(s)
INFO  [18:08:17.158] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:08:17.321] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -178.2176
[1] 24.69704
[1] -86.01733
[1] -0.02842304
[1] -62.47584
[1] 52.64303
[1] -81.04904
[1] 22.41477
[1] -39.5125
[1] 66.90687
INFO  [18:08:57.327] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 93.03864
[1] 2881.595
[1] -68.08556
[1] 102.1636
[1] -135.4544
[1] -4.29579
[1] -117.8963
[1] 22.93071
[1] -97.80275
[1] 23.63603
INFO  [18:09:21.936] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 67.49679
[1] 2070.831
[1] -62.03833
[1] 27.07388
[1] -121.8036
[1] 170.2483
[1] -293.4011
[1] -3.88725
[1] -80.54902
[1] 10.72314
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:10:13.141] [mlr3] Finished benchmark
INFO  [18:10:13.407] [bbotk] Result of batch 20:
INFO  [18:10:13.453] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:10:13.453] [bbotk]              -1.231304                         0.9405903
INFO  [18:10:13.453] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:10:13.453] [bbotk]                         0.3494564          -0.2408681               2.938748
INFO  [18:10:13.453] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:10:13.453] [bbotk]                         12                    2943                 0.2862442
INFO  [18:10:13.453] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:10:13.453] [bbotk]  0.01246415 <list[8]>              FALSE     0.02680404        0      0
INFO  [18:10:13.453] [bbotk]  runtime_learners                                uhash
INFO  [18:10:13.453] [bbotk]            114.98 d903434b-b8ac-47f3-8481-f0997eaeeffa
INFO  [18:10:14.158] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 51 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:10:21.445] [bbotk] Evaluating 1 configuration(s)
INFO  [18:10:21.504] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:10:21.711] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -3160.616
[1] -77.08557
[1] -37.98308
[1] 46.68245
[1] -104.9894
[1] -3.495091
[1] -86.17956
[1] -4.049923
[1] -113.4171
[1] 29.96005
INFO  [18:10:45.543] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -122.3444
[1] 21.58413
[1] -95.43147
[1] 1.737631
[1] -81.25616
[1] 90.30867
[1] -425.6207
[1] -3.255342
[1] -23443.2
[1] -881.6214
INFO  [18:11:34.960] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -5766.892
[1] -91.83491
[1] 3.990953
[1] 620.1822
[1] -36.80107
[1] 7.503323
[1] -1521.566
[1] -51.54153
[1] -82.11439
[1] 32.74
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:12:45.209] [mlr3] Finished benchmark
INFO  [18:12:45.346] [bbotk] Result of batch 21:
INFO  [18:12:45.421] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:12:45.421] [bbotk]              -4.349501                         0.5237998
INFO  [18:12:45.421] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:12:45.421] [bbotk]                         0.8110643           -3.499143               -1.43239
INFO  [18:12:45.421] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:12:45.421] [bbotk]                          4                    4952                 0.8324044
INFO  [18:12:45.421] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:12:45.421] [bbotk]  0.01189585 <list[8]>              FALSE     0.02544775        0      0
INFO  [18:12:45.421] [bbotk]  runtime_learners                                uhash
INFO  [18:12:45.421] [bbotk]            142.71 6b9d9734-b4a5-4aa2-a421-c30206231885
INFO  [18:12:46.546] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 52 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:12:52.411] [bbotk] Evaluating 1 configuration(s)
INFO  [18:12:52.689] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:12:52.928] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -66.58382
[1] 31.40339
[1] -82.07563
[1] 6.635766
[1] -110.7215
[1] 22.78707
[1] -37.46609
[1] 86.31348
[1] 294.9967
[1] 9643.954
INFO  [18:13:21.534] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -2574.419
[1] -69.16073
[1] -86.40509
[1] 40.16113
[1] -198.963
[1] -0.06682551
[1] -139.9526
[1] 79.72973
[1] -12.57649
[1] 85.41939
INFO  [18:13:56.132] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -122.4727
[1] 64.09623
[1] -222.1098
[1] 141.7505
[1] -30.56413
[1] 71.98517
[1] -90.19475
[1] 5.098019
[1] 287.4095
[1] 9196.768
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:14:42.424] [mlr3] Finished benchmark
INFO  [18:14:42.675] [bbotk] Result of batch 22:
INFO  [18:14:42.699] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:14:42.699] [bbotk]               1.935075                         0.1258167
INFO  [18:14:42.699] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:14:42.699] [bbotk]                         0.3609669          -0.2295109                2.75443
INFO  [18:14:42.699] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:14:42.699] [bbotk]                          4                    3456                 0.8909632
INFO  [18:14:42.699] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:14:42.699] [bbotk]  0.01055796 <list[8]>              FALSE     0.03926687        0      0
INFO  [18:14:42.699] [bbotk]  runtime_learners                                uhash
INFO  [18:14:42.699] [bbotk]           107.572 e6fea577-3ec4-4fcb-a126-ed80df563f5e
INFO  [18:14:43.961] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 53 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:14:49.351] [bbotk] Evaluating 1 configuration(s)
INFO  [18:14:49.435] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:14:49.547] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -68.48145
[1] 26.25134
[1] -176.1189
[1] 7.642638
[1] -51.28147
[1] 21.31486
[1] -32.40818
[1] 137.6998
[1] -40.06701
[1] 32.88864
INFO  [18:15:17.959] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -22.68643
[1] 34.85466
[1] -307.591
[1] -3.99929
[1] -72.61182
[1] 35.1386
[1] -34.32071
[1] 35.6414
[1] -56.47591
[1] 14.0711
INFO  [18:15:40.731] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 32.90601
[1] 747.4069
[1] -57.87904
[1] 41.00386
[1] -50.2435
[1] 10.7987
[1] -103.6733
[1] -0.3135867
[1] 33.57816
[1] 821.4948
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:16:03.927] [mlr3] Finished benchmark
INFO  [18:16:04.054] [bbotk] Result of batch 23:
INFO  [18:16:04.170] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:16:04.170] [bbotk]                -2.4998                         0.9585783
INFO  [18:16:04.170] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:16:04.170] [bbotk]                         0.9572843           -1.313319              0.8281069
INFO  [18:16:04.170] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:16:04.170] [bbotk]                          8                     754                 0.5464485
INFO  [18:16:04.170] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:16:04.170] [bbotk]  0.0109916 <list[8]>              FALSE     0.02497001        0      0
INFO  [18:16:04.170] [bbotk]  runtime_learners                                uhash
INFO  [18:16:04.170] [bbotk]             73.29 ddfc226e-bf00-40c0-9e4d-12166b03fd3b
INFO  [18:16:05.323] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 54 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:16:10.378] [bbotk] Evaluating 1 configuration(s)
INFO  [18:16:10.481] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:16:10.675] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -49.21129
[1] 223.2165
[1] -144.3042
[1] 8.367193
[1] -59.31974
[1] 109.078
[1] -152.8896
[1] 20.9501
[1] -63.41152
[1] 2.917772
INFO  [18:17:25.596] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -67.82953
[1] 834.1677
[1] -30.93981
[1] 55.42671
[1] -151.9983
[1] 3.614277
[1] -1299.608
[1] -32.67221
[1] -184.9939
[1] 14.84485
INFO  [18:18:26.160] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -93155.56
[1] -2876.602
[1] -125.6977
[1] 10.04109
[1] -253.6813
[1] 13.39799
[1] -54.14513
[1] 34.72589
[1] 31.85203
[1] 1013.395
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:19:20.681] [mlr3] Finished benchmark
INFO  [18:19:20.932] [bbotk] Result of batch 24:
INFO  [18:19:21.159] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:19:21.159] [bbotk]             -0.6519823                         0.6326316
INFO  [18:19:21.159] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:19:21.159] [bbotk]                         0.9153817           -5.523096              -5.591961
INFO  [18:19:21.159] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:19:21.159] [bbotk]                          4                    4821                 0.4710827
INFO  [18:19:21.159] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:19:21.159] [bbotk]  0.01065313 <list[8]>              FALSE     0.02584388        0      0
INFO  [18:19:21.159] [bbotk]  runtime_learners                                uhash
INFO  [18:19:21.159] [bbotk]           188.896 aa9e4d8d-7756-4b55-b0a1-89218effd52e
INFO  [18:19:23.485] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 55 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:19:28.904] [bbotk] Evaluating 1 configuration(s)
INFO  [18:19:29.046] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:19:29.158] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 34.01416
[1] 1017.731
[1] -28.68068
[1] 68.74313
[1] -70.47531
[1] -1.695766
[1] -64.63389
[1] 67.31246
[1] -48.79691
[1] 32.3722
INFO  [18:20:09.702] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -73.54399
[1] 37.45563
[1] -22633.63
[1] -838.0179
[1] -107.9496
[1] -1.820149
[1] -37.58683
[1] 24.22747
[1] -8801.757
[1] -344.1585
INFO  [18:20:43.018] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -36.42302
[1] 49.98092
[1] -250.0391
[1] -3.906728
[1] -111.7892
[1] 61.85903
[1] -50.33765
[1] 18.89423
[1] -6290.136
[1] -215.915
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:21:23.290] [mlr3] Finished benchmark
INFO  [18:21:23.425] [bbotk] Result of batch 25:
INFO  [18:21:23.563] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:21:23.563] [bbotk]              -2.157313                         0.6833728
INFO  [18:21:23.563] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:21:23.563] [bbotk]                           0.95558           -2.874638              0.2561272
INFO  [18:21:23.563] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:21:23.563] [bbotk]                         16                    3515                 0.2889049
INFO  [18:21:23.563] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:21:23.563] [bbotk]  0.01043886 <list[8]>              FALSE     0.02664839        0      0
INFO  [18:21:23.563] [bbotk]  runtime_learners                                uhash
INFO  [18:21:23.563] [bbotk]           111.654 ac14afee-c7a4-4304-a43c-7312eec3ea28
INFO  [18:21:25.506] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 56 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:21:33.475] [bbotk] Evaluating 1 configuration(s)
INFO  [18:21:33.528] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:21:33.619] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -62.63426
[1] 43.04221
[1] -4517.054
[1] -118.3269
[1] -255.5958
[1] 42.46584
[1] -55.2635
[1] 16.01744
[1] -748.5682
[1] -33.50918
INFO  [18:21:55.218] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -27.09649
[1] 244.8416
[1] -126.5839
[1] -4.014921
[1] -50.56757
[1] 28.89736
[1] -93.76651
[1] -3.745794
[1] -3575.7
[1] -61.18883
INFO  [18:22:14.668] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -33.96721
[1] 20.78164
[1] -827.9892
[1] -6.228787
[1] -124.0081
[1] 12.83216
[1] -325.706
[1] -4.123331
[1] -119.0865
[1] 90.3988
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:22:38.782] [mlr3] Finished benchmark
INFO  [18:22:38.938] [bbotk] Result of batch 26:
INFO  [18:22:39.020] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:22:39.020] [bbotk]              -1.536054                         0.8066144
INFO  [18:22:39.020] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:22:39.020] [bbotk]                         0.4259884           -2.273805              -4.995146
INFO  [18:22:39.020] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:22:39.020] [bbotk]                         12                    1359                 0.2357355
INFO  [18:22:39.020] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:22:39.020] [bbotk]  0.01039869 <list[8]>              FALSE     0.02606974        0      0
INFO  [18:22:39.020] [bbotk]  runtime_learners                                uhash
INFO  [18:22:39.020] [bbotk]            62.826 63809a0b-b347-4f51-8995-f83534dea0b4
WARN  [18:22:40.974] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:22:41.027] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 57 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:22:50.711] [bbotk] Evaluating 1 configuration(s)
INFO  [18:22:50.769] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:22:50.802] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1979.196
[1] -167.3085
[1] -186.7255
[1] -3.696924
[1] -24.4612
[1] 26.78504
[1] -66.74998
[1] 30.02245
[1] -95.22817
[1] 85.36362
INFO  [18:23:24.390] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -150.6879
[1] 0.7294868
[1] -95.53958
[1] 205.6908
[1] -216.9236
[1] 1.794446
[1] -2991.736
[1] -44.35983
[1] -11.76904
[1] 98.53089
INFO  [18:24:15.004] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1437.769
[1] -34.82769
[1] -3936.204
[1] -82.72889
[1] -34.79926
[1] 56.12645
[1] -24.09417
[1] 25.07616
[1] -119.1766
[1] 9.481508
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:24:58.112] [mlr3] Finished benchmark
INFO  [18:24:58.468] [bbotk] Result of batch 27:
INFO  [18:24:58.590] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:24:58.590] [bbotk]              -3.338786                         0.8129469
INFO  [18:24:58.590] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:24:58.590] [bbotk]                         0.7643701           -1.141463              -3.615605
INFO  [18:24:58.590] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:24:58.590] [bbotk]                          4                    2783                  0.556387
INFO  [18:24:58.590] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:24:58.590] [bbotk]  0.009552289 <list[8]>              FALSE      0.0281716        0      0
INFO  [18:24:58.590] [bbotk]  runtime_learners                                uhash
INFO  [18:24:58.590] [bbotk]           124.991 f3715f0f-287d-4d60-a1c9-968386cf83eb
INFO  [18:25:01.669] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 58 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:25:07.777] [bbotk] Evaluating 1 configuration(s)
INFO  [18:25:08.016] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:25:08.096] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -34.77086
[1] 20.88844
[1] -48.00813
[1] 54.61908
[1] 50.95543
[1] 1281.575
[1] -50.51458
[1] 29.91773
[1] -59.10567
[1] 20.24247
INFO  [18:25:29.325] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1762.021
[1] -43.89806
[1] -44.76146
[1] 61.91125
[1] -135.7722
[1] 9.982654
[1] -29.58364
[1] 47.69275
[1] -2192.137
[1] -36.22979
INFO  [18:26:13.433] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -106.3822
[1] 24.47891
[1] -16956.92
[1] -368.9875
[1] 32.49225
[1] 798.4112
[1] -40.97554
[1] 35.73722
[1] -47.41633
[1] 18.4378
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:27:00.672] [mlr3] Finished benchmark
INFO  [18:27:01.486] [bbotk] Result of batch 28:
INFO  [18:27:01.655] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:27:01.655] [bbotk]              -6.808492                         0.1440212
INFO  [18:27:01.655] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:27:01.655] [bbotk]                         0.6876054           -5.741291              -6.043771
INFO  [18:27:01.655] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:27:01.655] [bbotk]                         13                    4570                 0.6626323
INFO  [18:27:01.655] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:27:01.655] [bbotk]  0.009850016 <list[8]>              FALSE     0.02813094        0      0
INFO  [18:27:01.655] [bbotk]  runtime_learners                                uhash
INFO  [18:27:01.655] [bbotk]           111.282 245c6af4-6de7-42ec-b0fa-1d4285b6e433
INFO  [18:27:03.162] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 59 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:27:09.741] [bbotk] Evaluating 1 configuration(s)
INFO  [18:27:09.823] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:27:09.917] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -128.2929
[1] -4.449342
[1] -68.02115
[1] 85.63131
[1] -15627.55
[1] -236.8867
[1] -118.6525
[1] 69.51725
[1] -253.2019
[1] 3.761194
INFO  [18:27:33.111] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -159.0264
[1] 89.48279
[1] -60.02803
[1] 156.7632
[1] -137.025
[1] -4.856398
[1] -199.4527
[1] 139.7384
[1] -416.5108
[1] -3.731983
INFO  [18:27:59.266] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -369.8604
[1] -4.510536
[1] -42.98806
[1] 128.5391
[1] -32448.88
[1] -555.3415
[1] -53.04466
[1] 64.20743
[1] -72.39517
[1] 66.95825
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:28:26.260] [mlr3] Finished benchmark
INFO  [18:28:26.399] [bbotk] Result of batch 29:
INFO  [18:28:26.426] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:28:26.426] [bbotk]               1.942285                         0.1366841
INFO  [18:28:26.426] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:28:26.426] [bbotk]                         0.4656214           -4.248859              -3.782671
INFO  [18:28:26.426] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:28:26.426] [bbotk]                          6                    1463                 0.9644449
INFO  [18:28:26.426] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:28:26.426] [bbotk]  0.009818611 <list[8]>              FALSE     0.03772753        0      0
INFO  [18:28:26.426] [bbotk]  runtime_learners                                uhash
INFO  [18:28:26.426] [bbotk]             75.57 e297be45-ac62-4a5d-ba8b-cf30793056cf
INFO  [18:28:27.761] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 60 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:28:34.518] [bbotk] Evaluating 1 configuration(s)
INFO  [18:28:34.751] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:28:34.941] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -113.6019
[1] 7.114968
[1] -55.66703
[1] 26.99328
[1] -3078.446
[1] -46.55811
[1] -127.9896
[1] 11.17469
[1] 34.12124
[1] 1106.336
INFO  [18:30:13.261] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -120.4331
[1] -3.432777
[1] -47.45317
[1] 281.1287
[1] -30.8952
[1] 48.8438
[1] -101.5568
[1] 36.98695
[1] -60.96799
[1] 143.6877
INFO  [18:31:09.271] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -56.47131
[1] 49.95044
[1] -3278.499
[1] -60.56429
[1] -81.75154
[1] 22.8933
[1] -84.17527
[1] 29.02764
[1] -37.7294
[1] 153.3798
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:32:45.620] [mlr3] Finished benchmark
INFO  [18:32:45.791] [bbotk] Result of batch 30:
INFO  [18:32:45.916] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:32:45.916] [bbotk]              -1.351251                         0.9826583
INFO  [18:32:45.916] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:32:45.916] [bbotk]                         0.9506116           -6.852227              -6.839618
INFO  [18:32:45.916] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:32:45.916] [bbotk]                         20                    4563                 0.4335333
INFO  [18:32:45.916] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:32:45.916] [bbotk]  0.01058205 <list[8]>              FALSE     0.02919324        0      0
INFO  [18:32:45.916] [bbotk]  runtime_learners                                uhash
INFO  [18:32:45.916] [bbotk]           248.303 9e8fd081-98ca-4881-a112-e8371ae5a044
INFO  [18:32:47.363] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 61 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:32:53.780] [bbotk] Evaluating 1 configuration(s)
INFO  [18:32:54.014] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:32:54.128] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -60.45472
[1] 19.02873
[1] -119.6182
[1] 10.83353
[1] -50.47058
[1] 59.45883
[1] -8540.272
[1] -133.3579
[1] -64.84293
[1] 7.373148
INFO  [18:34:36.658] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -32.56036
[1] 143.8759
[1] -54.49065
[1] 32.4262
[1] -120.0153
[1] 7.440421
[1] -48.9236
[1] 42.87262
[1] -131.1275
[1] 8.74775
INFO  [18:36:29.173] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -65.87976
[1] 75.60344
[1] 35.08297
[1] 1007.508
[1] -107.6038
[1] 37.51731
[1] -65.83424
[1] 25.41561
[1] -61.17516
[1] 18.6569
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:37:51.024] [mlr3] Finished benchmark
INFO  [18:37:51.299] [bbotk] Result of batch 31:
INFO  [18:37:51.550] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:37:51.550] [bbotk]              -6.692121                         0.8009924
INFO  [18:37:51.550] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:37:51.550] [bbotk]                           0.68925           -6.112114              0.8114627
INFO  [18:37:51.550] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:37:51.550] [bbotk]                         19                    4964                   0.68029
INFO  [18:37:51.550] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:37:51.550] [bbotk]  0.009422069 <list[8]>              FALSE     0.02479454        0      0
INFO  [18:37:51.550] [bbotk]  runtime_learners                                uhash
INFO  [18:37:51.550] [bbotk]           296.568 647b2f15-712e-4243-a8a1-e0ec7651efe6
INFO  [18:37:52.891] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 62 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:38:17.305] [bbotk] Evaluating 1 configuration(s)
INFO  [18:38:17.420] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:38:17.511] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -113.3256
[1] 13.61824
[1] -42.49493
[1] 26.02557
[1] -70.10712
[1] 29.42077
[1] -98.496
[1] 65.97173
[1] -64.73277
[1] 14.55808
INFO  [18:38:47.022] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -154.2671
[1] -4.150246
[1] -46.41519
[1] 6.501307
[1] 126.8006
[1] 3513.002
[1] -2088.961
[1] -39.66209
[1] -8246.691
[1] -345.9488
INFO  [18:39:21.162] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 170.8456
[1] 3277.75
[1] -45481.75
[1] -1812.457
[1] -26.61803
[1] 37.4223
[1] -555.3177
[1] 0.7532155
[1] -164.5485
[1] 84.69582
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:39:55.561] [mlr3] Finished benchmark
INFO  [18:39:55.775] [bbotk] Result of batch 32:
INFO  [18:39:55.825] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:39:55.825] [bbotk]               -1.77659                         0.5506347
INFO  [18:39:55.825] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:39:55.825] [bbotk]                         0.6942688          -0.8928851               3.217033
INFO  [18:39:55.825] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:39:55.825] [bbotk]                         18                    1956                 0.6571735
INFO  [18:39:55.825] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:39:55.825] [bbotk]  0.009155088 <list[8]>              FALSE     0.02607364        0      0
INFO  [18:39:55.825] [bbotk]  runtime_learners                                uhash
INFO  [18:39:55.825] [bbotk]            96.525 b59eafd1-3cc0-477b-aa6a-b2f08f2c93a1
INFO  [18:39:59.065] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 63 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:40:06.412] [bbotk] Evaluating 1 configuration(s)
INFO  [18:40:06.576] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:40:06.700] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -31.53113
[1] 142.1107
[1] -53.40138
[1] 501.8079
[1] -28.4812
[1] 37.30866
[1] -181.6933
[1] -3.130601
[1] -83.2828
[1] 17.38401
INFO  [18:40:28.498] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -53.70808
[1] 23.21648
[1] -128.7809
[1] 57.15205
[1] -87.87757
[1] 61.25169
[1] -24.75578
[1] 142.5018
[1] -31.04047
[1] 37.49594
INFO  [18:40:49.285] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -287.8736
[1] 166.9837
[1] -78.89523
[1] 19.98546
[1] -1584.47
[1] -71.67306
[1] -35.82048
[1] 23.08562
[1] -1318.083
[1] -4.144416
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:41:05.114] [mlr3] Finished benchmark
INFO  [18:41:05.729] [bbotk] Result of batch 33:
INFO  [18:41:06.017] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:41:06.017] [bbotk]               -5.37472                         0.3663938
INFO  [18:41:06.017] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:41:06.017] [bbotk]                         0.8971181           -1.087834             -0.4802387
INFO  [18:41:06.017] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:41:06.017] [bbotk]                         11                     595                 0.2981647
INFO  [18:41:06.017] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:41:06.017] [bbotk]  0.008687559 <list[8]>              FALSE     0.02461946        0      0
INFO  [18:41:06.017] [bbotk]  runtime_learners                                uhash
INFO  [18:41:06.017] [bbotk]            56.754 be8e6c86-f5eb-4957-b44d-2dad6275a838
WARN  [18:41:07.598] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:41:07.617] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 64 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:41:12.428] [bbotk] Evaluating 1 configuration(s)
INFO  [18:41:12.510] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:41:12.651] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -50.73327
[1] -1.651386
[1] -108.8489
[1] 22.57126
[1] -27.06837
[1] 25.01942
[1] -4.761717
[1] 96.41381
[1] -3190.659
[1] -68.64793
INFO  [18:41:27.163] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -219.9519
[1] -0.8775973
[1] -470.9745
[1] -4.031648
[1] 126.1396
[1] 3543.043
[1] -47.16516
[1] -0.7982541
[1] -19.94594
[1] 62.99818
INFO  [18:41:44.279] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1.290921e+16
[1] 1.680508e+16
[1] -23.34054
[1] 102.9495
[1] -2399.132
[1] -3.609423
[1] -27.31496
[1] 33.12711
[1] -61.22736
[1] 23.86836
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:41:59.450] [mlr3] Finished benchmark
INFO  [18:41:59.817] [bbotk] Result of batch 34:
INFO  [18:41:59.866] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:41:59.866] [bbotk]              -3.784682                          0.920456
INFO  [18:41:59.866] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:41:59.866] [bbotk]                         0.1448586           -1.439545              -2.409623
INFO  [18:41:59.866] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:41:59.866] [bbotk]                         16                     285                 0.7895558
INFO  [18:41:59.866] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:41:59.866] [bbotk]  0.008927903 <list[8]>              FALSE     0.02597465        0      0
INFO  [18:41:59.866] [bbotk]  runtime_learners                                uhash
INFO  [18:41:59.866] [bbotk]            44.708 d966f198-e4ba-42a7-98f1-32cdc292dcf7
INFO  [18:42:02.049] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 65 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:42:10.757] [bbotk] Evaluating 1 configuration(s)
INFO  [18:42:10.841] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:42:10.929] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -60.53131
[1] 63.45265
[1] -2324.097
[1] -86.98883
[1] -93.24301
[1] 34.0767
[1] -81.25046
[1] 29.4664
[1] -44.73055
[1] 161.8172
INFO  [18:42:51.530] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -9595.432
[1] -254.59
[1] -173.2334
[1] -3.293003
[1] -122.21
[1] 19.91396
[1] -57.53129
[1] 44.62517
[1] -234.7814
[1] -11.30259
INFO  [18:43:30.463] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -249.0694
[1] 26.94841
[1] -57.48707
[1] 21.35177
[1] 95.36251
[1] 4411.096
[1] -60.94713
[1] 73.52275
[1] -240.243
[1] -4.068645
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:44:29.859] [mlr3] Finished benchmark
INFO  [18:44:30.054] [bbotk] Result of batch 35:
INFO  [18:44:30.187] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:44:30.187] [bbotk]              -5.013568                         0.2475416
INFO  [18:44:30.187] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:44:30.187] [bbotk]                         0.5737089           -4.050718               -6.19379
INFO  [18:44:30.187] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:44:30.187] [bbotk]                          4                    4622                 0.1300131
INFO  [18:44:30.187] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:44:30.187] [bbotk]  0.007365342 <list[8]>              FALSE     0.02592479        0      0
INFO  [18:44:30.187] [bbotk]  runtime_learners                                uhash
INFO  [18:44:30.187] [bbotk]           137.848 cd525534-3f7f-4f17-97c1-23bcaa4df03a
INFO  [18:44:31.847] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 66 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:44:37.467] [bbotk] Evaluating 1 configuration(s)
INFO  [18:44:37.542] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:44:37.620] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -77.3875
[1] 128.7537
[1] -57.37309
[1] 109.0805
[1] -246.3379
[1] 35.27933
[1] -133.8312
[1] -4.543892
[1] -99.53696
[1] 41.49081
INFO  [18:45:09.577] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -92.2677
[1] 62.68779
[1] -7366.979
[1] -80.07207
[1] -249.1624
[1] -4.493345
[1] -123.5479
[1] 5.104244
[1] -62.10988
[1] 72.47617
INFO  [18:45:44.641] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -210.8712
[1] 33.99468
[1] -116.2928
[1] 20.835
[1] -437.9435
[1] -2.038129
[1] 1148.944
[1] 38591.78
[1] -48.73543
[1] 145.4282
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:46:36.147] [mlr3] Finished benchmark
INFO  [18:46:36.281] [bbotk] Result of batch 36:
INFO  [18:46:36.377] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:46:36.377] [bbotk]               2.007974                         0.4060757
INFO  [18:46:36.377] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:46:36.377] [bbotk]                         0.1881038           -3.291279              -6.379028
INFO  [18:46:36.377] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:46:36.377] [bbotk]                         20                    4248                  0.929215
INFO  [18:46:36.377] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:46:36.377] [bbotk]  0.009252145 <list[8]>              FALSE     0.03772788        0      0
INFO  [18:46:36.377] [bbotk]  runtime_learners                                uhash
INFO  [18:46:36.377] [bbotk]           117.049 f27837f4-61d6-4204-a80c-7f49a2b9454b
INFO  [18:46:37.575] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 67 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:46:43.298] [bbotk] Evaluating 1 configuration(s)
INFO  [18:46:43.405] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:46:43.449] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -64.81677
[1] 17.76003
[1] -43.11806
[1] 34.41811
[1] -73.6175
[1] 10.37972
[1] -195.3552
[1] 5.299712
[1] -54.89567
[1] 35.5258
INFO  [18:47:22.601] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -34.12468
[1] 33.23919
[1] -216.8804
[1] -3.980911
[1] -75.27356
[1] 28.70967
[1] -95.55289
[1] 8.507218
[1] -90.82459
[1] 158.9329
INFO  [18:47:56.497] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -324.7365
[1] 3.516821
[1] -3297.255
[1] -85.29048
[1] -28.78229
[1] 56.01482
[1] -346.0714
[1] -4.105735
[1] -45.44489
[1] 25.94469
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:48:35.032] [mlr3] Finished benchmark
INFO  [18:48:35.245] [bbotk] Result of batch 37:
INFO  [18:48:35.266] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:48:35.266] [bbotk]              0.1190792                         0.2914848
INFO  [18:48:35.266] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:48:35.266] [bbotk]                         0.6547328          -0.6640295              -6.498774
INFO  [18:48:35.266] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:48:35.266] [bbotk]                         12                    3798                 0.1041217
INFO  [18:48:35.266] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:48:35.266] [bbotk]  0.008012696 <list[8]>              FALSE     0.02916104        0      0
INFO  [18:48:35.266] [bbotk]  runtime_learners                                uhash
INFO  [18:48:35.266] [bbotk]           110.368 01e9bb12-0499-4cc6-ac29-542de4cf3f7c
INFO  [18:48:36.510] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 68 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:48:48.378] [bbotk] Evaluating 1 configuration(s)
INFO  [18:48:48.419] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:48:48.477] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -44.23036
[1] 15.76314
[1] -2560.653
[1] -75.45001
[1] -63.42804
[1] 67.74941
[1] -1.543596e+15
[1] 3.837904e+16
[1] -205.2185
[1] 9.484266
INFO  [18:49:26.620] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -213.49
[1] -3.949115
[1] -92.97677
[1] 16.15956
[1] -93.16737
[1] 157.5313
[1] -114.6962
[1] 12.28795
[1] -240.7151
[1] 6.541447
INFO  [18:49:59.557] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -37.06992
[1] 218.3393
[1] -169.2534
[1] 11.75631
[1] 60.96899
[1] 1940.589
[1] -43.67151
[1] 74.33308
[1] -138.0035
[1] 0.9429766
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:50:37.031] [mlr3] Finished benchmark
INFO  [18:50:37.307] [bbotk] Result of batch 38:
INFO  [18:50:37.350] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:50:37.350] [bbotk]              -5.377964                         0.5450453
INFO  [18:50:37.350] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:50:37.350] [bbotk]                         0.5105962           -2.166588               3.678044
INFO  [18:50:37.350] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:50:37.350] [bbotk]                          7                    2668                  0.322327
INFO  [18:50:37.350] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:50:37.350] [bbotk]  0.007351131 <list[8]>              FALSE     0.02457245        0      0
INFO  [18:50:37.350] [bbotk]  runtime_learners                                uhash
INFO  [18:50:37.350] [bbotk]           108.271 17093e5e-7c74-4aab-b6af-cb3f7a5911d6
INFO  [18:50:38.039] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 69 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:50:51.952] [bbotk] Evaluating 1 configuration(s)
INFO  [18:50:52.048] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:50:52.079] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -56.25027
[1] 25.93863
[1] 39.64338
[1] 1473.217
[1] -21.51678
[1] 60.73882
[1] -47.39129
[1] 9.347016
[1] -76.47132
[1] 34.43608
INFO  [18:51:05.779] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -54.15244
[1] 46.7815
[1] -28.03195
[1] 17.10544
[1] -1516.362
[1] -34.29423
[1] -46.20899
[1] 15.99718
[1] 39.89208
[1] 531.7699
INFO  [18:51:23.139] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1756.147
[1] -49.58033
[1] -30.01377
[1] 51.87956
[1] -40.75353
[1] 28.09152
[1] -453.8007
[1] -3.972574
[1] -180.6911
[1] 14.33939
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:51:43.546] [mlr3] Finished benchmark
INFO  [18:51:43.922] [bbotk] Result of batch 39:
INFO  [18:51:43.981] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:51:43.981] [bbotk]               -4.38734                          0.260202
INFO  [18:51:43.981] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:51:43.981] [bbotk]                         0.6604577             -1.1305              -5.772617
INFO  [18:51:43.981] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:51:43.981] [bbotk]                         10                     377                 0.9642451
INFO  [18:51:43.981] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:51:43.981] [bbotk]  0.007009411 <list[8]>              FALSE     0.02340125        0      0
INFO  [18:51:43.981] [bbotk]  runtime_learners                                uhash
INFO  [18:51:43.981] [bbotk]            49.884 295acba3-e406-4108-ab4e-aa6f5633557d
INFO  [18:51:45.014] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 70 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:51:58.648] [bbotk] Evaluating 1 configuration(s)
INFO  [18:51:58.742] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:51:58.839] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -26.24803
[1] 119.8976
[1] -88.72416
[1] 7.189796
[1] -43.14709
[1] 17.9125
[1] -2397.058
[1] -72.30877
[1] -34.97379
[1] 77.94983
INFO  [18:52:13.890] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -49.11183
[1] 21.52563
[1] -78.15163
[1] 6.83574
[1] -4914.01
[1] -188.6655
[1] -18.81427
[1] 112.5081
[1] -43.69235
[1] 50.13141
INFO  [18:52:29.028] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -195.2473
[1] 36.27168
[1] -245.8138
[1] 26.5842
[1] -197.8102
[1] 1.83014
[1] -53.31342
[1] 57.23098
[1] -59.61239
[1] 46.33404
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:52:47.437] [mlr3] Finished benchmark
INFO  [18:52:47.616] [bbotk] Result of batch 40:
INFO  [18:52:47.628] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:52:47.628] [bbotk]              -5.298299                         0.8571768
INFO  [18:52:47.628] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:52:47.628] [bbotk]                         0.8087498           -1.756269               -2.29028
INFO  [18:52:47.628] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:52:47.628] [bbotk]                          5                      68                 0.5279343
INFO  [18:52:47.628] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:52:47.628] [bbotk]  0.007479205 <list[8]>              FALSE     0.02452931        0      0
INFO  [18:52:47.628] [bbotk]  runtime_learners                                uhash
INFO  [18:52:47.628] [bbotk]            48.195 b51d0a48-4b1c-4953-8056-34429fe062d2
INFO  [18:52:51.170] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 71 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:53:12.109] [bbotk] Evaluating 1 configuration(s)
INFO  [18:53:12.625] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:53:12.859] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -73.28142
[1] 7.933507
[1] -50.26494
[1] 62.61448
[1] -33.28125
[1] 19.14412
[1] -97.53494
[1] 18.30178
[1] -44.70444
[1] 42.52592
INFO  [18:54:21.866] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -65.29802
[1] 126.9141
[1] -68.33159
[1] 19.77999
[1] -143.7432
[1] -3.170967
[1] 34.89572
[1] 1225.323
[1] -38.23254
[1] 80.9575
INFO  [18:54:59.782] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -228.4635
[1] 23.28805
[1] -93.41906
[1] 96.86943
[1] -191.5052
[1] -3.920467
[1] -3407.035
[1] -84.65877
[1] -24.99164
[1] 36.26236
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:56:08.943] [mlr3] Finished benchmark
INFO  [18:56:09.916] [bbotk] Result of batch 41:
INFO  [18:56:09.970] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:56:09.970] [bbotk]              -6.850754                         0.9399172
INFO  [18:56:09.970] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:56:09.970] [bbotk]                         0.3453664           -5.840159              -6.822418
INFO  [18:56:09.970] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:56:09.970] [bbotk]                         16                    2888                 0.8822446
INFO  [18:56:09.970] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:56:09.970] [bbotk]  0.008322787 <list[8]>              FALSE     0.02817034        0      0
INFO  [18:56:09.970] [bbotk]  runtime_learners                                uhash
INFO  [18:56:09.970] [bbotk]            175.33 eec3d7e3-7e02-4f55-9ba6-472c3c3c264c
INFO  [18:56:15.891] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 72 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:56:21.863] [bbotk] Evaluating 1 configuration(s)
INFO  [18:56:21.948] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:56:21.965] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -50.84528
[1] 26.47599
[1] -42.20319
[1] 17.94848
[1] -49.43533
[1] 20.07701
[1] -958.7127
[1] -49.95574
[1] -3011.446
[1] -89.84385
INFO  [18:57:29.595] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -301.8561
[1] 87.21709
[1] -201.6131
[1] 5.360339
[1] -92.62617
[1] 3.153391
[1] -29.6802
[1] 120.8427
[1] -38.86308
[1] 47.6891
INFO  [18:58:42.794] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -28.04891
[1] 22.8657
[1] -590.4167
[1] -4.037007
[1] -16.68149
[1] 32.32862
[1] -195.4326
[1] 57.40663
[1] -296.7072
[1] -2.681127
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:00:09.008] [mlr3] Finished benchmark
INFO  [19:00:09.217] [bbotk] Result of batch 42:
INFO  [19:00:09.239] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:00:09.239] [bbotk]              -2.123247                          0.861358
INFO  [19:00:09.239] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:00:09.239] [bbotk]                         0.8110136           -5.307015              -2.691404
INFO  [19:00:09.239] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:00:09.239] [bbotk]                         10                    4804                 0.6670608
INFO  [19:00:09.239] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:00:09.239] [bbotk]  0.007325348 <list[8]>              FALSE     0.02603061        0      0
INFO  [19:00:09.239] [bbotk]  runtime_learners                                uhash
INFO  [19:00:09.239] [bbotk]           226.746 f446d147-507c-40c0-8792-9f0baf13433f
INFO  [19:00:10.760] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 73 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:00:25.816] [bbotk] Evaluating 1 configuration(s)
INFO  [19:00:26.653] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:00:26.740] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -170.8738
[1] 386.673
[1] -171.6502
[1] 56.89976
[1] -42.79519
[1] 65.52957
[1] -78.26741
[1] 33.74986
[1] -41.76606
[1] 68.42961
INFO  [19:01:15.729] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -165.3913
[1] -0.2633815
[1] -34.63141
[1] 115.6392
[1] -101.8897
[1] 11.92415
[1] -157.5166
[1] 59.46651
[1] -55.35495
[1] 154.2997
INFO  [19:01:56.939] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -32.5984
[1] 234.3949
[1] -155.8598
[1] 12.29548
[1] -3236.149
[1] -45.74273
[1] -41.2092
[1] 50.52452
[1] -217.1442
[1] 19.04034
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:03:07.021] [mlr3] Finished benchmark
INFO  [19:03:07.704] [bbotk] Result of batch 43:
INFO  [19:03:07.746] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:03:07.746] [bbotk]              -1.486993                         0.1767683
INFO  [19:03:07.746] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:03:07.746] [bbotk]                         0.3268573           -5.502856              -5.654094
INFO  [19:03:07.746] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:03:07.746] [bbotk]                         14                    4513                 0.1278724
INFO  [19:03:07.746] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:03:07.746] [bbotk]  0.007776223 <list[8]>              FALSE     0.03435002        0      0
INFO  [19:03:07.746] [bbotk]  runtime_learners                                uhash
INFO  [19:03:07.746] [bbotk]           159.636 6cf6a03f-baba-438e-b421-62166365ba4e
WARN  [19:03:12.329] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:03:12.364] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 74 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:03:26.101] [bbotk] Evaluating 1 configuration(s)
INFO  [19:03:26.160] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:03:26.212] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -21.15093
[1] 94.03417
[1] -115.1583
[1] -4.028523
[1] -42.03263
[1] 36.40361
[1] -108.9491
[1] -4.012532
[1] -28.80679
[1] 82.47261
INFO  [19:04:58.230] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -76.47405
[1] 19.98401
[1] -69.86156
[1] 84.49567
[1] -268.5644
[1] -4.325591
[1] -133.3004
[1] 34.10316
[1] -50.38087
[1] 62.60232
INFO  [19:06:29.426] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -122.0238
[1] 20.41679
[1] 49.50268
[1] 975.9155
[1] -36.13377
[1] 182.0558
[1] -57.59151
[1] 25.69048
[1] -188.6882
[1] -3.282603
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:08:35.992] [mlr3] Finished benchmark
INFO  [19:08:36.928] [bbotk] Result of batch 44:
INFO  [19:08:37.114] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:08:37.114] [bbotk]              0.2802842                         0.9877379
INFO  [19:08:37.114] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:08:37.114] [bbotk]                         0.6935094           -1.597756               6.609101
INFO  [19:08:37.114] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:08:37.114] [bbotk]                          3                    4530                 0.8011079
INFO  [19:08:37.114] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:08:37.114] [bbotk]  0.007137923 <list[8]>              FALSE     0.02742226        0      0
INFO  [19:08:37.114] [bbotk]  runtime_learners                                uhash
INFO  [19:08:37.114] [bbotk]           309.461 a721a0d0-d71d-49cb-ace4-fb6e7cda5e85
INFO  [19:08:41.178] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 75 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:09:01.920] [bbotk] Evaluating 1 configuration(s)
INFO  [19:09:02.087] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:09:02.400] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -86.29454
[1] 62.3433
[1] -40.38467
[1] 21.01557
[1] -56.95615
[1] 15.00449
[1] -824.9202
[1] -25.79242
[1] 101.1244
[1] 2477.241
INFO  [19:10:32.769] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -2746.231
[1] -83.74241
[1] -180.3341
[1] 3.904268
[1] -63.34623
[1] 12.1829
[1] -6389.239
[1] -78.32407
[1] -71.69629
[1] 10.96517
INFO  [19:12:05.516] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -230.9723
[1] 4.785524
[1] -48.03689
[1] 67.71587
[1] -1212.432
[1] -31.64702
[1] -143.2185
[1] 5.133077
[1] -29.2763
[1] 109.1206
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:13:21.938] [mlr3] Finished benchmark
INFO  [19:13:22.678] [bbotk] Result of batch 45:
INFO  [19:13:22.766] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:13:22.766] [bbotk]              -3.941385                         0.3580344
INFO  [19:13:22.766] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:13:22.766] [bbotk]                         0.9989016            -4.42292              -3.779325
INFO  [19:13:22.766] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:13:22.766] [bbotk]                         17                    4419                 0.3063327
INFO  [19:13:22.766] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:13:22.766] [bbotk]  0.007784248 <list[8]>              FALSE     0.02510399        0      0
INFO  [19:13:22.766] [bbotk]  runtime_learners                                uhash
INFO  [19:13:22.766] [bbotk]           259.052 c681e005-41aa-4fa8-a3ca-af71f7275820
INFO  [19:13:25.260] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 76 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:13:38.063] [bbotk] Evaluating 1 configuration(s)
INFO  [19:13:38.199] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:13:38.610] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -39.41955
[1] 19.44603
[1] -99.25992
[1] 158.6388
[1] -35.67576
[1] 53.96678
[1] -58.27138
[1] 32.34527
[1] -38.08311
[1] 34.13146
INFO  [19:14:16.809] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -163.0718
[1] 13.13731
[1] -2904.705
[1] -74.67571
[1] -99.1768
[1] 97.28873
[1] -100.1399
[1] 8.682292
[1] -164.7968
[1] -3.909095
INFO  [19:14:52.074] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -44.66674
[1] 128.2177
[1] -102.8059
[1] 8.801594
[1] -57.05543
[1] 59.27677
[1] -38.55083
[1] 60.45919
[1] -58.89195
[1] 21.21628
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:15:37.115] [mlr3] Finished benchmark
INFO  [19:15:37.839] [bbotk] Result of batch 46:
INFO  [19:15:37.858] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:15:37.858] [bbotk]             -0.5148171                         0.3658663
INFO  [19:15:37.858] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:15:37.858] [bbotk]                         0.5250125           -2.851432               1.289908
INFO  [19:15:37.858] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:15:37.858] [bbotk]                          1                    1518                 0.8103274
INFO  [19:15:37.858] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:15:37.858] [bbotk]  0.007280299 <list[8]>              FALSE     0.02852004        0      0
INFO  [19:15:37.858] [bbotk]  runtime_learners                                uhash
INFO  [19:15:37.858] [bbotk]           118.131 a5c3701d-2422-4619-ab86-bd74ebc12c2a
INFO  [19:15:41.397] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 77 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:16:02.566] [bbotk] Evaluating 1 configuration(s)
INFO  [19:16:02.852] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:16:02.918] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -26.6448
[1] 24.36938
[1] -20850.48
[1] -1077.095
[1] -66.44597
[1] 27.94088
[1] -151.6293
[1] 3.93155
[1] -35.01694
[1] 83.90147
INFO  [19:16:28.525] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -201.9899
[1] 4.474965
[1] -39.09613
[1] 14.93997
[1] -20.28809
[1] 18.251
[1] -71.48096
[1] 81.70821
[1] -2883.313
[1] -134.7062
INFO  [19:16:48.302] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -3072.81
[1] -51.15489
[1] -47.5289
[1] 1.213315
[1] 32.90686
[1] 999.3047
[1] -26.0324
[1] 30.49012
[1] -22.19935
[1] 80.31931
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:17:10.928] [mlr3] Finished benchmark
INFO  [19:17:11.429] [bbotk] Result of batch 47:
INFO  [19:17:11.482] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:17:11.482] [bbotk]               -2.77903                         0.7028047
INFO  [19:17:11.482] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:17:11.482] [bbotk]                         0.7041383           -0.623837              -2.869488
INFO  [19:17:11.482] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:17:11.482] [bbotk]                         12                      15                 0.8972166
INFO  [19:17:11.482] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:17:11.482] [bbotk]  0.006609249 <list[8]>              FALSE     0.02531083        0      0
INFO  [19:17:11.482] [bbotk]  runtime_learners                                uhash
INFO  [19:17:11.482] [bbotk]            67.729 50ae9f51-47ab-404a-861b-b6d177cb6eec
INFO  [19:17:13.461] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 78 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:17:34.702] [bbotk] Evaluating 1 configuration(s)
INFO  [19:17:34.886] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:17:34.958] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -47.5897
[1] 174.4818
[1] -78.54827
[1] -0.1141452
[1] -141.2464
[1] -3.953503
[1] -108.458
[1] 22.8377
[1] 32.64613
[1] 1000.106
INFO  [19:18:28.480] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -87.97328
[1] 183.2728
[1] -82.64476
[1] 109.1828
[1] -223.7607
[1] -3.406219
[1] -55.01541
[1] 60.88496
[1] -85.40707
[1] 44.93735
INFO  [19:19:45.148] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -24.59039
[1] 54.50037
[1] -47.82994
[1] 68.48026
[1] -106.2748
[1] 65.46129
[1] -62.76325
[1] 118.3079
[1] 57.44494
[1] 2759.619
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:21:07.007] [mlr3] Finished benchmark
INFO  [19:21:07.835] [bbotk] Result of batch 48:
INFO  [19:21:07.844] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:21:07.844] [bbotk]              0.2063798                         0.9091854
INFO  [19:21:07.844] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:21:07.844] [bbotk]                         0.5720234           -3.575642               5.357554
INFO  [19:21:07.844] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:21:07.844] [bbotk]                          5                    2268                 0.9582372
INFO  [19:21:07.844] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:21:07.844] [bbotk]  0.007267301 <list[8]>              FALSE     0.03360555        0      0
INFO  [19:21:07.844] [bbotk]  runtime_learners                                uhash
INFO  [19:21:07.844] [bbotk]           211.551 c9cde928-7a9c-4617-b2ca-41468bf33737
INFO  [19:21:09.874] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 79 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:21:24.002] [bbotk] Evaluating 1 configuration(s)
INFO  [19:21:24.028] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:21:24.041] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -77578
[1] -1938.458
[1] -144.4852
[1] 24.7989
[1] -112.0917
[1] 20.01571
[1] -50.36719
[1] 59.14469
[1] -70.26499
[1] 23.21872
INFO  [19:22:21.659] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -116.011
[1] 9.634773
[1] -11425.48
[1] -246.1887
[1] -37.01838
[1] 23.56792
[1] -23169.68
[1] -360.8476
[1] -2425.631
[1] -60.44156
INFO  [19:23:28.450] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -59.16318
[1] 235.5931
[1] -1.340041
[1] 169.3106
[1] -86.23972
[1] 6.43397
[1] -3.338841e+16
[1] 5.191393e+15
[1] -524.0644
[1] 2.521271
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:24:28.642] [mlr3] Finished benchmark
INFO  [19:24:28.737] [bbotk] Result of batch 49:
INFO  [19:24:28.831] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:24:28.831] [bbotk]              -6.040038                          0.523814
INFO  [19:24:28.831] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:24:28.831] [bbotk]                         0.7245498           -4.079354              -4.624804
INFO  [19:24:28.831] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:24:28.831] [bbotk]                          5                    3455                 0.2620107
INFO  [19:24:28.831] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:24:28.831] [bbotk]  0.006431878 <list[8]>              FALSE     0.02458039        0      0
INFO  [19:24:28.831] [bbotk]  runtime_learners                                uhash
INFO  [19:24:28.831] [bbotk]           183.598 786b9a48-5aff-4db4-9f93-3ec3a4810fad
INFO  [19:24:30.416] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 80 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:24:39.142] [bbotk] Evaluating 1 configuration(s)
INFO  [19:24:39.395] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:24:39.643] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -208.0794
[1] 45.09718
[1] -39.37298
[1] 24.57203
[1] -525.2595
[1] 63.79481
[1] -67.48711
[1] 8.708212
[1] -37.28001
[1] 214.0489
INFO  [19:25:17.013] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -91.55176
[1] -3.00491
[1] -31.70861
[1] 89.4717
[1] -52.42512
[1] 66.36435
[1] -157.1571
[1] 11.53382
[1] -103.246
[1] 85.39635
INFO  [19:26:07.769] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -121.7199
[1] -3.997644
[1] -23.33857
[1] 72.65739
[1] -44.011
[1] 102.0605
[1] -534.3394
[1] -4.134618
[1] -36.16497
[1] 30.42059
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:27:13.291] [mlr3] Finished benchmark
INFO  [19:27:13.486] [bbotk] Result of batch 50:
INFO  [19:27:13.532] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:27:13.532] [bbotk]              -3.967489                         0.6635793
INFO  [19:27:13.532] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:27:13.532] [bbotk]                         0.1921378           -2.685841              -4.596114
INFO  [19:27:13.532] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:27:13.532] [bbotk]                         16                    4989                 0.7152499
INFO  [19:27:13.532] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:27:13.532] [bbotk]  0.006651897 <list[8]>              FALSE     0.02526725        0      0
INFO  [19:27:13.532] [bbotk]  runtime_learners                                uhash
INFO  [19:27:13.532] [bbotk]           153.332 24d01cca-6eef-4049-9bce-ca7166aa0fd9
WARN  [19:27:18.579] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:27:18.591] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 81 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:27:31.212] [bbotk] Evaluating 1 configuration(s)
INFO  [19:27:31.564] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:27:31.664] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -37.78786
[1] 25.10952
[1] -42.55515
[1] 45.07727
[1] -28.27768
[1] 14.89762
[1] -1.277733
[1] 98.08744
[1] -3963.974
[1] -209.5553
INFO  [19:28:37.334] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -42.42993
[1] 24.09066
[1] -1599.961
[1] -40.85061
[1] -85.92037
[1] -3.814201
[1] -12.96615
[1] 19.40241
[1] -108.9333
[1] 43.08633
INFO  [19:30:10.604] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -158.9814
[1] -1.41457
[1] -1318.275
[1] 4.640703
[1] -57.66321
[1] 24.89598
[1] -28279.78
[1] -1133.092
[1] -26.57473
[1] 44.85576
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:31:32.419] [mlr3] Finished benchmark
INFO  [19:31:32.983] [bbotk] Result of batch 51:
INFO  [19:31:33.023] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:31:33.023] [bbotk]              -1.334846                         0.7651205
INFO  [19:31:33.023] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:31:33.023] [bbotk]                         0.9095021          -0.6305126              0.1488459
INFO  [19:31:33.023] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:31:33.023] [bbotk]                          2                    4577                 0.7573515
INFO  [19:31:33.023] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:31:33.023] [bbotk]  0.006218313 <list[8]>              FALSE      0.0273759        0      0
INFO  [19:31:33.023] [bbotk]  runtime_learners                                uhash
INFO  [19:31:33.023] [bbotk]            239.93 72dd283a-a679-48f5-823f-1d5a9abb5c12
INFO  [19:31:45.309] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 82 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:32:15.437] [bbotk] Evaluating 1 configuration(s)
INFO  [19:32:15.562] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:32:15.649] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -61.50235
[1] 22.47354
[1] -195.3337
[1] 5.972896
[1] -23.20922
[1] 42.56533
[1] -3464.396
[1] -85.88071
[1] -27.15814
[1] 361.6136
INFO  [19:32:38.893] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -47.25327
[1] 17.82308
[1] -43.69329
[1] 20.08934
[1] -27.92833
[1] 34.18723
[1] -14.94926
[1] 142.5732
[1] -1962.737
[1] -42.71607
INFO  [19:33:00.069] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -74.99848
[1] 6.267198
[1] -4328.636
[1] -52.97168
[1] 1147.927
[1] 39856.28
[1] -553.8249
[1] -3.92397
[1] -21.79129
[1] 52.59605
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:33:22.057] [mlr3] Finished benchmark
INFO  [19:33:24.750] [bbotk] Result of batch 52:
INFO  [19:33:24.770] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:33:24.770] [bbotk]              -1.236031                         0.1051183
INFO  [19:33:24.770] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:33:24.770] [bbotk]                         0.7874329            -2.01875               -1.80065
INFO  [19:33:24.770] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:33:24.770] [bbotk]                          4                     103                 0.7481357
INFO  [19:33:24.770] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:33:24.770] [bbotk]  0.006449623 <list[8]>              FALSE     0.02505875        0      0
INFO  [19:33:24.770] [bbotk]  runtime_learners                                uhash
INFO  [19:33:24.770] [bbotk]             66.01 d51b0510-325e-4a03-9761-995e22aa752f
INFO  [19:33:34.325] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 83 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:33:48.251] [bbotk] Evaluating 1 configuration(s)
INFO  [19:33:48.675] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:33:48.772] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -57.59992
[1] 25.2748
[1] -88.1153
[1] 8.966953
[1] -48.41609
[1] 51.98296
[1] 43.91818
[1] 1624.764
[1] -116.7233
[1] 104.551
INFO  [19:35:07.053] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -91.70806
[1] 68.21288
[1] -153.4704
[1] -4.220373
[1] -52.10674
[1] 77.58484
[1] -31.01443
[1] 192.686
[1] -308.1243
[1] 4.090998
INFO  [19:36:55.476] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -38.74975
[1] 33.14572
[1] -5800.358
[1] -109.2724
[1] -90.83906
[1] 33.49133
[1] -499.5104
[1] 2.917674
[1] -52.62187
[1] 57.75986
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:38:38.276] [mlr3] Finished benchmark
INFO  [19:38:38.974] [bbotk] Result of batch 53:
INFO  [19:38:39.186] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:38:39.186] [bbotk]              -6.812796                         0.7287919
INFO  [19:38:39.186] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:38:39.186] [bbotk]                         0.3280094           -6.673258              -6.041567
INFO  [19:38:39.186] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:38:39.186] [bbotk]                          6                    4823                 0.2403595
INFO  [19:38:39.186] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:38:39.186] [bbotk]  0.006444078 <list[8]>              FALSE     0.02972921        0      0
INFO  [19:38:39.186] [bbotk]  runtime_learners                                uhash
INFO  [19:38:39.186] [bbotk]           288.518 51be0cf3-b666-492c-b1c1-46e9be58d51c
INFO  [19:38:40.876] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 84 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:39:01.333] [bbotk] Evaluating 1 configuration(s)
INFO  [19:39:02.062] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:39:02.313] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -82.61934
[1] 24.48078
[1] -61.44106
[1] 16.20111
[1] -39.19691
[1] 62.7229
[1] -168.1488
[1] 8.96686
[1] -70.35148
[1] 14.82044
INFO  [19:40:40.333] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -36.60638
[1] 56.89223
[1] -66.28862
[1] -3.24996
[1] -470.1452
[1] -16.71188
[1] -60.91201
[1] 18.29278
[1] -77.64054
[1] 87.83121
INFO  [19:42:01.412] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -44.16876
[1] 28.78233
[1] 143.78
[1] 3142.674
[1] -31.81964
[1] 28.94891
[1] -90.14396
[1] -3.967832
[1] -5664.95
[1] -163.1384
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:43:20.692] [mlr3] Finished benchmark
INFO  [19:43:21.607] [bbotk] Result of batch 54:
INFO  [19:43:21.796] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:43:21.796] [bbotk]              -6.360588                         0.4959752
INFO  [19:43:21.796] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:43:21.796] [bbotk]                         0.5425678           -4.195495               2.412444
INFO  [19:43:21.796] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:43:21.796] [bbotk]                          8                    4310                  0.810558
INFO  [19:43:21.796] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:43:21.796] [bbotk]  0.006277002 <list[8]>              FALSE     0.02523217        0      0
INFO  [19:43:21.796] [bbotk]  runtime_learners                                uhash
INFO  [19:43:21.796] [bbotk]           257.509 4bcae5c6-3d2d-413e-ba41-32af52ee9230
INFO  [19:43:35.289] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 85 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:43:48.715] [bbotk] Evaluating 1 configuration(s)
INFO  [19:43:49.138] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:43:49.500] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -83.10242
[1] 32.33193
[1] -54.55092
[1] 10.75502
[1] -58.03348
[1] 95.31954
[1] -24.44318
[1] 59.3219
[1] -64.48051
[1] 81.85589
INFO  [19:44:12.059] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -77.12509
[1] 22.55523
[1] -29.68424
[1] 49.10477
[1] -153.2864
[1] 15.26084
[1] -176.0843
[1] -0.2396768
[1] -3832.204
[1] -82.47952
INFO  [19:44:32.956] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -39.25074
[1] 123.0054
[1] -109.4484
[1] 5.85094
[1] -83.63399
[1] 40.75847
[1] -45.21772
[1] 30.12473
[1] -3.435975e+16
[1] 5.00673e+15
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:45:04.910] [mlr3] Finished benchmark
INFO  [19:45:05.537] [bbotk] Result of batch 55:
INFO  [19:45:05.599] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:45:05.599] [bbotk]              -5.687871                         0.9383993
INFO  [19:45:05.599] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:45:05.599] [bbotk]                         0.2483905           -1.822757              -5.111444
INFO  [19:45:05.599] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:45:05.599] [bbotk]                         14                     537                 0.2137183
INFO  [19:45:05.599] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:45:05.599] [bbotk]  0.006492972 <list[8]>              FALSE     0.02636804        0      0
INFO  [19:45:05.599] [bbotk]  runtime_learners                                uhash
INFO  [19:45:05.599] [bbotk]            74.906 fad2419b-0bf2-4138-a5b2-489fa28d3d96
WARN  [19:45:09.622] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:45:09.631] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 86 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:45:29.408] [bbotk] Evaluating 1 configuration(s)
INFO  [19:45:29.647] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:45:29.791] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -224.0514
[1] 49.31421
[1] -3908.642
[1] -170.3876
[1] -40.98069
[1] 19.31741
[1] -2807.312
[1] -90.16973
[1] -47.20933
[1] 85.10017
INFO  [19:45:55.833] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -199.6015
[1] -3.20321
[1] -2379.916
[1] -80.3896
[1] -86.29791
[1] 3.805319
[1] -109.8152
[1] -0.7129875
[1] 93.01403
[1] 3357.095
INFO  [19:46:21.139] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -84.90626
[1] -3.729049
[1] -36.15359
[1] 32.0703
[1] -47.17347
[1] 65.30222
[1] 35.128
[1] 1166.047
[1] -197.5141
[1] 4.766817
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:46:48.290] [mlr3] Finished benchmark
INFO  [19:46:49.375] [bbotk] Result of batch 56:
INFO  [19:46:49.383] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:46:49.383] [bbotk]             -0.7532359                         0.4733056
INFO  [19:46:49.383] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:46:49.383] [bbotk]                          0.781634           -2.113869               -2.77694
INFO  [19:46:49.383] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:46:49.383] [bbotk]                         11                     680                 0.5102564
INFO  [19:46:49.383] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:46:49.383] [bbotk]  0.006053981 <list[8]>              FALSE     0.02527219        0      0
INFO  [19:46:49.383] [bbotk]  runtime_learners                                uhash
INFO  [19:46:49.383] [bbotk]            77.633 28267544-b17b-460a-b8ca-ebd8da5a3f8c
INFO  [19:46:51.383] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 87 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:47:03.643] [bbotk] Evaluating 1 configuration(s)
INFO  [19:47:03.917] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:47:04.070] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -88.01071
[1] 27.06345
[1] 138.7971
[1] 4074.525
[1] -106.5705
[1] -3.483771
[1] -21.18799
[1] 218.0272
[1] -80.92669
[1] 56.80455
INFO  [19:47:47.865] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -76.34442
[1] 95.54705
[1] -417.2478
[1] -13.24357
[1] -134.5334
[1] 23.53352
[1] -220.835
[1] 96.55215
[1] -64.88634
[1] 36.49426
INFO  [19:49:02.435] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -52.91141
[1] 56.90666
[1] -13930.95
[1] -198.2479
[1] -171.09
[1] 417.541
[1] -64.59941
[1] 47.48044
[1] -110.3993
[1] 63.12034
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:50:40.437] [mlr3] Finished benchmark
INFO  [19:50:40.564] [bbotk] Result of batch 57:
INFO  [19:50:40.612] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:50:40.612] [bbotk]               1.683721                         0.1902059
INFO  [19:50:40.612] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:50:40.612] [bbotk]                         0.6633358           -5.778303              -6.835864
INFO  [19:50:40.612] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:50:40.612] [bbotk]                         19                    4865                 0.8265999
INFO  [19:50:40.612] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:50:40.612] [bbotk]  0.006566169 <list[8]>              FALSE     0.03546436        0      0
INFO  [19:50:40.612] [bbotk]  runtime_learners                                uhash
INFO  [19:50:40.612] [bbotk]           215.961 6e61f3ba-0562-4d29-8029-62755f6ce9b8
INFO  [19:50:47.597] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 88 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:51:00.632] [bbotk] Evaluating 1 configuration(s)
INFO  [19:51:00.665] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:51:00.684] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 1672.683
[1] 32623.8
[1] -106.2373
[1] 23.0841
[1] -67.94125
[1] 9.998109
[1] -9031.421
[1] -561.5625
[1] -23.21232
[1] 31.80099
INFO  [19:52:14.260] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -162.4894
[1] 1.751206
[1] -43.46196
[1] 41.18565
[1] -93.07653
[1] -1.5769
[1] -1075.41
[1] -33.51752
[1] -213.456
[1] -3.147597
INFO  [19:53:03.075] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -54.29542
[1] 13.60965
[1] 43.13556
[1] 1338.429
[1] -374.97
[1] -0.5156207
[1] -36.18591
[1] 45.56784
[1] -156.2877
[1] 16.6657
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:53:40.223] [mlr3] Finished benchmark
INFO  [19:53:40.608] [bbotk] Result of batch 58:
INFO  [19:53:40.630] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:53:40.630] [bbotk]              -2.086619                         0.4551706
INFO  [19:53:40.630] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:53:40.630] [bbotk]                         0.5571872            -1.88214              -4.157764
INFO  [19:53:40.630] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:53:40.630] [bbotk]                          7                    4080                 0.7608533
INFO  [19:53:40.630] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:53:40.630] [bbotk]  0.006277467 <list[8]>              FALSE     0.02839042        0      0
INFO  [19:53:40.630] [bbotk]  runtime_learners                                uhash
INFO  [19:53:40.630] [bbotk]           158.671 ed8af095-5c1d-47ad-a03a-c38e4c95a64e
INFO  [19:53:45.244] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 89 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:54:00.807] [bbotk] Evaluating 1 configuration(s)
INFO  [19:54:01.143] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:54:01.339] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -46.50634
[1] 57.8867
[1] -25.75046
[1] 83.57223
[1] -45.5029
[1] 37.44613
[1] -64.3598
[1] 6.601855
[1] -77.80101
[1] 8.222052
INFO  [19:55:34.130] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -311.7118
[1] -4.156275
[1] -102.8036
[1] 0.8902674
[1] -55.40354
[1] 35.39619
[1] -1515.792
[1] -34.30724
[1] -73.29058
[1] 13.58686
INFO  [19:56:52.388] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -73.94973
[1] 17.04043
[1] -20.27151
[1] 138.2968
[1] -73.40802
[1] 12.3863
[1] -23.17351
[1] 67.88099
[1] -814.2053
[1] -4.292306
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:58:15.859] [mlr3] Finished benchmark
INFO  [19:58:19.974] [bbotk] Result of batch 59:
INFO  [19:58:20.291] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:58:20.291] [bbotk]              0.4758107                         0.9862783
INFO  [19:58:20.291] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:58:20.291] [bbotk]                         0.8337976        -0.003619591               3.249399
INFO  [19:58:20.291] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:58:20.291] [bbotk]                         18                    4721                 0.4343242
INFO  [19:58:20.291] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:58:20.291] [bbotk]  0.006481801 <list[8]>              FALSE     0.02582377        0      0
INFO  [19:58:20.291] [bbotk]  runtime_learners                                uhash
INFO  [19:58:20.291] [bbotk]           254.113 6489e18b-4b2b-4db1-a47a-8c49698c3be2
INFO  [19:58:28.402] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 90 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:58:45.165] [bbotk] Evaluating 1 configuration(s)
INFO  [19:58:46.677] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:58:46.906] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -9.425637e+15
[1] 2.540679e+16
[1] -86.48107
[1] 11.18963
[1] -40.89682
[1] 27.69099
[1] 52.48698
[1] 1436.23
[1] -40.0648
[1] 40.07311
INFO  [19:59:52.247] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -138.5935
[1] 11.71516
[1] -2110.872
[1] -40.99919
[1] 165.3624
[1] 5465.094
[1] -29.7921
[1] 23.2486
[1] -272.799
[1] -4.229145
INFO  [20:01:00.633] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -265.9129
[1] -3.095909
[1] -41.0803
[1] 62.61242
[1] -136.4273
[1] -3.985855
[1] -66.21531
[1] 169.9876
[1] -42.29271
[1] 74.81124
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:02:30.406] [mlr3] Finished benchmark
INFO  [20:02:31.341] [bbotk] Result of batch 60:
INFO  [20:02:31.349] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:02:31.349] [bbotk]              -4.226788                         0.5933437
INFO  [20:02:31.349] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:02:31.349] [bbotk]                         0.4020156           -3.464499              -2.425861
INFO  [20:02:31.349] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:02:31.349] [bbotk]                         14                    4925                 0.2854677
INFO  [20:02:31.349] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:02:31.349] [bbotk]  0.006687224 <list[8]>              FALSE     0.02587453        0      0
INFO  [20:02:31.349] [bbotk]  runtime_learners                                uhash
INFO  [20:02:31.349] [bbotk]           223.159 d85b5c22-20a2-40d6-8720-468686c6fb62
INFO  [20:02:34.738] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 91 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:02:53.561] [bbotk] Evaluating 1 configuration(s)
INFO  [20:02:53.676] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:02:53.701] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -43.59002
[1] 50.64883
[1] -55.96351
[1] 23.7348
[1] -79.19169
[1] 55.4751
[1] -163.5783
[1] 1.037327
[1] -377.0798
[1] 24.48902
INFO  [20:04:15.745] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -59.30396
[1] 36.1296
[1] -157.243
[1] -4.124879
[1] -122.6496
[1] 36.90171
[1] -53.29441
[1] 12.36305
[1] -3594.793
[1] -69.37204
INFO  [20:05:45.023] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -111.4754
[1] 16.29087
[1] -138.8835
[1] -3.966716
[1] -55.33833
[1] 92.90413
[1] -31.17416
[1] 50.00551
[1] -81.82078
[1] 156.7324
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:07:19.872] [mlr3] Finished benchmark
INFO  [20:07:20.838] [bbotk] Result of batch 61:
INFO  [20:07:20.893] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:07:20.893] [bbotk]              -1.765891                         0.4610373
INFO  [20:07:20.893] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:07:20.893] [bbotk]                         0.7786652           -5.308156              -4.800283
INFO  [20:07:20.893] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:07:20.893] [bbotk]                         15                    4330                 0.2346219
INFO  [20:07:20.893] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:07:20.893] [bbotk]  0.006241133 <list[8]>              FALSE     0.02506956        0      0
INFO  [20:07:20.893] [bbotk]  runtime_learners                                uhash
INFO  [20:07:20.893] [bbotk]           265.775 b45ea046-182b-4451-8a9b-25b83ab91e86
INFO  [20:07:36.984] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 92 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:07:52.532] [bbotk] Evaluating 1 configuration(s)
INFO  [20:07:52.588] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:07:52.628] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -10051.88
[1] -182.0133
[1] -41.98046
[1] 100.3141
[1] -350.4479
[1] -4.426029
[1] -82.41617
[1] 8.858274
[1] -78.60821
[1] 13.39395
INFO  [20:09:06.644] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -256.2876
[1] -4.25313
[1] -167.4634
[1] -4.072118
[1] -212.7523
[1] 6.604534
[1] -43.12609
[1] 54.26144
[1] -622.3095
[1] -13.85233
INFO  [20:10:30.297] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -54124.09
[1] -2457.313
[1] -270.2368
[1] 52.60387
[1] -63.9564
[1] 22.85011
[1] -476.4397
[1] 171.6415
[1] -70.63409
[1] 104.1138
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:11:58.574] [mlr3] Finished benchmark
INFO  [20:11:58.888] [bbotk] Result of batch 62:
INFO  [20:11:59.009] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:11:59.009] [bbotk]              0.9927533                         0.9956572
INFO  [20:11:59.009] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:11:59.009] [bbotk]                         0.9853071           -2.517688              -3.196286
INFO  [20:11:59.009] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:11:59.009] [bbotk]                         18                    4735                 0.2337068
INFO  [20:11:59.009] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:11:59.009] [bbotk]  0.005684996 <list[8]>              FALSE     0.02911093        0      0
INFO  [20:11:59.009] [bbotk]  runtime_learners                                uhash
INFO  [20:11:59.009] [bbotk]           245.276 06216235-11f5-407c-ab30-d9dbdca56362
INFO  [20:12:03.284] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 93 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:12:15.592] [bbotk] Evaluating 1 configuration(s)
INFO  [20:12:16.024] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:12:16.221] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -48.23872
[1] 33.90318
[1] -43.57046
[1] 85.25654
[1] -85.00392
[1] 14.24938
[1] -77.49956
[1] 5.555111
[1] -22.23427
[1] 35.8697
INFO  [20:12:43.445] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -111.0415
[1] 19.67222
[1] -71.25968
[1] 5.788159
[1] -31.67358
[1] 57.7385
[1] -100.0369
[1] -4.152007
[1] -83.24904
[1] 141.453
INFO  [20:13:11.257] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -49.12238
[1] 32.19136
[1] -31.11706
[1] 40.08193
[1] -1327.051
[1] -35.1756
[1] -655.3562
[1] -3.299852
[1] -319.5487
[1] -3.994877
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:13:31.593] [mlr3] Finished benchmark
INFO  [20:13:31.864] [bbotk] Result of batch 63:
INFO  [20:13:31.871] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:13:31.871] [bbotk]               -0.96296                         0.9250482
INFO  [20:13:31.871] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:13:31.871] [bbotk]                          0.772535           -3.274813              -4.622937
INFO  [20:13:31.871] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:13:31.871] [bbotk]                          5                     312                 0.9299821
INFO  [20:13:31.871] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:13:31.871] [bbotk]  0.005595587 <list[8]>              FALSE     0.02526693        0      0
INFO  [20:13:31.871] [bbotk]  runtime_learners                                uhash
INFO  [20:13:31.871] [bbotk]            74.571 54b858fb-0b0d-4bc7-8396-e012f2df37dd
INFO  [20:13:36.122] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 94 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:13:43.140] [bbotk] Evaluating 1 configuration(s)
INFO  [20:13:43.159] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:13:43.236] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -47.90505
[1] 148.2383
[1] -51.34431
[1] 30.76598
[1] -35.08803
[1] 36.42079
[1] -34.20547
[1] 18.0831
[1] -4003.384
[1] -116.7549
INFO  [20:15:11.162] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -120.1987
[1] 16.4418
[1] -52.35446
[1] 17.07315
[1] -128.229
[1] 53.80153
[1] -183.5564
[1] -4.009693
[1] -1550.225
[1] -31.41987
INFO  [20:16:56.080] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -797.0619
[1] -29.19899
[1] -42.6805
[1] 30.25841
[1] -539.1057
[1] -3.422991
[1] -213.4724
[1] 8.420709
[1] -12.85127
[1] 97.9124
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:19:01.668] [mlr3] Finished benchmark
INFO  [20:19:01.747] [bbotk] Result of batch 64:
INFO  [20:19:01.760] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:19:01.760] [bbotk]              -5.632549                         0.7914801
INFO  [20:19:01.760] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:19:01.760] [bbotk]                         0.2471631            -5.81788              -3.388533
INFO  [20:19:01.760] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:19:01.760] [bbotk]                         20                    4899                 0.6423774
INFO  [20:19:01.760] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:19:01.760] [bbotk]  0.005480476 <list[8]>              FALSE     0.02523541        0      0
INFO  [20:19:01.760] [bbotk]  runtime_learners                                uhash
INFO  [20:19:01.760] [bbotk]           318.176 87c234ff-9a82-4191-a3e3-349e4a2dcfc6
INFO  [20:19:02.850] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 95 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:19:15.774] [bbotk] Evaluating 1 configuration(s)
INFO  [20:19:15.896] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:19:16.050] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -66.19753
[1] 7.223896
[1] -96.67002
[1] 61.33561
[1] -54.19574
[1] 48.93704
[1] -189.4108
[1] 63.8859
[1] -195.3216
[1] 16.55509
INFO  [20:19:39.296] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -19.66147
[1] 173.6959
[1] -190.4359
[1] -3.251096
[1] -104.0125
[1] 14.67425
[1] -93.96617
[1] 33.90956
[1] -184.12
[1] 35.34259
INFO  [20:20:03.391] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -96.8296
[1] 1.782976
[1] -63.2865
[1] 61.68947
[1] -28259.44
[1] -358.9148
[1] -117.9136
[1] 23.40993
[1] -49.14952
[1] 97.6158
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:20:31.442] [mlr3] Finished benchmark
INFO  [20:20:31.686] [bbotk] Result of batch 65:
INFO  [20:20:31.700] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:20:31.700] [bbotk]             -0.3926425                         0.8688379
INFO  [20:20:31.700] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:20:31.700] [bbotk]                         0.8386295          -0.7594834               5.566344
INFO  [20:20:31.700] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:20:31.700] [bbotk]                         15                    4498                 0.1739152
INFO  [20:20:31.700] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:20:31.700] [bbotk]  0.006217541 <list[8]>              FALSE     0.02986409        0      0
INFO  [20:20:31.700] [bbotk]  runtime_learners                                uhash
INFO  [20:20:31.700] [bbotk]            75.057 9d48f59e-5ec2-45dd-ab2d-a519d38063b6
INFO  [20:20:33.148] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 96 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:20:40.948] [bbotk] Evaluating 1 configuration(s)
INFO  [20:20:41.144] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:20:41.174] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -11729.1
[1] -469.0607
[1] -32.82143
[1] 60.20124
[1] -37.03084
[1] 149.9594
[1] -38.8321
[1] 21.42268
[1] -25.79407
[1] 34.66525
INFO  [20:21:02.057] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -2195.513
[1] -37.13994
[1] -98.08546
[1] 11.05975
[1] -53.71687
[1] 1.487098
[1] -32.75636
[1] 151.8837
[1] -22808.58
[1] -984.7642
INFO  [20:21:24.501] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -802.4072
[1] 86.11646
[1] -45.49754
[1] 99.40286
[1] -13.15229
[1] 67.09781
[1] -195.9091
[1] -0.3262701
[1] -49.55321
[1] 27.26257
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:22:01.856] [mlr3] Finished benchmark
INFO  [20:22:02.202] [bbotk] Result of batch 66:
INFO  [20:22:02.232] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:22:02.232] [bbotk]              -4.173102                         0.1073773
INFO  [20:22:02.232] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:22:02.232] [bbotk]                         0.9566813          -0.4779026               3.200673
INFO  [20:22:02.232] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:22:02.232] [bbotk]                          6                    1078                 0.9964055
INFO  [20:22:02.232] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:22:02.232] [bbotk]  0.005905897 <list[8]>              FALSE     0.02585116        0      0
INFO  [20:22:02.232] [bbotk]  runtime_learners                                uhash
INFO  [20:22:02.232] [bbotk]              80.4 95a39576-e36e-44e8-81e5-d6eef2e3ecc3
INFO  [20:22:07.340] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 97 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:22:19.222] [bbotk] Evaluating 1 configuration(s)
INFO  [20:22:19.305] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:22:19.434] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -32.09538
[1] 16.04386
[1] -109.4133
[1] 22.63953
[1] -40.76957
[1] 12.49323
[1] -34.84329
[1] 46.23954
[1] -6.645004
[1] 41.17198
INFO  [20:23:20.311] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -12.37505
[1] 63.34481
[1] -70.8143
[1] -3.973659
[1] -20.68012
[1] 65.86232
[1] -26.51507
[1] 16.61009
[1] -37.30342
[1] 29.9316
INFO  [20:24:35.524] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -19.6544
[1] 20.63667
[1] -67.45334
[1] 10.0061
[1] -1287.603
[1] -32.71866
[1] -41.52294
[1] 456.972
[1] -47.59028
[1] 22.50203
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:25:41.217] [mlr3] Finished benchmark
INFO  [20:25:41.777] [bbotk] Result of batch 67:
INFO  [20:25:41.814] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:25:41.814] [bbotk]              -1.945819                         0.9903511
INFO  [20:25:41.814] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:25:41.814] [bbotk]                         0.1945647          -0.3808151              -3.881818
INFO  [20:25:41.814] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:25:41.814] [bbotk]                         18                    3412                 0.4115531
INFO  [20:25:41.814] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:25:41.814] [bbotk]  0.005474035 <list[8]>              FALSE      0.0270199        0      0
INFO  [20:25:41.814] [bbotk]  runtime_learners                                uhash
INFO  [20:25:41.814] [bbotk]            201.58 65d9f620-7174-4ceb-a9e1-5ac1b8292b45
INFO  [20:25:44.304] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 98 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:25:53.122] [bbotk] Evaluating 1 configuration(s)
INFO  [20:25:53.202] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:25:53.307] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -54.84154
[1] 11.90713
[1] -5.438292e+15
[1] 1.74949e+16
[1] -45.28304
[1] 46.28628
[1] -68.0841
[1] 9.188898
[1] -108.1269
[1] 9.162024
INFO  [20:26:25.124] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -34.01173
[1] 47.07733
[1] -58.63866
[1] -3.360206
[1] -281.7142
[1] -1.123402
[1] 347.8155
[1] 8276.057
[1] -149.8654
[1] 129.9581
INFO  [20:27:02.783] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -28.5676
[1] 36.6692
[1] -34.04563
[1] 13.24809
[1] -1867.623
[1] 11.04664
[1] -111.9953
[1] -3.464915
[1] -27.84341
[1] 77.14338
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:27:54.254] [mlr3] Finished benchmark
INFO  [20:27:54.322] [bbotk] Result of batch 68:
INFO  [20:27:54.364] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:27:54.364] [bbotk]              -4.036791                         0.2876245
INFO  [20:27:54.364] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:27:54.364] [bbotk]                         0.7642022           -1.771756              -1.158466
INFO  [20:27:54.364] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:27:54.364] [bbotk]                         13                    2807                  0.964195
INFO  [20:27:54.364] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:27:54.364] [bbotk]  0.005338093 <list[8]>              FALSE     0.02468891        0      0
INFO  [20:27:54.364] [bbotk]  runtime_learners                                uhash
INFO  [20:27:54.364] [bbotk]           120.488 726269bf-af65-43ef-81d9-88b99b197e7e
INFO  [20:27:56.492] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 99 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:28:00.833] [bbotk] Evaluating 1 configuration(s)
INFO  [20:28:00.958] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:28:01.362] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -32.08664
[1] 25.5273
[1] -106.839
[1] 84.99944
[1] -5263.205
[1] -131.9727
[1] -129.5133
[1] -3.99336
[1] -29.88129
[1] 103.2005
INFO  [20:28:20.701] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -100.7379
[1] -2.752354
[1] -29.42748
[1] 197.2669
[1] 127.6062
[1] 3002.937
[1] -2084.643
[1] -99.81823
[1] -84.25885
[1] 4.078353
INFO  [20:28:57.675] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -47.06714
[1] 58.2901
[1] -1810.021
[1] -40.45618
[1] -89.03638
[1] 10.75989
[1] -26.59443
[1] 36.1624
[1] -129.7596
[1] 11.56025
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:29:53.793] [mlr3] Finished benchmark
INFO  [20:29:53.983] [bbotk] Result of batch 69:
INFO  [20:29:54.067] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:29:54.067] [bbotk]              -1.104135                         0.9609702
INFO  [20:29:54.067] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:29:54.067] [bbotk]                         0.3969326           -2.831664              -4.421131
INFO  [20:29:54.067] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:29:54.067] [bbotk]                         19                    3596                 0.3705451
INFO  [20:29:54.067] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:29:54.067] [bbotk]  0.005262512 <list[8]>              FALSE     0.02818911        0      0
INFO  [20:29:54.067] [bbotk]  runtime_learners                                uhash
INFO  [20:29:54.067] [bbotk]            112.24 49c43436-6c3c-4096-8925-0c1bad8356da
INFO  [20:29:56.326] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 100 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:29:56.388] [bbotk] Finished optimizing after 100 evaluation(s)
INFO  [20:29:56.403] [bbotk] Result:
INFO  [20:29:56.416] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:29:56.416] [bbotk]                  <num>                             <num>
INFO  [20:29:56.416] [bbotk]               -4.38734                          0.260202
INFO  [20:29:56.416] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:29:56.416] [bbotk]                             <num>               <num>                  <num>
INFO  [20:29:56.416] [bbotk]                         0.6604577             -1.1305              -5.772617
INFO  [20:29:56.416] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:29:56.416] [bbotk]                      <int>                   <int>                     <num>
INFO  [20:29:56.416] [bbotk]                         10                     377                 0.9642451
INFO  [20:29:56.416] [bbotk]  learner_param_vals  x_domain classif.bbrier
INFO  [20:29:56.416] [bbotk]              <list>    <list>          <num>
INFO  [20:29:56.416] [bbotk]          <list[10]> <list[8]>     0.02340125
[1] -46.60042
[1] 13.95928
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] -79.53739
[1] 108.451
[1] -81.53718
[1] 16.41621
[1] -69.25289
[1] 4.180528
[1] -36.22588
[1] 23.22658

### [bt]: Job terminated successfully [batchtools job.id=1419]
### [bt]: Calculation finished!
