### [bt]: This is batchtools v0.9.17
### [bt]: Starting calculation of 1 jobs
### [bt]: Setting working directory to '/content/drive/MyDrive/GitHub/Mater_Thesis_Calibration'
ece.R :
Friedmann_tasks.R :
Functions.R :
ici.R :
mse_feature_effects.R :
PipeOpCalibration_TuningExperiment.R :
PipeOpCalibration.R :
PipeOpCalibrationUnion.R :
### [bt]: Memory measurement disabled
### [bt]: Starting job [batchtools job.id=1418]
### [bt]: Generating problem instance for problem '341ee781c7d79b8f' ...
### [bt]: Applying algorithm 'run_learner' on problem '341ee781c7d79b8f' for job 1418 (seed = 1541) ...
INFO  [16:06:31.149] [mlr3] Applying learner 'xgboost TwP beta' on task 'wdbc' (iter 8/10)
INFO  [16:06:32.093] [bbotk] Starting to optimize 8 parameter(s) with '<OptimizerMbo>' and '<TerminatorEvals> [n_evals=100, k=0]'
INFO  [16:06:40.348] [bbotk] Evaluating 32 configuration(s)
INFO  [16:06:40.507] [mlr3] Running benchmark with 96 resampling iterations
INFO  [16:06:40.626] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 20.42212
[1] 1019.755
[1] -1048.714
[1] 711.8372
[1] 42.02587
[1] 2044.755
[1] -2769.309
[1] -46.67094
[1] -1146.676
[1] -18.97051
INFO  [16:07:38.864] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 28.18581
[1] 1337.792
[1] -1736.835
[1] -27.3929
[1] -1482.726
[1] -25.02509
[1] 35.81159
[1] 1632.083
[1] 36.34176
[1] 1708.312
INFO  [16:08:14.133] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 25.2045
[1] 1200.461
[1] -69.09743
[1] 1771.377
[1] -2342.044
[1] -41.00666
[1] -1754.389
[1] -29.89376
[1] 29.38575
[1] 1408.049
INFO  [16:08:51.444] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -17.78017
[1] 25.1866
[1] -51.49652
[1] 58.21412
[1] -594.0777
[1] -36.04824
[1] -1206.614
[1] -81.40232
[1] -867.63
[1] 1.094683
INFO  [16:09:50.836] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -87.43912
[1] 40.8896
[1] -20.52942
[1] 49.6132
[1] -27.24039
[1] 25.29502
[1] -172.0575
[1] 4.936458
[1] -16.30519
[1] 53.33008
INFO  [16:11:29.030] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -17.07067
[1] 24.58425
[1] -10.58602
[1] 116.2765
[1] -25.53084
[1] 36.28995
[1] -1382.096
[1] -56.3053
[1] -89.96096
[1] 278.0739
INFO  [16:12:43.777] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:13:47.656] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:14:58.072] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:15:55.413] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -38.26465
[1] 309.3277
[1] -119.0887
[1] 253.6377
[1] -207.9802
[1] 166.3412
[1] -157.9011
[1] 4.102606
[1] -23.28588
[1] 152.9927
INFO  [16:16:27.367] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -192.0461
[1] 166.9172
[1] -63.35591
[1] 188.5867
[1] -295.0665
[1] -3.848247
[1] -119.6926
[1] 65.61797
[1] 6.341136
[1] 221.2804
INFO  [16:16:56.655] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -47.49171
[1] 280.0904
[1] -75.72605
[1] 132.9688
[1] -313.5687
[1] 154.223
[1] -59.29223
[1] 185.4032
[1] -142.7975
[1] 92.05359
INFO  [16:17:24.475] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1201.073
[1] 31.50686
[1] -1322.07
[1] -37.2207
[1] -266.7896
[1] 30.6928
[1] 263.8497
[1] 7309.551
[1] -27.65901
[1] 32.55211
INFO  [16:18:08.175] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -5838.779
[1] -131.1535
[1] -223.2717
[1] -3.199065
[1] -39.17174
[1] 59.29278
[1] -23.24009
[1] 26.64465
[1] -60.5255
[1] 116.0772
INFO  [16:19:08.897] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -69.90431
[1] -4.233159
[1] 82.99869
[1] 1620.177
[1] -57.18312
[1] 274.108
[1] -18.48605
[1] 40.97476
[1] -92.7811
[1] 32.25109
INFO  [16:19:46.064] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -715.0156
[1] -12.26324
[1] -464.9266
[1] -7.715644
[1] 21.83564
[1] 900.189
[1] -655.6845
[1] -11.70086
[1] -362.282
[1] -8.432009
INFO  [16:21:35.647] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -389.069
[1] -8.143345
[1] -363.7193
[1] 82.54547
[1] -378.8739
[1] 47.25885
[1] -640.4338
[1] 169.4701
[1] -271.5774
[1] 375.3672
INFO  [16:23:04.492] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -674.0704
[1] -12.3662
[1] 4.14772
[1] 291.2327
[1] -448.6573
[1] 146.2823
[1] -199.8803
[1] 280.48
[1] 9.973236
[1] 492.6522
INFO  [16:25:27.490] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -245.1848
[1] -4.106547
[1] -37.65755
[1] 201.9277
[1] -85.44392
[1] 33.58963
[1] 68.43076
[1] 1924.161
[1] -56.60162
[1] 52.29127
INFO  [16:26:30.366] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -35.30511
[1] 230.4344
[1] -157.4324
[1] 26.81475
[1] -70.56961
[1] 47.89179
[1] -194.3122
[1] 11.09635
[1] -13.66008
[1] 143.6669
INFO  [16:27:33.711] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -13781.07
[1] -217.3535
[1] -72.18507
[1] 43.04234
[1] -76.87582
[1] 69.72512
[1] -23.23626
[1] 108.1617
[1] -114.529
[1] 169.2784
INFO  [16:29:00.231] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:29:43.331] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 2892.698
[1] 156538.6
[1] 429.0884
[1] 22934.84
INFO  [16:30:28.286] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:31:02.192] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:31:41.813] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:32:18.013] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:32:53.409] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -434.9894
[1] -7.215495
[1] -464.3126
[1] 190.2952
[1] 5.07469
[1] 243.1131
[1] -319.1642
[1] -5.639388
[1] 8.884278
[1] 428.69
INFO  [16:34:58.927] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 8.866863
[1] 422.9052
[1] -366.9671
[1] -6.748361
[1] 6.015286
[1] 249.0175
[1] -111.3639
[1] 323.6114
[1] -306.9224
[1] -5.77651
INFO  [16:37:26.386] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -447.1699
[1] -8.056505
[1] -388.0165
[1] -7.858296
[1] -517.3558
[1] 56.73301
[1] 8.014961
[1] 357.6121
[1] -326.4631
[1] -6.764667
INFO  [16:39:50.882] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1861.687
[1] -30.39598
[1] 68.79898
[1] 3289.618
[1] 54.21754
[1] 2665.163
[1] 43.23824
[1] 2093.468
[1] -2724.796
[1] -46.26153
INFO  [16:40:50.245] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1669.729
[1] -25.20971
[1] 34.71989
[1] 1674.928
[1] 28.78757
[1] 1317.896
[1] 28.13679
[1] 1324.114
[1] 31.68134
[1] 1502.981
INFO  [16:41:47.095] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 38.9972
[1] 1898.43
[1] 44.60466
[1] 2211.914
[1] -3086.368
[1] -51.19255
[1] 31.52245
[1] 1548.272
[1] 49.0629
[1] 2352.531
INFO  [16:42:34.160] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1916.475
[1] -51.73568
[1] -105.9891
[1] 13.61009
[1] -28.16957
[1] 55.6005
[1] -28.02936
[1] 20.45265
[1] -65.67663
[1] -2.199637
INFO  [16:42:49.586] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -73.58081
[1] 130.2964
[1] -264.7896
[1] 64.80619
[1] -697.0166
[1] -4.069725
[1] -33.80647
[1] 19.05543
[1] -18.51361
[1] 54.37734
INFO  [16:43:11.637] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -41.12028
[1] 17.52951
[1] -15.71832
[1] 36.19205
[1] 48.6365
[1] 1003.409
[1] -87.75333
[1] 18.23233
[1] -17.70711
[1] 43.83521
INFO  [16:43:40.538] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:44:48.351] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:45:59.566] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:47:13.249] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 371.2401
[1] 19955.05
[1] -18065.12
[1] -333.3121
[1] 525.9482
[1] 28385.45
[1] 483.7032
[1] 26076.82
[1] -148833.8
[1] -2747.118
INFO  [16:48:03.826] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 379.6216
[1] 20432.27
[1] -22305.14
[1] -411.1634
[1] 391.247
[1] 21102.81
[1] -21939.03
[1] -402.6168
[1] -19119.88
[1] 150.5155
INFO  [16:48:54.766] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 364.5091
[1] 19582.59
[1] 525.5073
[1] 28489.31
[1] -42819.55
[1] -789.8065
[1] 342.2623
[1] 18446.56
[1] 21781.13
[1] 1172750
INFO  [16:49:41.904] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -131.9703
[1] 16.72834
[1] -7030.702
[1] -132.7857
[1] -120.2659
[1] 129.4007
[1] -321.9829
[1] -4.861627
[1] -113.1559
[1] 247.404
INFO  [16:50:24.698] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -167.3672
[1] 31.50145
[1] -44.21852
[1] 158.9916
[1] -422.9386
[1] -5.298513
[1] -86.55938
[1] 77.13508
[1] -43.61742
[1] 110.9812
INFO  [16:50:58.331] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -167.3241
[1] 32.64465
[1] -137.7261
[1] 11.48486
[1] -129.4078
[1] 83.70271
[1] 377.5619
[1] 14129.97
[1] -34.04013
[1] 141.3325
INFO  [16:51:47.490] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -917.3505
[1] -18.93154
[1] -1376.411
[1] -36.78331
[1] -217.428
[1] 6.545201
[1] -133.8265
[1] 7.303088
[1] -37.71869
[1] 46.3855
INFO  [16:52:39.964] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -3.600215e+16
[1] 3.396227e+15
[1] -41.01619
[1] 18.25947
[1] -65.59385
[1] 54.4416
[1] -31.81254
[1] 70.13608
[1] -438.3492
[1] -1.377411
INFO  [16:53:26.491] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -58.47233
[1] 52.14636
[1] -124.6914
[1] 103.4924
[1] -1828.131
[1] -56.6514
[1] -32.50899
[1] 52.13487
[1] -27.62181
[1] 38.422
INFO  [16:54:08.447] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -245.596
[1] -4.13162
[1] -918.4434
[1] -11.13409
[1] -160.5621
[1] 104.8734
[1] -7812.797
[1] -148.7934
[1] -142.2947
[1] 101.3073
INFO  [16:54:47.497] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -463.0743
[1] 134.6515
[1] -105.4292
[1] 159.0758
[1] -109.138
[1] 65.02454
[1] -179.312
[1] 47.62757
[1] -160.2762
[1] 190.4041
INFO  [16:55:37.752] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -177.165
[1] 41.30574
[1] -318.1316
[1] 160.5591
[1] -78.46566
[1] 174.2526
[1] -40.47225
[1] 134.5664
[1] 6.325303
[1] 254.7777
INFO  [16:56:38.477] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1364.395
[1] -27.40791
[1] 24.17936
[1] 1154.922
[1] 102.5354
[1] 5675.234
[1] -748.8976
[1] -12.53733
[1] -528.2928
[1] 381.4468
INFO  [16:57:24.714] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 14.6069
[1] 754.7266
[1] -930.5802
[1] 2904.598
[1] -716.7691
[1] -13.08887
[1] -146.9835
[1] 705.5025
[1] -516.7697
[1] 123.2135
INFO  [16:58:14.042] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -156.9147
[1] 670.7223
[1] -697.8215
[1] -13.38351
[1] 25.00736
[1] 1228.178
[1] 14.39915
[1] 769.0025
[1] 19.27912
[1] 1007.745
INFO  [16:59:08.823] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -3243.69
[1] -92.85175
[1] -29.34134
[1] 25.19589
[1] -1810.75
[1] -61.0627
[1] -114.2274
[1] 48.33912
[1] -29.83554
[1] 25.44583
INFO  [16:59:57.111] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -9037.244
[1] -145.7851
[1] -545.6497
[1] -3.936267
[1] -54.67952
[1] 52.17899
[1] -53.34256
[1] 12.54537
[1] 49.27288
[1] 1553.893
INFO  [17:00:55.316] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -93.99721
[1] 28.86497
[1] -64.05235
[1] 42.79292
[1] -94.19146
[1] 68.50043
[1] -25.61046
[1] 29.61801
[1] -39.12368
[1] 13.79632
INFO  [17:01:50.218] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:02:13.930] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:02:31.961] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:02:58.911] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:03:43.090] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:04:27.541] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:05:20.670] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -27.90049
[1] 25.26014
[1] -29.45296
[1] 12.09098
[1] -82.82951
[1] 34.90363
[1] -59.69873
[1] 35.45937
[1] 79.8297
[1] 1719.248
INFO  [17:05:56.922] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -18.40201
[1] 88.45353
[1] -50.1573
[1] 17.93664
[1] -19.87963
[1] 68.34831
[1] -40.17855
[1] 25.50431
[1] -24.37414
[1] 19.43208
INFO  [17:06:29.491] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -29.29707
[1] 13.72115
[1] -27.52426
[1] 36.44028
[1] -20.21012
[1] 27.06087
[1] -43.04047
[1] 34.39366
[1] 41.53029
[1] 1619.891
INFO  [17:07:02.269] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -109.3296
[1] 370.7801
[1] -81.71497
[1] 44.19765
[1] -1263.508
[1] -11.97768
[1] -265.8542
[1] 528.4885
[1] -264.0557
[1] -4.158087
INFO  [17:07:45.637] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -163.9348
[1] 14.19512
[1] -156.462
[1] -1.951498
[1] -56.73016
[1] 125.837
[1] 529.9687
[1] 16559.05
[1] 5.161481
[1] 203.1512
INFO  [17:08:34.253] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -113.8009
[1] 122.8504
[1] -127.5412
[1] 73.63445
[1] -45.15648
[1] 91.22738
[1] -51.47807
[1] 218.8217
[1] -99.41742
[1] 67.09718
INFO  [17:09:22.596] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -2332.825
[1] -68.23473
[1] -92.02248
[1] 92.7604
[1] -135.4838
[1] 108.0237
[1] -147.8494
[1] 6.866541
[1] -23.47962
[1] 102.689
INFO  [17:10:25.170] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -794.6939
[1] -5.284592
[1] -39.06939
[1] 251.3771
[1] 4.005144
[1] 129.7883
[1] -67.37863
[1] 65.38376
[1] -133.5749
[1] -4.429215
INFO  [17:11:30.593] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -75.90492
[1] 87.07859
[1] -101.4975
[1] 32.35005
[1] -52.74521
[1] 92.24995
[1] -51.33738
[1] 52.75324
[1] 109.9883
[1] 4051.656
INFO  [17:12:37.339] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -6.694695e+15
[1] 2.511907e+16
[1] -83.35711
[1] 46.86992
[1] -150.7673
[1] 0.6619086
[1] -122.1657
[1] 29.01848
[1] -15.85874
[1] 44.92388
INFO  [17:13:29.628] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -12.32877
[1] 48.73089
[1] -58.23643
[1] 3.976393
[1] -109.1538
[1] 18.95593
[1] -18.12492
[1] 29.31857
[1] -233.151
[1] 8.350325
INFO  [17:14:31.266] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -18.36303
[1] 85.12241
[1] -44.85596
[1] 58.67029
[1] -25.77693
[1] 21.42858
[1] -63.91108
[1] 17.04782
[1] -33.26363
[1] 63.32947
INFO  [17:15:31.028] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -245.7881
[1] 324.1791
[1] -328.268
[1] 469.3637
[1] -728.4438
[1] -12.49331
[1] -611.0997
[1] -11.01706
[1] -428.3593
[1] 144.659
INFO  [17:16:02.473] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -550.2915
[1] -9.12899
[1] -210.7602
[1] 312.4711
[1] -598.5726
[1] 53.80988
[1] -438.9147
[1] 132.6307
[1] -1314.51
[1] -19.31123
INFO  [17:16:29.325] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 13.94011
[1] 604.8377
[1] 12.72615
[1] 591.1957
[1] -740.2708
[1] -14.6203
[1] -542.5443
[1] -9.956964
[1] -724.1752
[1] -0.492978
INFO  [17:17:03.110] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -683.7893
[1] -33.2232
[1] -19.22482
[1] 27.65904
[1] -194.5968
[1] 15.59994
[1] -195.4228
[1] -3.718322
[1] -102.2374
[1] 100.5388
INFO  [17:17:47.613] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -45.72442
[1] 38.19796
[1] -32.17025
[1] 52.32355
[1] -865.3951
[1] -4.114352
[1] -62.7023
[1] 24.63714
[1] -19.629
[1] 73.48312
INFO  [17:18:35.070] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -62.3803
[1] 25.18391
[1] -39.58338
[1] 48.38753
[1] -126.0901
[1] 60.07852
[1] -52.93179
[1] 76.25946
[1] -49.45738
[1] 13.5489
INFO  [17:19:35.041] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:20:23.056] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:20:54.774] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:21:36.221] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -366.5504
[1] 102.9106
[1] -345.243
[1] 47.34722
[1] 7.993522
[1] 386.4628
[1] 7.651147
[1] 280.3442
[1] -12087.76
[1] -222.4647
INFO  [17:22:16.222] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 10.18299
[1] 393.3493
[1] 8.644059
[1] 347.4251
[1] -17027.49
[1] -228.3087
[1] -294.1637
[1] -5.286664
[1] -56.22504
[1] 312.2622
INFO  [17:22:51.375] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -559.3764
[1] -9.242055
[1] -23.15783
[1] 410.3016
[1] 10.50298
[1] 418.402
[1] -310.3652
[1] 327.9194
[1] 10.70039
[1] 438.8184
INFO  [17:23:35.468] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -38.82361
[1] 384.5484
[1] -86.88076
[1] 24.31923
[1] -108.6554
[1] 3.626444
[1] -72.56155
[1] 137.2932
[1] -99.7615
[1] 10.89412
INFO  [17:23:55.111] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -66.2415
[1] 63.37142
[1] -564.7032
[1] -4.56552
[1] -103.8594
[1] 46.41533
[1] -78.30899
[1] 37.50834
[1] -153.2481
[1] 18.67009
INFO  [17:24:16.929] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -181.9344
[1] 24.57002
[1] -55446.84
[1] -1239.244
[1] -53.543
[1] 123.9529
[1] -92.59838
[1] 45.42629
[1] -31.31902
[1] 73.08753
INFO  [17:24:32.732] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:25:24.498] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:26:05.913] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:26:39.464] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -108.2688
[1] -3.56476
[1] -73.81257
[1] 40.84536
[1] -52.58614
[1] 20.15757
[1] -53.48922
[1] 63.74328
[1] -74.90227
[1] 49.34732
INFO  [17:27:02.946] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -33.51941
[1] 112.3075
[1] -2830.758
[1] -64.54748
[1] -637.8874
[1] -4.208059
[1] -97.38549
[1] 0.4688686
[1] -49.62104
[1] 24.38886
INFO  [17:27:36.130] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -52.69165
[1] 17.17961
[1] 756.5736
[1] 26100
[1] -62.61896
[1] 59.13302
[1] -216.8742
[1] 55.90719
[1] -27.40051
[1] 123.4221
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:28:10.860] [mlr3] Finished benchmark
INFO  [17:28:12.223] [bbotk] Result of batch 1:
INFO  [17:28:12.372] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:28:12.372] [bbotk]              2.3306953                         0.2029788
INFO  [17:28:12.372] [bbotk]             -4.5770602                         0.6529788
INFO  [17:28:12.372] [bbotk]              5.7845729                         0.8779788
INFO  [17:28:12.372] [bbotk]             -1.1231823                         0.4279788
INFO  [17:28:12.372] [bbotk]             -6.3039990                         0.3154788
INFO  [17:28:12.372] [bbotk]              0.6037565                         0.7654788
INFO  [17:28:12.372] [bbotk]             -2.8501212                         0.9904788
INFO  [17:28:12.372] [bbotk]              4.0576341                         0.5404788
INFO  [17:28:12.372] [bbotk]              6.6480423                         0.2592288
INFO  [17:28:12.372] [bbotk]             -0.2597129                         0.7092288
INFO  [17:28:12.372] [bbotk]              3.1941647                         0.9342288
INFO  [17:28:12.372] [bbotk]             -3.7135908                         0.4842288
INFO  [17:28:12.372] [bbotk]              4.9211035                         0.5967288
INFO  [17:28:12.372] [bbotk]             -1.9866518                         0.1467288
INFO  [17:28:12.372] [bbotk]              1.4672259                         0.3717288
INFO  [17:28:12.372] [bbotk]             -5.4405295                         0.8217288
INFO  [17:28:12.372] [bbotk]              2.7624300                         0.4561038
INFO  [17:28:12.372] [bbotk]             -4.1453255                         0.9061038
INFO  [17:28:12.372] [bbotk]             -0.6914476                         0.2311038
INFO  [17:28:12.372] [bbotk]              6.2163076                         0.6811038
INFO  [17:28:12.372] [bbotk]              4.4893688                         0.1186038
INFO  [17:28:12.372] [bbotk]             -2.4183865                         0.5686038
INFO  [17:28:12.372] [bbotk]              1.0354912                         0.7936038
INFO  [17:28:12.372] [bbotk]             -5.8722642                         0.3436038
INFO  [17:28:12.372] [bbotk]              0.1720218                         0.2873538
INFO  [17:28:12.372] [bbotk]             -6.7357337                         0.7373538
INFO  [17:28:12.372] [bbotk]             -3.2818559                         0.5123538
INFO  [17:28:12.372] [bbotk]              3.6258994                         0.9623538
INFO  [17:28:12.372] [bbotk]             -5.0087949                         0.1748538
INFO  [17:28:12.372] [bbotk]              1.8989606                         0.6248538
INFO  [17:28:12.372] [bbotk]              5.3528382                         0.3998538
INFO  [17:28:12.372] [bbotk]             -1.5549171                         0.8498538
INFO  [17:28:12.372] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:28:12.372] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:28:12.372] [bbotk]                         0.3535379         -7.81540721             2.16806765
INFO  [17:28:12.372] [bbotk]                         0.8035379         -3.21023689            -4.73968762
INFO  [17:28:12.372] [bbotk]                         0.5785379         -0.90765179             5.62194529
INFO  [17:28:12.372] [bbotk]                         0.1285379         -5.51282225            -1.28580999
INFO  [17:28:12.372] [bbotk]                         0.6910379         -4.36152943            -6.46662639
INFO  [17:28:12.372] [bbotk]                         0.2410379         -8.96669979             0.44112883
INFO  [17:28:12.372] [bbotk]                         0.4660379         -6.66411480            -3.01274880
INFO  [17:28:12.372] [bbotk]                         0.9160379         -2.05894434             3.89500647
INFO  [17:28:12.372] [bbotk]                         0.1847879         -2.63459061            -2.14927939
INFO  [17:28:12.372] [bbotk]                         0.6347879         -7.23976094             4.75847588
INFO  [17:28:12.372] [bbotk]                         0.8597879         -4.93717598            -5.60315703
INFO  [17:28:12.372] [bbotk]                         0.4097879         -0.33200552             1.30459824
INFO  [17:28:12.372] [bbotk]                         0.5222879         -3.78588316            -0.42234058
INFO  [17:28:12.372] [bbotk]                         0.9722879         -8.39105348             6.48541470
INFO  [17:28:12.372] [bbotk]                         0.7472879         -6.08846853            -3.87621821
INFO  [17:28:12.372] [bbotk]                         0.2972879         -1.48329807             3.03153706
INFO  [17:28:12.372] [bbotk]                         0.2691629         -4.07370630             5.19021059
INFO  [17:28:12.372] [bbotk]                         0.7191629         -8.67887665            -1.71754469
INFO  [17:28:12.372] [bbotk]                         0.4941629         -1.77112120            -5.17142233
INFO  [17:28:12.372] [bbotk]                         0.9441629         -6.37629166             1.73633295
INFO  [17:28:12.372] [bbotk]                         0.6066629         -5.22499912             0.00939413
INFO  [17:28:12.372] [bbotk]                         0.1566629         -0.61982866            -6.89836112
INFO  [17:28:12.372] [bbotk]                         0.3816629         -2.92241375             3.46327177
INFO  [17:28:12.372] [bbotk]                         0.8316629         -7.52758407            -3.44448351
INFO  [17:28:12.372] [bbotk]                         0.7754129         -0.04418238            -0.85407528
INFO  [17:28:12.372] [bbotk]                         0.3254129         -4.64935284             6.05368000
INFO  [17:28:12.372] [bbotk]                         0.5504129         -2.34676748             2.59980236
INFO  [17:28:12.372] [bbotk]                         0.1004129         -6.95193780            -4.30795292
INFO  [17:28:12.372] [bbotk]                         0.2129129         -5.80064539             4.32674118
INFO  [17:28:12.372] [bbotk]                         0.6629129         -1.19547493            -2.58101410
INFO  [17:28:12.372] [bbotk]                         0.4379129         -8.10323035            -6.03489174
INFO  [17:28:12.372] [bbotk]                         0.8879129         -3.49806002             0.87286354
INFO  [17:28:12.372] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:28:12.372] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:28:12.372] [bbotk]                          1                    1770                 0.4794765
INFO  [17:28:12.372] [bbotk]                         11                    4270                 0.9294765
INFO  [17:28:12.372] [bbotk]                          6                    3020                 0.2544765
INFO  [17:28:12.372] [bbotk]                         16                     520                 0.7044765
INFO  [17:28:12.372] [bbotk]                         19                    2395                 0.3669765
INFO  [17:28:12.372] [bbotk]                          9                    4895                 0.8169765
INFO  [17:28:12.372] [bbotk]                         14                    3645                 0.1419765
INFO  [17:28:12.372] [bbotk]                          4                    1145                 0.5919765
INFO  [17:28:12.372] [bbotk]                         10                    1458                 0.5357265
INFO  [17:28:12.372] [bbotk]                         20                    3958                 0.9857265
INFO  [17:28:12.372] [bbotk]                          5                    2708                 0.3107265
INFO  [17:28:12.372] [bbotk]                         15                     208                 0.7607265
INFO  [17:28:12.372] [bbotk]                          2                    4583                 0.8732265
INFO  [17:28:12.372] [bbotk]                         12                    2083                 0.4232265
INFO  [17:28:12.372] [bbotk]                          7                     833                 0.6482265
INFO  [17:28:12.372] [bbotk]                         17                    3333                 0.1982265
INFO  [17:28:12.372] [bbotk]                         19                    4114                 0.7326015
INFO  [17:28:12.372] [bbotk]                          9                    1614                 0.2826015
INFO  [17:28:12.372] [bbotk]                          4                    2864                 0.5076015
INFO  [17:28:12.372] [bbotk]                         14                     364                 0.9576015
INFO  [17:28:12.372] [bbotk]                         17                    3489                 0.3951015
INFO  [17:28:12.372] [bbotk]                          7                     989                 0.8451015
INFO  [17:28:12.372] [bbotk]                         12                    2239                 0.1701015
INFO  [17:28:12.372] [bbotk]                          2                    4739                 0.6201015
INFO  [17:28:12.372] [bbotk]                         13                    3177                 0.3388515
INFO  [17:28:12.372] [bbotk]                          3                     677                 0.7888515
INFO  [17:28:12.372] [bbotk]                          8                    4427                 0.5638515
INFO  [17:28:12.372] [bbotk]                         18                    1927                 0.1138515
INFO  [17:28:12.372] [bbotk]                          6                    2552                 0.4513515
INFO  [17:28:12.372] [bbotk]                         16                      52                 0.9013515
INFO  [17:28:12.372] [bbotk]                         11                    3802                 0.6763515
INFO  [17:28:12.372] [bbotk]                          1                    1302                 0.2263515
INFO  [17:28:12.372] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:28:12.372] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:28:12.372] [bbotk]      0.04872635        0      0          129.840
INFO  [17:28:12.372] [bbotk]      0.02325797        0      0          231.673
INFO  [17:28:12.372] [bbotk]      0.54797135        0      0          191.033
INFO  [17:28:12.372] [bbotk]      0.03963684        0      0           88.407
INFO  [17:28:12.372] [bbotk]      0.02124807        0      0          140.745
INFO  [17:28:12.372] [bbotk]      0.04498130        0      0          339.620
INFO  [17:28:12.372] [bbotk]      0.03610452        0      0          212.128
INFO  [17:28:12.372] [bbotk]      0.54450891        0      0          121.285
INFO  [17:28:12.372] [bbotk]      0.54797135        0      0          110.242
INFO  [17:28:12.372] [bbotk]      0.04579325        0      0          416.761
INFO  [17:28:12.372] [bbotk]      0.04895116        0      0          163.037
INFO  [17:28:12.372] [bbotk]      0.02607261        0      0           65.106
INFO  [17:28:12.372] [bbotk]      0.54797135        0      0          211.766
INFO  [17:28:12.372] [bbotk]      0.52002924        0      0          148.161
INFO  [17:28:12.372] [bbotk]      0.04536699        0      0          124.206
INFO  [17:28:12.372] [bbotk]      0.02366658        0      0          140.272
INFO  [17:28:12.372] [bbotk]      0.04576323        0      0          149.637
INFO  [17:28:12.372] [bbotk]      0.04646269        0      0          149.739
INFO  [17:28:12.372] [bbotk]      0.02330131        0      0          160.424
INFO  [17:28:12.372] [bbotk]      0.54797135        0      0           67.185
INFO  [17:28:12.372] [bbotk]      0.54797135        0      0          140.394
INFO  [17:28:12.372] [bbotk]      0.02822312        0      0          100.831
INFO  [17:28:12.372] [bbotk]      0.04658235        0      0          137.707
INFO  [17:28:12.372] [bbotk]      0.04543924        0      0          193.624
INFO  [17:28:12.372] [bbotk]      0.02748526        0      0          173.082
INFO  [17:28:12.372] [bbotk]      0.04567009        0      0           91.554
INFO  [17:28:12.372] [bbotk]      0.02300519        0      0          151.457
INFO  [17:28:12.372] [bbotk]      0.54797135        0      0          120.853
INFO  [17:28:12.372] [bbotk]      0.05057912        0      0          118.944
INFO  [17:28:12.372] [bbotk]      0.03856694        0      0           56.808
INFO  [17:28:12.372] [bbotk]      0.54797135        0      0          125.917
INFO  [17:28:12.372] [bbotk]      0.02510572        0      0           82.275
INFO  [17:28:12.372] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:28:12.372] [bbotk]                                 uhash
INFO  [17:28:12.372] [bbotk]  5ac23916-6ecd-420f-812b-48b6804807a7
INFO  [17:28:12.372] [bbotk]  16e2dc06-fe32-4692-a639-4b57d9917080
INFO  [17:28:12.372] [bbotk]  ec6c95a5-8e15-464f-8d59-6ac54125cc5e
INFO  [17:28:12.372] [bbotk]  8f9a5c7c-e765-4f3a-ad4a-ef17bb7e39c7
INFO  [17:28:12.372] [bbotk]  9c21e404-e390-4b09-9499-315638b912b3
INFO  [17:28:12.372] [bbotk]  4ee1cf75-dc71-4205-b9a9-c38ce1418730
INFO  [17:28:12.372] [bbotk]  d8871e85-8187-451d-8a72-1e7463c6f99f
INFO  [17:28:12.372] [bbotk]  57c7c589-a35b-4863-a4c0-1e9fef27a7f7
INFO  [17:28:12.372] [bbotk]  092c8c88-4fc6-4b31-8f2a-679813de758a
INFO  [17:28:12.372] [bbotk]  2917f2e3-1510-4d4e-a24d-30b6b7287489
INFO  [17:28:12.372] [bbotk]  bf6f7e32-0b96-42d8-b22c-69bba39c6fb6
INFO  [17:28:12.372] [bbotk]  3fd0696f-659e-473d-bbb9-cb32c73eecf1
INFO  [17:28:12.372] [bbotk]  f8dd7afc-aa9f-4903-88f3-c9b5a9fab030
INFO  [17:28:12.372] [bbotk]  e684f5a7-c6b4-4437-a133-ecbcfd17818c
INFO  [17:28:12.372] [bbotk]  313b1dd6-acce-4775-821c-0edbd7bd9b63
INFO  [17:28:12.372] [bbotk]  310b6dd3-00fb-4e73-88e2-91a128d4e26e
INFO  [17:28:12.372] [bbotk]  5fc0316a-844d-49dc-961c-4c091a9a36ca
INFO  [17:28:12.372] [bbotk]  7da67390-b6c8-44c0-b53a-7f2f8e53bedc
INFO  [17:28:12.372] [bbotk]  4c231872-babd-4cd9-ac2f-3806a657d45a
INFO  [17:28:12.372] [bbotk]  0ea5aab8-034f-4614-80e7-0e6bdc7fdd20
INFO  [17:28:12.372] [bbotk]  21b8c05c-27d2-4710-a8eb-c5e69a7a1396
INFO  [17:28:12.372] [bbotk]  0ea978c8-fae6-4407-bb6b-c087b659c58f
INFO  [17:28:12.372] [bbotk]  c9d00637-6c41-44d3-b837-ea5e0b6f2ef6
INFO  [17:28:12.372] [bbotk]  89bf7280-2ad1-4c67-bc85-4f865a9f2b7e
INFO  [17:28:12.372] [bbotk]  8a18ce55-8dde-4983-a247-defca59d2700
INFO  [17:28:12.372] [bbotk]  8d915e90-6f5b-417c-b7be-5c21f41103d6
INFO  [17:28:12.372] [bbotk]  496cd0eb-0562-44b3-b022-eec3c6de7be5
INFO  [17:28:12.372] [bbotk]  883e8d22-5f25-48e8-824f-9badb58e2843
INFO  [17:28:12.372] [bbotk]  645752be-fbde-4bd5-a97f-40fd19f96f70
INFO  [17:28:12.372] [bbotk]  20d98420-5178-4cb8-9a3f-78b49c1ebace
INFO  [17:28:12.372] [bbotk]  49a3b406-d27b-4d1f-8b7a-a2bfb756e4ad
INFO  [17:28:12.372] [bbotk]  5bfeef1a-9130-49d4-ae6d-d7cee55b1fb2
INFO  [17:28:12.372] [bbotk]                                 uhash
INFO  [17:28:26.022] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 32 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:28:33.954] [bbotk] Evaluating 1 configuration(s)
INFO  [17:28:34.088] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:28:34.173] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -36.51618
[1] 17.83537
[1] -241.1103
[1] 31.59389
[1] -1619.848
[1] -49.4647
[1] -2003.484
[1] -61.95614
[1] -97.67255
[1] 2.990827
INFO  [17:28:49.652] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -84.57918
[1] 6.008941
[1] -22.05846
[1] 57.58782
[1] -77.45882
[1] 56.69916
[1] -59.43324
[1] 4.593535
[1] -1539.83
[1] 15.28848
INFO  [17:29:20.368] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -25.42801
[1] 42.58148
[1] -49.89424
[1] 18.81326
[1] -29.4934
[1] 86.40567
[1] 32.12283
[1] 994.507
[1] -48.23517
[1] 35.31966
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:29:51.097] [mlr3] Finished benchmark
INFO  [17:29:51.188] [bbotk] Result of batch 2:
INFO  [17:29:51.255] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:29:51.255] [bbotk]              -1.055098                         0.9218567
INFO  [17:29:51.255] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:29:51.255] [bbotk]                         0.8063447           -2.204168              -4.502497
INFO  [17:29:51.255] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:29:51.255] [bbotk]                          9                    1280                 0.6942655
INFO  [17:29:51.255] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:29:51.255] [bbotk]  0.1062504 <list[8]>              FALSE     0.01821137        0      0
INFO  [17:29:51.255] [bbotk]  runtime_learners                                uhash
INFO  [17:29:51.255] [bbotk]            75.935 1778251d-a218-4a9d-aefa-3a176a923f76
INFO  [17:29:52.503] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 33 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:30:01.404] [bbotk] Evaluating 1 configuration(s)
INFO  [17:30:01.767] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:30:01.932] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -480.4961
[1] -3.938103
[1] -712.0497
[1] -19.87881
[1] -5375.841
[1] -77.59565
[1] -42.19901
[1] 6.95869
[1] -102.5452
[1] 19.34121
INFO  [17:30:40.205] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -54.53732
[1] 32.21149
[1] -27.63007
[1] 74.62542
[1] -48.8905
[1] 5.771119
[1] -2.268482e+16
[1] 1.52795e+16
[1] -9.009327
[1] 67.17761
INFO  [17:31:05.541] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -49.32784
[1] 20.56783
[1] 55.81424
[1] 1182.298
[1] -76.39478
[1] 1.656744
[1] -21.14537
[1] 52.17667
[1] -114.4988
[1] 38.42289
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:31:29.722] [mlr3] Finished benchmark
INFO  [17:31:29.817] [bbotk] Result of batch 3:
INFO  [17:31:29.857] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:31:29.857] [bbotk]             -0.5021796                         0.9321761
INFO  [17:31:29.857] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:31:29.857] [bbotk]                         0.6269479           -2.424993             -0.5100236
INFO  [17:31:29.857] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:31:29.857] [bbotk]                          1                    2137                 0.6991405
INFO  [17:31:29.857] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:31:29.857] [bbotk]  0.08602764 <list[8]>              FALSE     0.02319363        0      0
INFO  [17:31:29.857] [bbotk]  runtime_learners                                uhash
INFO  [17:31:29.857] [bbotk]            86.628 1c28db1d-2fad-4223-9178-9eb63e81c108
INFO  [17:31:31.030] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 34 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:31:35.567] [bbotk] Evaluating 1 configuration(s)
INFO  [17:31:35.759] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:31:35.903] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -98.76227
[1] -3.311985
[1] 41.41099
[1] 985.0037
[1] -3156.561
[1] -64.27137
[1] -122.7756
[1] 22.38691
[1] -43.18424
[1] 34.55173
INFO  [17:32:10.563] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -284.9066
[1] -4.173878
[1] 80.32548
[1] 2419.735
[1] -86.43739
[1] 44.77386
[1] -37.64897
[1] 46.06755
[1] -77.53289
[1] 7.322704
INFO  [17:32:45.181] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -49.54176
[1] 111.0452
[1] -252.166
[1] 13.2846
[1] -70.12558
[1] 18.8619
[1] -2933.537
[1] -117.1513
[1] -33.04956
[1] 134.8098
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:33:22.191] [mlr3] Finished benchmark
INFO  [17:33:22.520] [bbotk] Result of batch 4:
INFO  [17:33:22.590] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:33:22.590] [bbotk]              0.9367513                         0.3952687
INFO  [17:33:22.590] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:33:22.590] [bbotk]                         0.3826561           -1.832062              -5.716787
INFO  [17:33:22.590] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:33:22.590] [bbotk]                          7                    4221                 0.7000313
INFO  [17:33:22.590] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:33:22.590] [bbotk]  0.1144894 <list[8]>              FALSE     0.02941342        0      0
INFO  [17:33:22.590] [bbotk]  runtime_learners                                uhash
INFO  [17:33:22.590] [bbotk]           103.708 e3bd858e-ad72-4ce8-8547-b767e7f3b9cc
WARN  [17:33:24.740] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:33:24.772] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 35 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:33:29.441] [bbotk] Evaluating 1 configuration(s)
INFO  [17:33:29.528] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:33:29.722] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -29.48848
[1] 180.5226
[1] -460.1698
[1] -5.110614
[1] 15.13967
[1] 877.5605
[1] 6.098243
[1] 246.681
[1] -126.8939
[1] 109.3672
INFO  [17:34:05.442] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -162.6196
[1] 61.97481
[1] -101.6526
[1] 91.91782
[1] -494.5428
[1] -5.621607
[1] -383.3092
[1] 120.9289
[1] 6.457994
[1] 267.1295
INFO  [17:35:16.549] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -165.7693
[1] 160.8351
[1] -16.90343
[1] 197.529
[1] -160.863
[1] 75.95319
[1] -233.4225
[1] 35.65066
[1] 9.89763
[1] 404.0245
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:35:54.720] [mlr3] Finished benchmark
INFO  [17:35:54.892] [bbotk] Result of batch 5:
INFO  [17:35:54.971] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:35:54.971] [bbotk]              0.9482376                          0.344504
INFO  [17:35:54.971] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:35:54.971] [bbotk]                         0.2487545           -4.028158               6.823331
INFO  [17:35:54.971] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:35:54.971] [bbotk]                         12                    4613                 0.8288934
INFO  [17:35:54.971] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:35:54.971] [bbotk]  0.08364533 <list[8]>              FALSE     0.04660757        0      0
INFO  [17:35:54.971] [bbotk]  runtime_learners                                uhash
INFO  [17:35:54.971] [bbotk]           144.291 3ace86cb-833c-445a-a189-682533ddde59
INFO  [17:35:56.067] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 36 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:36:01.530] [bbotk] Evaluating 1 configuration(s)
INFO  [17:36:01.575] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:36:01.779] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 72.44023
[1] 3740.537
[1] -4036.361
[1] -70.8432
[1] -3509.59
[1] -59.28483
[1] 130.973
[1] 6430.775
[1] 99.28614
[1] 4982.137
INFO  [17:36:56.323] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 56.04492
[1] 2747.803
[1] 139.2191
[1] 6820.529
[1] -2946.044
[1] -48.3796
[1] 41.43668
[1] 2011.493
[1] 62.18727
[1] 3076.97
INFO  [17:37:42.377] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 87.90746
[1] 4332.488
[1] -6264.499
[1] -109.6076
[1] 155.8932
[1] 7896.706
[1] 74.32537
[1] 3708.186
[1] 110.8585
[1] 5760.455
INFO  [17:38:36.808] [mlr3] Finished benchmark
INFO  [17:38:36.916] [bbotk] Result of batch 6:
INFO  [17:38:36.962] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:38:36.962] [bbotk]               2.442306                         0.7961012
INFO  [17:38:36.962] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:38:36.962] [bbotk]                         0.8255139           -6.345503              -3.971597
INFO  [17:38:36.962] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:38:36.962] [bbotk]                          3                    3753                 0.1258868
INFO  [17:38:36.962] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:38:36.962] [bbotk]  0.1028305 <list[8]>              FALSE     0.09035706        0      0
INFO  [17:38:36.962] [bbotk]  runtime_learners                                uhash
INFO  [17:38:36.962] [bbotk]           154.245 85966615-1e86-4b2b-8ad2-54ed799f4df3
INFO  [17:38:37.847] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 37 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:38:45.037] [bbotk] Evaluating 1 configuration(s)
INFO  [17:38:45.182] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:38:45.241] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -76.66404
[1] 51.91246
[1] -102.8877
[1] 14.74778
[1] 5.102243
[1] 144.5587
[1] -246.584
[1] -3.751007
[1] -160.3138
[1] -3.511849
INFO  [17:39:11.303] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -15.44658
[1] 86.63064
[1] -1789.399
[1] -52.37385
[1] -31.70805
[1] 136.9188
[1] -68.78443
[1] 67.0017
[1] -70.26495
[1] 31.15068
INFO  [17:39:31.966] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -18.59708
[1] 101.1392
[1] -233.5609
[1] 43.12551
[1] -37.25047
[1] 59.47127
[1] -652.0595
[1] -5.354548
[1] -42243.42
[1] -901.8646
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:39:53.308] [mlr3] Finished benchmark
INFO  [17:39:53.706] [bbotk] Result of batch 7:
INFO  [17:39:53.803] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:39:53.803] [bbotk]               1.907302                         0.7845898
INFO  [17:39:53.803] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:39:53.803] [bbotk]                         0.9489554          -0.3543413              -6.760734
INFO  [17:39:53.803] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:39:53.803] [bbotk]                          5                     892                 0.4006191
INFO  [17:39:53.803] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:39:53.803] [bbotk]  0.07200965 <list[8]>              FALSE     0.04561413        0      0
INFO  [17:39:53.803] [bbotk]  runtime_learners                                uhash
INFO  [17:39:53.803] [bbotk]            66.505 b48a03e7-e00a-4b60-9a4f-36aa28fae3a7
INFO  [17:39:58.101] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 38 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:40:14.287] [bbotk] Evaluating 1 configuration(s)
INFO  [17:40:14.334] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:40:14.460] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -38.54553
[1] 57.71574
[1] -1494.376
[1] 7.348639
[1] -190.7872
[1] -4.13413
[1] -100.7532
[1] 148.4975
[1] -266.9172
[1] 116.1225
INFO  [17:40:53.058] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -67.57243
[1] 79.5021
[1] -105.5747
[1] -4.217881
[1] -31.45334
[1] 49.49407
[1] -31.74112
[1] 89.84472
[1] -278.4385
[1] -3.945621
INFO  [17:41:48.966] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -446.9963
[1] 15.93404
[1] -115.0374
[1] 17.24573
[1] -127.8688
[1] 87.28842
[1] -61.43338
[1] 30.16229
[1] -31.4966
[1] 91.04596
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:42:46.805] [mlr3] Finished benchmark
INFO  [17:42:46.977] [bbotk] Result of batch 8:
INFO  [17:42:47.038] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:42:47.038] [bbotk]              0.3937613                         0.4925277
INFO  [17:42:47.038] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:42:47.038] [bbotk]                         0.3137193           -5.226325               2.197378
INFO  [17:42:47.038] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:42:47.038] [bbotk]                         15                    2877                 0.9173601
INFO  [17:42:47.038] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:42:47.038] [bbotk]  0.06310808 <list[8]>              FALSE     0.03493941        0      0
INFO  [17:42:47.038] [bbotk]  runtime_learners                                uhash
INFO  [17:42:47.038] [bbotk]           151.831 9075e00b-6bbf-4894-892c-6c4d5cccb646
WARN  [17:42:48.789] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:42:48.817] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 39 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:42:55.909] [bbotk] Evaluating 1 configuration(s)
INFO  [17:42:56.059] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:42:56.199] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1679.721
[1] -37.59432
[1] -75.13747
[1] 3.377518
[1] 35.28747
[1] 949.7867
[1] -296.1542
[1] 14.0141
[1] -24.63004
[1] 70.58076
INFO  [17:43:46.203] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -458.1494
[1] 139.591
[1] -43.9025
[1] 63.30196
[1] -108.6358
[1] 39.27348
[1] -23.973
[1] 95.5785
[1] -299.5676
[1] -1.373048
INFO  [17:44:25.561] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -96.25363
[1] 36.09008
[1] -149.6705
[1] 17.70424
[1] -110.1717
[1] 0.4157553
[1] -133.2999
[1] 24.55747
[1] -4325.737
[1] -43.89331
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:44:54.232] [mlr3] Finished benchmark
INFO  [17:44:54.436] [bbotk] Result of batch 9:
INFO  [17:44:54.470] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:44:54.470] [bbotk]              -4.717976                         0.4714502
INFO  [17:44:54.470] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:44:54.470] [bbotk]                         0.4528995           -3.288771              -2.689084
INFO  [17:44:54.470] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:44:54.470] [bbotk]                          6                    4786                 0.3044526
INFO  [17:44:54.470] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:44:54.470] [bbotk]  0.0578045 <list[8]>              FALSE     0.02269082        0      0
INFO  [17:44:54.470] [bbotk]  runtime_learners                                uhash
INFO  [17:44:54.470] [bbotk]           117.059 c1dc80a5-9d73-4dc5-9b6b-6ec23c99af1e
INFO  [17:44:55.243] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 40 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:45:02.093] [bbotk] Evaluating 1 configuration(s)
INFO  [17:45:02.258] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:45:02.342] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -12.48186
[1] 168.5478
[1] -83.42304
[1] 80.29775
[1] -103.1883
[1] 22.88543
[1] -185.7682
[1] -3.846697
[1] -29.20499
[1] 18.31385
INFO  [17:45:27.831] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -60.63591
[1] 16.62199
[1] -28.43568
[1] 15.84767
[1] -17.70789
[1] 35.97322
[1] -25.95615
[1] 37.11774
[1] -201.4352
[1] 47.24509
INFO  [17:46:08.109] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1043.392
[1] -50.4484
[1] -22.03578
[1] 40.93696
[1] -372.347
[1] 4.039797
[1] -59.53267
[1] 37.68233
[1] -58.64894
[1] 60.65927
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:46:37.970] [mlr3] Finished benchmark
INFO  [17:46:38.279] [bbotk] Result of batch 10:
INFO  [17:46:38.356] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:46:38.356] [bbotk]              -2.731409                         0.7662616
INFO  [17:46:38.356] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:46:38.356] [bbotk]                         0.5806034          -0.8865784              -1.592835
INFO  [17:46:38.356] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:46:38.356] [bbotk]                          4                    1920                  0.301294
INFO  [17:46:38.356] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:46:38.356] [bbotk]  0.05172283 <list[8]>              FALSE     0.02602594        0      0
INFO  [17:46:38.356] [bbotk]  runtime_learners                                uhash
INFO  [17:46:38.356] [bbotk]            94.124 e5536700-e870-467a-a635-d540ce7ad561
INFO  [17:46:39.724] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 41 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:46:47.060] [bbotk] Evaluating 1 configuration(s)
INFO  [17:46:47.195] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:46:47.342] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -52.80664
[1] 29.14287
[1] -836.5865
[1] -45.26028
[1] -43.66407
[1] 93.9846
[1] -19.00437
[1] 20.27678
[1] -23.66649
[1] 27.36407
INFO  [17:47:36.028] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -32.23457
[1] 17.37536
[1] -155.222
[1] -3.953602
[1] -36.5227
[1] 36.45199
[1] -111.7715
[1] 33.65901
[1] -55.76951
[1] 28.81945
INFO  [17:48:11.751] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -28.41668
[1] 61.03514
[1] -25.75633
[1] 12.19277
[1] -19.01077
[1] 54.61482
[1] -1.464402
[1] 162.0856
[1] 24.16391
[1] 592.1667
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:48:59.128] [mlr3] Finished benchmark
INFO  [17:48:59.364] [bbotk] Result of batch 11:
INFO  [17:48:59.449] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:48:59.449] [bbotk]             -0.9957522                         0.8130822
INFO  [17:48:59.449] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:48:59.449] [bbotk]                         0.6909715          -0.3549388             0.06010848
INFO  [17:48:59.449] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:48:59.449] [bbotk]                         19                    4070                 0.8888608
INFO  [17:48:59.449] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:48:59.449] [bbotk]  0.04642845 <list[8]>              FALSE     0.02750543        0      0
INFO  [17:48:59.449] [bbotk]  runtime_learners                                uhash
INFO  [17:48:59.449] [bbotk]            130.99 6154872d-6e99-4e6a-9236-ee25333d18c7
INFO  [17:49:00.796] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 42 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:49:07.238] [bbotk] Evaluating 1 configuration(s)
INFO  [17:49:07.461] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:49:07.545] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -22.13782
[1] 51.29493
[1] -39.5276
[1] 40.07853
[1] -99.84508
[1] 11.36967
[1] -86.32366
[1] 5.572848
[1] -31.05478
[1] 22.48827
INFO  [17:49:49.820] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -37.08673
[1] 98.94971
[1] -6814.673
[1] -149.0748
[1] -121.6026
[1] 19.411
[1] -192.8103
[1] -0.2762353
[1] -46.59253
[1] 40.27392
INFO  [17:50:22.041] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -51.30942
[1] 44.70665
[1] -141.0761
[1] 0.603836
[1] -41.79208
[1] 25.18106
[1] 12.23172
[1] 228.9252
[1] -22.4261
[1] 46.25044
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:50:55.420] [mlr3] Finished benchmark
INFO  [17:50:55.622] [bbotk] Result of batch 12:
INFO  [17:50:55.726] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:50:55.726] [bbotk]              -5.772902                         0.7916883
INFO  [17:50:55.726] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:50:55.726] [bbotk]                         0.5707199           -2.318482              0.1693773
INFO  [17:50:55.726] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:50:55.726] [bbotk]                         17                    3402                 0.9828862
INFO  [17:50:55.726] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:50:55.726] [bbotk]  0.04068357 <list[8]>              FALSE     0.02435751        0      0
INFO  [17:50:55.726] [bbotk]  runtime_learners                                uhash
INFO  [17:50:55.726] [bbotk]           107.275 3ef78718-1a57-410a-8d4f-194e9de512d9
INFO  [17:50:57.698] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 43 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:51:05.053] [bbotk] Evaluating 1 configuration(s)
INFO  [17:51:05.443] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:51:05.782] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -830.1283
[1] -15.16082
[1] -1000.285
[1] -17.343
[1] 15.83528
[1] 782.5734
[1] 21.72242
[1] 1166.298
[1] 367.4218
[1] 18537.63
INFO  [17:51:55.756] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -5.047693
[1] 958.5677
[1] -1219.242
[1] -20.88325
[1] 21.42006
[1] 1103.213
[1] -164.4655
[1] 618.3267
[1] -847.642
[1] -14.42958
INFO  [17:52:46.260] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -458.0724
[1] 704.9341
[1] -1039.014
[1] 464.9442
[1] -176.7113
[1] 606.7582
[1] -24124.9
[1] -425.6663
[1] -656.2485
[1] 330.0445
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:54:10.566] [mlr3] Finished benchmark
INFO  [17:54:12.575] [bbotk] Result of batch 13:
INFO  [17:54:12.677] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:54:12.677] [bbotk]              -4.054009                         0.6858275
INFO  [17:54:12.677] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:54:12.677] [bbotk]                         0.1613391           -9.176786               2.886638
INFO  [17:54:12.677] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:54:12.677] [bbotk]                         11                    4659                  0.957747
INFO  [17:54:12.677] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:54:12.677] [bbotk]  0.04318502 <list[8]>              FALSE     0.04104528        0      0
INFO  [17:54:12.677] [bbotk]  runtime_learners                                uhash
INFO  [17:54:12.677] [bbotk]           183.296 bdcb3825-5cc1-48ef-9858-12514d1c763c
INFO  [17:54:13.946] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 44 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:54:19.306] [bbotk] Evaluating 1 configuration(s)
INFO  [17:54:19.575] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:54:19.756] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -29.12567
[1] 37.93716
[1] -1049.462
[1] -58.39961
[1] -28.32912
[1] 29.04232
[1] -8306.294
[1] -286.3833
[1] -35.93398
[1] 31.26719
INFO  [17:54:44.130] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -326.3588
[1] -3.997084
[1] -113.1219
[1] 8.354892
[1] -30.16388
[1] 14.70229
[1] -26.72242
[1] 9.356824
[1] -13.0225
[1] 22.77392
INFO  [17:55:14.962] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 7.453103
[1] 145.446
[1] -44.25228
[1] 29.56803
[1] -39.01092
[1] 57.79921
[1] -32.89444
[1] 52.97914
[1] -34.24782
[1] 16.04715
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:55:56.463] [mlr3] Finished benchmark
INFO  [17:55:56.737] [bbotk] Result of batch 14:
INFO  [17:55:56.798] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:55:56.798] [bbotk]             -0.8914661                         0.6751541
INFO  [17:55:56.798] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:55:56.798] [bbotk]                         0.4530217          -0.3198026              -3.550701
INFO  [17:55:56.798] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:55:56.798] [bbotk]                         17                    2185                 0.1346531
INFO  [17:55:56.798] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:55:56.798] [bbotk]  0.05259707 <list[8]>              FALSE     0.02741977        0      0
INFO  [17:55:56.798] [bbotk]  runtime_learners                                uhash
INFO  [17:55:56.798] [bbotk]            95.052 4749c771-f5b2-41ef-b606-3b48d5468f93
INFO  [17:55:58.189] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 45 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:56:07.063] [bbotk] Evaluating 1 configuration(s)
INFO  [17:56:07.261] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:56:07.460] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1485.316
[1] -3.882002
[1] -114.9239
[1] -3.919528
[1] -100.3583
[1] 19.48904
[1] -147974
[1] -4406.492
[1] -26.08764
[1] 24.47781
INFO  [17:56:33.876] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -361.96
[1] 19.2024
[1] -41.23882
[1] 33.02084
[1] -93.97763
[1] -3.726172
[1] -81.17885
[1] 47.15898
[1] -5313.377
[1] -64.04092
INFO  [17:57:18.232] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -148.4767
[1] 5.758501
[1] -289.1422
[1] 70.82222
[1] -46.04558
[1] 34.15404
[1] -33.34293
[1] 29.74272
[1] -93.9808
[1] 4.274623
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:57:57.633] [mlr3] Finished benchmark
INFO  [17:57:57.824] [bbotk] Result of batch 15:
INFO  [17:57:57.914] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:57:57.914] [bbotk]              -4.265292                         0.9339198
INFO  [17:57:57.914] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:57:57.914] [bbotk]                         0.3384988           -1.827444                2.32864
INFO  [17:57:57.914] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:57:57.914] [bbotk]                          2                    3365                 0.8857578
INFO  [17:57:57.914] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:57:57.914] [bbotk]  0.0339611 <list[8]>              FALSE        0.02176        0      0
INFO  [17:57:57.914] [bbotk]  runtime_learners                                uhash
INFO  [17:57:57.914] [bbotk]           109.376 753ce2cd-21e5-4bd7-8bdc-6fcfc262347a
INFO  [17:57:59.609] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 46 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:58:06.203] [bbotk] Evaluating 1 configuration(s)
INFO  [17:58:06.773] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:58:07.232] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -52.97545
[1] 75.49737
[1] -53.11638
[1] 23.65911
[1] -98.89196
[1] 4.804694
[1] -74.17039
[1] 92.24119
[1] -144.4231
[1] 0.3192605
INFO  [17:58:49.838] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -75.95514
[1] 16.62981
[1] -43.01724
[1] 125.9778
[1] -5421.575
[1] -102.9679
[1] -159.7185
[1] 8.056269
[1] -165.1027
[1] 28.76707
INFO  [17:59:25.704] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -93.43686
[1] 31.57739
[1] -63.63451
[1] 31.71652
[1] -48.54538
[1] 25.21965
[1] -69.02257
[1] 20.79097
[1] -117.9055
[1] 33.55972
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:00:26.973] [mlr3] Finished benchmark
INFO  [18:00:27.441] [bbotk] Result of batch 16:
INFO  [18:00:27.545] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:00:27.545] [bbotk]              0.5777981                         0.8696005
INFO  [18:00:27.545] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:00:27.545] [bbotk]                         0.7437558           -2.291233              -5.833842
INFO  [18:00:27.545] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:00:27.545] [bbotk]                         18                    2674                 0.7025242
INFO  [18:00:27.545] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:00:27.545] [bbotk]  0.0363643 <list[8]>              FALSE     0.02815353        0      0
INFO  [18:00:27.545] [bbotk]  runtime_learners                                uhash
INFO  [18:00:27.545] [bbotk]           137.121 16bab887-e2f0-4fe0-8dd6-959417adf1d1
INFO  [18:00:29.484] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 47 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:00:34.657] [bbotk] Evaluating 1 configuration(s)
INFO  [18:00:34.691] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:00:34.729] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 93.82779
[1] 4947.944
[1] -4546.805
[1] -83.58976
[1] 75.31117
[1] 4008.119
[1] -3820.508
[1] -69.58137
[1] -5297.616
[1] -94.44747
INFO  [18:01:21.380] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 79.89296
[1] 4201.576
[1] 101.4547
[1] 5323.459
[1] -7158.812
[1] -126.6757
[1] 86.27062
[1] 4440.45
[1] -4909.936
[1] -90.96539
INFO  [18:02:16.940] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -3468.616
[1] -63.16627
[1] 147.6492
[1] 7800.822
[1] 6335.916
[1] 335426
[1] 65.72628
[1] 3465.165
[1] 114.4212
[1] 6175.195
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:03:08.920] [mlr3] Finished benchmark
INFO  [18:03:09.012] [bbotk] Result of batch 17:
INFO  [18:03:09.059] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:03:09.059] [bbotk]               1.463592                         0.3536802
INFO  [18:03:09.059] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:03:09.059] [bbotk]                         0.3795741           -8.826208               5.283675
INFO  [18:03:09.059] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:03:09.059] [bbotk]                         17                    3979                 0.6834321
INFO  [18:03:09.059] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:03:09.059] [bbotk]  0.03427048 <list[8]>              FALSE      0.2868044        0      0
INFO  [18:03:09.059] [bbotk]  runtime_learners                                uhash
INFO  [18:03:09.059] [bbotk]           153.865 095d421a-1b82-4f25-a64f-d62cf91322c5
INFO  [18:03:10.807] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 48 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:03:15.687] [bbotk] Evaluating 1 configuration(s)
INFO  [18:03:15.830] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:03:15.892] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -76.7511
[1] 60.15537
[1] -80.00081
[1] 86.19784
[1] -201.1349
[1] -3.748544
[1] -125.3133
[1] 52.58586
[1] -117.0509
[1] 118.2122
INFO  [18:03:46.351] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1109.837
[1] -7.591697
[1] -93.04076
[1] 57.84245
[1] -227.2897
[1] -4.53507
[1] 9.439173
[1] 717.0725
[1] -171.3966
[1] 21.21248
INFO  [18:04:08.990] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -163.723
[1] 3.947693
[1] -94.83026
[1] 53.25665
[1] 5.207673
[1] 262.2665
[1] 1.612758
[1] 143.466
[1] -247.0974
[1] -4.666945
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:04:41.074] [mlr3] Finished benchmark
INFO  [18:04:41.323] [bbotk] Result of batch 18:
INFO  [18:04:41.454] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:04:41.454] [bbotk]               2.793495                         0.6250164
INFO  [18:04:41.454] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:04:41.454] [bbotk]                         0.9674636          -0.2665673              -2.431117
INFO  [18:04:41.454] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:04:41.454] [bbotk]                          8                    1617                 0.8750795
INFO  [18:04:41.454] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:04:41.454] [bbotk]  0.08682753 <list[8]>              FALSE     0.04104895        0      0
INFO  [18:04:41.454] [bbotk]  runtime_learners                                uhash
INFO  [18:04:41.454] [bbotk]            84.724 89f3398b-d7ee-4d34-9a71-cbedfb591bc2
INFO  [18:04:43.385] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 49 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:04:54.097] [bbotk] Evaluating 1 configuration(s)
INFO  [18:04:54.331] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:04:54.395] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -185.1052
[1] -4.54948
[1] -47.33525
[1] 92.48181
[1] -287.646
[1] 52.79087
[1] -112.7845
[1] 74.57126
[1] -139.0781
[1] 5.330367
INFO  [18:05:38.473] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -383.2659
[1] -1.793357
[1] -25.16186
[1] 83.24756
[1] -42.8391
[1] 124.9844
[1] -31.33013
[1] 140.1513
[1] -92.73936
[1] 58.51847
INFO  [18:06:31.823] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -77.73698
[1] 64.16022
[1] -57.74926
[1] 68.08462
[1] -7.580773
[1] 154.8631
[1] -113.2135
[1] 38.50619
[1] -55.6436
[1] 144.5615
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:07:08.122] [mlr3] Finished benchmark
INFO  [18:07:08.238] [bbotk] Result of batch 19:
INFO  [18:07:08.256] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:07:08.256] [bbotk]               2.370463                         0.5011538
INFO  [18:07:08.256] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:07:08.256] [bbotk]                         0.6696023           -4.021009              -5.097702
INFO  [18:07:08.256] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:07:08.256] [bbotk]                          2                    4081                 0.8353481
INFO  [18:07:08.256] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:07:08.256] [bbotk]  0.06128869 <list[8]>              FALSE     0.04419751        0      0
INFO  [18:07:08.256] [bbotk]  runtime_learners                                uhash
INFO  [18:07:08.256] [bbotk]           133.475 6279b8ae-e770-4fea-bdae-aa09524ae307
INFO  [18:07:10.070] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 50 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:07:16.655] [bbotk] Evaluating 1 configuration(s)
INFO  [18:07:16.691] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:07:16.736] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 45.83375
[1] 2476.601
[1] -5911.62
[1] -263.8151
[1] -71.78992
[1] 22.72477
[1] -99.40293
[1] -3.41686
[1] -38.94071
[1] 7.309299
INFO  [18:07:46.695] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -49.64146
[1] 75.73207
[1] -55.20557
[1] 13.91328
[1] -96.27021
[1] 68.6434
[1] -40.96905
[1] 24.6355
[1] -23.4453
[1] 19.7792
INFO  [18:08:18.543] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -153.6716
[1] 1.888005
[1] -18.11098
[1] 44.11381
[1] -184.4541
[1] -4.043081
[1] -17.2755
[1] 67.51211
[1] -15.91158
[1] 40.0283
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:08:51.655] [mlr3] Finished benchmark
INFO  [18:08:51.820] [bbotk] Result of batch 20:
INFO  [18:08:51.934] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:08:51.934] [bbotk]              -1.341042                         0.9864256
INFO  [18:08:51.934] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:08:51.934] [bbotk]                         0.2589295          -0.5993794              -3.122465
INFO  [18:08:51.934] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:08:51.934] [bbotk]                          1                    1843                 0.7024153
INFO  [18:08:51.934] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:08:51.934] [bbotk]  0.07843265 <list[8]>              FALSE       0.023642        0      0
INFO  [18:08:51.934] [bbotk]  runtime_learners                                uhash
INFO  [18:08:51.934] [bbotk]            93.554 5f8bfeae-aa7c-4035-bba5-a37254a7ba27
INFO  [18:08:52.880] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 51 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:09:00.087] [bbotk] Evaluating 1 configuration(s)
INFO  [18:09:00.179] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:09:00.254] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -51.25045
[1] 57.46996
[1] -16.80417
[1] 37.03272
[1] -71.96177
[1] 28.47311
[1] -136.0417
[1] -3.81928
[1] -108.309
[1] -3.812401
INFO  [18:09:32.281] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -69.10276
[1] -1.341744
[1] -137.5677
[1] 40.74653
[1] -1662.314
[1] -60.53359
[1] -3896.248
[1] -61.84282
[1] -18.06603
[1] 29.30297
INFO  [18:10:31.763] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -49.00272
[1] 12.94301
[1] -13827.11
[1] -205.166
[1] -38.76133
[1] 18.71806
[1] -39.84534
[1] 71.41551
[1] -54.63732
[1] 47.03767
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:11:08.355] [mlr3] Finished benchmark
INFO  [18:11:08.509] [bbotk] Result of batch 21:
INFO  [18:11:08.552] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:11:08.552] [bbotk]              -3.453216                         0.9464657
INFO  [18:11:08.552] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:11:08.552] [bbotk]                         0.2809727           -3.130049              -6.694954
INFO  [18:11:08.552] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:11:08.552] [bbotk]                         17                    3793                 0.5426874
INFO  [18:11:08.552] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:11:08.552] [bbotk]  0.0656765 <list[8]>              FALSE     0.02690808        0      0
INFO  [18:11:08.552] [bbotk]  runtime_learners                                uhash
INFO  [18:11:08.552] [bbotk]           126.744 0f2d4b70-b69a-40c9-8d85-d5fc7e1fcffe
INFO  [18:11:09.669] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 52 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:11:18.832] [bbotk] Evaluating 1 configuration(s)
INFO  [18:11:19.093] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:11:19.123] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -123.4452
[1] 17.02375
[1] -45.20665
[1] 50.05214
[1] -2322.273
[1] -36.60559
[1] -145.9214
[1] 4.370084
[1] -65.72944
[1] 16.21406
INFO  [18:11:46.765] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -44.88325
[1] 43.15503
[1] -34.05635
[1] 51.92478
[1] -108.8601
[1] 124.96
[1] -1781.714
[1] -56.56366
[1] -272.7301
[1] 6.866343
INFO  [18:12:24.590] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -3713.128
[1] -61.34015
[1] -33.16881
[1] 51.6043
[1] -1996.168
[1] -48.14629
[1] -30.18776
[1] 35.27212
[1] -78.1205
[1] 81.42492
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:13:01.705] [mlr3] Finished benchmark
INFO  [18:13:01.906] [bbotk] Result of batch 22:
INFO  [18:13:02.017] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:13:02.017] [bbotk]              0.7483782                         0.6042876
INFO  [18:13:02.017] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:13:02.017] [bbotk]                         0.2938227           -2.102809               1.364782
INFO  [18:13:02.017] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:13:02.017] [bbotk]                          4                    1779                 0.8151746
INFO  [18:13:02.017] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:13:02.017] [bbotk]  0.04399836 <list[8]>              FALSE     0.03125488        0      0
INFO  [18:13:02.017] [bbotk]  runtime_learners                                uhash
INFO  [18:13:02.017] [bbotk]           101.431 1a9b2a48-0d23-430a-a539-963eb1dc32c7
INFO  [18:13:03.960] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 53 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:13:09.915] [bbotk] Evaluating 1 configuration(s)
INFO  [18:13:09.949] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:13:09.979] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -338826.8
[1] -6256.008
[1] 3740.806
[1] 202591.4
[1] 4909.106
[1] 265833
[1] -228990
[1] -4228.661
[1] -303977.4
[1] -5613.209
INFO  [18:13:23.311] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 6556.242
[1] 355001.9
[1] -264835.6
[1] -4890.525
[1] -213653.9
[1] -3944.716
[1] -193947.7
[1] -3581.829
[1] 5124.667
[1] 277479.4
INFO  [18:13:36.264] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 5891.836
[1] 319065.4
[1] 6679.429
[1] 361704.1
[1] 5363.804
[1] 290472.3
[1] -306412.2
[1] -5659.102
[1] -202870.3
[1] -3746.441
INFO  [18:13:50.905] [mlr3] Finished benchmark
INFO  [18:13:51.075] [bbotk] Result of batch 23:
INFO  [18:13:51.189] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:13:51.189] [bbotk]               2.876048                         0.4532331
INFO  [18:13:51.189] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:13:51.189] [bbotk]                         0.7123992            -7.20034              -6.710224
INFO  [18:13:51.189] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:13:51.189] [bbotk]                          4                       1                  0.968563
INFO  [18:13:51.189] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:13:51.189] [bbotk]  0.04208469 <list[8]>              FALSE       0.546768        0      0
INFO  [18:13:51.189] [bbotk]  runtime_learners                                uhash
INFO  [18:13:51.189] [bbotk]            40.646 291c8f1f-146e-4b05-835a-6ebe2d1ef623
INFO  [18:13:52.768] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 54 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:14:02.446] [bbotk] Evaluating 1 configuration(s)
INFO  [18:14:02.619] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:14:02.692] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -63.22089
[1] 55.9719
[1] -45.83782
[1] 96.6118
[1] -114.1751
[1] -2.66188
[1] -1281.683
[1] -33.71385
[1] -79.58015
[1] 120.3005
INFO  [18:14:41.957] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 671.4117
[1] 27117.48
[1] -134.795
[1] 80.4077
[1] -41.11604
[1] 49.32135
[1] -64.11002
[1] 52.10122
[1] -58.61795
[1] 27.91492
INFO  [18:15:49.720] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -42.20701
[1] 106.1128
[1] -30.70876
[1] 82.26249
[1] -273.1702
[1] -3.80273
[1] 105.7877
[1] 3195.334
[1] -37.96352
[1] 99.93766
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:16:22.445] [mlr3] Finished benchmark
INFO  [18:16:22.604] [bbotk] Result of batch 24:
INFO  [18:16:22.651] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:16:22.651] [bbotk]               1.776344                         0.7414969
INFO  [18:16:22.651] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:16:22.651] [bbotk]                         0.6503004           -2.549546             -0.3569705
INFO  [18:16:22.651] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:16:22.651] [bbotk]                          1                    4759                 0.5156218
INFO  [18:16:22.651] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:16:22.651] [bbotk]  0.07045225 <list[8]>              FALSE     0.04225788        0      0
INFO  [18:16:22.651] [bbotk]  runtime_learners                                uhash
INFO  [18:16:22.651] [bbotk]           138.894 d2202834-0749-43f1-b94b-9de9ec1c4713
INFO  [18:16:23.808] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 55 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:16:29.403] [bbotk] Evaluating 1 configuration(s)
INFO  [18:16:29.744] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:16:30.450] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -30.63479
[1] 58.62382
[1] -98.70025
[1] 16.04827
[1] -70.62869
[1] 83.44511
[1] -64.99338
[1] 113.0621
[1] -146.9606
[1] 139.889
INFO  [18:17:20.156] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -143.5893
[1] -4.701582
[1] 2.988987
[1] 117.8274
[1] -3295.272
[1] -46.70182
[1] -96.39954
[1] 57.17317
[1] -88.34368
[1] 193.5121
INFO  [18:18:03.024] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -50.53857
[1] 108.3587
[1] -29.47541
[1] 89.668
[1] -133.5928
[1] -0.04783127
[1] -271.667
[1] -5.194326
[1] -55.56869
[1] 96.15458
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:18:50.472] [mlr3] Finished benchmark
INFO  [18:18:50.698] [bbotk] Result of batch 25:
INFO  [18:18:50.868] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:18:50.868] [bbotk]               2.189133                          0.488857
INFO  [18:18:50.868] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:18:50.868] [bbotk]                         0.8657506          -0.1797823              -3.333702
INFO  [18:18:50.868] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:18:50.868] [bbotk]                         10                    3920                 0.4755571
INFO  [18:18:50.868] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:18:50.868] [bbotk]  0.05518876 <list[8]>              FALSE     0.03839936        0      0
INFO  [18:18:50.868] [bbotk]  runtime_learners                                uhash
INFO  [18:18:50.868] [bbotk]            139.39 4c01d6f0-312d-47ec-8de1-96c2f24dc4e5
INFO  [18:18:52.336] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 56 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:19:00.291] [bbotk] Evaluating 1 configuration(s)
INFO  [18:19:00.918] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:19:01.614] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -214.7923
[1] -3.645257
[1] -28.80283
[1] 28.64606
[1] -39.91154
[1] 29.74945
[1] -157.9419
[1] 28.72709
[1] -646.5088
[1] -25.30432
INFO  [18:19:45.882] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -19.54828
[1] 111.5697
[1] -233.8465
[1] 26.62167
[1] -25.35712
[1] 134.1162
[1] -65.40886
[1] 13.39992
[1] -215.2679
[1] 16.75857
INFO  [18:20:24.578] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -65.55471
[1] 8.644438
[1] 126.2647
[1] 4475.264
[1] -63.49075
[1] 21.77365
[1] -19.45477
[1] 90.37395
[1] 97.59916
[1] 2738.675
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:21:06.535] [mlr3] Finished benchmark
INFO  [18:21:06.755] [bbotk] Result of batch 26:
INFO  [18:21:06.801] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:21:06.801] [bbotk]             -0.5002791                         0.7636084
INFO  [18:21:06.801] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:21:06.801] [bbotk]                         0.1502808           -4.630019              -3.032827
INFO  [18:21:06.801] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:21:06.801] [bbotk]                         13                    4611                 0.8513477
INFO  [18:21:06.801] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:21:06.801] [bbotk]  0.05881175 <list[8]>              FALSE     0.03096444        0      0
INFO  [18:21:06.801] [bbotk]  runtime_learners                                uhash
INFO  [18:21:06.801] [bbotk]            123.23 cb32b55a-f9d1-4c52-9f88-7f67940267d0
INFO  [18:21:08.537] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 57 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:21:13.353] [bbotk] Evaluating 1 configuration(s)
INFO  [18:21:13.462] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:21:13.567] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -38.88429
[1] 275.1342
[1] -336.5566
[1] 686.3576
[1] -42.68844
[1] 34.94168
[1] 157.9755
[1] 5614.704
[1] -113.5057
[1] 8.701341
INFO  [18:21:31.315] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -26.12383
[1] 60.33888
[1] -300.6644
[1] 8.77131
[1] -48.72163
[1] 36.2304
[1] -97.40907
[1] 7.531278
[1] -24.67707
[1] 64.07864
INFO  [18:22:07.709] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -613.3941
[1] 16.07158
[1] -76.57798
[1] 42.09048
[1] -88.27593
[1] 51.6305
[1] -52.9753
[1] 6.686125
[1] -24.64736
[1] 53.00628
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:22:46.001] [mlr3] Finished benchmark
INFO  [18:22:46.117] [bbotk] Result of batch 27:
INFO  [18:22:46.151] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:22:46.151] [bbotk]              -4.393017                         0.9735378
INFO  [18:22:46.151] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:22:46.151] [bbotk]                         0.2896566           -4.444341             -0.1384149
INFO  [18:22:46.151] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:22:46.151] [bbotk]                          9                    3368                 0.4360894
INFO  [18:22:46.151] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:22:46.151] [bbotk]  0.04757412 <list[8]>              FALSE     0.02482524        0      0
INFO  [18:22:46.151] [bbotk]  runtime_learners                                uhash
INFO  [18:22:46.151] [bbotk]            91.927 0762c507-3f2b-42b4-a773-2169c7c9bf5c
INFO  [18:22:47.244] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 58 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:22:53.489] [bbotk] Evaluating 1 configuration(s)
INFO  [18:22:53.628] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:22:54.048] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -80.05565
[1] 8.998679
[1] -83.64685
[1] -3.380667
[1] -1469.228
[1] -37.43145
[1] 148.9357
[1] 2944.132
[1] -55.05558
[1] 14.9689
INFO  [18:23:15.619] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -39.70845
[1] 21.2397
[1] -18.35061
[1] 86.34857
[1] 12.4246
[1] 357.4447
[1] -51.66152
[1] 25.26862
[1] -40.27778
[1] 43.0834
INFO  [18:23:51.865] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -87.92743
[1] 10.23584
[1] -1055.032
[1] 2.49987
[1] -56.82222
[1] 55.65237
[1] -42.40724
[1] 99.57668
[1] -13.57578
[1] 42.70597
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:24:19.063] [mlr3] Finished benchmark
INFO  [18:24:19.231] [bbotk] Result of batch 28:
INFO  [18:24:19.312] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:24:19.312] [bbotk]              -0.285502                         0.9659364
INFO  [18:24:19.312] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:24:19.312] [bbotk]                         0.2119084           -2.113496              -2.606126
INFO  [18:24:19.312] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:24:19.312] [bbotk]                          9                    1431                 0.6952697
INFO  [18:24:19.312] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:24:19.312] [bbotk]  0.04489892 <list[8]>              FALSE     0.02559585        0      0
INFO  [18:24:19.312] [bbotk]  runtime_learners                                uhash
INFO  [18:24:19.312] [bbotk]            83.713 70a4200f-c434-44f5-ba3b-31da9ababb1d
INFO  [18:24:20.387] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 59 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:24:28.753] [bbotk] Evaluating 1 configuration(s)
INFO  [18:24:28.813] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:24:28.890] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -63.14188
[1] 27.48193
[1] -1020.403
[1] -31.95819
[1] -26.3022
[1] 55.33319
[1] -503.7627
[1] 7.235275
[1] -89.96622
[1] -3.226166
INFO  [18:25:02.503] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -22.45083
[1] 44.8978
[1] -50.28204
[1] 12.60945
[1] -1446.084
[1] -70.76925
[1] -61.53356
[1] 34.99929
[1] 84.02723
[1] 2094.471
INFO  [18:25:30.565] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -52.04756
[1] 24.54555
[1] -85.86322
[1] 128.5427
[1] -38.22489
[1] 30.87609
[1] 45.27752
[1] 1986.89
[1] 142.5916
[1] 3773.179
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:26:05.389] [mlr3] Finished benchmark
INFO  [18:26:05.515] [bbotk] Result of batch 29:
INFO  [18:26:05.568] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:26:05.568] [bbotk]              -5.325333                         0.6842785
INFO  [18:26:05.568] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:26:05.568] [bbotk]                         0.3074198           -5.242468              -6.600471
INFO  [18:26:05.568] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:26:05.568] [bbotk]                         13                    2057                 0.4325441
INFO  [18:26:05.568] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:26:05.568] [bbotk]  0.04281986 <list[8]>              FALSE     0.02551368        0      0
INFO  [18:26:05.568] [bbotk]  runtime_learners                                uhash
INFO  [18:26:05.568] [bbotk]             95.44 f0fa8505-456f-4bde-88e7-6d06f3eed99b
INFO  [18:26:06.801] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 60 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:26:13.648] [bbotk] Evaluating 1 configuration(s)
INFO  [18:26:14.127] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:26:14.316] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -220.1381
[1] -4.847529
[1] -109.2743
[1] 12.67303
[1] -202.3825
[1] 92.22665
[1] -343.1128
[1] -4.304199
[1] -55.64001
[1] 110.2744
INFO  [18:26:55.990] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -151.45
[1] 11.58129
[1] -41.42624
[1] 101.5907
[1] -117.4889
[1] 35.64455
[1] -192.9963
[1] 169.3997
[1] -196.0764
[1] 11.93967
INFO  [18:27:34.412] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -103.6936
[1] 61.09101
[1] -177.789
[1] 19.99794
[1] -127.0888
[1] 76.57569
[1] -64.2089
[1] 89.88015
[1] -136.2835
[1] 71.07274
INFO  [18:28:05.295] [mlr3] Finished benchmark
INFO  [18:28:05.480] [bbotk] Result of batch 30:
INFO  [18:28:05.568] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:28:05.568] [bbotk]                2.23272                          0.891562
INFO  [18:28:05.568] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:28:05.568] [bbotk]                         0.8563826           -2.922954                2.69459
INFO  [18:28:05.568] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:28:05.568] [bbotk]                          2                    2630                 0.5756449
INFO  [18:28:05.568] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:28:05.568] [bbotk]  0.04862847 <list[8]>              FALSE     0.04529551        0      0
INFO  [18:28:05.568] [bbotk]  runtime_learners                                uhash
INFO  [18:28:05.568] [bbotk]            110.37 91fd95c7-60c0-4b78-869a-88e474299ef0
INFO  [18:28:06.877] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 61 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:28:13.340] [bbotk] Evaluating 1 configuration(s)
INFO  [18:28:13.706] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:28:14.231] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -672.806
[1] -10.27158
[1] -1046.392
[1] -15.73171
[1] -390.6663
[1] 492.9935
[1] -70.39755
[1] 293.3536
[1] 1377.087
[1] 52102.61
INFO  [18:28:35.663] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -515.0207
[1] -7.377855
[1] 66.22647
[1] 2417.689
[1] -182.3846
[1] 772.1001
[1] -2.328223
[1] 516.8272
[1] 16.4406
[1] 663.181
INFO  [18:29:03.467] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 14.47743
[1] 626.8143
[1] 16.70515
[1] 723.0149
[1] 8.736351
[1] 418.1536
[1] -220.1895
[1] 292.6235
[1] -748.276
[1] -12.34281
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:29:35.946] [mlr3] Finished benchmark
INFO  [18:29:36.134] [bbotk] Result of batch 31:
INFO  [18:29:36.210] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:29:36.210] [bbotk]               1.883887                         0.1737557
INFO  [18:29:36.210] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:29:36.210] [bbotk]                         0.4211937           -3.502256               2.383218
INFO  [18:29:36.210] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:29:36.210] [bbotk]                          4                    2765                 0.1151818
INFO  [18:29:36.210] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:29:36.210] [bbotk]  0.04107349 <list[8]>              FALSE     0.07895193        0      0
INFO  [18:29:36.210] [bbotk]  runtime_learners                                uhash
INFO  [18:29:36.210] [bbotk]            80.477 6d2a65f1-3e76-4a1b-9f6d-e4c5b24d77ba
INFO  [18:29:37.796] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 62 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:29:42.400] [bbotk] Evaluating 1 configuration(s)
INFO  [18:29:42.433] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:29:42.513] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -75.7232
[1] 14.21876
[1] -939.15
[1] 17.21642
[1] -66.7056
[1] 17.83625
[1] -531.1564
[1] -3.886285
[1] -38.81195
[1] 10.8748
INFO  [18:30:05.670] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -134.3478
[1] 19.74142
[1] -20.36132
[1] 58.90304
[1] -72.27506
[1] 4.910531
[1] -58.55425
[1] 58.1479
[1] 73.87359
[1] 1266.709
INFO  [18:30:46.660] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -30.3455
[1] 83.77207
[1] -65.35045
[1] 16.34871
[1] 57.91134
[1] 1536.112
[1] -93.60708
[1] 21.56631
[1] -30.40811
[1] 43.66801
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:31:17.902] [mlr3] Finished benchmark
INFO  [18:31:18.073] [bbotk] Result of batch 32:
INFO  [18:31:18.103] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:31:18.103] [bbotk]              -3.297295                            0.9885
INFO  [18:31:18.103] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:31:18.103] [bbotk]                         0.3460039           -2.570908              -3.581543
INFO  [18:31:18.103] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:31:18.103] [bbotk]                          6                    1945                 0.6534643
INFO  [18:31:18.103] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:31:18.103] [bbotk]  0.04208527 <list[8]>              FALSE     0.02213218        0      0
INFO  [18:31:18.103] [bbotk]  runtime_learners                                uhash
INFO  [18:31:18.103] [bbotk]            93.864 06722fea-bd44-4a28-ac99-5bbadf8f0d20
INFO  [18:31:19.627] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 63 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:31:25.899] [bbotk] Evaluating 1 configuration(s)
INFO  [18:31:26.022] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:31:26.155] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -177.1988
[1] 4.440185
[1] -1954.472
[1] -64.78867
[1] -31.13407
[1] 64.22235
[1] -39.95518
[1] 11.83938
[1] -40.35841
[1] 22.18915
INFO  [18:32:08.733] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 191.4678
[1] 6947.728
[1] -30.32259
[1] 57.90956
[1] 106.4843
[1] 2814.44
[1] -74.08658
[1] 7.974498
[1] -177.3453
[1] 27.8806
INFO  [18:32:52.422] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -136.5679
[1] 21.96739
[1] -27.2283
[1] 62.99425
[1] -18.96657
[1] 125.5793
[1] -32.69605
[1] 94.66985
[1] -20.24385
[1] 91.89794
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:33:47.280] [mlr3] Finished benchmark
INFO  [18:33:47.396] [bbotk] Result of batch 33:
INFO  [18:33:47.429] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:33:47.429] [bbotk]            -0.01140242                         0.8118053
INFO  [18:33:47.429] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:33:47.429] [bbotk]                         0.6112667           -3.368201               -5.23028
INFO  [18:33:47.429] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:33:47.429] [bbotk]                          1                    4226                 0.6473503
INFO  [18:33:47.429] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:33:47.429] [bbotk]  0.04018028 <list[8]>              FALSE     0.02117828        0      0
INFO  [18:33:47.429] [bbotk]  runtime_learners                                uhash
INFO  [18:33:47.429] [bbotk]           140.322 8db362d0-0692-412d-8941-49d6fd29ec29
INFO  [18:33:48.644] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 64 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:33:54.000] [bbotk] Evaluating 1 configuration(s)
INFO  [18:33:54.154] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:33:54.356] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -21.1622
[1] 41.60915
[1] -1720.361
[1] -31.36225
[1] -24.18936
[1] 34.79328
[1] -35.32652
[1] 148.183
[1] -187.12
[1] -3.095115
INFO  [18:34:11.816] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 149.436
[1] 3609.95
[1] -84.87258
[1] -3.945519
[1] -12.40227
[1] 199.3526
[1] -629.0386
[1] 9.243489
[1] -34.59892
[1] 14.42311
INFO  [18:34:28.667] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -105.9261
[1] 67.81344
[1] -45.80014
[1] 33.33091
[1] -37.55807
[1] 24.89977
[1] -23.43111
[1] 27.54079
[1] -23.77967
[1] 97.68858
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:34:54.196] [mlr3] Finished benchmark
INFO  [18:34:54.743] [bbotk] Result of batch 34:
INFO  [18:34:55.093] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:34:55.093] [bbotk]             -0.4912658                         0.6199233
INFO  [18:34:55.093] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:34:55.093] [bbotk]                         0.4732021           -1.804977              -3.434949
INFO  [18:34:55.093] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:34:55.093] [bbotk]                         16                    1088                 0.6070234
INFO  [18:34:55.093] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:34:55.093] [bbotk]  0.03835691 <list[8]>              FALSE     0.02302336        0      0
INFO  [18:34:55.093] [bbotk]  runtime_learners                                uhash
INFO  [18:34:55.093] [bbotk]            57.923 76170bad-486c-4bd2-885a-6139372aeeb4
INFO  [18:34:57.219] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 65 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:35:03.661] [bbotk] Evaluating 1 configuration(s)
INFO  [18:35:03.803] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:35:03.981] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -45.06832
[1] 58.86044
[1] 37.19084
[1] 947.8936
[1] -106.4499
[1] 1.295963
[1] -89.529
[1] 14.80106
[1] -132.81
[1] 195.7246
INFO  [18:35:32.631] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -155.6617
[1] 57.97157
[1] -32.75365
[1] 162.7023
[1] -101.7597
[1] 2.465848
[1] -111.9715
[1] -3.967955
[1] 11.55771
[1] 278.8099
INFO  [18:36:07.119] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -63.92261
[1] 78.404
[1] -77.01181
[1] 54.99817
[1] -214.0007
[1] 44.76395
[1] -40.26699
[1] 98.55019
[1] -69.21381
[1] 17.7795
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:36:43.299] [mlr3] Finished benchmark
INFO  [18:36:43.863] [bbotk] Result of batch 35:
INFO  [18:36:43.978] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:36:43.978] [bbotk]               1.162454                         0.8730976
INFO  [18:36:43.978] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:36:43.978] [bbotk]                         0.9299521           -4.660901              -2.948373
INFO  [18:36:43.978] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:36:43.978] [bbotk]                          8                    2660                 0.3966765
INFO  [18:36:43.978] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:36:43.978] [bbotk]  0.1094153 <list[8]>              FALSE     0.03643848        0      0
INFO  [18:36:43.978] [bbotk]  runtime_learners                                uhash
INFO  [18:36:43.978] [bbotk]            98.993 297b6b2f-6686-4def-8db5-842c862d2f43
INFO  [18:36:45.528] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 66 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:36:53.167] [bbotk] Evaluating 1 configuration(s)
INFO  [18:36:53.203] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:36:53.228] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -257.6046
[1] -4.636971
[1] -64.326
[1] 685.8712
[1] -127.5363
[1] 204.5797
[1] -99.97903
[1] 59.7351
[1] -269.0071
[1] -5.168838
INFO  [18:37:32.185] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -634.9857
[1] -5.17666
[1] -232.3914
[1] -4.141721
[1] 5.679574
[1] 225.5334
[1] -16921.01
[1] -336.4197
[1] -124.9513
[1] 44.3273
INFO  [18:37:52.526] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -85.8935
[1] 138.4668
[1] -148.0407
[1] 33.9873
[1] -9.174608
[1] 427.4762
[1] -209.0291
[1] 24.94994
[1] -146.6354
[1] 133.8404
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:38:27.605] [mlr3] Finished benchmark
INFO  [18:38:27.738] [bbotk] Result of batch 36:
INFO  [18:38:27.777] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:38:27.777] [bbotk]               2.816135                         0.6561495
INFO  [18:38:27.777] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:38:27.777] [bbotk]                          0.672561           -1.234152               -3.26749
INFO  [18:38:27.777] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:38:27.777] [bbotk]                          9                    2927                 0.6773977
INFO  [18:38:27.777] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:38:27.777] [bbotk]  0.05836345 <list[8]>              FALSE     0.04166898        0      0
INFO  [18:38:27.777] [bbotk]  runtime_learners                                uhash
INFO  [18:38:27.777] [bbotk]            93.995 d8acd4a4-dba8-4590-a18b-5c8c8b5a58db
INFO  [18:38:29.259] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 67 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:38:34.896] [bbotk] Evaluating 1 configuration(s)
INFO  [18:38:35.291] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:38:35.483] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -103.8279
[1] 1.984051
[1] -155.9384
[1] 8.876462
[1] -13.51488
[1] 43.72676
[1] -52.49556
[1] 18.52544
[1] -42.08463
[1] 3.816755
INFO  [18:38:51.332] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -25.99786
[1] 27.23008
[1] -24.3466
[1] 20.55511
[1] -135.2577
[1] 21.23969
[1] -60.49218
[1] 32.5875
[1] -87.11495
[1] -1.729868
INFO  [18:39:06.799] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 31.78129
[1] 914.1018
[1] -70.25531
[1] 8.736878
[1] -16.44509
[1] 36.17767
[1] -29.81166
[1] 33.31403
[1] -59.83941
[1] 15.64112
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:39:21.699] [mlr3] Finished benchmark
INFO  [18:39:22.038] [bbotk] Result of batch 37:
INFO  [18:39:22.089] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:39:22.089] [bbotk]             -0.9989282                         0.4821394
INFO  [18:39:22.089] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:39:22.089] [bbotk]                         0.3217329          -0.5446956              -5.185895
INFO  [18:39:22.089] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:39:22.089] [bbotk]                          3                     228                 0.4365153
INFO  [18:39:22.089] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:39:22.089] [bbotk]  0.03904505 <list[8]>              FALSE     0.03098221        0      0
INFO  [18:39:22.089] [bbotk]  runtime_learners                                uhash
INFO  [18:39:22.089] [bbotk]            45.175 afaeead3-a2cb-4104-a735-5430936e1a3e
INFO  [18:39:23.893] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 68 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:39:28.812] [bbotk] Evaluating 1 configuration(s)
INFO  [18:39:28.859] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:39:28.887] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 104.0741
[1] 4125.22
[1] -4553.395
[1] -112.7461
[1] -37.36454
[1] 86.07785
[1] -98.74137
[1] -3.692214
[1] -50.38249
[1] 48.86118
INFO  [18:40:17.968] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -3.351129e+16
[1] 4.167919e+16
[1] -249.9518
[1] 21.07313
[1] -66.14278
[1] 50.22452
[1] 21.49297
[1] 882.4639
[1] -48.12986
[1] 56.83054
INFO  [18:40:59.116] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -62.49979
[1] 176.1503
[1] -29.55726
[1] 73.31984
[1] -31.38376
[1] 114.8674
[1] -131.5028
[1] 22.63879
[1] -92.04933
[1] 79.76777
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:41:47.887] [mlr3] Finished benchmark
INFO  [18:41:48.662] [bbotk] Result of batch 38:
INFO  [18:41:48.820] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:41:48.820] [bbotk]              0.5257904                         0.8198831
INFO  [18:41:48.820] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:41:48.820] [bbotk]                         0.4612445           -6.467791             -0.7909807
INFO  [18:41:48.820] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:41:48.820] [bbotk]                          1                    3487                 0.7780326
INFO  [18:41:48.820] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:41:48.820] [bbotk]  0.07274378 <list[8]>              FALSE     0.03875411        0      0
INFO  [18:41:48.820] [bbotk]  runtime_learners                                uhash
INFO  [18:41:48.820] [bbotk]           138.359 b57f7d08-8514-4f89-a9fd-144c4d779c7d
WARN  [18:41:51.416] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:41:51.439] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 69 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:41:59.821] [bbotk] Evaluating 1 configuration(s)
INFO  [18:42:00.157] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:42:00.573] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -290.426
[1] -5.030855
[1] -325.9842
[1] -6.717852
[1] -299.0397
[1] -5.649537
[1] 6.878493
[1] 283.8664
[1] -266.3402
[1] -5.271125
INFO  [18:43:14.990] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -353.6392
[1] 47.45413
[1] -66.66788
[1] 209.5541
[1] -261.4408
[1] -5.390469
[1] 15.90931
[1] 509.8962
[1] 6.255091
[1] 201.0448
INFO  [18:44:04.868] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -221.1146
[1] -4.127396
[1] 6.770579
[1] 255.3921
[1] 6.308532
[1] 280.1998
[1] -158.0451
[1] 89.43494
[1] -1.067367
[1] 345.398
INFO  [18:44:50.625] [mlr3] Finished benchmark
INFO  [18:44:50.741] [bbotk] Result of batch 39:
INFO  [18:44:50.764] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:44:50.764] [bbotk]               2.856601                         0.9096374
INFO  [18:44:50.764] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:44:50.764] [bbotk]                         0.9740362          -0.2493772              -4.851528
INFO  [18:44:50.764] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:44:50.764] [bbotk]                         12                    4406                 0.4176021
INFO  [18:44:50.764] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:44:50.764] [bbotk]  0.04050771 <list[8]>              FALSE     0.04771499        0      0
INFO  [18:44:50.764] [bbotk]  runtime_learners                                uhash
INFO  [18:44:50.764] [bbotk]           169.753 7145fc8f-7d2c-4631-8445-a7df14133185
INFO  [18:44:52.252] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 70 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:44:57.685] [bbotk] Evaluating 1 configuration(s)
INFO  [18:44:58.002] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:44:58.183] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 2.146677
[1] 226.1917
[1] -176.1898
[1] 312.9677
[1] -252.6936
[1] -4.684396
[1] -128.984
[1] 169.0232
[1] -325.4257
[1] -5.274052
INFO  [18:45:29.656] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -58.0742
[1] 170.1227
[1] -179.1896
[1] 73.93749
[1] -85.74848
[1] 85.90183
[1] -94.78468
[1] 177.901
[1] -576.1677
[1] -6.576057
INFO  [18:45:52.399] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -120.4813
[1] 126.5964
[1] -150.1208
[1] 109.9119
[1] -31.68251
[1] 162.0839
[1] -98.02182
[1] 166.8003
[1] -471.1372
[1] -5.804212
INFO  [18:46:18.286] [mlr3] Finished benchmark
INFO  [18:46:18.477] [bbotk] Result of batch 40:
INFO  [18:46:18.524] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:46:18.524] [bbotk]               2.216062                         0.7794358
INFO  [18:46:18.524] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:46:18.524] [bbotk]                         0.4096728           -5.447687               2.541274
INFO  [18:46:18.524] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:46:18.524] [bbotk]                          1                    2154                 0.4190514
INFO  [18:46:18.524] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:46:18.524] [bbotk]  0.04250767 <list[8]>              FALSE      0.0621049        0      0
INFO  [18:46:18.524] [bbotk]  runtime_learners                                uhash
INFO  [18:46:18.524] [bbotk]            79.764 ca4a2903-6ff0-4c61-89d3-0292dc3df931
INFO  [18:46:21.009] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 71 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:46:29.444] [bbotk] Evaluating 1 configuration(s)
INFO  [18:46:29.694] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:46:30.078] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -428.5243
[1] -7.357055
[1] -554.2154
[1] -10.47631
[1] 1079.812
[1] 43161.07
[1] -549.0506
[1] -8.364646
[1] 10.62473
[1] 444.2886
INFO  [18:47:09.977] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -45.42681
[1] 278.8482
[1] 14.31848
[1] 583.1397
[1] -164.5265
[1] 455.4945
[1] -352.5386
[1] 134.8759
[1] -200.0098
[1] 353.3267
INFO  [18:48:03.468] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -264.8828
[1] 338.5174
[1] 8.455825
[1] 350.768
[1] 11.23211
[1] 415.7404
[1] 13.24342
[1] 540.8029
[1] -88.01969
[1] 268.2481
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:48:41.360] [mlr3] Finished benchmark
INFO  [18:48:41.544] [bbotk] Result of batch 41:
INFO  [18:48:41.569] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:48:41.569] [bbotk]               2.430834                         0.9547503
INFO  [18:48:41.569] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:48:41.569] [bbotk]                          0.979488           -2.700674              -3.017385
INFO  [18:48:41.569] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:48:41.569] [bbotk]                          2                    3535                 0.1849918
INFO  [18:48:41.569] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:48:41.569] [bbotk]  0.04861476 <list[8]>              FALSE     0.06107734        0      0
INFO  [18:48:41.569] [bbotk]  runtime_learners                                uhash
INFO  [18:48:41.569] [bbotk]           130.741 a0f0f366-46da-47e8-8f08-57c766f11d91
INFO  [18:48:42.941] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 72 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:48:52.386] [bbotk] Evaluating 1 configuration(s)
INFO  [18:48:52.694] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:48:52.726] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -260.6746
[1] -3.893581
[1] -940.7784
[1] -28.97167
[1] -670.4378
[1] -29.06705
[1] -30.20091
[1] 36.84967
[1] -43.99459
[1] 102.3017
INFO  [18:49:12.361] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -26485.87
[1] -634.8526
[1] -26.33101
[1] 58.6907
[1] -229.5713
[1] -3.767439
[1] -78.31875
[1] 38.19376
[1] -48.86103
[1] 20.56535
INFO  [18:49:28.759] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -49.71238
[1] 48.40852
[1] 83.58139
[1] 3007.85
[1] -29.20764
[1] 26.64374
[1] -16.03702
[1] 38.37549
[1] -30.44307
[1] 124.8545
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:49:50.633] [mlr3] Finished benchmark
INFO  [18:49:51.397] [bbotk] Result of batch 42:
INFO  [18:49:51.426] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:49:51.426] [bbotk]              -1.517463                         0.9434079
INFO  [18:49:51.426] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:49:51.426] [bbotk]                         0.3281214           -1.758704              -5.107547
INFO  [18:49:51.426] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:49:51.426] [bbotk]                          3                     732                 0.2122902
INFO  [18:49:51.426] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:49:51.426] [bbotk]  0.03857535 <list[8]>              FALSE     0.02258823        0      0
INFO  [18:49:51.426] [bbotk]  runtime_learners                                uhash
INFO  [18:49:51.426] [bbotk]            57.526 f606df4b-78a4-49a1-af59-053c3505ff69
INFO  [18:49:53.061] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 73 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:50:06.134] [bbotk] Evaluating 1 configuration(s)
INFO  [18:50:06.291] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:50:06.605] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -188.6443
[1] -4.043709
[1] -38.17474
[1] 42.98025
[1] -157.708
[1] -4.245385
[1] -870.8654
[1] 78.8864
[1] -1742.773
[1] -117.1965
INFO  [18:51:08.957] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -32.46109
[1] 30.44445
[1] -63.78623
[1] 51.16382
[1] -271.7849
[1] -4.09435
[1] -33.21068
[1] 67.12288
[1] -55.66753
[1] 113.838
INFO  [18:52:07.521] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -82.27746
[1] 16.87326
[1] -28.39658
[1] 77.71901
[1] -33.78342
[1] 99.79337
[1] -454.149
[1] 18.43825
[1] -64.47164
[1] 107.5669
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:53:04.427] [mlr3] Finished benchmark
INFO  [18:53:04.712] [bbotk] Result of batch 43:
INFO  [18:53:04.729] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:53:04.729] [bbotk]              0.4294983                         0.6148501
INFO  [18:53:04.729] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:53:04.729] [bbotk]                         0.7274667           -2.589099               4.574806
INFO  [18:53:04.729] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:53:04.729] [bbotk]                         15                    4873                 0.8732111
INFO  [18:53:04.729] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:53:04.729] [bbotk]  0.04441499 <list[8]>              FALSE      0.0288841        0      0
INFO  [18:53:04.729] [bbotk]  runtime_learners                                uhash
INFO  [18:53:04.729] [bbotk]           177.444 91de2ab8-056b-42a2-ae6e-3098bee72775
INFO  [18:53:07.175] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 74 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:53:15.370] [bbotk] Evaluating 1 configuration(s)
INFO  [18:53:15.450] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:53:15.504] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -99.20455
[1] 61.32304
[1] -92.61886
[1] -3.449401
[1] -141.3419
[1] -4.324676
[1] -46.42218
[1] 98.2485
[1] -74.56528
[1] 79.62538
INFO  [18:53:50.655] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -125.8032
[1] 36.54681
[1] -191.3876
[1] 7.260743
[1] -63.48076
[1] 76.55781
[1] -87.78945
[1] 21.44723
[1] -165.4393
[1] 161.0327
INFO  [18:54:17.184] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -20.97584
[1] 66.46098
[1] -1699.458
[1] -93.40523
[1] -205.2365
[1] 37.52946
[1] -8.436564
[1] 127.8402
[1] -221.6913
[1] -4.10428
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:54:53.813] [mlr3] Finished benchmark
INFO  [18:54:54.583] [bbotk] Result of batch 44:
INFO  [18:54:54.630] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:54:54.630] [bbotk]               1.681776                         0.3772903
INFO  [18:54:54.630] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:54:54.630] [bbotk]                         0.7430532           -1.677841               2.523525
INFO  [18:54:54.630] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:54:54.630] [bbotk]                         16                    1709                 0.9209452
INFO  [18:54:54.630] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:54:54.630] [bbotk]  0.0520672 <list[8]>              FALSE     0.03720405        0      0
INFO  [18:54:54.630] [bbotk]  runtime_learners                                uhash
INFO  [18:54:54.630] [bbotk]            98.074 aa3faf41-ee72-46a8-b8d4-c2f8369c2b14
INFO  [18:55:06.609] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 75 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:55:15.024] [bbotk] Evaluating 1 configuration(s)
INFO  [18:55:15.116] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:55:15.177] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -218.9845
[1] -4.1217
[1] -35.77646
[1] 101.1791
[1] -101.3627
[1] 55.35256
[1] -57.13724
[1] 57.76522
[1] -72.27707
[1] 41.0534
INFO  [18:57:36.876] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -29.91595
[1] 145.9973
[1] -135.2846
[1] -3.723152
[1] -46.21858
[1] 95.4255
[1] 2.774343
[1] 102.4332
[1] -44.77804
[1] 132.7743
INFO  [18:59:51.059] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -81.91086
[1] 127.2199
[1] -11.40994
[1] 78.16624
[1] -171.7171
[1] -4.177159
[1] -112.6367
[1] 45.65071
[1] -99.46967
[1] 58.59325
INFO  [19:01:47.758] [mlr3] Finished benchmark
INFO  [19:01:48.257] [bbotk] Result of batch 45:
INFO  [19:01:48.304] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:01:48.304] [bbotk]              -0.272299                         0.9273088
INFO  [19:01:48.304] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:01:48.304] [bbotk]                         0.8401943           -7.544932             -0.3118346
INFO  [19:01:48.304] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:01:48.304] [bbotk]                         13                    4406                 0.8822348
INFO  [19:01:48.304] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:01:48.304] [bbotk]  0.04202161 <list[8]>              FALSE     0.04109655        0      0
INFO  [19:01:48.304] [bbotk]  runtime_learners                                uhash
INFO  [19:01:48.304] [bbotk]           392.199 4f74b4a6-70bb-44d7-9dfa-a28b16db625a
INFO  [19:01:53.427] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 76 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:02:06.435] [bbotk] Evaluating 1 configuration(s)
INFO  [19:02:06.677] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:02:06.851] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -31.17652
[1] 13.21092
[1] -1552.335
[1] -100.8139
[1] -823.3473
[1] -28.72469
[1] -76.1844
[1] 190.1277
[1] -133.9317
[1] 40.28809
INFO  [19:02:57.517] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -103.5212
[1] -1.006839
[1] -40.76833
[1] 118.4359
[1] -20.33364
[1] 54.04942
[1] -70.29947
[1] 46.6963
[1] -134.8466
[1] 6.707089
INFO  [19:03:37.230] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -11.27653
[1] 89.76671
[1] -85.59091
[1] 25.48712
[1] -107.9753
[1] 34.29916
[1] -67.0954
[1] 21.16287
[1] -94.87972
[1] 34.41771
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:04:21.020] [mlr3] Finished benchmark
INFO  [19:04:21.446] [bbotk] Result of batch 46:
INFO  [19:04:21.457] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:04:21.457] [bbotk]              -6.003708                         0.6661091
INFO  [19:04:21.457] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:04:21.457] [bbotk]                         0.7612733           -2.201016                 -2.272
INFO  [19:04:21.457] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:04:21.457] [bbotk]                          4                    2079                 0.2935958
INFO  [19:04:21.457] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:04:21.457] [bbotk]  0.03455577 <list[8]>              FALSE     0.02155814        0      0
INFO  [19:04:21.457] [bbotk]  runtime_learners                                uhash
INFO  [19:04:21.457] [bbotk]           133.706 a96223ab-9e2c-498f-bf9d-1c825a106f2c
INFO  [19:04:25.661] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 77 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:04:38.921] [bbotk] Evaluating 1 configuration(s)
INFO  [19:04:39.323] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:04:39.663] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -427.5896
[1] -5.929138
[1] -81.61041
[1] 174.6848
[1] -131.1454
[1] 93.47815
[1] -10728.96
[1] -213.2894
[1] -143.7191
[1] 15.88316
INFO  [19:05:22.049] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -71.7449
[1] 423.3717
[1] -309.2833
[1] 119.5644
[1] -134.4551
[1] 126.7195
[1] -214.3121
[1] 35.76251
[1] -212.4702
[1] 31.92539
INFO  [19:06:06.834] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -125.9644
[1] 83.76222
[1] -374.1519
[1] -5.597157
[1] -76.26927
[1] 341.3963
[1] -129.2455
[1] 104.426
[1] -129.5078
[1] 101.0994
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:07:05.837] [mlr3] Finished benchmark
INFO  [19:07:06.898] [bbotk] Result of batch 47:
INFO  [19:07:07.000] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:07:07.000] [bbotk]               2.402542                         0.3951211
INFO  [19:07:07.000] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:07:07.000] [bbotk]                         0.9381992           -4.014748              -3.992807
INFO  [19:07:07.000] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:07:07.000] [bbotk]                          6                    1919                 0.3911775
INFO  [19:07:07.000] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:07:07.000] [bbotk]  0.06399541 <list[8]>              FALSE     0.04439797        0      0
INFO  [19:07:07.000] [bbotk]  runtime_learners                                uhash
INFO  [19:07:07.000] [bbotk]           145.789 1c60dba3-7d29-4080-8620-283155570421
INFO  [19:07:12.092] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 78 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:07:24.107] [bbotk] Evaluating 1 configuration(s)
INFO  [19:07:24.306] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:07:24.514] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -105.1597
[1] 43.90236
[1] 3.474921
[1] 205.711
[1] 520.5034
[1] 13892.41
[1] -107.9871
[1] -2.248528
[1] -75.72272
[1] 55.65683
INFO  [19:08:16.810] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -52.79933
[1] 60.47999
[1] -144.2492
[1] 25.95955
[1] -77.02971
[1] 40.68071
[1] -44.15158
[1] 77.7719
[1] -104.6359
[1] 92.74598
INFO  [19:09:21.614] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -117.6967
[1] 17.13456
[1] -71.96983
[1] 58.81531
[1] -31.97073
[1] 147.2741
[1] -42.21997
[1] 64.42433
[1] -3.103459
[1] 86.51439
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:10:14.450] [mlr3] Finished benchmark
INFO  [19:10:14.545] [bbotk] Result of batch 48:
INFO  [19:10:14.570] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:10:14.570] [bbotk]               2.326653                         0.8907153
INFO  [19:10:14.570] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:10:14.570] [bbotk]                         0.8410099          -0.2273448              0.8002817
INFO  [19:10:14.570] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:10:14.570] [bbotk]                         12                    3561                 0.9275681
INFO  [19:10:14.570] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:10:14.570] [bbotk]  0.06243955 <list[8]>              FALSE     0.04069444        0      0
INFO  [19:10:14.570] [bbotk]  runtime_learners                                uhash
INFO  [19:10:14.570] [bbotk]           169.284 71206444-9de0-4723-b4d4-75c9c6832305
INFO  [19:10:17.331] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 79 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:10:28.069] [bbotk] Evaluating 1 configuration(s)
INFO  [19:10:28.094] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:10:28.125] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -58.41149
[1] 295.4076
[1] -208355.6
[1] -4091.599
[1] -326.3909
[1] -6.615087
[1] -377.2374
[1] -6.673616
[1] 185.6365
[1] 7913.976
INFO  [19:11:16.226] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -50.61828
[1] 253.2555
[1] -243.9056
[1] 176.2958
[1] -319.8928
[1] 93.32179
[1] -599.5091
[1] -9.473448
[1] 8.184052
[1] 428.4834
INFO  [19:12:08.113] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -179.5974
[1] 198.9821
[1] -34970.13
[1] -559.0682
[1] -139.7644
[1] 299.6819
[1] -142.9877
[1] 249.912
[1] -107.0185
[1] 246.3276
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:13:00.006] [mlr3] Finished benchmark
INFO  [19:13:00.081] [bbotk] Result of batch 49:
INFO  [19:13:00.108] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:13:00.108] [bbotk]              -4.852102                         0.6868787
INFO  [19:13:00.108] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:13:00.108] [bbotk]                         0.1108817           -7.846791              -0.685324
INFO  [19:13:00.108] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:13:00.108] [bbotk]                         15                    2111                 0.9633848
INFO  [19:13:00.108] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:13:00.108] [bbotk]  0.03879385 <list[8]>              FALSE      0.0385898        0      0
INFO  [19:13:00.108] [bbotk]  runtime_learners                                uhash
INFO  [19:13:00.108] [bbotk]           151.339 3ae6664c-4e8b-404a-9480-3f4276b7f3ef
INFO  [19:13:02.882] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 80 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:13:10.573] [bbotk] Evaluating 1 configuration(s)
INFO  [19:13:10.644] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:13:10.714] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -68.62754
[1] 11.45685
[1] -14.70948
[1] 222.5031
[1] 73.01592
[1] 2989.036
[1] -114.8474
[1] 45.70959
[1] -199.6252
[1] 35.73676
INFO  [19:13:33.771] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -154.4521
[1] 41.34896
[1] -44.23053
[1] 48.18356
[1] -78.12835
[1] 54.49103
[1] -5.569446
[1] 248.7062
[1] -89.47676
[1] 88.99798
INFO  [19:14:02.343] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -85.31589
[1] 31.27461
[1] -72.01964
[1] 98.40333
[1] -5078.2
[1] -77.91325
[1] -22662.36
[1] -490.0451
[1] -50.67484
[1] 58.44629
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:14:33.833] [mlr3] Finished benchmark
INFO  [19:14:34.421] [bbotk] Result of batch 50:
INFO  [19:14:34.468] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:14:34.468] [bbotk]              0.5915607                         0.5484141
INFO  [19:14:34.468] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:14:34.468] [bbotk]                         0.5087185           -4.327009              -2.001966
INFO  [19:14:34.468] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:14:34.468] [bbotk]                         14                     526                 0.2663912
INFO  [19:14:34.468] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:14:34.468] [bbotk]  0.04242258 <list[8]>              FALSE     0.03698457        0      0
INFO  [19:14:34.468] [bbotk]  runtime_learners                                uhash
INFO  [19:14:34.468] [bbotk]            82.398 cb7d22e5-2fec-4344-9a7d-d39a8c9c46a9
WARN  [19:14:38.756] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:14:38.763] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 81 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:14:47.453] [bbotk] Evaluating 1 configuration(s)
INFO  [19:14:47.566] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:14:47.623] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -56.10914
[1] 26.1452
[1] -126.3333
[1] 3.149693
[1] 159.5111
[1] 5149.534
[1] -22.70241
[1] 226.9319
[1] -37.44456
[1] 95.26879
INFO  [19:16:04.658] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -12713.29
[1] -242.4829
[1] -33.4619
[1] 76.24835
[1] -7840.824
[1] -119.4883
[1] -112.1481
[1] 12.1392
[1] -29.34833
[1] 107.936
INFO  [19:17:39.553] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2.981147e+16
[1] 1.541938e+16
[1] -40.57269
[1] 197.8109
[1] -25.60514
[1] 48.80602
[1] -110.9208
[1] 20.01178
[1] -49.84584
[1] 96.66
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:18:59.124] [mlr3] Finished benchmark
INFO  [19:18:59.935] [bbotk] Result of batch 51:
INFO  [19:19:00.110] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:19:00.110] [bbotk]              -3.148165                         0.9851507
INFO  [19:19:00.110] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:19:00.110] [bbotk]                         0.7159776           -5.076137              -5.546833
INFO  [19:19:00.110] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:19:00.110] [bbotk]                          2                    4060                 0.1371741
INFO  [19:19:00.110] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:19:00.110] [bbotk]  0.03764459 <list[8]>              FALSE     0.02975605        0      0
INFO  [19:19:00.110] [bbotk]  runtime_learners                                uhash
INFO  [19:19:00.110] [bbotk]           251.206 c8b8654c-851f-47bc-9253-f4927870284f
INFO  [19:19:16.397] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 82 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:19:27.835] [bbotk] Evaluating 1 configuration(s)
INFO  [19:19:28.218] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:19:28.338] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -21.65144
[1] 18.00774
[1] -714.389
[1] -27.70826
[1] -62.49257
[1] 46.89268
[1] -110.2185
[1] 3.220056
[1] -34.26414
[1] 45.75875
INFO  [19:20:11.455] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -6768.869
[1] -323.9442
[1] 609.7702
[1] 16198.09
[1] -60.03769
[1] 8.44657
[1] -5072.848
[1] -172.5729
[1] -137.4493
[1] 69.00607
INFO  [19:21:02.066] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -137.363
[1] 2.062238
[1] -40.62042
[1] 191.2904
[1] -1250.124
[1] -29.05693
[1] -54.50942
[1] 19.64065
[1] -57.39016
[1] 30.38834
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:21:39.540] [mlr3] Finished benchmark
INFO  [19:21:40.359] [bbotk] Result of batch 52:
INFO  [19:21:40.407] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:21:40.407] [bbotk]               -4.92455                         0.8579467
INFO  [19:21:40.407] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:21:40.407] [bbotk]                         0.6110457           -2.230111               2.637004
INFO  [19:21:40.407] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:21:40.407] [bbotk]                         18                    1138                  0.708902
INFO  [19:21:40.407] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:21:40.407] [bbotk]  0.03197618 <list[8]>              FALSE     0.02212119        0      0
INFO  [19:21:40.407] [bbotk]  runtime_learners                                uhash
INFO  [19:21:40.407] [bbotk]           130.701 e7b8f684-3d34-47a1-b5a0-cd7356dedfbc
INFO  [19:21:41.171] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 83 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:22:06.917] [bbotk] Evaluating 1 configuration(s)
INFO  [19:22:07.392] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:22:07.465] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -482.7504
[1] -6.855054
[1] 12.5754
[1] 445.3745
[1] -336.2366
[1] -6.755617
[1] -553.6221
[1] -10.72678
[1] -104.0615
[1] 281.1112
INFO  [19:23:10.334] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -549.5407
[1] -8.112994
[1] -160.1565
[1] 112.094
[1] -461.0207
[1] -6.804387
[1] 12.62305
[1] 454.9232
[1] -445.7698
[1] 210.4532
INFO  [19:24:17.113] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -318.8304
[1] 36.61023
[1] -35.52212
[1] 402.5284
[1] -196.5586
[1] 204.4227
[1] -202.7331
[1] 191.1988
[1] -243.1227
[1] 219.0496
INFO  [19:25:15.436] [mlr3] Finished benchmark
INFO  [19:25:15.598] [bbotk] Result of batch 53:
INFO  [19:25:15.655] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:25:15.655] [bbotk]               2.808907                         0.2039621
INFO  [19:25:15.655] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:25:15.655] [bbotk]                         0.7373804            -3.79447               3.284026
INFO  [19:25:15.655] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:25:15.655] [bbotk]                          5                    4243                 0.4151192
INFO  [19:25:15.655] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:25:15.655] [bbotk]  0.05320215 <list[8]>              FALSE     0.04977108        0      0
INFO  [19:25:15.655] [bbotk]  runtime_learners                                uhash
INFO  [19:25:15.655] [bbotk]           187.628 05f73fb2-cf1d-4a8f-bf6c-6183cd343f82
INFO  [19:25:22.105] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 84 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:25:30.500] [bbotk] Evaluating 1 configuration(s)
INFO  [19:25:30.597] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:25:30.643] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -82.83566
[1] 214.5265
[1] -407.6556
[1] -7.001906
[1] -113.5526
[1] 350.5721
[1] -43.39391
[1] 241.4121
[1] -526.3658
[1] -7.712718
INFO  [19:25:51.813] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -47.95663
[1] 264.524
[1] 13.31237
[1] 487.2325
[1] 11.96958
[1] 469.2675
[1] -137.2562
[1] 130.0843
[1] -101.3479
[1] 137.9485
INFO  [19:26:10.949] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -72.33485
[1] 251.8769
[1] -16767.44
[1] -252.6369
[1] 7.33291
[1] 277.8494
[1] -301.3931
[1] -4.722455
[1] -154.1283
[1] 246.494
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:26:32.253] [mlr3] Finished benchmark
INFO  [19:26:32.417] [bbotk] Result of batch 54:
INFO  [19:26:32.428] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:26:32.428] [bbotk]                1.90971                         0.1481474
INFO  [19:26:32.428] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:26:32.428] [bbotk]                         0.4802572           -6.016055             -0.2942866
INFO  [19:26:32.428] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:26:32.428] [bbotk]                          1                     905                 0.4967682
INFO  [19:26:32.428] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:26:32.428] [bbotk]  0.03694029 <list[8]>              FALSE     0.06132166        0      0
INFO  [19:26:32.428] [bbotk]  runtime_learners                                uhash
INFO  [19:26:32.428] [bbotk]            61.275 2e1969f1-e9ed-482b-bca2-ed8f022779d0
INFO  [19:26:38.474] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 85 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:26:49.577] [bbotk] Evaluating 1 configuration(s)
INFO  [19:26:49.676] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:26:49.756] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 3.473694
[1] 723.4552
[1] -402.7432
[1] 12.73742
[1] -1043.811
[1] -28.99907
[1] -116.5568
[1] 1.049245
[1] 821.3347
[1] 15938.65
INFO  [19:27:48.798] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 69.59526
[1] 1839.004
[1] -1653.448
[1] -49.58612
[1] -2803.586
[1] -80.74233
[1] -46.9193
[1] 4.633936
[1] -125.3275
[1] 104.1472
INFO  [19:28:39.773] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -9.387758
[1] 194.8347
[1] -51.47128
[1] 32.81088
[1] -72.61655
[1] 43.93068
[1] -31.74161
[1] 41.99676
[1] -177.6801
[1] -3.751492
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:29:18.769] [mlr3] Finished benchmark
INFO  [19:29:19.184] [bbotk] Result of batch 55:
INFO  [19:29:19.211] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:29:19.211] [bbotk]                -2.2285                         0.9999063
INFO  [19:29:19.211] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:29:19.211] [bbotk]                         0.4210293           -1.866905              -4.324471
INFO  [19:29:19.211] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:29:19.211] [bbotk]                          4                    4468                 0.1773826
INFO  [19:29:19.211] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:29:19.211] [bbotk]  0.03117876 <list[8]>              FALSE     0.02376183        0      0
INFO  [19:29:19.211] [bbotk]  runtime_learners                                uhash
INFO  [19:29:19.211] [bbotk]           148.779 e952386e-624a-4206-9b3f-dbd3da7c401a
WARN  [19:29:21.307] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:29:21.373] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 86 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:29:37.148] [bbotk] Evaluating 1 configuration(s)
INFO  [19:29:37.342] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:29:37.672] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -97.46865
[1] 41.37829
[1] -134.5364
[1] 197.6562
[1] -47.25872
[1] 11.32346
[1] -1401.114
[1] -34.00797
[1] 88.76645
[1] 2895.702
INFO  [19:30:03.472] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -101.5481
[1] 4.259778
[1] -5862.352
[1] -216.1588
[1] -51.4981
[1] 23.58941
[1] -18.97987
[1] 96.54924
[1] -24.77242
[1] 75.34929
INFO  [19:30:37.841] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -211.6162
[1] 21.33246
[1] -83.35822
[1] 485.6153
[1] -40.56481
[1] 26.56164
[1] 315.7976
[1] 9401.478
[1] 66.48373
[1] 1589.447
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:31:32.187] [mlr3] Finished benchmark
INFO  [19:31:32.388] [bbotk] Result of batch 56:
INFO  [19:31:32.431] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:31:32.431] [bbotk]             -0.0902385                          0.869263
INFO  [19:31:32.431] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:31:32.431] [bbotk]                         0.8026212           -1.894781              -3.248589
INFO  [19:31:32.431] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:31:32.431] [bbotk]                          4                    2137                 0.2027687
INFO  [19:31:32.431] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:31:32.431] [bbotk]  0.04457113 <list[8]>              FALSE     0.02337796        0      0
INFO  [19:31:32.431] [bbotk]  runtime_learners                                uhash
INFO  [19:31:32.431] [bbotk]           113.961 c4e5962f-81f4-4f38-937b-b54c27990d0a
INFO  [19:31:39.156] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 87 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:31:52.876] [bbotk] Evaluating 1 configuration(s)
INFO  [19:31:52.975] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:31:53.430] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -3119.508
[1] -74.78688
[1] -75.36834
[1] 28.62583
[1] -345.7958
[1] -3.738518
[1] -77.3835
[1] 93.98078
[1] -51.54911
[1] 33.18915
INFO  [19:32:48.250] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -40.62787
[1] 66.11337
[1] -88.45081
[1] -1.963994
[1] -78.72405
[1] 47.07726
[1] -283.4256
[1] 15.82102
[1] -2.868708e+16
[1] 2.032732e+16
INFO  [19:34:07.408] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -39.687
[1] 64.24079
[1] -108.0851
[1] 3.081853
[1] -71.58791
[1] 22.2465
[1] -83.32086
[1] 58.88141
[1] 342.6143
[1] 12419.63
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:34:57.948] [mlr3] Finished benchmark
INFO  [19:34:58.040] [bbotk] Result of batch 57:
INFO  [19:34:58.061] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:34:58.061] [bbotk]              0.2214002                         0.8744932
INFO  [19:34:58.061] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:34:58.061] [bbotk]                         0.2306391           -4.076444               1.025451
INFO  [19:34:58.061] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:34:58.061] [bbotk]                          6                    4527                 0.5601356
INFO  [19:34:58.061] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:34:58.061] [bbotk]  0.03734561 <list[8]>              FALSE     0.02793248        0      0
INFO  [19:34:58.061] [bbotk]  runtime_learners                                uhash
INFO  [19:34:58.061] [bbotk]           184.161 e730450e-441e-442c-a72f-e094df26f726
INFO  [19:35:04.228] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 88 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:35:15.124] [bbotk] Evaluating 1 configuration(s)
INFO  [19:35:15.528] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:35:15.587] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -61.89721
[1] 82.4407
[1] -269.8656
[1] 9.065591
[1] -36.36948
[1] 41.78611
[1] -82.26161
[1] 1.960011
[1] 29.36153
[1] 838.6449
INFO  [19:36:53.180] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -363.6463
[1] 17.4329
[1] -45.89945
[1] 128.1226
[1] -88.44165
[1] 21.65789
[1] -71.66786
[1] 106.3116
[1] 155.5395
[1] 5186.812
INFO  [19:39:20.788] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -57.64972
[1] 30.69501
[1] -32.95816
[1] 36.65866
[1] -61.43834
[1] 44.18755
[1] -28.56504
[1] 56.02094
[1] -27.8436
[1] 67.38214
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:42:11.953] [mlr3] Finished benchmark
INFO  [19:42:13.533] [bbotk] Result of batch 58:
INFO  [19:42:13.562] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:42:13.562] [bbotk]              -3.930977                         0.7677872
INFO  [19:42:13.562] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:42:13.562] [bbotk]                         0.6486916           -7.124063              -3.903393
INFO  [19:42:13.562] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:42:13.562] [bbotk]                         19                    4869                 0.8022568
INFO  [19:42:13.562] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:42:13.562] [bbotk]  0.03435816 <list[8]>              FALSE     0.03307554        0      0
INFO  [19:42:13.562] [bbotk]  runtime_learners                                uhash
INFO  [19:42:13.562] [bbotk]           415.644 3f626fec-56a7-4b74-b181-ae6412fb69a4
INFO  [19:42:31.470] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 89 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:42:44.111] [bbotk] Evaluating 1 configuration(s)
INFO  [19:42:44.437] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:42:44.477] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -2004.686
[1] -35.18328
[1] 71.41516
[1] 3958.414
[1] -2305.88
[1] 410.7494
[1] 40.64256
[1] 2089.694
[1] -1690.882
[1] -30.21567
INFO  [19:43:22.498] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 40.54279
[1] 2094.408
[1] 37.80261
[1] 1961.74
[1] -2271.069
[1] -39.29076
[1] -1371.226
[1] -24.78961
[1] 36.32199
[1] 1857.379
INFO  [19:44:03.698] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 41.51815
[1] 2155.292
[1] 42.90469
[1] 2201.003
[1] 35.74044
[1] 1856.821
[1] -942.4945
[1] 1798.587
[1] 49.22613
[1] 2639.679
INFO  [19:44:36.078] [mlr3] Finished benchmark
INFO  [19:44:37.140] [bbotk] Result of batch 59:
INFO  [19:44:37.358] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:44:37.358] [bbotk]              0.4459755                         0.2336891
INFO  [19:44:37.358] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:44:37.358] [bbotk]                         0.2215562           -8.782536              -6.820273
INFO  [19:44:37.358] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:44:37.358] [bbotk]                          2                    1454                 0.2631397
INFO  [19:44:37.358] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:44:37.358] [bbotk]  0.03991601 <list[8]>              FALSE     0.06588126        0      0
INFO  [19:44:37.358] [bbotk]  runtime_learners                                uhash
INFO  [19:44:37.358] [bbotk]           111.211 ba541993-665f-44e0-86f8-f15a261850d7
INFO  [19:44:39.011] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 90 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:44:59.682] [bbotk] Evaluating 1 configuration(s)
INFO  [19:45:00.097] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:45:00.633] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -3185.101
[1] -57.61179
[1] 101.718
[1] 5377.852
[1] 87.55412
[1] 4650.809
[1] -3514.881
[1] -64.31149
[1] 72.34755
[1] 3832.171
INFO  [19:46:14.046] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 56.53154
[1] 3031.194
[1] -3630.432
[1] -65.40799
[1] -4197.48
[1] -75.20692
[1] 89.9379
[1] 4648.41
[1] -16369.3
[1] -295.2709
INFO  [19:47:21.623] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -5706.084
[1] -105.2919
[1] 184.4229
[1] 9574.653
[1] 57.7735
[1] 3091.342
[1] -4324.801
[1] -78.909
[1] -3695.409
[1] -67.2902
INFO  [19:48:24.988] [mlr3] Finished benchmark
INFO  [19:48:25.439] [bbotk] Result of batch 60:
INFO  [19:48:25.819] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:48:25.819] [bbotk]              -5.938323                         0.7163138
INFO  [19:48:25.819] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:48:25.819] [bbotk]                         0.6553783           -6.336691                6.89824
INFO  [19:48:25.819] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:48:25.819] [bbotk]                         14                    3249                 0.2610205
INFO  [19:48:25.819] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:48:25.819] [bbotk]  0.02902846 <list[8]>              FALSE      0.2796121        0      0
INFO  [19:48:25.819] [bbotk]  runtime_learners                                uhash
INFO  [19:48:25.819] [bbotk]           203.706 45c2d96c-1409-4653-a4a0-994149b88cc8
INFO  [19:48:27.473] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 91 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:48:38.438] [bbotk] Evaluating 1 configuration(s)
INFO  [19:48:38.854] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:48:39.065] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -279.5471
[1] 2.204662
[1] -3509.023
[1] -93.15448
[1] 655.5613
[1] 18463.15
[1] -49.12907
[1] 9.992266
[1] -21.96634
[1] 139.9971
INFO  [19:49:11.388] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -57.84197
[1] 28.15828
[1] -193.4739
[1] 8.474822
[1] -51.32863
[1] 29.19192
[1] -51.7227
[1] 106.4007
[1] -67.51447
[1] 91.06421
INFO  [19:49:42.054] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -37.45167
[1] 136.1925
[1] -26.138
[1] 67.1322
[1] -48.38836
[1] 62.0857
[1] -15.53792
[1] 86.46039
[1] -242.1774
[1] -3.991157
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:50:17.464] [mlr3] Finished benchmark
INFO  [19:50:17.529] [bbotk] Result of batch 61:
INFO  [19:50:17.537] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:50:17.537] [bbotk]              -5.192465                         0.4127954
INFO  [19:50:17.537] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:50:17.537] [bbotk]                         0.1696491           -3.306711               3.032406
INFO  [19:50:17.537] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:50:17.537] [bbotk]                          1                    1623                  0.961958
INFO  [19:50:17.537] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:50:17.537] [bbotk]  0.04903272 <list[8]>              FALSE     0.03247653        0      0
INFO  [19:50:17.537] [bbotk]  runtime_learners                                uhash
INFO  [19:50:17.537] [bbotk]            97.479 78084728-888f-4d1c-8cca-3e8097ef5612
INFO  [19:50:20.532] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 92 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:50:32.663] [bbotk] Evaluating 1 configuration(s)
INFO  [19:50:33.092] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:50:33.442] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -2442.784
[1] -47.98945
[1] -179.518
[1] 9.267748
[1] -146.282
[1] 0.6120474
[1] -27.17845
[1] 37.54043
[1] -69822.08
[1] -972.4615
INFO  [19:51:41.256] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -480.6223
[1] 156.6032
[1] -91.07325
[1] 6.10852
[1] -45.85691
[1] 64.70687
[1] -30.30152
[1] 19.09617
[1] -58.79087
[1] 56.55686
INFO  [19:52:25.590] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -133.1604
[1] 19.179
[1] -506.5472
[1] -4.040653
[1] -1831.63
[1] -119.3651
[1] -2138.856
[1] -42.07877
[1] 109.5245
[1] 2432.533
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:53:01.653] [mlr3] Finished benchmark
INFO  [19:53:03.276] [bbotk] Result of batch 62:
INFO  [19:53:03.351] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:53:03.351] [bbotk]              -6.576846                         0.3095055
INFO  [19:53:03.351] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:53:03.351] [bbotk]                         0.3120681             -4.3452              -3.054014
INFO  [19:53:03.351] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:53:03.351] [bbotk]                          1                    2444                 0.5515573
INFO  [19:53:03.351] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:53:03.351] [bbotk]  0.03690486 <list[8]>              FALSE     0.02403287        0      0
INFO  [19:53:03.351] [bbotk]  runtime_learners                                uhash
INFO  [19:53:03.351] [bbotk]           147.677 f0669fc7-af6e-4ec7-b580-547785b5dc81
INFO  [19:53:10.175] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 93 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:53:25.181] [bbotk] Evaluating 1 configuration(s)
INFO  [19:53:25.315] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:53:25.358] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -37.33991
[1] 61.02674
[1] -97.02709
[1] 66.1323
[1] -4256.551
[1] -91.57271
[1] -410.1007
[1] -4.435023
[1] -65.04277
[1] 46.47073
INFO  [19:54:40.280] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -9.179815
[1] 131.5643
[1] -111.4919
[1] 57.76405
[1] -12.52037
[1] 138.0352
[1] -213.8972
[1] -3.592223
[1] -135.4543
[1] 80.4739
INFO  [19:55:40.091] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -90.04868
[1] 53.52248
[1] -65.02912
[1] 107.3714
[1] -70.03332
[1] 95.80817
[1] -162.8795
[1] 94.30128
[1] -42.95337
[1] 127.7061
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:56:35.967] [mlr3] Finished benchmark
INFO  [19:56:36.315] [bbotk] Result of batch 63:
INFO  [19:56:36.324] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:56:36.324] [bbotk]              -4.034086                         0.2084717
INFO  [19:56:36.324] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:56:36.324] [bbotk]                         0.1739896           -6.714302              -0.250218
INFO  [19:56:36.324] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:56:36.324] [bbotk]                          3                    3582                 0.6730919
INFO  [19:56:36.324] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:56:36.324] [bbotk]  0.03876534 <list[8]>              FALSE      0.0400857        0      0
INFO  [19:56:36.324] [bbotk]  runtime_learners                                uhash
INFO  [19:56:36.324] [bbotk]           190.311 de1e3be5-17a9-4ac7-b12e-1bb88ae61ac0
WARN  [19:56:45.738] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:56:46.002] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 94 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:57:08.322] [bbotk] Evaluating 1 configuration(s)
INFO  [19:57:08.648] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:57:08.762] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -89.97747
[1] -3.89311
[1] -58.46384
[1] 28.84771
[1] -260.7519
[1] -3.779751
[1] -27.5828
[1] 94.47047
[1] -33.64684
[1] 289.6304
INFO  [19:58:04.417] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -212.3726
[1] 21.42326
[1] -36.97245
[1] 14.36968
[1] -11.25317
[1] 76.93583
[1] -82.72343
[1] 35.46703
[1] -239.2752
[1] -3.984173
INFO  [19:58:58.827] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -46.03643
[1] 41.78731
[1] -103.147
[1] 145.0188
[1] -11.04367
[1] 92.78018
[1] -15.7639
[1] 557.3143
[1] -167.8688
[1] 32.60365
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:59:33.302] [mlr3] Finished benchmark
INFO  [19:59:33.378] [bbotk] Result of batch 64:
INFO  [19:59:33.389] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:59:33.389] [bbotk]              -2.188096                         0.6526825
INFO  [19:59:33.389] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:59:33.389] [bbotk]                          0.117839           -1.871907              0.1474493
INFO  [19:59:33.389] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:59:33.389] [bbotk]                         18                    2098                  0.743025
INFO  [19:59:33.389] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:59:33.389] [bbotk]  0.03154614 <list[8]>              FALSE     0.02705051        0      0
INFO  [19:59:33.389] [bbotk]  runtime_learners                                uhash
INFO  [19:59:33.389] [bbotk]             143.6 b002520a-6d46-43aa-8a3e-76886b5a07f9
INFO  [19:59:42.824] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 95 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:59:54.469] [bbotk] Evaluating 1 configuration(s)
INFO  [19:59:55.140] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:59:55.351] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -55.69271
[1] 11.16161
[1] -14.28714
[1] 145.1012
[1] -60.39904
[1] 24.716
[1] -18.51878
[1] 110.4319
[1] -196.1677
[1] 4.937892
INFO  [20:00:40.222] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -38.38909
[1] 30.57266
[1] -68.1574
[1] 17.00726
[1] -3619.895
[1] -44.51267
[1] -61.17802
[1] 2.677052
[1] 19.21287
[1] 776.1556
INFO  [20:01:22.207] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -158.0744
[1] 14.88233
[1] -18.69621
[1] 38.54806
[1] -51.47414
[1] 10.59545
[1] -5.472153
[1] 49.43969
[1] -86.93699
[1] 31.66262
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:02:12.495] [mlr3] Finished benchmark
INFO  [20:02:13.227] [bbotk] Result of batch 65:
INFO  [20:02:13.237] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:02:13.237] [bbotk]              -4.974549                         0.3780433
INFO  [20:02:13.237] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:02:13.237] [bbotk]                         0.2302021          -0.8236421             -0.4451548
INFO  [20:02:13.237] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:02:13.237] [bbotk]                         18                    1385                 0.3190342
INFO  [20:02:13.237] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:02:13.237] [bbotk]  0.03861239 <list[8]>              FALSE     0.02575732        0      0
INFO  [20:02:13.237] [bbotk]  runtime_learners                                uhash
INFO  [20:02:13.237] [bbotk]           136.581 f340e279-03a1-4962-abea-214d1ea58b5e
INFO  [20:02:26.835] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 96 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:02:45.935] [bbotk] Evaluating 1 configuration(s)
INFO  [20:02:45.977] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:02:46.096] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -72.95821
[1] 37.55174
[1] -53.524
[1] 47.43089
[1] -286.3091
[1] -3.928386
[1] -32.2288
[1] 32.10422
[1] -128.3661
[1] -3.792822
INFO  [20:03:54.625] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -44.21076
[1] 36.60362
[1] -67.72083
[1] 8.480116
[1] -297.5546
[1] 2.486513
[1] -79.70375
[1] 42.8174
[1] -25.56487
[1] 41.69647
INFO  [20:05:47.057] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -29.61393
[1] 18.69247
[1] -19.78921
[1] 58.75618
[1] 58.63961
[1] 911.4935
[1] -22.17128
[1] 24.25253
[1] -64.35051
[1] 44.60567
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:07:29.986] [mlr3] Finished benchmark
INFO  [20:07:30.086] [bbotk] Result of batch 66:
INFO  [20:07:30.127] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:07:30.127] [bbotk]              -5.403388                         0.3872901
INFO  [20:07:30.127] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:07:30.127] [bbotk]                         0.6482141           -1.703445              -4.347287
INFO  [20:07:30.127] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:07:30.127] [bbotk]                         13                    4104                 0.7751903
INFO  [20:07:30.127] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:07:30.127] [bbotk]  0.04075483 <list[8]>              FALSE     0.02360049        0      0
INFO  [20:07:30.127] [bbotk]  runtime_learners                                uhash
INFO  [20:07:30.127] [bbotk]           283.137 a40ad3fa-48d7-48e1-aebb-d8a394bd624e
WARN  [20:07:47.605] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [20:07:47.686] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 97 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:07:58.185] [bbotk] Evaluating 1 configuration(s)
INFO  [20:07:58.281] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:07:58.354] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -136.3473
[1] 2.992593
[1] -44.86293
[1] 125.0627
[1] -51.60227
[1] 39.97764
[1] -48.46665
[1] 58.13315
[1] -70.76774
[1] -3.16155
INFO  [20:09:15.768] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -30.79959
[1] 72.2504
[1] -6149.442
[1] -107.6884
[1] -60.62346
[1] 10.4962
[1] -168.8305
[1] -3.119034
[1] -15.37637
[1] 59.64849
INFO  [20:10:20.601] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -54.48037
[1] 17.96017
[1] -40.44607
[1] 81.91198
[1] -27.94889
[1] 53.50891
[1] -36.79989
[1] 69.53549
[1] -175.949
[1] 68.31429
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:11:28.349] [mlr3] Finished benchmark
INFO  [20:11:28.608] [bbotk] Result of batch 67:
INFO  [20:11:28.637] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:11:28.637] [bbotk]               1.246127                         0.8607638
INFO  [20:11:28.637] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:11:28.637] [bbotk]                         0.9259115          -0.3424051              -3.142216
INFO  [20:11:28.637] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:11:28.637] [bbotk]                         14                    1313                 0.8178625
INFO  [20:11:28.637] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:11:28.637] [bbotk]  0.04473477 <list[8]>              FALSE     0.03147405        0      0
INFO  [20:11:28.637] [bbotk]  runtime_learners                                uhash
INFO  [20:11:28.637] [bbotk]           209.645 616a94ce-9c9f-4fe2-b375-0f14e26963e8
INFO  [20:11:34.178] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 98 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:11:41.819] [bbotk] Evaluating 1 configuration(s)
INFO  [20:11:41.977] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:11:42.102] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -348.5236
[1] 1.440063
[1] -75.3873
[1] 101.87
[1] -142.9944
[1] 32.97693
[1] -88.18249
[1] 62.7642
[1] -177.5937
[1] 235.4142
INFO  [20:13:33.420] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -129.1234
[1] 76.83439
[1] -154.1547
[1] 5.710103
[1] -169.4596
[1] -1.3233
[1] 104.2816
[1] 2996.939
[1] -87.13574
[1] 155.3668
INFO  [20:15:02.876] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -70.70623
[1] 93.94578
[1] -57.14742
[1] 143.5773
[1] -70.59934
[1] 78.0641
[1] -218.5338
[1] 23.59749
[1] -94.49062
[1] 63.55454
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:16:52.247] [mlr3] Finished benchmark
INFO  [20:16:52.562] [bbotk] Result of batch 68:
INFO  [20:16:52.585] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:16:52.585] [bbotk]               2.411549                          0.369136
INFO  [20:16:52.585] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:16:52.585] [bbotk]                         0.3963212           -3.645648               5.157921
INFO  [20:16:52.585] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:16:52.585] [bbotk]                          8                    4997                 0.8974911
INFO  [20:16:52.585] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:16:52.585] [bbotk]  0.0305482 <list[8]>              FALSE     0.04502804        0      0
INFO  [20:16:52.585] [bbotk]  runtime_learners                                uhash
INFO  [20:16:52.585] [bbotk]           309.926 07002dfe-afdb-4f32-b348-d4e5ddc8035b
INFO  [20:16:56.494] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 99 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:17:07.038] [bbotk] Evaluating 1 configuration(s)
INFO  [20:17:07.631] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:17:07.938] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -681.6604
[1] -30.51772
[1] -36.96321
[1] 6.097666
[1] -94.9595
[1] -3.694348
[1] -272.7648
[1] -2.663676
[1] 208.8223
[1] 2515.493
INFO  [20:17:30.965] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -34.82636
[1] 61.11704
[1] -37.63045
[1] 174.8162
[1] 56.70297
[1] 1171.616
[1] -79.86044
[1] 9.424945
[1] -73.34821
[1] 17.6696
INFO  [20:18:10.445] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -79.21425
[1] 1.818565
[1] -235.8448
[1] 9.854135
[1] -139.4269
[1] 81.2173
[1] -18.57927
[1] 129.1519
[1] -2.254377e+16
[1] 1.167099e+16
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:18:57.254] [mlr3] Finished benchmark
INFO  [20:18:57.362] [bbotk] Result of batch 69:
INFO  [20:18:57.371] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:18:57.371] [bbotk]              -6.611073                         0.4632607
INFO  [20:18:57.371] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:18:57.371] [bbotk]                         0.7096583           -2.115313               1.329182
INFO  [20:18:57.371] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:18:57.371] [bbotk]                          9                     760                 0.8736041
INFO  [20:18:57.371] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:18:57.371] [bbotk]  0.02788471 <list[8]>              FALSE     0.02479265        0      0
INFO  [20:18:57.371] [bbotk]  runtime_learners                                uhash
INFO  [20:18:57.371] [bbotk]           109.164 3734c787-ba64-4db5-a196-900b7ff2bacd
INFO  [20:19:00.564] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 100 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:19:00.817] [bbotk] Finished optimizing after 100 evaluation(s)
INFO  [20:19:00.853] [bbotk] Result:
INFO  [20:19:00.859] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:19:00.859] [bbotk]                  <num>                             <num>
INFO  [20:19:00.859] [bbotk]              -1.055098                         0.9218567
INFO  [20:19:00.859] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:19:00.859] [bbotk]                             <num>               <num>                  <num>
INFO  [20:19:00.859] [bbotk]                         0.8063447           -2.204168              -4.502497
INFO  [20:19:00.859] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:19:00.859] [bbotk]                      <int>                   <int>                     <num>
INFO  [20:19:00.859] [bbotk]                          9                    1280                 0.6942655
INFO  [20:19:00.859] [bbotk]  learner_param_vals  x_domain classif.bbrier
INFO  [20:19:00.859] [bbotk]              <list>    <list>          <num>
INFO  [20:19:00.859] [bbotk]          <list[10]> <list[8]>     0.01821137
[1] -33.14345
[1] 28.79587
[1] -30.65028
[1] 83.32975
[1] -24.06429
[1] 28.9033
[1] -46.41089
[1] 35.05191
[1] -108.0305
[1] -4.450899

### [bt]: Job terminated successfully [batchtools job.id=1418]
### [bt]: Calculation finished!
