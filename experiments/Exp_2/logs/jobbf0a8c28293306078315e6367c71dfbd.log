### [bt]: This is batchtools v0.9.17
### [bt]: Starting calculation of 1 jobs
### [bt]: Setting working directory to '/content/drive/MyDrive/GitHub/Mater_Thesis_Calibration'
ece.R :
Friedmann_tasks.R :
Functions.R :
ici.R :
mse_feature_effects.R :
PipeOpCalibration_TuningExperiment.R :
PipeOpCalibration.R :
PipeOpCalibrationUnion.R :
### [bt]: Memory measurement disabled
### [bt]: Starting job [batchtools job.id=1434]
### [bt]: Generating problem instance for problem '341ee781c7d79b8f' ...
### [bt]: Applying algorithm 'run_learner' on problem '341ee781c7d79b8f' for job 1434 (seed = 1557) ...
INFO  [16:13:38.388] [mlr3] Applying learner 'xgboost TwP platt' on task 'wdbc' (iter 4/10)
INFO  [16:13:39.766] [bbotk] Starting to optimize 8 parameter(s) with '<OptimizerMbo>' and '<TerminatorEvals> [n_evals=100, k=0]'
INFO  [16:13:44.253] [bbotk] Evaluating 32 configuration(s)
INFO  [16:13:44.541] [mlr3] Running benchmark with 96 resampling iterations
INFO  [16:13:44.865] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:14:50.733] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:15:21.893] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:16:49.367] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:17:49.312] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:18:34.383] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:19:25.193] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:20:42.232] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:22:10.978] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:23:17.832] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:23:36.922] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:24:06.625] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:24:33.932] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:25:14.254] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:26:15.523] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:27:07.769] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:28:43.146] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:30:05.188] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:31:24.873] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:33:25.860] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:34:17.991] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:35:41.052] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:36:31.897] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:37:08.881] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:37:48.003] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:38:53.195] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:39:55.087] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:40:37.686] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:41:55.395] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:43:29.937] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:44:22.836] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:44:47.744] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:45:19.660] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:45:46.821] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:46:54.027] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:47:59.270] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:49:07.922] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:50:47.596] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:52:43.641] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:54:07.300] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:54:36.654] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:55:06.345] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:55:33.172] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:56:32.672] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:57:25.627] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:58:20.406] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:58:44.438] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:59:06.818] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:59:30.265] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:00:45.130] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:01:55.249] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:02:53.877] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:03:50.357] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:05:02.365] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:06:14.241] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:07:02.039] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:08:09.778] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:09:07.881] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:09:41.698] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:10:25.028] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:11:08.659] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:11:38.508] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:12:12.422] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:12:39.300] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:13:50.251] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:14:39.156] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:15:31.448] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:15:55.769] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:16:30.906] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:17:06.158] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:18:27.188] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:19:21.927] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:20:19.727] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:21:07.004] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:21:53.559] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:22:36.825] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:23:12.611] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:23:36.452] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:24:17.871] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:24:42.338] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:25:02.178] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:25:20.963] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:26:00.104] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:26:31.341] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:27:08.183] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:27:49.062] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:28:37.455] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:29:16.236] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:29:46.955] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:30:19.046] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:30:43.393] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:31:32.228] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:32:19.885] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:33:18.647] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:33:51.752] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:34:25.079] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:35:15.196] [mlr3] Finished benchmark
INFO  [17:35:17.956] [bbotk] Result of batch 1:
INFO  [17:35:18.271] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:35:18.271] [bbotk]             -1.8834444                         0.8865912
INFO  [17:35:18.271] [bbotk]              5.0243105                         0.4365912
INFO  [17:35:18.271] [bbotk]              1.5704328                         0.6615912
INFO  [17:35:18.271] [bbotk]             -5.3373220                         0.2115912
INFO  [17:35:18.271] [bbotk]              3.2973717                         0.3240912
INFO  [17:35:18.271] [bbotk]             -3.6103832                         0.7740912
INFO  [17:35:18.271] [bbotk]              6.7512493                         0.9990912
INFO  [17:35:18.271] [bbotk]             -0.1565056                         0.5490912
INFO  [17:35:18.271] [bbotk]             -4.4738526                         0.3803412
INFO  [17:35:18.271] [bbotk]              2.4339023                         0.8303412
INFO  [17:35:18.271] [bbotk]              5.8877799                         0.1553412
INFO  [17:35:18.271] [bbotk]             -1.0199750                         0.6053412
INFO  [17:35:18.271] [bbotk]             -6.2007915                         0.9428412
INFO  [17:35:18.271] [bbotk]              0.7069634                         0.4928412
INFO  [17:35:18.271] [bbotk]              4.1608411                         0.7178412
INFO  [17:35:18.271] [bbotk]             -2.7469138                         0.2678412
INFO  [17:35:18.271] [bbotk]             -3.1786485                         0.6897162
INFO  [17:35:18.271] [bbotk]              3.7291064                         0.2397162
INFO  [17:35:18.271] [bbotk]             -6.6325262                         0.4647162
INFO  [17:35:18.271] [bbotk]              0.2752287                         0.9147162
INFO  [17:35:18.271] [bbotk]             -4.9055873                         0.8022162
INFO  [17:35:18.271] [bbotk]              2.0021676                         0.3522162
INFO  [17:35:18.271] [bbotk]              5.4560452                         0.5772162
INFO  [17:35:18.271] [bbotk]             -1.4517097                         0.1272162
INFO  [17:35:18.271] [bbotk]              1.1386981                         0.1834662
INFO  [17:35:18.271] [bbotk]             -5.7690567                         0.6334662
INFO  [17:35:18.271] [bbotk]              4.5925758                         0.8584662
INFO  [17:35:18.271] [bbotk]             -2.3151791                         0.4084662
INFO  [17:35:18.271] [bbotk]              6.3195146                         0.5209662
INFO  [17:35:18.271] [bbotk]             -0.5882403                         0.9709662
INFO  [17:35:18.271] [bbotk]             -4.0421179                         0.2959662
INFO  [17:35:18.271] [bbotk]              2.8656370                         0.7459662
INFO  [17:35:18.271] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:35:18.271] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:35:18.271] [bbotk]                         0.8333785          -1.0597893             -2.4457878
INFO  [17:35:18.271] [bbotk]                         0.3833785          -5.6649595              4.4619679
INFO  [17:35:18.271] [bbotk]                         0.6083785          -3.3623744              1.0080903
INFO  [17:35:18.271] [bbotk]                         0.1583785          -7.9675445             -5.8996653
INFO  [17:35:18.271] [bbotk]                         0.9458785          -4.5136669              2.7350291
INFO  [17:35:18.271] [bbotk]                         0.4958785          -9.1188371             -4.1727264
INFO  [17:35:18.271] [bbotk]                         0.2708785          -6.8162520              6.1889067
INFO  [17:35:18.271] [bbotk]                         0.7208785          -2.2110818             -0.7188490
INFO  [17:35:18.271] [bbotk]                         0.8896285          -6.2406057              0.1446208
INFO  [17:35:18.271] [bbotk]                         0.4396285          -1.6354355             -6.7631347
INFO  [17:35:18.271] [bbotk]                         0.6646285          -8.5431907             -3.3092572
INFO  [17:35:18.271] [bbotk]                         0.2146285          -3.9380206              3.5984985
INFO  [17:35:18.271] [bbotk]                         0.5521285          -5.0893132              1.8715597
INFO  [17:35:18.271] [bbotk]                         0.1021285          -0.4841430             -5.0361958
INFO  [17:35:18.271] [bbotk]                         0.7771285          -7.3918983             -1.5823184
INFO  [17:35:18.271] [bbotk]                         0.3271285          -2.7867281              5.3254373
INFO  [17:35:18.271] [bbotk]                         0.6927535          -6.5284289             -5.4679306
INFO  [17:35:18.271] [bbotk]                         0.2427535          -1.9232587              1.4398250
INFO  [17:35:18.271] [bbotk]                         0.4677535          -4.2258438             -2.0140531
INFO  [17:35:18.271] [bbotk]                         0.9177535          -8.8310139              4.8937026
INFO  [17:35:18.271] [bbotk]                         0.1302535          -3.0745512             -0.2871143
INFO  [17:35:18.271] [bbotk]                         0.5802535          -7.6797214              6.6206414
INFO  [17:35:18.271] [bbotk]                         0.3552535          -0.7719661              3.1667638
INFO  [17:35:18.271] [bbotk]                         0.8052535          -5.3771363             -3.7409917
INFO  [17:35:18.271] [bbotk]                         0.5240035          -5.9527826             -1.1505837
INFO  [17:35:18.271] [bbotk]                         0.9740035          -1.3476124              5.7571720
INFO  [17:35:18.271] [bbotk]                         0.7490035          -3.6501975             -4.6044611
INFO  [17:35:18.271] [bbotk]                         0.2990035          -8.2553676              2.3032944
INFO  [17:35:18.271] [bbotk]                         0.8615035          -2.4989049             -6.3314000
INFO  [17:35:18.271] [bbotk]                         0.4115035          -7.1040751              0.5763556
INFO  [17:35:18.271] [bbotk]                         0.6365035          -0.1963199              4.0302332
INFO  [17:35:18.271] [bbotk]                         0.1865035          -4.8014900             -2.8775225
INFO  [17:35:18.271] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:35:18.271] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:35:18.271] [bbotk]                          2                    4117                  0.691459
INFO  [17:35:18.271] [bbotk]                         12                    1617                  0.241459
INFO  [17:35:18.271] [bbotk]                         17                    2867                  0.466459
INFO  [17:35:18.271] [bbotk]                          7                     367                  0.916459
INFO  [17:35:18.271] [bbotk]                         14                     992                  0.803959
INFO  [17:35:18.271] [bbotk]                          4                    3492                  0.353959
INFO  [17:35:18.271] [bbotk]                         19                    4742                  0.578959
INFO  [17:35:18.271] [bbotk]                          9                    2242                  0.128959
INFO  [17:35:18.271] [bbotk]                          3                    1929                  0.185209
INFO  [17:35:18.271] [bbotk]                         13                    4429                  0.635209
INFO  [17:35:18.271] [bbotk]                         18                     679                  0.860209
INFO  [17:35:18.271] [bbotk]                          8                    3179                  0.410209
INFO  [17:35:18.271] [bbotk]                         10                    3804                  0.747709
INFO  [17:35:18.271] [bbotk]                         20                    1304                  0.297709
INFO  [17:35:18.271] [bbotk]                         15                    2554                  0.522709
INFO  [17:35:18.271] [bbotk]                          5                      54                  0.972709
INFO  [17:35:18.271] [bbotk]                         20                    1773                  0.494584
INFO  [17:35:18.271] [bbotk]                         10                    4273                  0.944584
INFO  [17:35:18.271] [bbotk]                         15                    3023                  0.269584
INFO  [17:35:18.271] [bbotk]                          5                     523                  0.719584
INFO  [17:35:18.271] [bbotk]                         17                    1148                  0.607084
INFO  [17:35:18.271] [bbotk]                          7                    3648                  0.157084
INFO  [17:35:18.271] [bbotk]                          2                    2398                  0.382084
INFO  [17:35:18.271] [bbotk]                         12                    4898                  0.832084
INFO  [17:35:18.271] [bbotk]                          1                    3960                  0.888334
INFO  [17:35:18.271] [bbotk]                         11                    1460                  0.438334
INFO  [17:35:18.271] [bbotk]                          6                     210                  0.663334
INFO  [17:35:18.271] [bbotk]                         16                    2710                  0.213334
INFO  [17:35:18.271] [bbotk]                          4                    3335                  0.100834
INFO  [17:35:18.271] [bbotk]                         14                     835                  0.550834
INFO  [17:35:18.271] [bbotk]                         19                    4585                  0.775834
INFO  [17:35:18.271] [bbotk]                          9                    2085                  0.325834
INFO  [17:35:18.271] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:35:18.271] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:35:18.271] [bbotk]      0.02947216        0      0          183.743
INFO  [17:35:18.271] [bbotk]      0.28430803        0      0          153.704
INFO  [17:35:18.271] [bbotk]      0.04355178        0      0          230.831
INFO  [17:35:18.271] [bbotk]      0.25368671        0      0           75.574
INFO  [17:35:18.271] [bbotk]      0.15976382        0      0          153.434
INFO  [17:35:18.271] [bbotk]      0.20004392        0      0          256.735
INFO  [17:35:18.271] [bbotk]      0.28430803        0      0          254.512
INFO  [17:35:18.271] [bbotk]      0.03480805        0      0          126.655
INFO  [17:35:18.271] [bbotk]      0.04895890        0      0          169.175
INFO  [17:35:18.271] [bbotk]      0.06937060        0      0          224.491
INFO  [17:35:18.271] [bbotk]      0.28430803        0      0           83.499
INFO  [17:35:18.271] [bbotk]      0.03795137        0      0          200.599
INFO  [17:35:18.271] [bbotk]      0.03072483        0      0          299.067
INFO  [17:35:18.271] [bbotk]      0.03416425        0      0           85.501
INFO  [17:35:18.271] [bbotk]      0.28430803        0      0          166.199
INFO  [17:35:18.271] [bbotk]      0.20405517        0      0           68.810
INFO  [17:35:18.271] [bbotk]      0.04481239        0      0          203.029
INFO  [17:35:18.271] [bbotk]      0.20504454        0      0          198.988
INFO  [17:35:18.271] [bbotk]      0.03011068        0      0          172.651
INFO  [17:35:18.271] [bbotk]      0.28044693        0      0          119.753
INFO  [17:35:18.271] [bbotk]      0.02901946        0      0           89.880
INFO  [17:35:18.271] [bbotk]      0.28306630        0      0          171.812
INFO  [17:35:18.271] [bbotk]      0.28430803        0      0           94.164
INFO  [17:35:18.271] [bbotk]      0.03013579        0      0          193.118
INFO  [17:35:18.271] [bbotk]      0.04754739        0      0          136.738
INFO  [17:35:18.271] [bbotk]      0.03465225        0      0          100.482
INFO  [17:35:18.271] [bbotk]      0.28430803        0      0           62.028
INFO  [17:35:18.271] [bbotk]      0.22362959        0      0          107.000
INFO  [17:35:18.271] [bbotk]      0.28430803        0      0          127.713
INFO  [17:35:18.271] [bbotk]      0.17201662        0      0           86.686
INFO  [17:35:18.271] [bbotk]      0.03112981        0      0          154.722
INFO  [17:35:18.271] [bbotk]      0.21208242        0      0          103.951
INFO  [17:35:18.271] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:35:18.271] [bbotk]                                 uhash
INFO  [17:35:18.271] [bbotk]  93110609-5f48-4f48-acef-167f35668d4f
INFO  [17:35:18.271] [bbotk]  18496ced-33d8-4a26-aeb0-aa1fb99764ee
INFO  [17:35:18.271] [bbotk]  8c988ee0-a892-47fd-8439-7627ba59e4a0
INFO  [17:35:18.271] [bbotk]  12ac27b3-ccd6-4fc2-82fd-9f3acd5d10de
INFO  [17:35:18.271] [bbotk]  e04d2e00-bca7-43cf-971f-e402e307f0e8
INFO  [17:35:18.271] [bbotk]  e85e7b86-a991-4a9a-858b-c5055252b494
INFO  [17:35:18.271] [bbotk]  97e50b68-760c-4f30-89ff-b4bff1bf5aa5
INFO  [17:35:18.271] [bbotk]  97dd3719-e841-4e68-94cf-076f45ea92ab
INFO  [17:35:18.271] [bbotk]  80ebe406-adb8-43d9-a078-30dac0ed4188
INFO  [17:35:18.271] [bbotk]  cf96a2d6-d1aa-43ba-9dbc-c6b4b220ddb8
INFO  [17:35:18.271] [bbotk]  853e091a-dea1-43d8-897b-560ba135300a
INFO  [17:35:18.271] [bbotk]  6b567d42-5009-4732-9839-4cac94910f8b
INFO  [17:35:18.271] [bbotk]  899d8d9a-3806-41fb-9344-c9506afd21a3
INFO  [17:35:18.271] [bbotk]  1dad04b9-dbd2-4ebe-a5a1-61e4a5a6df5d
INFO  [17:35:18.271] [bbotk]  088a85c6-d7a9-4a5c-b12d-e77c5ccac12d
INFO  [17:35:18.271] [bbotk]  8e12f178-7a17-4b2d-a7eb-c29bfaae0600
INFO  [17:35:18.271] [bbotk]  2310edca-b06e-4793-bd5e-9cc4fb486ba6
INFO  [17:35:18.271] [bbotk]  06afc408-92cd-47cc-80c6-959f7e197753
INFO  [17:35:18.271] [bbotk]  c8c95b1d-eea8-485e-aeb4-a5ef66cb9c9f
INFO  [17:35:18.271] [bbotk]  69916ce2-2882-4edb-ba73-dbe9b360236f
INFO  [17:35:18.271] [bbotk]  ab8c00c7-fa5d-4a23-a09b-0d508d63b97e
INFO  [17:35:18.271] [bbotk]  c6a5799a-2f5f-434b-a131-a2148440c4c2
INFO  [17:35:18.271] [bbotk]  86b9dfb3-1ac6-4330-bc71-8e93b9014d89
INFO  [17:35:18.271] [bbotk]  e2565781-03d3-45b4-bf7d-c18e950a0a9b
INFO  [17:35:18.271] [bbotk]  404fc843-656d-43cc-844c-93eb102a55de
INFO  [17:35:18.271] [bbotk]  5fd9ef1d-23ea-4874-ad95-3104a832bf52
INFO  [17:35:18.271] [bbotk]  a18a282a-bf99-4578-a7fb-9098951f2ad1
INFO  [17:35:18.271] [bbotk]  d043e082-5da1-4311-9b67-53ff0332d88c
INFO  [17:35:18.271] [bbotk]  73002359-321d-4a2b-bb3e-9d9bffd031d6
INFO  [17:35:18.271] [bbotk]  e23df107-b64f-418b-b6a6-4dfdbd63e662
INFO  [17:35:18.271] [bbotk]  d21073ff-135c-49d3-88d0-cf8b57975d55
INFO  [17:35:18.271] [bbotk]  4065d686-52bb-4364-bbba-1fa6b9798ac7
INFO  [17:35:18.271] [bbotk]                                 uhash
INFO  [17:35:29.081] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 32 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:35:34.256] [bbotk] Evaluating 1 configuration(s)
INFO  [17:35:34.384] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:35:34.646] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:36:33.336] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:37:32.487] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:38:17.632] [mlr3] Finished benchmark
INFO  [17:38:17.824] [bbotk] Result of batch 2:
INFO  [17:38:17.854] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:38:17.854] [bbotk]              -2.397648                          0.866317
INFO  [17:38:17.854] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:38:17.854] [bbotk]                         0.5347134           -1.550501              -4.364032
INFO  [17:38:17.854] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:38:17.854] [bbotk]                         17                    4748                 0.5527908
INFO  [17:38:17.854] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:38:17.854] [bbotk]  0.07548852 <list[8]>              FALSE     0.02815273        0      0
INFO  [17:38:17.854] [bbotk]  runtime_learners                                uhash
INFO  [17:38:17.854] [bbotk]             162.5 6c0631e9-1c0b-482f-a0ae-5546074e5604
INFO  [17:38:18.506] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 33 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:38:25.213] [bbotk] Evaluating 1 configuration(s)
INFO  [17:38:25.777] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:38:26.269] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:39:15.247] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:39:56.052] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:40:43.325] [mlr3] Finished benchmark
INFO  [17:40:43.438] [bbotk] Result of batch 3:
INFO  [17:40:43.509] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:40:43.509] [bbotk]               -4.51705                         0.7740592
INFO  [17:40:43.509] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:40:43.509] [bbotk]                         0.9109214           -3.872265               1.298286
INFO  [17:40:43.509] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:40:43.509] [bbotk]                         20                    3750                 0.4011732
INFO  [17:40:43.509] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:40:43.509] [bbotk]  0.0538899 <list[8]>              FALSE     0.03081912        0      0
INFO  [17:40:43.509] [bbotk]  runtime_learners                                uhash
INFO  [17:40:43.509] [bbotk]           136.323 df971aeb-4bda-4b67-a1c9-33e4bb014f9d
INFO  [17:40:44.223] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 34 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:40:51.480] [bbotk] Evaluating 1 configuration(s)
INFO  [17:40:51.600] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:40:51.813] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:41:34.484] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:42:17.255] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:42:42.618] [mlr3] Finished benchmark
INFO  [17:42:42.870] [bbotk] Result of batch 4:
INFO  [17:42:42.915] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:42:42.915] [bbotk]              -2.114551                         0.7191048
INFO  [17:42:42.915] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:42:42.915] [bbotk]                         0.6766021           -3.415628              -4.235195
INFO  [17:42:42.915] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:42:42.915] [bbotk]                         20                    2038                 0.5595853
INFO  [17:42:42.915] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:42:42.915] [bbotk]  0.06344287 <list[8]>              FALSE     0.03072088        0      0
INFO  [17:42:42.915] [bbotk]  runtime_learners                                uhash
INFO  [17:42:42.915] [bbotk]           109.849 da2a0e57-c08f-42c9-9b24-33ebb56f538d
INFO  [17:42:43.667] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 35 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:42:51.514] [bbotk] Evaluating 1 configuration(s)
INFO  [17:42:51.631] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:42:51.826] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:44:00.202] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:44:51.778] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:45:54.003] [mlr3] Finished benchmark
INFO  [17:45:54.459] [bbotk] Result of batch 5:
INFO  [17:45:54.529] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:45:54.529] [bbotk]              0.1730726                         0.5875101
INFO  [17:45:54.529] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:45:54.529] [bbotk]                          0.719194           -2.381966              -6.780743
INFO  [17:45:54.529] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:45:54.529] [bbotk]                          6                    4779                 0.6167107
INFO  [17:45:54.529] [bbotk]    acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:45:54.529] [bbotk]  0.035292 <list[8]>              FALSE     0.03015759        0      0
INFO  [17:45:54.529] [bbotk]  runtime_learners                                uhash
INFO  [17:45:54.529] [bbotk]           180.856 91961662-23fc-4809-8d56-f230865f3ddc
INFO  [17:45:55.095] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 36 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:46:02.610] [bbotk] Evaluating 1 configuration(s)
INFO  [17:46:02.684] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:46:02.982] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:46:24.466] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:46:44.770] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:47:18.470] [mlr3] Finished benchmark
INFO  [17:47:18.581] [bbotk] Result of batch 6:
INFO  [17:47:18.608] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:47:18.608] [bbotk]             0.05791472                          0.966407
INFO  [17:47:18.608] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:47:18.608] [bbotk]                         0.5704681            -1.13259               1.395508
INFO  [17:47:18.608] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:47:18.608] [bbotk]                         19                    2905                  0.351219
INFO  [17:47:18.608] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:47:18.608] [bbotk]  0.0341902 <list[8]>              FALSE     0.03206159        0      0
INFO  [17:47:18.608] [bbotk]  runtime_learners                                uhash
INFO  [17:47:18.608] [bbotk]            74.801 9401f1ac-1f4a-42e3-9954-5967a25eca2b
WARN  [17:47:19.684] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:47:19.716] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 37 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:47:25.939] [bbotk] Evaluating 1 configuration(s)
INFO  [17:47:26.023] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:47:26.111] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:48:03.417] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:48:48.446] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:49:32.952] [mlr3] Finished benchmark
INFO  [17:49:33.109] [bbotk] Result of batch 7:
INFO  [17:49:33.177] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:49:33.177] [bbotk]              -4.519308                         0.8230016
INFO  [17:49:33.177] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:49:33.177] [bbotk]                         0.3226607          -0.7015129              -1.356027
INFO  [17:49:33.177] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:49:33.177] [bbotk]                          4                    4199                  0.465308
INFO  [17:49:33.177] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:49:33.177] [bbotk]  0.02686862 <list[8]>              FALSE     0.02755592        0      0
INFO  [17:49:33.177] [bbotk]  runtime_learners                                uhash
INFO  [17:49:33.177] [bbotk]           126.279 8f6b9e62-4111-49d8-9825-3ef4d07107ac
INFO  [17:49:35.223] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 38 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:49:44.259] [bbotk] Evaluating 1 configuration(s)
INFO  [17:49:44.473] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:49:44.729] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:50:23.740] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:51:05.258] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:51:38.803] [mlr3] Finished benchmark
INFO  [17:51:38.977] [bbotk] Result of batch 8:
INFO  [17:51:39.011] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:51:39.011] [bbotk]              -5.229038                         0.8460228
INFO  [17:51:39.011] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:51:39.011] [bbotk]                         0.6146431           -5.182149              -4.111754
INFO  [17:51:39.011] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:51:39.011] [bbotk]                          9                    1629                 0.4192235
INFO  [17:51:39.011] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:51:39.011] [bbotk]  0.02643942 <list[8]>              FALSE     0.02929393        0      0
INFO  [17:51:39.011] [bbotk]  runtime_learners                                uhash
INFO  [17:51:39.011] [bbotk]           113.106 afb156ea-718b-412d-a8b7-ffbeaebae604
INFO  [17:51:40.842] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 39 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:51:50.178] [bbotk] Evaluating 1 configuration(s)
INFO  [17:51:50.336] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:51:50.408] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:52:23.577] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:52:59.060] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:53:40.111] [mlr3] Finished benchmark
INFO  [17:53:40.376] [bbotk] Result of batch 9:
INFO  [17:53:40.455] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:53:40.455] [bbotk]              -4.691876                         0.7682933
INFO  [17:53:40.455] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:53:40.455] [bbotk]                         0.3638823           -1.599769               1.767737
INFO  [17:53:40.455] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:53:40.455] [bbotk]                         18                    3175                 0.5369884
INFO  [17:53:40.455] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:53:40.455] [bbotk]  0.02470504 <list[8]>              FALSE      0.0292633        0      0
INFO  [17:53:40.455] [bbotk]  runtime_learners                                uhash
INFO  [17:53:40.455] [bbotk]           108.871 ab73216f-6f3f-4175-91c6-efd4ae3de4f3
INFO  [17:53:43.885] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 40 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:53:49.720] [bbotk] Evaluating 1 configuration(s)
INFO  [17:53:49.803] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:53:49.842] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:54:21.653] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:55:23.511] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:55:58.849] [mlr3] Finished benchmark
INFO  [17:55:59.050] [bbotk] Result of batch 10:
INFO  [17:55:59.282] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:55:59.282] [bbotk]              -3.930677                         0.6484684
INFO  [17:55:59.282] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:55:59.282] [bbotk]                         0.7681001           -3.983362               1.303657
INFO  [17:55:59.282] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:55:59.282] [bbotk]                          2                    4906                 0.3096148
INFO  [17:55:59.282] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:55:59.282] [bbotk]  0.05989022 <list[8]>              FALSE     0.03084883        0      0
INFO  [17:55:59.282] [bbotk]  runtime_learners                                uhash
INFO  [17:55:59.282] [bbotk]           127.911 2c37401b-ec36-4844-943e-c498c27da1ee
INFO  [17:56:00.153] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 41 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:56:19.353] [bbotk] Evaluating 1 configuration(s)
INFO  [17:56:19.388] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:56:19.414] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:57:11.835] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:57:45.550] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:58:45.255] [mlr3] Finished benchmark
INFO  [17:58:45.473] [bbotk] Result of batch 11:
INFO  [17:58:45.655] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:58:45.655] [bbotk]              -1.532021                         0.4116938
INFO  [17:58:45.655] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:58:45.655] [bbotk]                         0.8489191         -0.04329645              -4.093106
INFO  [17:58:45.655] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:58:45.655] [bbotk]                         16                    4597                  0.480468
INFO  [17:58:45.655] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:58:45.655] [bbotk]  0.02476505 <list[8]>              FALSE     0.02925231        0      0
INFO  [17:58:45.655] [bbotk]  runtime_learners                                uhash
INFO  [17:58:45.655] [bbotk]           144.819 bd160cd3-d8b8-4d77-b2c2-13de82c89d15
INFO  [17:58:46.421] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 42 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:58:53.551] [bbotk] Evaluating 1 configuration(s)
INFO  [17:58:53.671] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:58:53.727] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:59:50.738] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:00:38.906] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:01:18.841] [mlr3] Finished benchmark
INFO  [18:01:18.971] [bbotk] Result of batch 12:
INFO  [18:01:18.994] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:01:18.994] [bbotk]             -0.8791555                         0.4797018
INFO  [18:01:18.994] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:01:18.994] [bbotk]                         0.6764267           -3.257028                -1.6133
INFO  [18:01:18.994] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:01:18.994] [bbotk]                         16                    4506                 0.3932351
INFO  [18:01:18.994] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:01:18.994] [bbotk]  0.01892737 <list[8]>              FALSE     0.02933446        0      0
INFO  [18:01:18.994] [bbotk]  runtime_learners                                uhash
INFO  [18:01:18.994] [bbotk]           144.529 c99bc526-5cb7-49bb-9ee8-d8e94a0efa4f
INFO  [18:01:20.192] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 43 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:01:25.769] [bbotk] Evaluating 1 configuration(s)
INFO  [18:01:25.860] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:01:25.915] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:02:08.712] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:02:53.127] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:04:03.912] [mlr3] Finished benchmark
INFO  [18:04:04.748] [bbotk] Result of batch 13:
INFO  [18:04:04.860] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:04:04.860] [bbotk]              -3.596296                         0.7746129
INFO  [18:04:04.860] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:04:04.860] [bbotk]                         0.4493904           -5.170139             -0.9881451
INFO  [18:04:04.860] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:04:04.860] [bbotk]                         18                    3205                 0.6720515
INFO  [18:04:04.860] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:04:04.860] [bbotk]  0.01948775 <list[8]>              FALSE      0.0294034        0      0
INFO  [18:04:04.860] [bbotk]  runtime_learners                                uhash
INFO  [18:04:04.860] [bbotk]           157.537 7abd7ce9-5c67-44a0-b2cc-021b6830f1a5
INFO  [18:04:06.410] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 44 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:04:12.860] [bbotk] Evaluating 1 configuration(s)
INFO  [18:04:13.031] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:04:13.087] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:05:17.331] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:05:49.952] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:06:43.526] [mlr3] Finished benchmark
INFO  [18:06:43.644] [bbotk] Result of batch 14:
INFO  [18:06:43.748] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:06:43.748] [bbotk]              -5.747683                         0.4825456
INFO  [18:06:43.748] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:06:43.748] [bbotk]                         0.8751669           -4.331256               5.147827
INFO  [18:06:43.748] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:06:43.748] [bbotk]                          9                    3796                  0.509486
INFO  [18:06:43.748] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:06:43.748] [bbotk]  0.01604131 <list[8]>              FALSE     0.04877928        0      0
INFO  [18:06:43.748] [bbotk]  runtime_learners                                uhash
INFO  [18:06:43.748] [bbotk]           150.132 c0a21a2f-694e-4066-bd34-35be8759fd45
WARN  [18:06:44.956] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:06:45.042] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 45 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:06:51.440] [bbotk] Evaluating 1 configuration(s)
INFO  [18:06:51.528] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:06:51.604] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:07:33.496] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:08:04.790] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:08:34.023] [mlr3] Finished benchmark
INFO  [18:08:34.334] [bbotk] Result of batch 15:
INFO  [18:08:34.457] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:08:34.457] [bbotk]              -5.114418                         0.6479666
INFO  [18:08:34.457] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:08:34.457] [bbotk]                         0.9970016          -0.2258733              -3.398705
INFO  [18:08:34.457] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:08:34.457] [bbotk]                         18                    2134                 0.6071972
INFO  [18:08:34.457] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:08:34.457] [bbotk]  0.01887145 <list[8]>              FALSE     0.03163478        0      0
INFO  [18:08:34.457] [bbotk]  runtime_learners                                uhash
INFO  [18:08:34.457] [bbotk]           101.965 b92fb960-2caa-48c7-8790-3ce6dc208797
INFO  [18:08:35.452] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 46 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:08:41.382] [bbotk] Evaluating 1 configuration(s)
INFO  [18:08:41.577] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:08:41.694] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:09:09.522] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:09:36.787] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:10:04.241] [mlr3] Finished benchmark
INFO  [18:10:04.434] [bbotk] Result of batch 16:
INFO  [18:10:04.482] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:10:04.482] [bbotk]              -5.599008                         0.8860093
INFO  [18:10:04.482] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:10:04.482] [bbotk]                         0.4047336           -4.014184             -0.5712952
INFO  [18:10:04.482] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:10:04.482] [bbotk]                         10                    2661                 0.2367023
INFO  [18:10:04.482] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:10:04.482] [bbotk]  0.01735609 <list[8]>              FALSE     0.03080848        0      0
INFO  [18:10:04.482] [bbotk]  runtime_learners                                uhash
INFO  [18:10:04.482] [bbotk]            81.833 70428ee5-f9b7-4c51-b810-15fc10297072
INFO  [18:10:05.950] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 47 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:10:11.036] [bbotk] Evaluating 1 configuration(s)
INFO  [18:10:11.091] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:10:11.196] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:10:49.663] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:11:46.704] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:13:01.305] [mlr3] Finished benchmark
INFO  [18:13:01.926] [bbotk] Result of batch 17:
INFO  [18:13:02.049] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:13:02.049] [bbotk]              -3.691108                         0.8832431
INFO  [18:13:02.049] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:13:02.049] [bbotk]                         0.8538931           -5.247187              -5.272282
INFO  [18:13:02.049] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:13:02.049] [bbotk]                         15                    3505                 0.4899863
INFO  [18:13:02.049] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:13:02.049] [bbotk]  0.01779726 <list[8]>              FALSE     0.02876626        0      0
INFO  [18:13:02.049] [bbotk]  runtime_learners                                uhash
INFO  [18:13:02.049] [bbotk]           169.615 f242709e-e045-45ad-bcfa-13162fe2f818
INFO  [18:13:04.335] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 48 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:13:09.904] [bbotk] Evaluating 1 configuration(s)
INFO  [18:13:09.966] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:13:10.025] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:13:36.348] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:13:53.685] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:14:16.773] [mlr3] Finished benchmark
INFO  [18:14:16.965] [bbotk] Result of batch 18:
INFO  [18:14:17.008] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:14:17.008] [bbotk]              -6.893837                         0.9885711
INFO  [18:14:17.008] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:14:17.008] [bbotk]                          0.358395           -3.577763              -3.967719
INFO  [18:14:17.008] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:14:17.008] [bbotk]                         20                     261                 0.5759006
INFO  [18:14:17.008] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:14:17.008] [bbotk]  0.01752466 <list[8]>              FALSE     0.03245795        0      0
INFO  [18:14:17.008] [bbotk]  runtime_learners                                uhash
INFO  [18:14:17.008] [bbotk]            66.098 7928457e-78d4-404e-84b5-788fb7e6365e
INFO  [18:14:18.815] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 49 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:14:27.300] [bbotk] Evaluating 1 configuration(s)
INFO  [18:14:27.458] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:14:27.578] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:15:01.296] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:15:42.411] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [18:16:22.610] [mlr3] Finished benchmark
INFO  [18:16:22.724] [bbotk] Result of batch 19:
INFO  [18:16:22.762] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:16:22.762] [bbotk]              0.4086547                         0.4960406
INFO  [18:16:22.762] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:16:22.762] [bbotk]                         0.5302721          -0.7911787              -4.872144
INFO  [18:16:22.762] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:16:22.762] [bbotk]                         19                    3683                 0.5251357
INFO  [18:16:22.762] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:16:22.762] [bbotk]  0.01559246 <list[8]>              FALSE     0.03356861        0      0
INFO  [18:16:22.762] [bbotk]  runtime_learners                                uhash
INFO  [18:16:22.762] [bbotk]           114.546 948ca3a5-7b78-41ec-9f64-dd4aaaf67b9c
INFO  [18:16:24.875] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 50 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:16:29.694] [bbotk] Evaluating 1 configuration(s)
INFO  [18:16:30.431] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:16:30.598] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:16:44.920] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:17:09.108] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:17:35.298] [mlr3] Finished benchmark
INFO  [18:17:35.393] [bbotk] Result of batch 20:
INFO  [18:17:35.420] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:17:35.420] [bbotk]              -4.904369                         0.8265486
INFO  [18:17:35.420] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:17:35.420] [bbotk]                         0.6459947           -4.062094              -3.144334
INFO  [18:17:35.420] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:17:35.420] [bbotk]                         19                    1480                 0.2503621
INFO  [18:17:35.420] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:17:35.420] [bbotk]  0.01987091 <list[8]>              FALSE     0.02921057        0      0
INFO  [18:17:35.420] [bbotk]  runtime_learners                                uhash
INFO  [18:17:35.420] [bbotk]            64.107 5bf92fd5-2bd3-4ce2-93a4-9b76b492be00
INFO  [18:17:36.543] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 51 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:17:43.857] [bbotk] Evaluating 1 configuration(s)
INFO  [18:17:44.077] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:17:44.173] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:18:38.778] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:19:46.580] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:20:42.734] [mlr3] Finished benchmark
INFO  [18:20:43.454] [bbotk] Result of batch 21:
INFO  [18:20:43.792] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:20:43.792] [bbotk]             -0.2573094                         0.6064951
INFO  [18:20:43.792] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:20:43.792] [bbotk]                         0.6391015            -5.43049              -1.825136
INFO  [18:20:43.792] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:20:43.792] [bbotk]                          4                    4925                 0.9195272
INFO  [18:20:43.792] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:20:43.792] [bbotk]  0.01508277 <list[8]>              FALSE     0.03156506        0      0
INFO  [18:20:43.792] [bbotk]  runtime_learners                                uhash
INFO  [18:20:43.792] [bbotk]           176.396 e0817ee4-8e88-46f7-a1b1-9c4c72884e15
WARN  [18:20:58.005] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:20:58.063] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 52 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:21:09.199] [bbotk] Evaluating 1 configuration(s)
INFO  [18:21:09.342] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:21:09.405] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:21:27.223] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:21:47.349] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:22:10.011] [mlr3] Finished benchmark
INFO  [18:22:10.112] [bbotk] Result of batch 22:
INFO  [18:22:10.127] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:22:10.127] [bbotk]              -6.545811                         0.9076634
INFO  [18:22:10.127] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:22:10.127] [bbotk]                         0.1526205           -1.574631               -1.60669
INFO  [18:22:10.127] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:22:10.127] [bbotk]                         13                    1127                   0.42494
INFO  [18:22:10.127] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:22:10.127] [bbotk]  0.01534712 <list[8]>              FALSE     0.02913319        0      0
INFO  [18:22:10.127] [bbotk]  runtime_learners                                uhash
INFO  [18:22:10.127] [bbotk]            60.161 5591e664-f140-4f6c-b88d-40cc6b77686c
INFO  [18:22:11.670] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 53 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:22:20.948] [bbotk] Evaluating 1 configuration(s)
INFO  [18:22:22.262] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:22:22.354] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:22:57.833] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:23:53.218] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:25:13.577] [mlr3] Finished benchmark
INFO  [18:25:13.824] [bbotk] Result of batch 23:
INFO  [18:25:13.865] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:25:13.865] [bbotk]              -4.064922                         0.7908497
INFO  [18:25:13.865] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:25:13.865] [bbotk]                         0.9750123          -0.4595035               4.873343
INFO  [18:25:13.865] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:25:13.865] [bbotk]                          4                    4894                 0.5570342
INFO  [18:25:13.865] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:25:13.865] [bbotk]  0.01406784 <list[8]>              FALSE     0.02904455        0      0
INFO  [18:25:13.865] [bbotk]  runtime_learners                                uhash
INFO  [18:25:13.865] [bbotk]           170.293 9a3ea64c-a1f6-4a91-9632-9a9b3821ffb1
WARN  [18:25:16.492] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:25:16.628] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 54 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:25:22.047] [bbotk] Evaluating 1 configuration(s)
INFO  [18:25:22.222] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:25:22.597] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:25:56.493] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:26:23.397] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:26:50.393] [mlr3] Finished benchmark
INFO  [18:26:50.665] [bbotk] Result of batch 24:
INFO  [18:26:50.714] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:26:50.714] [bbotk]              -3.368036                         0.5794251
INFO  [18:26:50.714] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:26:50.714] [bbotk]                         0.5211708          -0.5460142             -0.0485314
INFO  [18:26:50.714] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:26:50.714] [bbotk]                         14                    2002                 0.3274023
INFO  [18:26:50.714] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:26:50.714] [bbotk]  0.01431501 <list[8]>              FALSE     0.03089871        0      0
INFO  [18:26:50.714] [bbotk]  runtime_learners                                uhash
INFO  [18:26:50.714] [bbotk]            86.912 72040c38-0b2e-4b16-bb47-d105006bf97a
INFO  [18:26:52.227] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 55 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:26:59.113] [bbotk] Evaluating 1 configuration(s)
INFO  [18:26:59.165] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:26:59.334] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:27:59.378] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:28:54.838] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:29:52.723] [mlr3] Finished benchmark
INFO  [18:29:52.863] [bbotk] Result of batch 25:
INFO  [18:29:52.933] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:29:52.933] [bbotk]              -6.456181                         0.7479823
INFO  [18:29:52.933] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:29:52.933] [bbotk]                         0.5119246           -5.298722              -1.514656
INFO  [18:29:52.933] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:29:52.933] [bbotk]                         19                    4874                  0.487717
INFO  [18:29:52.933] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:29:52.933] [bbotk]  0.01254158 <list[8]>              FALSE     0.02982073        0      0
INFO  [18:29:52.933] [bbotk]  runtime_learners                                uhash
INFO  [18:29:52.933] [bbotk]           172.869 4d538cf6-9f9b-4f02-8eab-a29266f96b3e
INFO  [18:29:55.044] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 56 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:30:02.627] [bbotk] Evaluating 1 configuration(s)
INFO  [18:30:02.898] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:30:03.279] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:30:54.668] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:31:33.077] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:32:46.836] [mlr3] Finished benchmark
INFO  [18:32:47.006] [bbotk] Result of batch 26:
INFO  [18:32:47.081] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:32:47.081] [bbotk]              -4.480439                         0.2682699
INFO  [18:32:47.081] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:32:47.081] [bbotk]                         0.8957955          -0.1969971              -2.784866
INFO  [18:32:47.081] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:32:47.081] [bbotk]                         11                    4731                 0.5834217
INFO  [18:32:47.081] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:32:47.081] [bbotk]  0.01302941 <list[8]>              FALSE     0.03082276        0      0
INFO  [18:32:47.081] [bbotk]  runtime_learners                                uhash
INFO  [18:32:47.081] [bbotk]           163.213 c8f1d2db-a13e-4aa8-a3ff-128a62493586
INFO  [18:32:48.456] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 57 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:32:54.201] [bbotk] Evaluating 1 configuration(s)
INFO  [18:32:54.376] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:32:54.467] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:33:29.662] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:34:12.777] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:35:02.876] [mlr3] Finished benchmark
INFO  [18:35:03.097] [bbotk] Result of batch 27:
INFO  [18:35:03.221] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:35:03.221] [bbotk]               -6.15966                           0.90649
INFO  [18:35:03.221] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:35:03.221] [bbotk]                         0.2903428           -3.381417               1.935589
INFO  [18:35:03.221] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:35:03.221] [bbotk]                         17                    3414                 0.5944407
INFO  [18:35:03.221] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:35:03.221] [bbotk]  0.01226728 <list[8]>              FALSE     0.02899614        0      0
INFO  [18:35:03.221] [bbotk]  runtime_learners                                uhash
INFO  [18:35:03.221] [bbotk]           127.713 9af822a0-6193-46a7-9f25-447aabf21b0c
WARN  [18:35:06.877] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:35:06.954] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 58 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:35:14.700] [bbotk] Evaluating 1 configuration(s)
INFO  [18:35:14.907] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:35:15.167] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:36:14.736] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:37:07.030] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:37:53.860] [mlr3] Finished benchmark
INFO  [18:37:54.220] [bbotk] Result of batch 28:
INFO  [18:37:54.287] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:37:54.287] [bbotk]            0.007994642                         0.8763285
INFO  [18:37:54.287] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:37:54.287] [bbotk]                         0.6704608           -2.714786              -2.964629
INFO  [18:37:54.287] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:37:54.287] [bbotk]                         13                    4960                 0.5948234
INFO  [18:37:54.287] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:37:54.287] [bbotk]  0.01527849 <list[8]>              FALSE     0.03137311        0      0
INFO  [18:37:54.287] [bbotk]  runtime_learners                                uhash
INFO  [18:37:54.287] [bbotk]           158.137 9cae7174-13eb-4aaf-8917-e7aa110269a5
INFO  [18:37:56.555] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 59 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:38:03.002] [bbotk] Evaluating 1 configuration(s)
INFO  [18:38:03.033] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:38:03.074] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:38:48.943] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:39:40.182] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:40:34.955] [mlr3] Finished benchmark
INFO  [18:40:35.247] [bbotk] Result of batch 29:
INFO  [18:40:35.384] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:40:35.384] [bbotk]              -3.418175                         0.8283655
INFO  [18:40:35.384] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:40:35.384] [bbotk]                         0.4244851          -0.4918148              -6.278046
INFO  [18:40:35.384] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:40:35.384] [bbotk]                         15                    4876                 0.7074224
INFO  [18:40:35.384] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:40:35.384] [bbotk]  0.01022064 <list[8]>              FALSE     0.03048565        0      0
INFO  [18:40:35.384] [bbotk]  runtime_learners                                uhash
INFO  [18:40:35.384] [bbotk]           151.557 94d8db9d-b8eb-4370-ad43-a007554f2d01
INFO  [18:40:38.085] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 60 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:40:45.940] [bbotk] Evaluating 1 configuration(s)
INFO  [18:40:46.259] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:40:46.466] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:41:10.002] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:41:41.397] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:42:44.545] [mlr3] Finished benchmark
INFO  [18:42:44.993] [bbotk] Result of batch 30:
INFO  [18:42:45.054] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:42:45.054] [bbotk]              -1.610733                         0.7236002
INFO  [18:42:45.054] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:42:45.054] [bbotk]                         0.5441704           -1.385092              -2.486056
INFO  [18:42:45.054] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:42:45.054] [bbotk]                          2                    4919                 0.3761117
INFO  [18:42:45.054] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:42:45.054] [bbotk]  0.01202985 <list[8]>              FALSE     0.02868675        0      0
INFO  [18:42:45.054] [bbotk]  runtime_learners                                uhash
INFO  [18:42:45.054] [bbotk]           117.227 fd16248e-d907-44a7-93d3-71627d789a40
INFO  [18:42:46.827] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 61 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:42:53.479] [bbotk] Evaluating 1 configuration(s)
INFO  [18:42:53.736] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:42:53.943] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:43:29.991] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:44:28.999] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:45:24.551] [mlr3] Finished benchmark
INFO  [18:45:24.671] [bbotk] Result of batch 31:
INFO  [18:45:24.747] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:45:24.747] [bbotk]              -6.682203                         0.6728359
INFO  [18:45:24.747] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:45:24.747] [bbotk]                         0.9233327           -5.447466              -3.562555
INFO  [18:45:24.747] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:45:24.747] [bbotk]                         16                    3145                 0.4512253
INFO  [18:45:24.747] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:45:24.747] [bbotk]  0.01078948 <list[8]>              FALSE     0.02935445        0      0
INFO  [18:45:24.747] [bbotk]  runtime_learners                                uhash
INFO  [18:45:24.747] [bbotk]           149.959 4ed1056b-98a7-44d2-a9f7-14747bafd9fc
INFO  [18:45:41.686] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 62 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:45:48.696] [bbotk] Evaluating 1 configuration(s)
INFO  [18:45:48.807] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:45:49.047] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:46:36.471] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:47:19.656] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:48:32.106] [mlr3] Finished benchmark
INFO  [18:48:33.533] [bbotk] Result of batch 32:
INFO  [18:48:33.663] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:48:33.663] [bbotk]               -1.10097                         0.4452202
INFO  [18:48:33.663] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:48:33.663] [bbotk]                         0.7830712           -5.136326              -2.249788
INFO  [18:48:33.663] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:48:33.663] [bbotk]                          3                    4992                 0.5228426
INFO  [18:48:33.663] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:48:33.663] [bbotk]  0.01117325 <list[8]>              FALSE     0.02845006        0      0
INFO  [18:48:33.663] [bbotk]  runtime_learners                                uhash
INFO  [18:48:33.663] [bbotk]           162.244 af98520f-b426-4335-a604-157443a7b456
INFO  [18:48:39.558] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 63 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:48:45.911] [bbotk] Evaluating 1 configuration(s)
INFO  [18:48:46.106] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:48:46.299] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:49:08.676] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:49:38.182] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:50:02.658] [mlr3] Finished benchmark
INFO  [18:50:02.807] [bbotk] Result of batch 33:
INFO  [18:50:02.889] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:50:02.889] [bbotk]              -4.245222                         0.7106381
INFO  [18:50:02.889] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:50:02.889] [bbotk]                           0.15075           -2.966946              -4.721202
INFO  [18:50:02.889] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:50:02.889] [bbotk]                         16                    2279                 0.3537843
INFO  [18:50:02.889] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:50:02.889] [bbotk]  0.01055609 <list[8]>              FALSE       0.028651        0      0
INFO  [18:50:02.889] [bbotk]  runtime_learners                                uhash
INFO  [18:50:02.889] [bbotk]            76.082 871bcde2-dbd8-46f7-a597-cff43a10139d
INFO  [18:50:05.749] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 64 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:50:12.330] [bbotk] Evaluating 1 configuration(s)
INFO  [18:50:12.487] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:50:12.642] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:50:31.894] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:50:56.645] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:51:22.650] [mlr3] Finished benchmark
INFO  [18:51:22.801] [bbotk] Result of batch 34:
INFO  [18:51:22.842] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:51:22.842] [bbotk]              0.2642164                         0.4875805
INFO  [18:51:22.842] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:51:22.842] [bbotk]                         0.2974994           -2.862999               4.539361
INFO  [18:51:22.842] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:51:22.842] [bbotk]                         20                    1496                 0.3046051
INFO  [18:51:22.842] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:51:22.842] [bbotk]  0.008747564 <list[8]>              FALSE     0.04915667        0      0
INFO  [18:51:22.842] [bbotk]  runtime_learners                                uhash
INFO  [18:51:22.842] [bbotk]            69.413 b6573afb-b745-4790-bad5-1252740feaac
INFO  [18:51:26.074] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 65 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:51:30.693] [bbotk] Evaluating 1 configuration(s)
INFO  [18:51:31.140] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:51:31.247] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:51:53.386] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:52:14.350] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:53:06.602] [mlr3] Finished benchmark
INFO  [18:53:06.754] [bbotk] Result of batch 35:
INFO  [18:53:06.779] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:53:06.779] [bbotk]              -1.403831                         0.7527439
INFO  [18:53:06.779] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:53:06.779] [bbotk]                         0.7915245          -0.4428427              -5.057418
INFO  [18:53:06.779] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:53:06.779] [bbotk]                         14                    2173                 0.4088432
INFO  [18:53:06.779] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:53:06.779] [bbotk]  0.008980372 <list[8]>              FALSE     0.03100798        0      0
INFO  [18:53:06.779] [bbotk]  runtime_learners                                uhash
INFO  [18:53:06.779] [bbotk]            94.746 f2952ad0-71c7-4a5e-9ef5-b72563461f90
INFO  [18:53:10.041] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 66 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:53:22.058] [bbotk] Evaluating 1 configuration(s)
INFO  [18:53:22.108] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:53:22.390] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:54:10.975] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:55:08.790] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:56:32.887] [mlr3] Finished benchmark
INFO  [18:56:33.179] [bbotk] Result of batch 36:
INFO  [18:56:33.244] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:56:33.244] [bbotk]              0.2448287                         0.1873043
INFO  [18:56:33.244] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:56:33.244] [bbotk]                         0.9384483           -4.140922              0.3211312
INFO  [18:56:33.244] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:56:33.244] [bbotk]                          3                    4972                 0.7236073
INFO  [18:56:33.244] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:56:33.244] [bbotk]  0.01039836 <list[8]>              FALSE     0.03178044        0      0
INFO  [18:56:33.244] [bbotk]  runtime_learners                                uhash
INFO  [18:56:33.244] [bbotk]           190.214 3d897589-abf2-4762-af3d-b8ff63352b1d
INFO  [18:56:35.967] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 67 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:56:51.078] [bbotk] Evaluating 1 configuration(s)
INFO  [18:56:51.267] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:56:51.296] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:57:47.560] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:58:58.185] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:00:10.064] [mlr3] Finished benchmark
INFO  [19:00:10.735] [bbotk] Result of batch 37:
INFO  [19:00:10.779] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:00:10.779] [bbotk]              -2.524368                         0.7522812
INFO  [19:00:10.779] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:00:10.779] [bbotk]                         0.8189276          -0.4546912              0.2314712
INFO  [19:00:10.779] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:00:10.779] [bbotk]                         11                    4858                 0.5651529
INFO  [19:00:10.779] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:00:10.779] [bbotk]  0.009008987 <list[8]>              FALSE     0.02990582        0      0
INFO  [19:00:10.779] [bbotk]  runtime_learners                                uhash
INFO  [19:00:10.779] [bbotk]           198.253 d45131a9-af0e-454d-8dee-aacadeb4be00
WARN  [19:00:13.577] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:00:13.605] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 68 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:00:29.395] [bbotk] Evaluating 1 configuration(s)
INFO  [19:00:29.474] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:00:29.561] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:01:35.826] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:02:41.829] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:03:46.308] [mlr3] Finished benchmark
INFO  [19:03:46.413] [bbotk] Result of batch 38:
INFO  [19:03:46.432] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:03:46.432] [bbotk]               -5.62519                         0.6262113
INFO  [19:03:46.432] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:03:46.432] [bbotk]                         0.6212969          -0.1954861               5.629755
INFO  [19:03:46.432] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:03:46.432] [bbotk]                         16                    3503                 0.4155725
INFO  [19:03:46.432] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:03:46.432] [bbotk]  0.008624506 <list[8]>              FALSE       0.029407        0      0
INFO  [19:03:46.432] [bbotk]  runtime_learners                                uhash
INFO  [19:03:46.432] [bbotk]            196.58 9b8b3235-ef46-403a-bd7c-da2769f55ccb
INFO  [19:03:57.658] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 69 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:04:07.192] [bbotk] Evaluating 1 configuration(s)
INFO  [19:04:07.944] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:04:08.095] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:05:06.144] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:06:12.312] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:07:13.822] [mlr3] Finished benchmark
INFO  [19:07:13.899] [bbotk] Result of batch 39:
INFO  [19:07:13.909] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:07:13.909] [bbotk]              -4.881183                         0.6771305
INFO  [19:07:13.909] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:07:13.909] [bbotk]                         0.5678489           -5.390068              0.7762778
INFO  [19:07:13.909] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:07:13.909] [bbotk]                         19                    2338                 0.4516908
INFO  [19:07:13.909] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:07:13.909] [bbotk]  0.008857023 <list[8]>              FALSE     0.03257449        0      0
INFO  [19:07:13.909] [bbotk]  runtime_learners                                uhash
INFO  [19:07:13.909] [bbotk]           184.273 def5e781-e6ea-4bc7-8cc9-91cee2d9391d
INFO  [19:07:18.581] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 70 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:07:31.093] [bbotk] Evaluating 1 configuration(s)
INFO  [19:07:31.216] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:07:31.267] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:08:35.345] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:09:38.851] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:11:20.052] [mlr3] Finished benchmark
INFO  [19:11:20.654] [bbotk] Result of batch 40:
INFO  [19:11:20.668] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:11:20.668] [bbotk]             -0.2068684                          0.582318
INFO  [19:11:20.668] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:11:20.668] [bbotk]                         0.9920798           -3.755779             -0.1293016
INFO  [19:11:20.668] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:11:20.668] [bbotk]                         13                    3417                 0.5927069
INFO  [19:11:20.668] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:11:20.668] [bbotk]  0.01064065 <list[8]>              FALSE     0.02918417        0      0
INFO  [19:11:20.668] [bbotk]  runtime_learners                                uhash
INFO  [19:11:20.668] [bbotk]           228.556 1e5c31b9-a89e-40e5-a15b-89c19b8c0324
INFO  [19:11:22.227] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 71 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:11:35.151] [bbotk] Evaluating 1 configuration(s)
INFO  [19:11:35.561] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:11:35.589] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:12:57.250] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:14:24.397] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:15:34.141] [mlr3] Finished benchmark
INFO  [19:15:34.246] [bbotk] Result of batch 41:
INFO  [19:15:34.295] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:15:34.295] [bbotk]              -5.882073                         0.9321195
INFO  [19:15:34.295] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:15:34.295] [bbotk]                         0.1957236           -5.310331               -5.14807
INFO  [19:15:34.295] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:15:34.295] [bbotk]                          3                    4418                 0.6376651
INFO  [19:15:34.295] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:15:34.295] [bbotk]  0.009590426 <list[8]>              FALSE     0.02793312        0      0
INFO  [19:15:34.295] [bbotk]  runtime_learners                                uhash
INFO  [19:15:34.295] [bbotk]           238.428 39721fc4-ca58-48f4-aade-ad7061a278a3
INFO  [19:15:39.975] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 72 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:15:51.572] [bbotk] Evaluating 1 configuration(s)
INFO  [19:15:51.897] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:15:51.932] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:16:41.219] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:17:53.918] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:18:50.844] [mlr3] Finished benchmark
INFO  [19:18:51.308] [bbotk] Result of batch 42:
INFO  [19:18:51.318] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:18:51.318] [bbotk]             -0.3316599                          0.914873
INFO  [19:18:51.318] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:18:51.318] [bbotk]                         0.5065339           -2.196939              -6.399912
INFO  [19:18:51.318] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:18:51.318] [bbotk]                         20                    2904                 0.3923269
INFO  [19:18:51.318] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:18:51.318] [bbotk]  0.009756563 <list[8]>              FALSE     0.02852523        0      0
INFO  [19:18:51.318] [bbotk]  runtime_learners                                uhash
INFO  [19:18:51.318] [bbotk]           178.507 e35abc88-5891-4529-867f-a57237f01775
INFO  [19:18:52.624] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 73 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:19:16.481] [bbotk] Evaluating 1 configuration(s)
INFO  [19:19:16.509] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:19:16.531] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:20:16.452] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:21:31.824] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:22:29.259] [mlr3] Finished benchmark
INFO  [19:22:29.796] [bbotk] Result of batch 43:
INFO  [19:22:29.860] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:22:29.860] [bbotk]               -5.45263                         0.9141099
INFO  [19:22:29.860] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:22:29.860] [bbotk]                         0.4072007           -2.629346              -3.690936
INFO  [19:22:29.860] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:22:29.860] [bbotk]                          5                    3197                 0.6315359
INFO  [19:22:29.860] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:22:29.860] [bbotk]  0.008126438 <list[8]>              FALSE     0.02992377        0      0
INFO  [19:22:29.860] [bbotk]  runtime_learners                                uhash
INFO  [19:22:29.860] [bbotk]           192.261 a582cdb1-26ec-4687-b127-bb2431cec373
WARN  [19:23:00.293] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:23:00.314] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 74 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:23:21.155] [bbotk] Evaluating 1 configuration(s)
INFO  [19:23:21.556] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:23:21.662] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:24:26.634] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:25:46.365] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:26:48.398] [mlr3] Finished benchmark
INFO  [19:26:49.108] [bbotk] Result of batch 44:
INFO  [19:26:49.144] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:26:49.144] [bbotk]              -2.675598                          0.881072
INFO  [19:26:49.144] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:26:49.144] [bbotk]                          0.110099           -3.287479              -3.151369
INFO  [19:26:49.144] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:26:49.144] [bbotk]                          1                    4535                 0.4462427
INFO  [19:26:49.144] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:26:49.144] [bbotk]  0.007985219 <list[8]>              FALSE     0.02914554        0      0
INFO  [19:26:49.144] [bbotk]  runtime_learners                                uhash
INFO  [19:26:49.144] [bbotk]           206.369 dc51c6e2-254e-4850-b5e9-8601ad257868
WARN  [19:27:11.373] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:27:11.492] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 75 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:27:25.298] [bbotk] Evaluating 1 configuration(s)
INFO  [19:27:25.437] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:27:25.483] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:28:18.827] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:29:06.302] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:29:41.756] [mlr3] Finished benchmark
INFO  [19:29:42.012] [bbotk] Result of batch 45:
INFO  [19:29:42.036] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:29:42.036] [bbotk]              -2.573218                         0.2880686
INFO  [19:29:42.036] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:29:42.036] [bbotk]                         0.8712713            -4.74326              -3.975149
INFO  [19:29:42.036] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:29:42.036] [bbotk]                          1                    3579                 0.6360441
INFO  [19:29:42.036] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:29:42.036] [bbotk]  0.008342935 <list[8]>              FALSE     0.02891625        0      0
INFO  [19:29:42.036] [bbotk]  runtime_learners                                uhash
INFO  [19:29:42.036] [bbotk]           135.909 e555e711-27d8-4691-b26a-19300e06d9ef
WARN  [19:29:44.608] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:29:44.619] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 76 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:29:55.930] [bbotk] Evaluating 1 configuration(s)
INFO  [19:29:56.081] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:29:56.165] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:30:39.545] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:31:48.218] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:32:53.471] [mlr3] Finished benchmark
INFO  [19:32:54.389] [bbotk] Result of batch 46:
INFO  [19:32:54.396] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:32:54.396] [bbotk]               -4.03105                         0.4509624
INFO  [19:32:54.396] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:32:54.396] [bbotk]                         0.8513038         -0.02855864              0.1536037
INFO  [19:32:54.396] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:32:54.396] [bbotk]                         20                    4042                 0.4951002
INFO  [19:32:54.396] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:32:54.396] [bbotk]  0.008077613 <list[8]>              FALSE     0.03241541        0      0
INFO  [19:32:54.396] [bbotk]  runtime_learners                                uhash
INFO  [19:32:54.396] [bbotk]           176.852 3866ff3a-6116-4214-9789-7a8fd4a89121
INFO  [19:33:05.291] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 77 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:33:30.608] [bbotk] Evaluating 1 configuration(s)
INFO  [19:33:30.663] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:33:30.689] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:34:30.638] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:35:19.466] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:36:06.719] [mlr3] Finished benchmark
INFO  [19:36:06.831] [bbotk] Result of batch 47:
INFO  [19:36:06.944] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:36:06.944] [bbotk]              -1.389605                         0.5101535
INFO  [19:36:06.944] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:36:06.944] [bbotk]                         0.1375492         -0.07762466              -6.461517
INFO  [19:36:06.944] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:36:06.944] [bbotk]                         11                    3448                 0.1971642
INFO  [19:36:06.944] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:36:06.944] [bbotk]  0.007346673 <list[8]>              FALSE     0.03146281        0      0
INFO  [19:36:06.944] [bbotk]  runtime_learners                                uhash
INFO  [19:36:06.944] [bbotk]            155.45 046b6131-aaed-4f49-9ea6-90d24f082fe5
INFO  [19:36:24.478] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 78 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:36:47.443] [bbotk] Evaluating 1 configuration(s)
INFO  [19:36:47.910] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:36:48.464] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:37:42.667] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:38:38.741] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:39:39.521] [mlr3] Finished benchmark
INFO  [19:39:40.891] [bbotk] Result of batch 48:
INFO  [19:39:41.260] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:39:41.260] [bbotk]               -5.08229                         0.5583248
INFO  [19:39:41.260] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:39:41.260] [bbotk]                         0.5368617           -5.225435              -4.545367
INFO  [19:39:41.260] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:39:41.260] [bbotk]                          1                    4620                 0.6004604
INFO  [19:39:41.260] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:39:41.260] [bbotk]  0.007544848 <list[8]>              FALSE     0.02902213        0      0
INFO  [19:39:41.260] [bbotk]  runtime_learners                                uhash
INFO  [19:39:41.260] [bbotk]           170.486 264942a4-82f6-43a6-a4f7-dd477fe13449
INFO  [19:39:52.573] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 79 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:40:19.815] [bbotk] Evaluating 1 configuration(s)
INFO  [19:40:19.872] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:40:19.888] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:41:07.079] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:42:09.596] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:43:05.947] [mlr3] Finished benchmark
INFO  [19:43:06.006] [bbotk] Result of batch 49:
INFO  [19:43:06.013] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:43:06.013] [bbotk]              -6.527231                          0.898245
INFO  [19:43:06.013] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:43:06.013] [bbotk]                         0.7930412         -0.05407428             -0.2107379
INFO  [19:43:06.013] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:43:06.013] [bbotk]                          2                    2618                 0.7627163
INFO  [19:43:06.013] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:43:06.013] [bbotk]  0.008256509 <list[8]>              FALSE     0.03271945        0      0
INFO  [19:43:06.013] [bbotk]  runtime_learners                                uhash
INFO  [19:43:06.013] [bbotk]           165.673 72df9b97-5cae-469e-90a5-12da62770985
INFO  [19:43:14.084] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 80 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:43:26.158] [bbotk] Evaluating 1 configuration(s)
INFO  [19:43:26.419] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:43:26.726] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:44:17.404] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:45:09.238] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [19:46:16.778] [mlr3] Finished benchmark
INFO  [19:46:17.162] [bbotk] Result of batch 50:
INFO  [19:46:17.223] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:46:17.223] [bbotk]              -5.521217                         0.7380287
INFO  [19:46:17.223] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:46:17.223] [bbotk]                         0.6098096          -0.3905678               1.652353
INFO  [19:46:17.223] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:46:17.223] [bbotk]                         13                    3508                  0.684434
INFO  [19:46:17.223] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:46:17.223] [bbotk]  0.007167744 <list[8]>              FALSE     0.02995364        0      0
INFO  [19:46:17.223] [bbotk]  runtime_learners                                uhash
INFO  [19:46:17.223] [bbotk]           169.732 b1f91b64-f31f-4a4f-881a-41fba7b2efe7
INFO  [19:46:24.248] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 81 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:46:38.887] [bbotk] Evaluating 1 configuration(s)
INFO  [19:46:38.944] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:46:39.041] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:47:13.946] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:47:55.928] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:48:42.974] [mlr3] Finished benchmark
INFO  [19:48:44.661] [bbotk] Result of batch 51:
INFO  [19:48:44.754] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:48:44.754] [bbotk]              -6.661166                          0.726506
INFO  [19:48:44.754] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:48:44.754] [bbotk]                         0.8333954           -1.058932               -6.67781
INFO  [19:48:44.754] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:48:44.754] [bbotk]                          2                    1222                 0.2270827
INFO  [19:48:44.754] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:48:44.754] [bbotk]  0.007416953 <list[8]>              FALSE     0.02978035        0      0
INFO  [19:48:44.754] [bbotk]  runtime_learners                                uhash
INFO  [19:48:44.754] [bbotk]           123.377 a213aab0-01d3-4b1e-95de-ec5733238f38
INFO  [19:48:49.652] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 82 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:49:07.552] [bbotk] Evaluating 1 configuration(s)
INFO  [19:49:08.481] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:49:08.735] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:50:38.363] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:51:57.288] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:53:11.412] [mlr3] Finished benchmark
INFO  [19:53:12.235] [bbotk] Result of batch 52:
INFO  [19:53:12.242] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:53:12.242] [bbotk]              -4.466692                         0.9825761
INFO  [19:53:12.242] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:53:12.242] [bbotk]                         0.9497721          -0.9606202              -4.944827
INFO  [19:53:12.242] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:53:12.242] [bbotk]                          1                    4106                 0.4583202
INFO  [19:53:12.242] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:53:12.242] [bbotk]  0.007406954 <list[8]>              FALSE     0.03154372        0      0
INFO  [19:53:12.242] [bbotk]  runtime_learners                                uhash
INFO  [19:53:12.242] [bbotk]           242.169 76d7d524-ed84-4198-98ba-8f48dffb49aa
INFO  [19:53:25.273] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 83 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:53:39.134] [bbotk] Evaluating 1 configuration(s)
INFO  [19:53:39.502] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:53:39.540] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:54:18.459] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:55:05.447] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:55:41.064] [mlr3] Finished benchmark
INFO  [19:55:41.699] [bbotk] Result of batch 53:
INFO  [19:55:41.943] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:55:41.943] [bbotk]              -6.184027                         0.5035336
INFO  [19:55:41.943] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:55:41.943] [bbotk]                         0.6895299         -0.03429958               4.804734
INFO  [19:55:41.943] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:55:41.943] [bbotk]                          6                    1812                  0.155534
INFO  [19:55:41.943] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:55:41.943] [bbotk]  0.007621708 <list[8]>              FALSE     0.03454972        0      0
INFO  [19:55:41.943] [bbotk]  runtime_learners                                uhash
INFO  [19:55:41.943] [bbotk]           121.355 499a2870-d1d6-43a6-a6ed-0cbddef26d3b
INFO  [19:55:46.899] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 84 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:56:18.121] [bbotk] Evaluating 1 configuration(s)
INFO  [19:56:19.407] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:56:19.601] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:57:15.419] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:58:20.271] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:59:08.669] [mlr3] Finished benchmark
INFO  [19:59:09.613] [bbotk] Result of batch 54:
INFO  [19:59:10.210] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:59:10.210] [bbotk]              -6.143194                         0.8406228
INFO  [19:59:10.210] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:59:10.210] [bbotk]                          0.356157           -2.121962              -5.740493
INFO  [19:59:10.210] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:59:10.210] [bbotk]                         19                    1523                 0.4256587
INFO  [19:59:10.210] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:59:10.210] [bbotk]  0.008261461 <list[8]>              FALSE     0.02945421        0      0
INFO  [19:59:10.210] [bbotk]  runtime_learners                                uhash
INFO  [19:59:10.210] [bbotk]           168.546 4f550744-d095-47c4-b9ae-86a2696934b0
INFO  [19:59:26.444] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 85 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:59:55.723] [bbotk] Evaluating 1 configuration(s)
INFO  [19:59:56.196] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:59:56.373] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:01:26.517] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:02:30.088] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:03:25.626] [mlr3] Finished benchmark
INFO  [20:03:26.976] [bbotk] Result of batch 55:
INFO  [20:03:27.015] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:03:27.015] [bbotk]              -1.596118                         0.2067915
INFO  [20:03:27.015] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:03:27.015] [bbotk]                         0.8846834            -5.80263              -6.381538
INFO  [20:03:27.015] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:03:27.015] [bbotk]                          2                    3642                 0.6967801
INFO  [20:03:27.015] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:03:27.015] [bbotk]  0.006559708 <list[8]>              FALSE     0.03105129        0      0
INFO  [20:03:27.015] [bbotk]  runtime_learners                                uhash
INFO  [20:03:27.015] [bbotk]           208.041 ae70aab2-a9d5-4263-aa47-d54271a7723b
INFO  [20:03:32.316] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 86 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:03:42.222] [bbotk] Evaluating 1 configuration(s)
INFO  [20:03:42.484] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:03:42.790] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:04:20.057] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:04:52.185] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:06:01.988] [mlr3] Finished benchmark
INFO  [20:06:02.169] [bbotk] Result of batch 56:
INFO  [20:06:02.180] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:06:02.180] [bbotk]              -2.103457                         0.9180772
INFO  [20:06:02.180] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:06:02.180] [bbotk]                         0.1017816           -1.276197              -5.568607
INFO  [20:06:02.180] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:06:02.180] [bbotk]                         19                    3577                 0.6263299
INFO  [20:06:02.180] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:06:02.180] [bbotk]  0.006981008 <list[8]>              FALSE     0.02940146        0      0
INFO  [20:06:02.180] [bbotk]  runtime_learners                                uhash
INFO  [20:06:02.180] [bbotk]           138.815 a8f83d10-40cb-4c01-82e7-a622a83ce359
INFO  [20:06:05.841] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 87 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:06:14.476] [bbotk] Evaluating 1 configuration(s)
INFO  [20:06:14.557] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:06:14.602] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:07:40.432] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:08:38.860] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:09:48.393] [mlr3] Finished benchmark
INFO  [20:09:48.612] [bbotk] Result of batch 57:
INFO  [20:09:48.794] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:09:48.794] [bbotk]              -6.524797                         0.9849879
INFO  [20:09:48.794] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:09:48.794] [bbotk]                         0.3607626           -4.201057               1.898144
INFO  [20:09:48.794] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:09:48.794] [bbotk]                          2                    3826                 0.4738068
INFO  [20:09:48.794] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:09:48.794] [bbotk]  0.006045383 <list[8]>              FALSE     0.02883791        0      0
INFO  [20:09:48.794] [bbotk]  runtime_learners                                uhash
INFO  [20:09:48.794] [bbotk]           213.353 962a7d97-9ec8-4e75-89a8-bc30fc48f3d0
INFO  [20:09:53.523] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 88 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:10:07.730] [bbotk] Evaluating 1 configuration(s)
INFO  [20:10:07.774] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:10:07.793] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:10:42.007] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:11:22.558] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:13:37.834] [mlr3] Finished benchmark
INFO  [20:13:37.991] [bbotk] Result of batch 58:
INFO  [20:13:38.016] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:13:38.016] [bbotk]              -4.821498                         0.8015515
INFO  [20:13:38.016] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:13:38.016] [bbotk]                         0.2654376             -4.1913              -2.195919
INFO  [20:13:38.016] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:13:38.016] [bbotk]                         10                    4217                 0.5707687
INFO  [20:13:38.016] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:13:38.016] [bbotk]  0.006268784 <list[8]>              FALSE     0.02936912        0      0
INFO  [20:13:38.016] [bbotk]  runtime_learners                                uhash
INFO  [20:13:38.016] [bbotk]           209.726 c8a39efd-a05c-49fa-af84-39060c805425
INFO  [20:13:43.108] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 89 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:14:14.608] [bbotk] Evaluating 1 configuration(s)
INFO  [20:14:14.959] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:14:16.007] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:15:41.383] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:17:21.403] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:18:14.111] [mlr3] Finished benchmark
INFO  [20:18:14.191] [bbotk] Result of batch 59:
INFO  [20:18:14.212] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:18:14.212] [bbotk]              -2.106383                         0.8651309
INFO  [20:18:14.212] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:18:14.212] [bbotk]                         0.9693988           -2.608687               3.792144
INFO  [20:18:14.212] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:18:14.212] [bbotk]                          1                    3839                 0.2265365
INFO  [20:18:14.212] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:18:14.212] [bbotk]  0.005250713 <list[8]>              FALSE     0.03147243        0      0
INFO  [20:18:14.212] [bbotk]  runtime_learners                                uhash
INFO  [20:18:14.212] [bbotk]           237.526 051d837f-3519-42a1-93e1-5d522db4a181
INFO  [20:18:17.236] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 90 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:18:27.401] [bbotk] Evaluating 1 configuration(s)
INFO  [20:18:27.458] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:18:27.539] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:18:59.514] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:19:35.960] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:19:59.609] [mlr3] Finished benchmark
INFO  [20:19:59.707] [bbotk] Result of batch 60:
INFO  [20:19:59.735] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:19:59.735] [bbotk]              -6.434404                          0.506621
INFO  [20:19:59.735] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:19:59.735] [bbotk]                         0.7195976           -3.526684              -2.567044
INFO  [20:19:59.735] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:19:59.735] [bbotk]                          2                     462                 0.1157626
INFO  [20:19:59.735] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:19:59.735] [bbotk]  0.005661786 <list[8]>              FALSE     0.03806721        0      0
INFO  [20:19:59.735] [bbotk]  runtime_learners                                uhash
INFO  [20:19:59.735] [bbotk]            91.652 ba77b86e-75cb-471d-a72a-3ad17db2d1c0
WARN  [20:20:19.402] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [20:20:19.421] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 91 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:20:26.983] [bbotk] Evaluating 1 configuration(s)
INFO  [20:20:27.076] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:20:27.174] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:21:30.020] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:22:30.432] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:23:34.770] [mlr3] Finished benchmark
INFO  [20:23:34.918] [bbotk] Result of batch 61:
INFO  [20:23:34.977] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:23:34.977] [bbotk]              -2.413703                         0.6749176
INFO  [20:23:34.977] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:23:34.977] [bbotk]                         0.4966631          -0.7935773              -6.035129
INFO  [20:23:34.977] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:23:34.977] [bbotk]                          5                    4933                 0.6459929
INFO  [20:23:34.977] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:23:34.977] [bbotk]  0.005590065 <list[8]>              FALSE     0.02636736        0      0
INFO  [20:23:34.977] [bbotk]  runtime_learners                                uhash
INFO  [20:23:34.977] [bbotk]           187.329 91c46306-9677-47ab-b21e-6beaf3a153cb
WARN  [20:23:39.316] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [20:23:39.325] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 92 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:23:50.839] [bbotk] Evaluating 1 configuration(s)
INFO  [20:23:50.918] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:23:50.985] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:25:06.861] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:26:03.715] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:27:29.061] [mlr3] Finished benchmark
INFO  [20:27:29.189] [bbotk] Result of batch 62:
INFO  [20:27:29.213] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:27:29.213] [bbotk]              -5.758562                         0.7165325
INFO  [20:27:29.213] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:27:29.213] [bbotk]                         0.8784937           -5.542883               -2.74907
INFO  [20:27:29.213] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:27:29.213] [bbotk]                          3                    3196                  0.225503
INFO  [20:27:29.213] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:27:29.213] [bbotk]  0.004685867 <list[8]>              FALSE     0.03191872        0      0
INFO  [20:27:29.213] [bbotk]  runtime_learners                                uhash
INFO  [20:27:29.213] [bbotk]           217.864 81d2eb6a-7aab-45ee-84f0-048da8a65fbe
WARN  [20:27:30.918] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [20:27:31.122] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 93 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:27:42.006] [bbotk] Evaluating 1 configuration(s)
INFO  [20:27:42.071] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:27:42.137] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:28:35.095] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:29:17.873] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:30:19.994] [mlr3] Finished benchmark
INFO  [20:30:20.081] [bbotk] Result of batch 63:
INFO  [20:30:20.121] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:30:20.121] [bbotk]              -3.068993                         0.7481177
INFO  [20:30:20.121] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:30:20.121] [bbotk]                         0.6365534           -4.147956              -1.833774
INFO  [20:30:20.121] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:30:20.121] [bbotk]                          1                    4677                 0.6294504
INFO  [20:30:20.121] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:30:20.121] [bbotk]  0.00498583 <list[8]>              FALSE     0.02946416        0      0
INFO  [20:30:20.121] [bbotk]  runtime_learners                                uhash
INFO  [20:30:20.121] [bbotk]           157.728 56af3c72-36c5-490e-a0b0-2055de6ca71b
INFO  [20:30:22.614] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 94 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:30:32.816] [bbotk] Evaluating 1 configuration(s)
INFO  [20:30:32.965] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:30:33.023] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:31:06.443] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:31:52.183] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:32:40.308] [mlr3] Finished benchmark
INFO  [20:32:40.392] [bbotk] Result of batch 64:
INFO  [20:32:40.402] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:32:40.402] [bbotk]              -6.829009                         0.8990424
INFO  [20:32:40.402] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:32:40.402] [bbotk]                         0.5841697           -4.636386              -6.076092
INFO  [20:32:40.402] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:32:40.402] [bbotk]                         16                    3311                  0.703452
INFO  [20:32:40.402] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:32:40.402] [bbotk]  0.0049121 <list[8]>              FALSE     0.03022979        0      0
INFO  [20:32:40.402] [bbotk]  runtime_learners                                uhash
INFO  [20:32:40.402] [bbotk]           127.046 2da10d3f-890b-4901-84f1-93d9c224e4ba
INFO  [20:32:44.786] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 95 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:32:55.214] [bbotk] Evaluating 1 configuration(s)
INFO  [20:32:55.257] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:32:55.275] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:33:10.535] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:33:25.237] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:33:41.877] [mlr3] Finished benchmark
INFO  [20:33:41.960] [bbotk] Result of batch 65:
INFO  [20:33:41.987] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:33:41.987] [bbotk]              -3.160194                         0.1900129
INFO  [20:33:41.987] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:33:41.987] [bbotk]                         0.9784172           -5.316591              -4.018472
INFO  [20:33:41.987] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:33:41.987] [bbotk]                         11                    2739                 0.2950785
INFO  [20:33:41.987] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:33:41.987] [bbotk]  0.005260676 <list[8]>              FALSE      0.0317246        0      0
INFO  [20:33:41.987] [bbotk]  runtime_learners                                uhash
INFO  [20:33:41.987] [bbotk]            46.503 1c4a51f6-a894-4751-b348-f3e9be94acaa
INFO  [20:33:45.059] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 96 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:33:49.617] [bbotk] Evaluating 1 configuration(s)
INFO  [20:33:49.661] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:33:49.706] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:34:00.254] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:34:09.240] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:34:18.510] [mlr3] Finished benchmark
INFO  [20:34:18.685] [bbotk] Result of batch 66:
INFO  [20:34:18.773] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:34:18.773] [bbotk]              -5.213511                         0.9421622
INFO  [20:34:18.773] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:34:18.773] [bbotk]                         0.4778081          -0.6635141              -1.732641
INFO  [20:34:18.773] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:34:18.773] [bbotk]                          1                    1049                 0.4072365
INFO  [20:34:18.773] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:34:18.773] [bbotk]  0.005234247 <list[8]>              FALSE      0.0306655        0      0
INFO  [20:34:18.773] [bbotk]  runtime_learners                                uhash
INFO  [20:34:18.773] [bbotk]            28.707 8cecb5d6-baf8-472e-9ac9-2c899fc77bf3
WARN  [20:34:22.780] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [20:34:22.791] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 97 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:34:26.879] [bbotk] Evaluating 1 configuration(s)
INFO  [20:34:26.900] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:34:26.933] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:34:43.365] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:35:01.205] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:35:27.212] [mlr3] Finished benchmark
INFO  [20:35:27.286] [bbotk] Result of batch 67:
INFO  [20:35:27.293] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:35:27.293] [bbotk]              -3.474994                         0.5789582
INFO  [20:35:27.293] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:35:27.293] [bbotk]                         0.9220639           -1.387483              -5.854646
INFO  [20:35:27.293] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:35:27.293] [bbotk]                          1                    3371                   0.39201
INFO  [20:35:27.293] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:35:27.293] [bbotk]  0.004690579 <list[8]>              FALSE     0.03083035        0      0
INFO  [20:35:27.293] [bbotk]  runtime_learners                                uhash
INFO  [20:35:27.293] [bbotk]            60.162 a43d0485-cbb6-42ab-9997-406a7e0e25c8
INFO  [20:35:32.068] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 98 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:35:40.484] [bbotk] Evaluating 1 configuration(s)
INFO  [20:35:40.587] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:35:40.755] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:36:18.605] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:36:54.912] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:37:25.864] [mlr3] Finished benchmark
INFO  [20:37:26.041] [bbotk] Result of batch 68:
INFO  [20:37:26.048] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:37:26.048] [bbotk]               1.124274                         0.4810914
INFO  [20:37:26.048] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:37:26.048] [bbotk]                         0.8310868           -2.055788              -4.966323
INFO  [20:37:26.048] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:37:26.048] [bbotk]                         20                    3062                 0.3354642
INFO  [20:37:26.048] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:37:26.048] [bbotk]  0.004208543 <list[8]>              FALSE     0.03708966        0      0
INFO  [20:37:26.048] [bbotk]  runtime_learners                                uhash
INFO  [20:37:26.048] [bbotk]           104.947 301c9015-9912-4f3d-a485-a47f4e31c0dd
INFO  [20:37:29.684] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 99 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:37:36.329] [bbotk] Evaluating 1 configuration(s)
INFO  [20:37:36.358] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:37:36.370] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:38:12.947] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:39:02.488] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:39:49.550] [mlr3] Finished benchmark
INFO  [20:39:49.662] [bbotk] Result of batch 69:
INFO  [20:39:49.672] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:39:49.672] [bbotk]              0.1463235                         0.5476971
INFO  [20:39:49.672] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:39:49.672] [bbotk]                         0.9233131           -4.074522               3.598697
INFO  [20:39:49.672] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:39:49.672] [bbotk]                         20                    4074                 0.5869405
INFO  [20:39:49.672] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:39:49.672] [bbotk]  0.004294032 <list[8]>              FALSE     0.03439536        0      0
INFO  [20:39:49.672] [bbotk]  runtime_learners                                uhash
INFO  [20:39:49.672] [bbotk]           133.086 e3fe27bd-0b75-4724-a1ad-44355b2683eb
INFO  [20:39:52.182] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 100 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:39:52.256] [bbotk] Finished optimizing after 100 evaluation(s)
INFO  [20:39:52.343] [bbotk] Result:
INFO  [20:39:52.358] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:39:52.358] [bbotk]                  <num>                             <num>
INFO  [20:39:52.358] [bbotk]              -2.413703                         0.6749176
INFO  [20:39:52.358] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:39:52.358] [bbotk]                             <num>               <num>                  <num>
INFO  [20:39:52.358] [bbotk]                         0.4966631          -0.7935773              -6.035129
INFO  [20:39:52.358] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:39:52.358] [bbotk]                      <int>                   <int>                     <num>
INFO  [20:39:52.358] [bbotk]                          5                    4933                 0.6459929
INFO  [20:39:52.358] [bbotk]  learner_param_vals  x_domain classif.bbrier
INFO  [20:39:52.358] [bbotk]              <list>    <list>          <num>
INFO  [20:39:52.358] [bbotk]          <list[10]> <list[8]>     0.02636736

### [bt]: Job terminated successfully [batchtools job.id=1434]
### [bt]: Calculation finished!
