### [bt]: This is batchtools v0.9.17
### [bt]: Starting calculation of 1 jobs
### [bt]: Setting working directory to '/content/drive/MyDrive/GitHub/Mater_Thesis_Calibration'
ece.R :
Friedmann_tasks.R :
Functions.R :
ici.R :
mse_feature_effects.R :
PipeOpCalibration_TuningExperiment.R :
PipeOpCalibration.R :
PipeOpCalibrationUnion.R :
### [bt]: Memory measurement disabled
### [bt]: Starting job [batchtools job.id=1412]
### [bt]: Generating problem instance for problem '341ee781c7d79b8f' ...
### [bt]: Applying algorithm 'run_learner' on problem '341ee781c7d79b8f' for job 1412 (seed = 1535) ...
INFO  [16:05:20.033] [mlr3] Applying learner 'xgboost TwP beta' on task 'wdbc' (iter 2/10)
INFO  [16:05:21.075] [bbotk] Starting to optimize 8 parameter(s) with '<OptimizerMbo>' and '<TerminatorEvals> [n_evals=100, k=0]'
INFO  [16:05:28.457] [bbotk] Evaluating 32 configuration(s)
INFO  [16:05:28.638] [mlr3] Running benchmark with 96 resampling iterations
INFO  [16:05:28.699] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 8.902087
[1] 522.9025
[1] -145.637
[1] 90.86308
[1] -206.227
[1] -4.969912
[1] -236.7403
[1] 24.80494
[1] 378.9918
[1] 14886.58
INFO  [16:06:52.310] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -77.86952
[1] 91.22946
[1] -204.1292
[1] 144.4212
[1] -118.5924
[1] 178.7803
[1] -167.4088
[1] 93.48903
[1] -120.7335
[1] 79.34192
INFO  [16:08:14.771] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -112.1484
[1] 56.01226
[1] -905.6394
[1] -24.19347
[1] -103.6535
[1] 232.764
[1] -67.30643
[1] 104.2273
[1] -93.28533
[1] 132.3677
INFO  [16:09:01.044] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -117.6312
[1] 43.8432
[1] -146.8991
[1] 8.092914
[1] -224.7108
[1] -4.465804
[1] -69.34243
[1] 33.56332
[1] -223.5191
[1] 90.89
INFO  [16:09:58.482] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -46.0607
[1] 34.2211
[1] -169.8157
[1] -4.157909
[1] -69.1646
[1] 38.88586
[1] -83.00813
[1] 43.34922
[1] -154.4858
[1] -4.099282
INFO  [16:10:51.773] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -74.37337
[1] 42.67487
[1] 14.45574
[1] 345.2244
[1] -72.77371
[1] 18.26293
[1] -135.2857
[1] 39.04972
[1] -339.0563
[1] -4.197575
INFO  [16:11:57.741] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:12:17.256] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:12:45.707] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:13:10.719] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -57.89336
[1] 22.5656
[1] -164.5585
[1] 11.51484
[1] -130.0654
[1] 77.25375
[1] -9.025223
[1] 927.1826
[1] -70.60169
[1] 5.353495
INFO  [16:14:13.410] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -46.19162
[1] 30.58454
[1] -97.9259
[1] 34.34367
[1] -63.06368
[1] 10.73573
[1] -90.80833
[1] 7.999675
[1] -2980.981
[1] -58.85197
INFO  [16:15:02.649] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -41.50683
[1] 65.92372
[1] -55.6449
[1] 21.94711
[1] -4155.103
[1] -113.2691
[1] -121.3433
[1] 39.47445
[1] -182.3311
[1] -4.083898
INFO  [16:15:57.497] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -349.5078
[1] 71.33913
[1] -103.6907
[1] 323.7965
[1] 7.776801
[1] 397.9253
[1] -360.1742
[1] -6.27439
[1] -377.9347
[1] -5.530402
INFO  [16:16:36.916] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -204.8654
[1] 130.8637
[1] -67.7385
[1] 233.8186
[1] -27.0128
[1] 311.1225
[1] -60.47802
[1] 322.6232
[1] 7.600821
[1] 351.6928
INFO  [16:17:22.833] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 8.789039
[1] 360.1515
[1] 12.28456
[1] 586.0332
[1] 7.386742
[1] 340.7114
[1] -244.7499
[1] -5.405584
[1] -110.8068
[1] 227.1335
INFO  [16:17:59.919] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:19:00.167] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:19:41.627] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:20:30.654] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 30.97543
[1] 1546.265
[1] -1031.1
[1] -17.86306
[1] -1185.998
[1] -20.74829
[1] -569.7318
[1] 827.9012
[1] -1373.255
[1] -25.01392
INFO  [16:22:01.232] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1495.044
[1] 1725.948
[1] -900.1598
[1] -15.68132
[1] -1824.49
[1] -32.67774
[1] 29.07715
[1] 1496.604
[1] -1113.346
[1] -19.76656
INFO  [16:23:19.035] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 28.19369
[1] 1376.31
[1] -1297.426
[1] -22.76838
[1] -790.1055
[1] -14.25805
[1] -1358.839
[1] -24.31872
[1] -1092.392
[1] -19.78198
INFO  [16:25:07.378] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -167.7
[1] 4.222596
[1] -103.7746
[1] 14.04446
[1] -215.3527
[1] 0.7339042
[1] -4.255199e+16
[1] 3.297852e+16
[1] -47.11132
[1] 48.19976
INFO  [16:26:14.113] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -51.77151
[1] 46.713
[1] -43.70585
[1] 46.46467
[1] -87.64286
[1] 94.98021
[1] -138.1388
[1] 21.45391
[1] 153.3869
[1] 5924.698
INFO  [16:27:40.900] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -64.80236
[1] 20.74657
[1] -307.3496
[1] -4.14998
[1] -3777.604
[1] -123.2329
[1] -28.04806
[1] 56.41685
[1] -43.44093
[1] 145.8713
INFO  [16:28:41.059] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -691.8734
[1] -12.23877
[1] -713.4295
[1] -10.51113
[1] -23153.5
[1] -442.3818
[1] -174.7725
[1] 234.7552
[1] -190.6864
[1] 466.8605
INFO  [16:30:34.854] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -547.0754
[1] -9.316265
[1] -610.0764
[1] 264.0419
[1] -313.5015
[1] 160.7888
[1] 18.79954
[1] 949.9857
[1] 12.04893
[1] 631.8816
INFO  [16:32:18.356] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -439.9177
[1] -8.536007
[1] -663.7069
[1] -11.31814
[1] 11.48268
[1] 626.1632
[1] 14.06615
[1] 753.4209
[1] 13.46055
[1] 640.9326
INFO  [16:33:41.851] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:34:43.362] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:35:40.837] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:36:52.335] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 38.44586
[1] 2004.2
[1] -2714.237
[1] -48.12836
[1] -2444.609
[1] -44.02202
[1] 92.51496
[1] 4799.354
[1] -2225.085
[1] -38.98333
INFO  [16:38:26.801] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 44.58339
[1] 2291.432
[1] 38.20347
[1] 1942.233
[1] -2764.444
[1] -48.58995
[1] 231.0214
[1] 12084.83
[1] -3099.714
[1] -55.63676
INFO  [16:40:00.151] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 70.9928
[1] 3616.509
[1] -2478.262
[1] -43.92764
[1] -2374.052
[1] -41.3864
[1] -2580.052
[1] -45.91928
[1] -3149.15
[1] -56.40125
INFO  [16:40:53.247] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -29.15455
[1] 28.76465
[1] -4107.51
[1] -156.0159
[1] -185.2178
[1] 5.153167
[1] -65.67511
[1] 9.303126
[1] -1284.831
[1] -32.3098
INFO  [16:41:30.301] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -59.77361
[1] 22.88393
[1] -47.65396
[1] 67.21883
[1] -29.1557
[1] 69.50283
[1] -25.49391
[1] 50.0998
[1] -224.4
[1] 7.182432
INFO  [16:42:01.826] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -4.243829e+16
[1] 3.122701e+15
[1] -65.26955
[1] 18.69539
[1] -28.52175
[1] 148.7553
[1] -105.053
[1] 48.93259
[1] -138.4313
[1] -3.652581
INFO  [16:42:34.908] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:43:39.364] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:44:43.366] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:45:42.160] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -526.6086
[1] -9.364779
[1] -1599.568
[1] -28.05657
[1] -230.3996
[1] 182.6289
[1] -694.4124
[1] 180.5493
[1] 17.16129
[1] 789.6864
INFO  [16:46:32.098] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -594.0923
[1] 122.6117
[1] -489.0161
[1] -8.790566
[1] -2351.082
[1] -44.39489
[1] 11.36371
[1] 563.4401
[1] -295.9126
[1] 262.1967
INFO  [16:47:00.441] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -419.8529
[1] -7.9836
[1] 8.675581
[1] 491.3221
[1] 14.63215
[1] 724.7428
[1] 19.20053
[1] 1053.52
[1] -538.582
[1] -9.542197
INFO  [16:48:01.989] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -71.05691
[1] 1.43138
[1] -21.28081
[1] 38.52032
[1] -60.84975
[1] 24.80155
[1] -13.86137
[1] 31.74921
[1] -70.38962
[1] 37.88494
INFO  [16:48:34.270] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -29.49552
[1] 12.7913
[1] -1805.512
[1] -42.06477
[1] -10035.57
[1] -218.9117
[1] -34.40145
[1] 24.63976
[1] -70.10938
[1] 61.51939
INFO  [16:49:08.210] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -23.40102
[1] 27.69253
[1] -1838.399
[1] -100.2245
[1] -88.17915
[1] 1.815647
[1] 25.70377
[1] 494.6204
[1] -43.32098
[1] 54.81434
INFO  [16:49:56.065] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -2513.355
[1] -44.78516
[1] -1712.748
[1] -30.75607
[1] 48.85414
[1] 2600.427
[1] -3118.899
[1] -53.69525
[1] -2020.794
[1] -36.19521
INFO  [16:50:21.654] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 27.94358
[1] 1451.266
[1] 32.85543
[1] 1708.506
[1] 37.29166
[1] 1967.198
[1] -121147.5
[1] -2143.187
[1] -2763.939
[1] -48.78073
INFO  [16:50:52.076] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 96.06018
[1] 4835.712
[1] -1541.478
[1] -27.17157
[1] 46.04918
[1] 2370.864
[1] -10034.94
[1] -178.454
[1] 34.52749
[1] 1815.462
INFO  [16:51:18.231] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -160.3166
[1] 139.2515
[1] -276.4821
[1] -4.540282
[1] -166.7153
[1] 24.73563
[1] -291.8356
[1] 182.7471
[1] -88.69652
[1] 79.71084
INFO  [16:52:07.507] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -162.8989
[1] 36.82964
[1] -154.1142
[1] 91.54249
[1] -96.95975
[1] 65.55969
[1] -96.20062
[1] 216.8223
[1] -85018.94
[1] -1892.508
INFO  [16:52:50.023] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -82.23431
[1] 122.879
[1] -134.6251
[1] 163.2556
[1] -347.5462
[1] -5.529543
[1] -47.14783
[1] 176.1506
[1] -112.9745
[1] 77.17948
INFO  [16:53:34.045] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -109.1354
[1] 199.4359
[1] -45.62573
[1] 212.998
[1] -85.05175
[1] 79.06184
[1] -229.4101
[1] -2.870018
[1] -219.2417
[1] -4.789207
INFO  [16:55:07.015] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -49.98808
[1] 158.6392
[1] -33.21469
[1] 157.6918
[1] -293.7976
[1] -5.506024
[1] -75.51798
[1] 123.66
[1] -110.1937
[1] 61.39316
INFO  [16:56:22.967] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -143.3848
[1] 257.5594
[1] -154.7064
[1] 108.1319
[1] 11.42328
[1] 386.7404
[1] -943.1098
[1] -19.60458
[1] -105.2838
[1] 42.23212
INFO  [16:57:49.149] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -108.5175
[1] 4.91666
[1] -57.91175
[1] 6.578738
[1] -47.7553
[1] 20.54042
[1] -21.17347
[1] 43.3416
[1] -52.64964
[1] 21.99394
INFO  [16:58:45.150] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -17.99095
[1] 297.5743
[1] -41.95262
[1] 17.88029
[1] -67.38099
[1] 13.72796
[1] -32.62098
[1] 51.14198
[1] 2213.529
[1] 22031.68
INFO  [16:59:55.649] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -15.4363
[1] 59.36802
[1] -113.6732
[1] 31.06577
[1] -34.08934
[1] 49.20895
[1] -2540.268
[1] -77.03176
[1] -66.11955
[1] -3.306626
INFO  [17:01:17.942] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:01:40.981] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:02:10.998] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:02:29.318] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -248.6268
[1] 430.6113
[1] -595.0055
[1] -10.89023
[1] 14.67456
[1] 679.6421
[1] -487.543
[1] -9.031919
[1] -567.506
[1] -10.55189
INFO  [17:03:38.528] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -351.5281
[1] 305.8759
[1] -162.3228
[1] 232.9494
[1] -580.4438
[1] 13.46137
[1] 13.81346
[1] 701.6658
[1] -831.6513
[1] -16.30275
INFO  [17:04:56.651] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 22.94921
[1] 1121.694
[1] -104.0237
[1] 425.6176
[1] 11.01271
[1] 589.6787
[1] -496.1452
[1] -8.234189
[1] -394.9596
[1] 195.3124
INFO  [17:05:57.377] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -43.54754
[1] 17.55039
[1] -53.75001
[1] 26.8689
[1] -29.91434
[1] 87.73914
[1] -63.06379
[1] 12.93007
[1] -63.2773
[1] 36.26957
INFO  [17:06:43.031] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -58.78363
[1] 39.58301
[1] -118.2468
[1] 5.410492
[1] -65.9533
[1] 40.52813
[1] -13316.72
[1] -240.3495
[1] -40.98639
[1] 29.05538
INFO  [17:07:30.198] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -143.091
[1] -3.155704
[1] -29.88608
[1] 60.01548
[1] -106.8155
[1] 54.76925
[1] -60.94627
[1] 15.40597
[1] -41.95354
[1] 90.88158
INFO  [17:08:09.759] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -116.347
[1] 127.2507
[1] -154.6043
[1] -3.404846
[1] -100.0972
[1] 47.32715
[1] -14.52016
[1] 169.0585
[1] -167.5752
[1] 46.2849
INFO  [17:08:36.706] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -73.70543
[1] 51.02738
[1] -146.6076
[1] 44.938
[1] -256.9508
[1] 22.53587
[1] -238.2197
[1] -4.942008
[1] -173.7663
[1] 97.29086
INFO  [17:09:06.746] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -163.5133
[1] -4.03193
[1] -177.4226
[1] 103.8336
[1] -91.32353
[1] 148.2938
[1] -67.29659
[1] 129.8873
[1] -163.7935
[1] 18.27061
INFO  [17:09:27.276] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 7.374627
[1] 280.4828
[1] -305.9582
[1] 429.9963
[1] -994.0481
[1] -19.89576
[1] -918.7477
[1] -16.19381
[1] -761.0897
[1] -9.442502
INFO  [17:10:22.387] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1643.256
[1] -27.56622
[1] -704.4399
[1] -10.55525
[1] -523.2135
[1] -8.264661
[1] 11.96004
[1] 491.3826
[1] -319.3902
[1] 138.3935
INFO  [17:11:12.946] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -558.6204
[1] -7.611552
[1] 9.337764
[1] 394.0483
[1] -428.1584
[1] -7.542234
[1] -1623.954
[1] -24.92813
[1] -182.8371
[1] 432.8415
INFO  [17:11:51.845] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -48.90041
[1] 2.006302
[1] -44.97754
[1] 32.12119
[1] -41.38829
[1] 12.12312
[1] -55.14795
[1] 74.34352
[1] -65.59433
[1] 18.21905
INFO  [17:13:46.353] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -62.15783
[1] 15.0744
[1] -38.05423
[1] 34.35506
[1] -3.895584
[1] 504.2628
[1] -1076.682
[1] -37.56466
[1] -48.90225
[1] 21.22777
INFO  [17:15:29.548] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1567.218
[1] -41.45451
[1] -44.44722
[1] 37.72013
[1] -11.02686
[1] 30.06057
[1] -4743.711
[1] -141.7786
[1] -55.14681
[1] 0.7870527
INFO  [17:16:41.026] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -383.6519
[1] -6.549211
[1] -638.6977
[1] -9.182217
[1] 63.81073
[1] 3370.575
[1] -411.5563
[1] 340.8704
[1] -410.3492
[1] -6.241972
INFO  [17:17:08.562] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 3565.35
[1] 130607.1
[1] -252.1936
[1] 135.2287
[1] -499.366
[1] -7.801323
[1] 6.889627
[1] 276.5191
[1] -406.9443
[1] 48.46077
INFO  [17:17:31.411] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -422.9295
[1] -7.550516
[1] 12.1128
[1] 481.7072
[1] -110.258
[1] 267.5112
[1] -319.4501
[1] 100.1742
[1] 8.493626
[1] 356.9763
INFO  [17:17:54.684] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -82.12624
[1] -3.195242
[1] -2745.406
[1] -130.9901
[1] -91.05922
[1] 58.67933
[1] -57.68939
[1] 20.23756
[1] -26.8743
[1] 46.73244
INFO  [17:18:35.074] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -205.4186
[1] 18.44987
[1] -52.49496
[1] 21.29864
[1] -1078.807
[1] -40.62695
[1] -31.18733
[1] 228.4077
[1] -50.03132
[1] 48.07781
INFO  [17:19:17.882] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -326.5825
[1] -3.833406
[1] 280.3528
[1] 6965.955
[1] -35.29426
[1] 20.17792
[1] -31.05996
[1] 86.10678
[1] -125.6973
[1] 85.70333
INFO  [17:19:55.831] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:20:48.680] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:21:36.499] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:22:28.186] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -317.2938
[1] -7.547476
[1] -358.6904
[1] -7.060967
[1] 189.2516
[1] 7779.613
[1] -207.7212
[1] 49.97666
[1] 8.995803
[1] 402.1155
INFO  [17:22:50.547] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -421.9106
[1] -6.715463
[1] -843.2815
[1] -16.65681
[1] -256.4342
[1] 45.76978
[1] -17567.57
[1] -458.0127
[1] 4.047164
[1] 297.9234
INFO  [17:23:15.480] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 9.169427
[1] 475.7546
[1] 5.677106
[1] 271.7553
[1] -273.8018
[1] 102.5983
[1] -110.2547
[1] 134.8021
[1] -325.8778
[1] -6.424744
INFO  [17:23:47.120] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -144.0094
[1] 3.777507
[1] -68.6356
[1] 32.23773
[1] -201.0478
[1] -1.071989
[1] -49.90016
[1] 30.16103
[1] -135.2646
[1] -3.787441
INFO  [17:24:21.340] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -77.39121
[1] 25.21264
[1] -30.3058
[1] 49.51279
[1] -161.6868
[1] 185.4772
[1] -6690.809
[1] -133.9931
[1] -104.8739
[1] 9.683312
INFO  [17:24:59.572] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -217.4234
[1] -4.114665
[1] -42.0969
[1] 27.73637
[1] -295.0971
[1] -4.152745
[1] -21.00781
[1] 95.78237
[1] -108.7153
[1] 57.35543
INFO  [17:25:30.478] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -115.0345
[1] 1.460067
[1] -122.3601
[1] 15.81686
[1] -43.65641
[1] 30.91329
[1] -112.0996
[1] 90.75939
[1] -1479.228
[1] -40.93941
INFO  [17:25:58.626] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -72.06139
[1] 49.80196
[1] -3012.364
[1] -83.71815
[1] -32.55978
[1] 36.65776
[1] -23.22059
[1] 39.27846
[1] -167.5241
[1] 10.19671
INFO  [17:26:41.926] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 80.18335
[1] 2363.712
[1] -26.89842
[1] 37.68366
[1] -55.22682
[1] 73.10229
[1] -2599.879
[1] -79.20357
[1] -1569.78
[1] -4.046412
INFO  [17:27:28.706] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:27:56.141] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:28:28.700] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:29:05.072] [mlr3] Finished benchmark
INFO  [17:29:05.984] [bbotk] Result of batch 1:
INFO  [17:29:06.030] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:29:06.030] [bbotk]              1.4942776                         0.2114204
INFO  [17:29:06.030] [bbotk]             -5.4134779                         0.6614204
INFO  [17:29:06.030] [bbotk]              4.9481553                         0.8864204
INFO  [17:29:06.030] [bbotk]             -1.9596004                         0.4364204
INFO  [17:29:06.030] [bbotk]             -0.2326616                         0.9989204
INFO  [17:29:06.030] [bbotk]              6.6750941                         0.5489204
INFO  [17:29:06.030] [bbotk]              3.2212165                         0.7739204
INFO  [17:29:06.030] [bbotk]             -3.6865392                         0.3239204
INFO  [17:29:06.030] [bbotk]             -1.0961310                         0.1551704
INFO  [17:29:06.030] [bbotk]              5.8116247                         0.6051704
INFO  [17:29:06.030] [bbotk]              2.3577471                         0.3801704
INFO  [17:29:06.030] [bbotk]             -4.5500086                         0.8301704
INFO  [17:29:06.030] [bbotk]              4.0846859                         0.2676704
INFO  [17:29:06.030] [bbotk]             -2.8230698                         0.7176704
INFO  [17:29:06.030] [bbotk]             -6.2769473                         0.4926704
INFO  [17:29:06.030] [bbotk]              0.6308082                         0.9426704
INFO  [17:29:06.030] [bbotk]             -4.9817433                         0.3520454
INFO  [17:29:06.030] [bbotk]              1.9260124                         0.8020454
INFO  [17:29:06.030] [bbotk]             -1.5278657                         0.5770454
INFO  [17:29:06.030] [bbotk]              5.3798900                         0.1270454
INFO  [17:29:06.030] [bbotk]             -6.7086821                         0.9145454
INFO  [17:29:06.030] [bbotk]              0.1990735                         0.4645454
INFO  [17:29:06.030] [bbotk]             -3.2548045                         0.2395454
INFO  [17:29:06.030] [bbotk]              3.6529512                         0.6895454
INFO  [17:29:06.030] [bbotk]             -4.1182739                         0.7457954
INFO  [17:29:06.030] [bbotk]              2.7894818                         0.2957954
INFO  [17:29:06.030] [bbotk]             -0.6643963                         0.5207954
INFO  [17:29:06.030] [bbotk]              6.2433594                         0.9707954
INFO  [17:29:06.030] [bbotk]             -5.8452126                         0.1832954
INFO  [17:29:06.030] [bbotk]              1.0625429                         0.6332954
INFO  [17:29:06.030] [bbotk]             -2.3913351                         0.8582954
INFO  [17:29:06.030] [bbotk]              4.5164206                         0.4082954
INFO  [17:29:06.030] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:29:06.030] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:29:06.030] [bbotk]                         0.8871933          -7.4507562             -1.5068825
INFO  [17:29:06.030] [bbotk]                         0.4371933          -2.8455863              5.4008728
INFO  [17:29:06.030] [bbotk]                         0.2121933          -0.5430012             -4.9607601
INFO  [17:29:06.030] [bbotk]                         0.6621933          -5.1481711              1.9469952
INFO  [17:29:06.030] [bbotk]                         0.9996933          -6.2994637              0.2200563
INFO  [17:29:06.030] [bbotk]                         0.5496933          -1.6942938             -6.6876990
INFO  [17:29:06.030] [bbotk]                         0.7746933          -8.6020489             -3.2338213
INFO  [17:29:06.030] [bbotk]                         0.3246933          -3.9968789              3.6739340
INFO  [17:29:06.030] [bbotk]                         0.4934433          -9.1776951             -4.0972907
INFO  [17:29:06.030] [bbotk]                         0.9434433          -4.5725251              2.8104646
INFO  [17:29:06.030] [bbotk]                         0.2684433          -6.8751100              6.2643422
INFO  [17:29:06.030] [bbotk]                         0.7184433          -2.2699401             -0.6434131
INFO  [17:29:06.030] [bbotk]                         0.6059433          -3.4212326              1.0835257
INFO  [17:29:06.030] [bbotk]                         0.1559433          -8.0264025             -5.8242295
INFO  [17:29:06.030] [bbotk]                         0.8309433          -1.1186475             -2.3703519
INFO  [17:29:06.030] [bbotk]                         0.3809433          -5.7238174              4.5374034
INFO  [17:29:06.030] [bbotk]                         0.3528183          -7.1629331              0.6517910
INFO  [17:29:06.030] [bbotk]                         0.8028183          -2.5577632             -6.2559643
INFO  [17:29:06.030] [bbotk]                         0.5778183          -0.2551781              4.1056687
INFO  [17:29:06.030] [bbotk]                         0.1278183          -4.8603480             -2.8020866
INFO  [17:29:06.030] [bbotk]                         0.2403183          -8.3142257              2.3787299
INFO  [17:29:06.030] [bbotk]                         0.6903183          -3.7090557             -4.5290254
INFO  [17:29:06.030] [bbotk]                         0.9153183          -1.4064706              5.8326075
INFO  [17:29:06.030] [bbotk]                         0.4653183          -6.0116406             -1.0751478
INFO  [17:29:06.030] [bbotk]                         0.8590683          -5.4359943             -3.6655560
INFO  [17:29:06.030] [bbotk]                         0.4090683          -0.8308244              3.2421993
INFO  [17:29:06.030] [bbotk]                         0.1840683          -3.1334095             -0.2116784
INFO  [17:29:06.030] [bbotk]                         0.6340683          -7.7385794              6.6960769
INFO  [17:29:06.030] [bbotk]                         0.7465683          -6.5872868             -5.3924948
INFO  [17:29:06.030] [bbotk]                         0.2965683          -1.9821169              1.5152605
INFO  [17:29:06.030] [bbotk]                         0.5215683          -4.2847020             -1.9386172
INFO  [17:29:06.030] [bbotk]                         0.9715683          -8.8898720              4.9691381
INFO  [17:29:06.030] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:29:06.030] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:29:06.030] [bbotk]                         17                    3835                 0.4405780
INFO  [17:29:06.030] [bbotk]                          7                    1335                 0.8905780
INFO  [17:29:06.030] [bbotk]                         12                      85                 0.2155780
INFO  [17:29:06.030] [bbotk]                          2                    2585                 0.6655780
INFO  [17:29:06.030] [bbotk]                          9                     710                 0.1030781
INFO  [17:29:06.030] [bbotk]                         19                    3210                 0.5530780
INFO  [17:29:06.030] [bbotk]                         14                    1960                 0.7780780
INFO  [17:29:06.030] [bbotk]                          4                    4460                 0.3280780
INFO  [17:29:06.030] [bbotk]                          6                    4772                 0.3843280
INFO  [17:29:06.030] [bbotk]                         16                    2272                 0.8343280
INFO  [17:29:06.030] [bbotk]                         11                    3522                 0.6093280
INFO  [17:29:06.030] [bbotk]                          1                    1022                 0.1593281
INFO  [17:29:06.030] [bbotk]                         13                    4147                 0.4968280
INFO  [17:29:06.030] [bbotk]                          3                    1647                 0.9468280
INFO  [17:29:06.030] [bbotk]                          8                    2897                 0.7218280
INFO  [17:29:06.030] [bbotk]                         18                     397                 0.2718280
INFO  [17:29:06.030] [bbotk]                         16                    2116                 0.6374530
INFO  [17:29:06.030] [bbotk]                          6                    4616                 0.1874531
INFO  [17:29:06.030] [bbotk]                         11                    3366                 0.8624530
INFO  [17:29:06.030] [bbotk]                          1                     866                 0.4124530
INFO  [17:29:06.030] [bbotk]                         14                    3991                 0.2999530
INFO  [17:29:06.030] [bbotk]                          4                    1491                 0.7499530
INFO  [17:29:06.030] [bbotk]                         19                     241                 0.5249530
INFO  [17:29:06.030] [bbotk]                          9                    2741                 0.9749530
INFO  [17:29:06.030] [bbotk]                         20                    3678                 0.8062030
INFO  [17:29:06.030] [bbotk]                         10                    1178                 0.3562030
INFO  [17:29:06.030] [bbotk]                         15                    2428                 0.5812030
INFO  [17:29:06.030] [bbotk]                          5                    4928                 0.1312031
INFO  [17:29:06.030] [bbotk]                         13                     553                 0.4687030
INFO  [17:29:06.030] [bbotk]                          3                    3053                 0.9187030
INFO  [17:29:06.030] [bbotk]                         18                    4303                 0.2437030
INFO  [17:29:06.030] [bbotk]                          8                    1803                 0.6937030
INFO  [17:29:06.030] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:29:06.030] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:29:06.030] [bbotk]      0.03703776        0      0          211.875
INFO  [17:29:06.030] [bbotk]      0.03197104        0      0          176.322
INFO  [17:29:06.030] [bbotk]      0.30467982        0      0           71.774
INFO  [17:29:06.030] [bbotk]      0.02681970        0      0          165.952
INFO  [17:29:06.030] [bbotk]      0.04560262        0      0          120.742
INFO  [17:29:06.030] [bbotk]      0.30467982        0      0          148.700
INFO  [17:29:06.030] [bbotk]      0.18806388        0      0          276.327
INFO  [17:29:06.030] [bbotk]      0.03240450        0      0          213.076
INFO  [17:29:06.030] [bbotk]      0.05944809        0      0          300.395
INFO  [17:29:06.030] [bbotk]      0.30467982        0      0          190.007
INFO  [17:29:06.030] [bbotk]      0.22865136        0      0          240.331
INFO  [17:29:06.030] [bbotk]      0.02472427        0      0          101.393
INFO  [17:29:06.030] [bbotk]      0.30467982        0      0          186.894
INFO  [17:29:06.030] [bbotk]      0.05553688        0      0          138.885
INFO  [17:29:06.030] [bbotk]      0.02193095        0      0          113.943
INFO  [17:29:06.030] [bbotk]      0.21906605        0      0           81.766
INFO  [17:29:06.030] [bbotk]      0.03581934        0      0          135.443
INFO  [17:29:06.030] [bbotk]      0.04098657        0      0          254.215
INFO  [17:29:06.030] [bbotk]      0.02269217        0      0          208.142
INFO  [17:29:06.030] [bbotk]      0.30467982        0      0           70.870
INFO  [17:29:06.030] [bbotk]      0.05839169        0      0          207.503
INFO  [17:29:06.030] [bbotk]      0.02309027        0      0          130.665
INFO  [17:29:06.030] [bbotk]      0.03690154        0      0           76.553
INFO  [17:29:06.030] [bbotk]      0.06382385        0      0          143.020
INFO  [17:29:06.030] [bbotk]      0.02184449        0      0          288.545
INFO  [17:29:06.030] [bbotk]      0.04813369        0      0           73.269
INFO  [17:29:06.030] [bbotk]      0.02289775        0      0          120.826
INFO  [17:29:06.030] [bbotk]      0.30467982        0      0          151.952
INFO  [17:29:06.030] [bbotk]      0.03904673        0      0           78.331
INFO  [17:29:06.030] [bbotk]      0.03062397        0      0          102.853
INFO  [17:29:06.030] [bbotk]      0.02392005        0      0          117.865
INFO  [17:29:06.030] [bbotk]      0.30467982        0      0           87.936
INFO  [17:29:06.030] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:29:06.030] [bbotk]                                 uhash
INFO  [17:29:06.030] [bbotk]  50dd8b15-73fe-4f5d-bacd-ce006711418b
INFO  [17:29:06.030] [bbotk]  8c9b35a5-4fb8-4c2b-8d24-8386080a71e7
INFO  [17:29:06.030] [bbotk]  20cd3217-607b-4528-966f-9b95bf2b69c3
INFO  [17:29:06.030] [bbotk]  4c407038-fc4c-4cd4-a51f-a94c5b4d30e5
INFO  [17:29:06.030] [bbotk]  d984a6a0-8ab2-49cd-92ec-0a645a6273de
INFO  [17:29:06.030] [bbotk]  e4b3630a-3d5f-4bfb-97df-21dda7c3634b
INFO  [17:29:06.030] [bbotk]  821cfcad-9eda-4f42-a64a-a8fe1a21d4cf
INFO  [17:29:06.030] [bbotk]  c1e2c26f-804f-4397-b732-0bc656051574
INFO  [17:29:06.030] [bbotk]  b9e5ccab-5daa-492d-800e-368d80a758f2
INFO  [17:29:06.030] [bbotk]  59de69bc-7add-4994-8e11-3eedd659d678
INFO  [17:29:06.030] [bbotk]  dce37d9b-ff8e-4c43-bafe-03f81611cbdd
INFO  [17:29:06.030] [bbotk]  0cce2011-6900-4c12-8fa3-d09becb787fc
INFO  [17:29:06.030] [bbotk]  c0afe082-aec1-4db9-acf4-b7b638717132
INFO  [17:29:06.030] [bbotk]  cca791ec-0e5f-4b49-a804-7224625cfb59
INFO  [17:29:06.030] [bbotk]  3c472ee8-634c-4aa9-b473-82752d844637
INFO  [17:29:06.030] [bbotk]  7f7688d9-0abe-4a04-b8bf-1bb5c37ed605
INFO  [17:29:06.030] [bbotk]  1376f392-f5d0-4435-a490-9963d781afa6
INFO  [17:29:06.030] [bbotk]  7ff9275e-5a8d-402c-8d0c-04842c390c59
INFO  [17:29:06.030] [bbotk]  7cdeabe4-bbd1-489f-aaba-210664c3d81c
INFO  [17:29:06.030] [bbotk]  aee3e0df-df34-4e2b-bf14-c93c5159732c
INFO  [17:29:06.030] [bbotk]  e499cda5-84ec-48d8-92b0-5552f56bf928
INFO  [17:29:06.030] [bbotk]  e1fd357f-2c81-469a-80aa-6e162eef649e
INFO  [17:29:06.030] [bbotk]  e4ff601e-270f-44c8-8093-a5bf2b2d0a67
INFO  [17:29:06.030] [bbotk]  78c8e566-b302-48e9-bb91-aeeebed722e0
INFO  [17:29:06.030] [bbotk]  0293f715-a51f-4717-94dc-cd30a9413eab
INFO  [17:29:06.030] [bbotk]  7864ebbd-6f0f-46e5-aea5-ade20f9c5e8f
INFO  [17:29:06.030] [bbotk]  58b1b2d6-64f9-4e33-ad37-13f44aee7367
INFO  [17:29:06.030] [bbotk]  7cf241de-9a84-49f1-9739-f48ab5397b20
INFO  [17:29:06.030] [bbotk]  50ecaf94-70a4-4d57-9e18-4df48a87716f
INFO  [17:29:06.030] [bbotk]  5f3d38c2-e42e-4efc-9a6c-b0f694d5b395
INFO  [17:29:06.030] [bbotk]  11f15e69-479d-4e78-9b34-268d0253ef6d
INFO  [17:29:06.030] [bbotk]  52a1f653-ecff-44da-8105-4cd63e260961
INFO  [17:29:06.030] [bbotk]                                 uhash
INFO  [17:29:12.511] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 32 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:29:17.688] [bbotk] Evaluating 1 configuration(s)
INFO  [17:29:17.915] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:29:17.995] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -62.72879
[1] -3.199107
[1] -75.28759
[1] 10.49747
[1] -48.63257
[1] 26.97848
[1] -77.04741
[1] 26.68041
[1] -25.34961
[1] 68.56276
INFO  [17:30:07.063] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -275.9591
[1] 5.336492
[1] -40.76228
[1] 36.19507
[1] 356.5728
[1] 3826.82
[1] -34.44469
[1] 24.47281
[1] -68.91445
[1] 18.62475
INFO  [17:30:36.317] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -109.5442
[1] -3.428603
[1] -37.60297
[1] 17.83069
[1] -25.12352
[1] 60.41929
[1] -36.95922
[1] 50.81361
[1] -8045.517
[1] -177.3826
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:31:27.949] [mlr3] Finished benchmark
INFO  [17:31:28.191] [bbotk] Result of batch 2:
INFO  [17:31:28.218] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:31:28.218] [bbotk]             -0.2685909                         0.4181638
INFO  [17:31:28.218] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:31:28.218] [bbotk]                         0.8697006          -0.7599416              -5.258144
INFO  [17:31:28.218] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:31:28.218] [bbotk]                         11                    3780                 0.7752177
INFO  [17:31:28.218] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:31:28.218] [bbotk]  0.03535222 <list[8]>              FALSE      0.0220851        0      0
INFO  [17:31:28.218] [bbotk]  runtime_learners                                uhash
INFO  [17:31:28.218] [bbotk]            129.28 3e6c4f0b-303a-4305-ada8-6e658e636368
INFO  [17:31:29.773] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 33 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:31:33.987] [bbotk] Evaluating 1 configuration(s)
INFO  [17:31:34.118] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:31:34.227] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -21.86848
[1] 48.43588
[1] -38.21309
[1] 12.00056
[1] -71.86484
[1] -3.918455
[1] -57.38078
[1] 59.14669
[1] -431.4398
[1] -4.186946
INFO  [17:32:06.529] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -2.455136e+16
[1] 1.43901e+16
[1] -64.95669
[1] 22.29596
[1] 0.2786587
[1] 213.1697
[1] 1303.695
[1] 22818.36
[1] -32.44046
[1] 17.9057
INFO  [17:32:46.110] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -261.4692
[1] 22.97482
[1] 61.71086
[1] 1041.5
[1] -3727.363
[1] -149.3836
[1] -38.34671
[1] 55.08091
[1] -263.8525
[1] 2.777885
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:33:18.391] [mlr3] Finished benchmark
INFO  [17:33:18.499] [bbotk] Result of batch 3:
INFO  [17:33:18.575] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:33:18.575] [bbotk]               -1.20885                         0.4284162
INFO  [17:33:18.575] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:33:18.575] [bbotk]                         0.9539326           -0.778618               -3.63186
INFO  [17:33:18.575] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:33:18.575] [bbotk]                          4                    3276                 0.5412984
INFO  [17:33:18.575] [bbotk]    acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:33:18.575] [bbotk]  0.032536 <list[8]>              FALSE     0.02077882        0      0
INFO  [17:33:18.575] [bbotk]  runtime_learners                                uhash
INFO  [17:33:18.575] [bbotk]           103.378 43b5fc9f-df02-4a07-9e82-f8fb0e99e9bc
INFO  [17:33:19.190] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 34 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:33:22.959] [bbotk] Evaluating 1 configuration(s)
INFO  [17:33:23.113] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:33:23.289] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -113.823
[1] 10.04636
[1] -79.79524
[1] 67.27706
[1] -12.51885
[1] 51.95524
[1] -26.50408
[1] 17.05421
[1] -2587.975
[1] -79.59304
INFO  [17:34:02.310] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -52.04189
[1] 118.5898
[1] -26.36042
[1] 24.8105
[1] -362.6268
[1] 6.714716
[1] -2890.552
[1] -147.1017
[1] -63.97192
[1] 91.92362
INFO  [17:34:50.069] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -249.6278
[1] -3.775002
[1] -184.6166
[1] 27.74356
[1] -1610.261
[1] -35.51521
[1] -34.42608
[1] 47.05881
[1] -38.47286
[1] 29.20052
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:35:17.572] [mlr3] Finished benchmark
INFO  [17:35:18.557] [bbotk] Result of batch 4:
INFO  [17:35:18.766] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:35:18.766] [bbotk]              -1.652468                         0.6034216
INFO  [17:35:18.766] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:35:18.766] [bbotk]                         0.8679705           -1.526485              -5.549619
INFO  [17:35:18.766] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:35:18.766] [bbotk]                         10                    3331                  0.581738
INFO  [17:35:18.766] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:35:18.766] [bbotk]  0.02896191 <list[8]>              FALSE      0.0207402        0      0
INFO  [17:35:18.766] [bbotk]  runtime_learners                                uhash
INFO  [17:35:18.766] [bbotk]           111.466 44970088-c090-4792-b7ae-dc30246b7168
INFO  [17:35:20.959] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 35 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:35:29.597] [bbotk] Evaluating 1 configuration(s)
INFO  [17:35:29.689] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:35:29.807] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -63.14972
[1] 10.55554
[1] -36.47739
[1] 15.80098
[1] -27.1737
[1] 27.88767
[1] -34.27778
[1] 11.84713
[1] -1550.835
[1] -76.76361
INFO  [17:36:01.089] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -242.0916
[1] 10.7026
[1] -20.2684
[1] 16.52391
[1] -18.2382
[1] 57.28206
[1] -1694.477
[1] -32.53258
[1] -43.12127
[1] 22.21351
INFO  [17:36:47.209] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -79.28477
[1] 73.24437
[1] -102.5426
[1] -3.986586
[1] -19.08848
[1] 28.56699
[1] -12.78827
[1] 23.38599
[1] -42.14061
[1] 20.91313
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:37:23.977] [mlr3] Finished benchmark
INFO  [17:37:24.161] [bbotk] Result of batch 5:
INFO  [17:37:24.294] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:37:24.294] [bbotk]              -3.036522                          0.530915
INFO  [17:37:24.294] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:37:24.294] [bbotk]                         0.6203009          -0.2148378              -1.563767
INFO  [17:37:24.294] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:37:24.294] [bbotk]                          7                    3969                 0.5843973
INFO  [17:37:24.294] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:37:24.294] [bbotk]  0.02623542 <list[8]>              FALSE     0.02241517        0      0
INFO  [17:37:24.294] [bbotk]  runtime_learners                                uhash
INFO  [17:37:24.294] [bbotk]           111.461 b2961069-2e6d-4c2b-8b3c-1903455548fc
INFO  [17:37:25.367] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 36 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:37:28.844] [bbotk] Evaluating 1 configuration(s)
INFO  [17:37:28.880] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:37:28.955] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -46.08967
[1] 34.44345
[1] -23.59729
[1] 26.56832
[1] -54.79213
[1] 20.9072
[1] -32.9526
[1] 25.00885
[1] -8816.047
[1] -476.6907
INFO  [17:37:51.563] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1322.573
[1] -54.1571
[1] -68.99308
[1] 23.42607
[1] -41.62144
[1] 14.51536
[1] -25.50495
[1] 81.07208
[1] 43.575
[1] 881.7129
INFO  [17:38:18.119] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -80.81422
[1] -3.131259
[1] -63.52134
[1] 15.86444
[1] -44.58652
[1] 16.67361
[1] -9.622726
[1] 59.97336
[1] -35.1565
[1] 52.53878
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:38:55.265] [mlr3] Finished benchmark
INFO  [17:38:55.538] [bbotk] Result of batch 6:
INFO  [17:38:55.720] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:38:55.720] [bbotk]               -0.40987                           0.51949
INFO  [17:38:55.720] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:38:55.720] [bbotk]                         0.8209591           -0.616653              -4.501935
INFO  [17:38:55.720] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:38:55.720] [bbotk]                          3                    1835                 0.9129839
INFO  [17:38:55.720] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:38:55.720] [bbotk]  0.02526991 <list[8]>              FALSE     0.02306444        0      0
INFO  [17:38:55.720] [bbotk]  runtime_learners                                uhash
INFO  [17:38:55.720] [bbotk]            85.646 d4674ca1-0280-4c15-9c51-e79d6a4e0bba
INFO  [17:38:56.740] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 37 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:39:04.536] [bbotk] Evaluating 1 configuration(s)
INFO  [17:39:04.868] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:39:05.327] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -233.6093
[1] 12.07746
[1] -120.3107
[1] 8.324646
[1] -34.47891
[1] 51.99019
[1] -71.40139
[1] 34.93035
[1] -92.15771
[1] 10.92234
INFO  [17:39:40.522] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -66.79085
[1] 28.65668
[1] -41.47598
[1] 19.32209
[1] -31.48433
[1] 60.11172
[1] -4620.933
[1] -108.2007
[1] -79.05628
[1] 16.42786
INFO  [17:40:15.697] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -21.74207
[1] 60.80494
[1] -70.75019
[1] 31.8122
[1] -252.1835
[1] -3.903784
[1] 87.90902
[1] 1355.071
[1] -28.35648
[1] 13.47124
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:40:45.175] [mlr3] Finished benchmark
INFO  [17:40:45.357] [bbotk] Result of batch 7:
INFO  [17:40:45.405] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:40:45.405] [bbotk]              -4.277111                         0.4881454
INFO  [17:40:45.405] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:40:45.405] [bbotk]                         0.8880279           -1.804055             -0.8533603
INFO  [17:40:45.405] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:40:45.405] [bbotk]                         12                    2376                 0.5449056
INFO  [17:40:45.405] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:40:45.405] [bbotk]  0.0266025 <list[8]>              FALSE     0.02179064        0      0
INFO  [17:40:45.405] [bbotk]  runtime_learners                                uhash
INFO  [17:40:45.405] [bbotk]            99.233 72512118-369b-4805-8fc7-c830477ca5af
WARN  [17:40:47.763] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:40:47.791] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 38 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:40:53.807] [bbotk] Evaluating 1 configuration(s)
INFO  [17:40:54.197] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:40:54.584] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -178.9757
[1] 37.32527
[1] -39.63249
[1] 5.310313
[1] 62.20574
[1] 1620.229
[1] -107.6473
[1] 4.735419
[1] -152.7778
[1] -3.652902
INFO  [17:41:34.175] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -32.28471
[1] 21.30167
[1] -201.7681
[1] 16.07874
[1] -7.370917e+15
[1] 3.525535e+16
[1] -80.75515
[1] 7.779499
[1] -13.16112
[1] 38.51036
INFO  [17:42:17.519] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -30.24829
[1] 30.25751
[1] -84.22175
[1] -4.095719
[1] -267.6377
[1] -2.968124
[1] -87.90267
[1] 61.74711
[1] -4354.882
[1] -100.3815
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:42:56.995] [mlr3] Finished benchmark
INFO  [17:42:57.369] [bbotk] Result of batch 8:
INFO  [17:42:57.512] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:42:57.512] [bbotk]              0.5035003                         0.5140804
INFO  [17:42:57.512] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:42:57.512] [bbotk]                         0.9395858          -0.3966439              -5.050436
INFO  [17:42:57.512] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:42:57.512] [bbotk]                          4                    2808                  0.861592
INFO  [17:42:57.512] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:42:57.512] [bbotk]  0.02543529 <list[8]>              FALSE     0.02610546        0      0
INFO  [17:42:57.512] [bbotk]  runtime_learners                                uhash
INFO  [17:42:57.512] [bbotk]           121.239 35732c85-a1b2-45cd-8e47-2fb61e1e6f77
INFO  [17:42:58.465] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 39 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:43:04.444] [bbotk] Evaluating 1 configuration(s)
INFO  [17:43:04.907] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:43:05.139] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -57.22414
[1] 14.89165
[1] -45.15892
[1] 2.744474
[1] -50.21714
[1] 19.13069
[1] -56.55515
[1] 72.48816
[1] -66.87077
[1] 3.038931
INFO  [17:43:36.178] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 493.8082
[1] 6985.91
[1] -78.84373
[1] 1.445009
[1] -69.60775
[1] 58.96597
[1] -393.8491
[1] 25.48063
[1] -36.21935
[1] 9.627905
INFO  [17:44:03.225] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -50.92086
[1] 76.54515
[1] -14.7546
[1] 73.06052
[1] -56.01504
[1] 49.0933
[1] -27.98081
[1] 31.95811
[1] -403.5498
[1] 2.477998
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:44:29.740] [mlr3] Finished benchmark
INFO  [17:44:29.824] [bbotk] Result of batch 9:
INFO  [17:44:29.857] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:44:29.857] [bbotk]              -1.922276                         0.2887207
INFO  [17:44:29.857] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:44:29.857] [bbotk]                         0.6341583          -0.9022921              -2.861881
INFO  [17:44:29.857] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:44:29.857] [bbotk]                         13                    2306                 0.5132614
INFO  [17:44:29.857] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:44:29.857] [bbotk]  0.02359214 <list[8]>              FALSE     0.02552918        0      0
INFO  [17:44:29.857] [bbotk]  runtime_learners                                uhash
INFO  [17:44:29.857] [bbotk]             83.67 43740348-7521-4896-aff3-e6ce45a7749d
WARN  [17:44:32.217] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:44:32.260] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 40 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:44:38.835] [bbotk] Evaluating 1 configuration(s)
INFO  [17:44:38.969] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:44:39.144] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -34.87297
[1] 53.04516
[1] -23.07526
[1] 28.76165
[1] -387.1604
[1] 20.98947
[1] -46.68682
[1] 12.96375
[1] -54.7202
[1] 5.858334
INFO  [17:45:20.154] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -25.17664
[1] 27.0585
[1] -586.1671
[1] -33.16516
[1] 1.245414e+15
[1] 3.09481e+16
[1] -1384.967
[1] -99.6698
[1] -46.31286
[1] 26.45212
INFO  [17:45:54.760] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -49.80216
[1] 21.14325
[1] -55.63803
[1] 64.28864
[1] -33.8009
[1] 34.64148
[1] -62.52703
[1] 2.805576
[1] -60.27172
[1] 12.74631
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:46:44.722] [mlr3] Finished benchmark
INFO  [17:46:44.872] [bbotk] Result of batch 10:
INFO  [17:46:44.892] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:46:44.892] [bbotk]              -4.109243                         0.5573419
INFO  [17:46:44.892] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:46:44.892] [bbotk]                         0.5634787           -2.549211             -0.5854091
INFO  [17:46:44.892] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:46:44.892] [bbotk]                          9                    3099                 0.7448463
INFO  [17:46:44.892] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:46:44.892] [bbotk]  0.02159151 <list[8]>              FALSE     0.02038094        0      0
INFO  [17:46:44.892] [bbotk]  runtime_learners                                uhash
INFO  [17:46:44.892] [bbotk]           123.834 4fc68137-2f56-43a1-ae34-2c6c6b21def0
INFO  [17:46:46.106] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 41 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:46:52.043] [bbotk] Evaluating 1 configuration(s)
INFO  [17:46:52.140] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:46:52.242] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -78.02248
[1] 45.39147
[1] -57.78673
[1] -2.807596
[1] -562.12
[1] -29.65896
[1] -23.84152
[1] 26.04987
[1] -61.78434
[1] 10.79983
INFO  [17:47:22.582] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -40.99888
[1] 29.44529
[1] -36.66505
[1] 39.56313
[1] -1567.158
[1] -47.17602
[1] -30.53626
[1] 241.5822
[1] -72.86025
[1] 43.64345
INFO  [17:47:50.658] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -62.99229
[1] 53.83366
[1] -31.23896
[1] 13.74043
[1] -75.86253
[1] 24.68414
[1] -36.25349
[1] 22.03488
[1] -51.31165
[1] 24.71201
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:48:30.047] [mlr3] Finished benchmark
INFO  [17:48:30.161] [bbotk] Result of batch 11:
INFO  [17:48:30.190] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:48:30.190] [bbotk]             -0.4783493                         0.8550058
INFO  [17:48:30.190] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:48:30.190] [bbotk]                          0.445169          -0.1522497             -0.3067958
INFO  [17:48:30.190] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:48:30.190] [bbotk]                          5                    2166                 0.7258558
INFO  [17:48:30.190] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:48:30.190] [bbotk]  0.06263213 <list[8]>              FALSE     0.02391687        0      0
INFO  [17:48:30.190] [bbotk]  runtime_learners                                uhash
INFO  [17:48:30.190] [bbotk]            95.469 f9778770-1845-499e-a35e-f2165c9b9d57
INFO  [17:48:32.103] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 42 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:48:37.706] [bbotk] Evaluating 1 configuration(s)
INFO  [17:48:37.843] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:48:37.953] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -82.06606
[1] 28.07166
[1] -35.98672
[1] 41.96663
[1] -72.30959
[1] -0.9269454
[1] -58.47393
[1] 17.61072
[1] -39.00099
[1] 13.17575
INFO  [17:49:18.524] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -90.39009
[1] 44.55376
[1] -1666.173
[1] -33.64775
[1] -69.72386
[1] 12.16731
[1] -40.02105
[1] 18.8822
[1] -20.73486
[1] 90.82403
INFO  [17:49:57.925] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -3.442658e+16
[1] 2.251174e+15
[1] -21.925
[1] 44.14563
[1] -38.36127
[1] 22.78756
[1] -15.04592
[1] 84.40424
[1] -99.17608
[1] -4.045313
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:50:44.469] [mlr3] Finished benchmark
INFO  [17:50:44.630] [bbotk] Result of batch 12:
INFO  [17:50:44.721] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:50:44.721] [bbotk]            -0.06713429                         0.4186198
INFO  [17:50:44.721] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:50:44.721] [bbotk]                         0.6460006          -0.5357406              -2.310704
INFO  [17:50:44.721] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:50:44.721] [bbotk]                          7                    3788                 0.8751774
INFO  [17:50:44.721] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:50:44.721] [bbotk]  0.02267295 <list[8]>              FALSE      0.0235607        0      0
INFO  [17:50:44.721] [bbotk]  runtime_learners                                uhash
INFO  [17:50:44.721] [bbotk]           125.336 07b0e3bd-f60e-48f0-a99d-c2d7d68de675
WARN  [17:50:46.526] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:50:46.643] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 43 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:50:55.220] [bbotk] Evaluating 1 configuration(s)
INFO  [17:50:55.330] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:50:55.374] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -167.2956
[1] 23.63697
[1] -115.8798
[1] 205.6942
[1] -23290.26
[1] -590.3376
[1] -151.2458
[1] -2.572074
[1] -66.35493
[1] 61.78902
INFO  [17:51:18.677] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -125.4539
[1] 42.78756
[1] -140.6794
[1] -4.752618
[1] -71.60944
[1] 36.70209
[1] -209.0309
[1] 30.26404
[1] -9286.927
[1] -102.93
INFO  [17:51:40.490] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -346.7981
[1] -4.427098
[1] -117.7597
[1] 94.27693
[1] -254.4461
[1] 12.71252
[1] -64.28508
[1] 41.15045
[1] -2916.024
[1] 455.3298
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:52:01.362] [mlr3] Finished benchmark
INFO  [17:52:01.448] [bbotk] Result of batch 13:
INFO  [17:52:01.555] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:52:01.555] [bbotk]               1.488644                         0.1452047
INFO  [17:52:01.555] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:52:01.555] [bbotk]                         0.8776888          -0.5012012               3.141436
INFO  [17:52:01.555] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:52:01.555] [bbotk]                          7                    1102                 0.3665698
INFO  [17:52:01.555] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:52:01.555] [bbotk]  0.06885698 <list[8]>              FALSE      0.0350756        0      0
INFO  [17:52:01.555] [bbotk]  runtime_learners                                uhash
INFO  [17:52:01.555] [bbotk]            65.108 1c163481-3291-4e1d-a8ff-fc06d0ac6933
INFO  [17:52:03.212] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 44 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:52:18.868] [bbotk] Evaluating 1 configuration(s)
INFO  [17:52:19.185] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:52:19.382] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -125.1895
[1] 83.45964
[1] -105.8702
[1] 85.75965
[1] -79.92636
[1] 113.0577
[1] -200.1851
[1] -3.694775
[1] -60.02308
[1] 85.789
INFO  [17:52:39.256] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -180.16
[1] -5.852617
[1] -86.8057
[1] 181.9445
[1] -227.6208
[1] 4.298193
[1] -272.9558
[1] -4.730385
[1] 966.4013
[1] 29813.52
INFO  [17:53:12.675] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -94.34184
[1] 125.283
[1] -35.36699
[1] 166.6507
[1] -35.97455
[1] 122.9172
[1] -68.48345
[1] 71.01956
[1] -56.81588
[1] 110.9696
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:53:32.294] [mlr3] Finished benchmark
INFO  [17:53:32.416] [bbotk] Result of batch 14:
INFO  [17:53:32.518] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:53:32.518] [bbotk]               2.312876                         0.2575546
INFO  [17:53:32.518] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:53:32.518] [bbotk]                         0.8418139          -0.2127423              -6.350789
INFO  [17:53:32.518] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:53:32.518] [bbotk]                          1                    1064                 0.3331627
INFO  [17:53:32.518] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:53:32.518] [bbotk]  0.02975566 <list[8]>              FALSE     0.04984785        0      0
INFO  [17:53:32.518] [bbotk]  runtime_learners                                uhash
INFO  [17:53:32.518] [bbotk]            71.484 eb1e486c-4bf1-4e4d-8420-6d4e3b644faa
INFO  [17:53:34.619] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 45 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:53:40.752] [bbotk] Evaluating 1 configuration(s)
INFO  [17:53:41.064] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:53:41.178] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -121.2888
[1] 29.40735
[1] -147.0622
[1] 4.806324
[1] -51.04248
[1] 112.3571
[1] -87.13511
[1] 8.39842
[1] -116.519
[1] 52.64003
INFO  [17:54:10.933] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -195.1955
[1] 34.42118
[1] -2670.633
[1] -72.73294
[1] -34.59989
[1] 55.47785
[1] -39.18384
[1] 32.0977
[1] -135.6587
[1] 25.20752
INFO  [17:54:57.278] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -133.9243
[1] 34.72925
[1] -2474.16
[1] -60.07417
[1] -138.3994
[1] 119.5118
[1] -42.5019
[1] 31.14208
[1] -67.64402
[1] 65.45396
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:55:23.141] [mlr3] Finished benchmark
INFO  [17:55:23.324] [bbotk] Result of batch 15:
INFO  [17:55:23.393] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:55:23.393] [bbotk]              -3.276886                         0.8077244
INFO  [17:55:23.393] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:55:23.393] [bbotk]                         0.8867026           -5.028398              -2.055826
INFO  [17:55:23.393] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:55:23.393] [bbotk]                          6                    3751                 0.1279296
INFO  [17:55:23.393] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:55:23.393] [bbotk]  0.02739746 <list[8]>              FALSE     0.02755833        0      0
INFO  [17:55:23.393] [bbotk]  runtime_learners                                uhash
INFO  [17:55:23.393] [bbotk]           100.957 55240a2f-0a79-4d4e-b133-2be9d721d8b9
INFO  [17:55:24.251] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 46 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:55:31.437] [bbotk] Evaluating 1 configuration(s)
INFO  [17:55:31.599] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:55:31.884] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -97.61206
[1] 107.5203
[1] -296.7153
[1] -5.082403
[1] -123.8231
[1] 57.36245
[1] -145.0025
[1] 141.235
[1] -304.0094
[1] 5.558496
INFO  [17:56:05.082] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -50.59304
[1] 119.0131
[1] -105.0305
[1] 63.22359
[1] -117.3784
[1] 146.243
[1] -144.0716
[1] 48.89341
[1] 33.10803
[1] 2040.893
INFO  [17:56:51.433] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -211.6131
[1] -4.568928
[1] -62.01533
[1] 169.2384
[1] -28.98106
[1] 408.3302
[1] -233.6949
[1] -4.689543
[1] 5.841083
[1] 204.0248
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:57:34.096] [mlr3] Finished benchmark
INFO  [17:57:34.856] [bbotk] Result of batch 16:
INFO  [17:57:34.930] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:57:34.930] [bbotk]               1.999873                         0.2885999
INFO  [17:57:34.930] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:57:34.930] [bbotk]                         0.9291325           -1.036493             -0.4144056
INFO  [17:57:34.930] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:57:34.930] [bbotk]                         14                    3698                 0.1774379
INFO  [17:57:34.930] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:57:34.930] [bbotk]  0.02251757 <list[8]>              FALSE     0.04070634        0      0
INFO  [17:57:34.930] [bbotk]  runtime_learners                                uhash
INFO  [17:57:34.930] [bbotk]           121.493 2a213c71-a506-464c-a269-185a8862653c
INFO  [17:57:36.692] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 47 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:57:46.584] [bbotk] Evaluating 1 configuration(s)
INFO  [17:57:46.740] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:57:47.054] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -44.47562
[1] 155.6443
[1] -7187.1
[1] -154.4675
[1] -23.53239
[1] 155.6132
[1] -49.3009
[1] 19.50063
[1] -51.16006
[1] 21.36868
INFO  [17:58:23.822] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -128.5227
[1] 23.3536
[1] -79.33602
[1] 18.83241
[1] -70.47844
[1] 34.12188
[1] 38.21163
[1] 953.5929
[1] -29.80493
[1] 45.92972
INFO  [17:58:58.027] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -144.435
[1] 23.73912
[1] -96.86644
[1] -4.120148
[1] -42.91728
[1] 58.85873
[1] -8550.627
[1] -161.971
[1] -117.4198
[1] 36.99581
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:59:37.907] [mlr3] Finished benchmark
INFO  [17:59:38.081] [bbotk] Result of batch 17:
INFO  [17:59:38.138] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:59:38.138] [bbotk]              -1.628844                         0.1930061
INFO  [17:59:38.138] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:59:38.138] [bbotk]                         0.9156221           -2.615051               -2.04025
INFO  [17:59:38.138] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:59:38.138] [bbotk]                         11                    2993                 0.1141346
INFO  [17:59:38.138] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:59:38.138] [bbotk]  0.01899163 <list[8]>              FALSE     0.02650459        0      0
INFO  [17:59:38.138] [bbotk]  runtime_learners                                uhash
INFO  [17:59:38.138] [bbotk]            109.67 def6d0fc-5cf9-4387-ab47-1adbb56b7459
INFO  [17:59:39.008] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 48 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:59:45.217] [bbotk] Evaluating 1 configuration(s)
INFO  [17:59:45.489] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:59:45.703] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -33.71195
[1] 9.216568
[1] -430.0315
[1] -2.452002
[1] -32.53552
[1] 235.1049
[1] -39.57508
[1] 8.961362
[1] -969.0686
[1] -40.76506
INFO  [18:00:35.212] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -69.19865
[1] 15.13263
[1] -25.67204
[1] 21.53969
[1] -51.87417
[1] 21.72673
[1] -1834.278
[1] -51.71734
[1] -47.19689
[1] 19.0954
INFO  [18:01:22.547] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -147.5688
[1] 22.45933
[1] -17.77243
[1] 43.07751
[1] -15.89948
[1] 35.47619
[1] -45.69306
[1] 24.70258
[1] -22.30556
[1] 25.09495
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:02:04.609] [mlr3] Finished benchmark
INFO  [18:02:04.729] [bbotk] Result of batch 18:
INFO  [18:02:04.788] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:02:04.788] [bbotk]              -1.311272                         0.9135335
INFO  [18:02:04.788] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:02:04.788] [bbotk]                         0.8230032           -0.445032             -0.7930833
INFO  [18:02:04.788] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:02:04.788] [bbotk]                          4                    4976                 0.1332106
INFO  [18:02:04.788] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:02:04.788] [bbotk]  0.01889975 <list[8]>              FALSE     0.02884772        0      0
INFO  [18:02:04.788] [bbotk]  runtime_learners                                uhash
INFO  [18:02:04.788] [bbotk]           137.939 c5efc995-0a38-440e-a750-795d45b40438
INFO  [18:02:07.050] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 49 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:02:13.396] [bbotk] Evaluating 1 configuration(s)
INFO  [18:02:13.723] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:02:13.941] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -20.18065
[1] 56.94168
[1] -2130.671
[1] -44.13182
[1] -81.9561
[1] 25.10132
[1] -5164.26
[1] -80.64884
[1] -60.05869
[1] 0.2968845
INFO  [18:02:47.242] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -11.27305
[1] 505.6249
[1] 91.52417
[1] 2897.245
[1] -101.4383
[1] 65.84386
[1] -51.21756
[1] 16.58787
[1] -447.5712
[1] 24.178
INFO  [18:03:07.719] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -69.34015
[1] 18.80894
[1] -86.47111
[1] -4.039583
[1] -35.12415
[1] 73.50251
[1] -5700.097
[1] -127.8945
[1] -20.10617
[1] 70.23033
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:03:53.343] [mlr3] Finished benchmark
INFO  [18:03:53.930] [bbotk] Result of batch 19:
INFO  [18:03:54.064] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:03:54.064] [bbotk]              -4.155357                         0.8982521
INFO  [18:03:54.064] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:03:54.064] [bbotk]                         0.8505292           -3.782455              -5.192171
INFO  [18:03:54.064] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:03:54.064] [bbotk]                         18                    2128                 0.2572244
INFO  [18:03:54.064] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:03:54.064] [bbotk]  0.01867589 <list[8]>              FALSE     0.02401945        0      0
INFO  [18:03:54.064] [bbotk]  runtime_learners                                uhash
INFO  [18:03:54.064] [bbotk]            98.207 057a633d-659f-4ce5-bad3-9d906171bc81
INFO  [18:03:56.200] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 50 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:04:03.552] [bbotk] Evaluating 1 configuration(s)
INFO  [18:04:03.602] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:04:03.652] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -83.12642
[1] 5.231903
[1] -54.32025
[1] 86.31481
[1] -33.59323
[1] 34.64629
[1] -83.36712
[1] 117.395
[1] -39.68156
[1] 134.7591
INFO  [18:04:34.360] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -3080.572
[1] -39.59014
[1] -917.4906
[1] -35.20179
[1] -24.97588
[1] 30.71649
[1] -44.74587
[1] 30.50325
[1] -55.74282
[1] 46.63895
INFO  [18:04:53.528] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -34.79127
[1] 42.04707
[1] -51.85264
[1] 19.01185
[1] -4224.268
[1] -93.50563
[1] -65.9438
[1] 14.31689
[1] -25.96882
[1] 140.1389
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:05:35.548] [mlr3] Finished benchmark
INFO  [18:05:35.680] [bbotk] Result of batch 20:
INFO  [18:05:35.717] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:05:35.717] [bbotk]             -0.6416598                         0.1316716
INFO  [18:05:35.717] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:05:35.717] [bbotk]                         0.9459493           -4.019652              -3.768417
INFO  [18:05:35.717] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:05:35.717] [bbotk]                         19                    2022                 0.5591452
INFO  [18:05:35.717] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:05:35.717] [bbotk]  0.01737514 <list[8]>              FALSE     0.02384168        0      0
INFO  [18:05:35.717] [bbotk]  runtime_learners                                uhash
INFO  [18:05:35.717] [bbotk]            90.985 397e0d82-934b-4b5a-abd3-0302f29561f7
INFO  [18:05:37.112] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 51 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:05:44.127] [bbotk] Evaluating 1 configuration(s)
INFO  [18:05:44.260] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:05:44.417] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -101.3129
[1] 144.9355
[1] -190.2471
[1] -5.077066
[1] -109.1844
[1] 333.7972
[1] -146.9878
[1] 25.54851
[1] -80.87249
[1] 79.35083
INFO  [18:06:15.962] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -70.23903
[1] 101.3574
[1] -125.5823
[1] 235.4884
[1] -105.6514
[1] 77.04435
[1] 77.83822
[1] 2901.335
[1] -150.7749
[1] 6.705159
INFO  [18:06:43.490] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -112.4995
[1] 95.93718
[1] -6.90423
[1] 179.2454
[1] -91.75006
[1] 105.5598
[1] -122.9809
[1] 43.06451
[1] -264.5324
[1] -4.845671
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:07:12.158] [mlr3] Finished benchmark
INFO  [18:07:12.289] [bbotk] Result of batch 21:
INFO  [18:07:12.322] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:07:12.322] [bbotk]               1.284494                         0.2764474
INFO  [18:07:12.322] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:07:12.322] [bbotk]                         0.4754229           -6.320593              -4.132693
INFO  [18:07:12.322] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:07:12.322] [bbotk]                          7                    1083                 0.9995424
INFO  [18:07:12.322] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:07:12.322] [bbotk]  0.01769245 <list[8]>              FALSE     0.03573095        0      0
INFO  [18:07:12.322] [bbotk]  runtime_learners                                uhash
INFO  [18:07:12.322] [bbotk]            87.499 eb2f75fa-9e17-4ee7-b91a-202b87641ee5
INFO  [18:07:13.212] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 52 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:07:29.102] [bbotk] Evaluating 1 configuration(s)
INFO  [18:07:29.378] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:07:29.616] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -66.16053
[1] 21.14008
[1] -609.3358
[1] -3.959256
[1] -903.9985
[1] 885.5832
[1] -252.7826
[1] -3.394902
[1] -57.97727
[1] 1.085513
INFO  [18:07:56.474] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -86.13225
[1] 119.0548
[1] -34.04336
[1] 17.07882
[1] -37.32994
[1] 26.56809
[1] -2969.964
[1] -73.66883
[1] 39.73432
[1] 1104.044
INFO  [18:08:31.693] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -41.16451
[1] 19.33931
[1] -173.346
[1] -3.855822
[1] -39.60098
[1] 69.67579
[1] -43.83212
[1] 44.95656
[1] -10.60417
[1] 50.8748
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:09:04.053] [mlr3] Finished benchmark
INFO  [18:09:04.826] [bbotk] Result of batch 22:
INFO  [18:09:05.038] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:09:05.038] [bbotk]             -0.9469539                         0.4124367
INFO  [18:09:05.038] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:09:05.038] [bbotk]                         0.1279986           -1.529003              -6.782028
INFO  [18:09:05.038] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:09:05.038] [bbotk]                          6                    2539                 0.7316497
INFO  [18:09:05.038] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:09:05.038] [bbotk]  0.01599935 <list[8]>              FALSE     0.02328469        0      0
INFO  [18:09:05.038] [bbotk]  runtime_learners                                uhash
INFO  [18:09:05.038] [bbotk]            92.756 ecf2900e-f5d7-48e6-9a53-e4bb727ae78b
INFO  [18:09:07.032] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 53 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:09:13.785] [bbotk] Evaluating 1 configuration(s)
INFO  [18:09:13.928] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:09:14.128] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -32.97664
[1] 15.37382
[1] -50.28507
[1] 3.596369
[1] -633.5121
[1] -63.6318
[1] -157.9428
[1] 14.26423
[1] -65.1633
[1] 40.02165
INFO  [18:09:41.547] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 170.7632
[1] 3339.714
[1] -50.64457
[1] 41.4579
[1] -52.3622
[1] 9.502766
[1] -3624.369
[1] -71.64051
[1] -55.97267
[1] 30.74054
INFO  [18:10:13.816] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -26.83927
[1] 35.36073
[1] -24.38115
[1] 18.18295
[1] -24.3448
[1] 27.8561
[1] -49.3246
[1] 10.01052
[1] -297.107
[1] 108.0754
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:10:45.791] [mlr3] Finished benchmark
INFO  [18:10:47.536] [bbotk] Result of batch 23:
INFO  [18:10:47.650] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:10:47.650] [bbotk]              -5.300336                         0.8024273
INFO  [18:10:47.650] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:10:47.650] [bbotk]                         0.8936827           -1.240628              -4.402953
INFO  [18:10:47.650] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:10:47.650] [bbotk]                         13                    1818                 0.7980597
INFO  [18:10:47.650] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:10:47.650] [bbotk]  0.01391304 <list[8]>              FALSE     0.02309381        0      0
INFO  [18:10:47.650] [bbotk]  runtime_learners                                uhash
INFO  [18:10:47.650] [bbotk]            90.864 ab0645ce-0dd2-42e0-8bed-b3eced71ad1a
INFO  [18:10:48.879] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 54 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:10:53.622] [bbotk] Evaluating 1 configuration(s)
INFO  [18:10:54.058] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:10:54.373] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -2107.383
[1] -40.53838
[1] 110.9547
[1] 5657.178
[1] -1776.17
[1] -32.34664
[1] -1648.397
[1] -29.49571
[1] -1681.923
[1] -31.42575
INFO  [18:11:12.897] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 32.99113
[1] 1749.553
[1] -72.45336
[1] 2761.51
[1] -110.3403
[1] 1437.099
[1] -105339.8
[1] -1918.146
[1] -565.6517
[1] 679.714
INFO  [18:11:32.753] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 39.39798
[1] 2164.593
[1] 58.73733
[1] 3041.731
[1] -1447.89
[1] -27.01162
[1] -2173.649
[1] -38.90332
[1] -478.3473
[1] 1175.658
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:11:52.368] [mlr3] Finished benchmark
INFO  [18:11:52.525] [bbotk] Result of batch 24:
INFO  [18:11:52.560] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:11:52.560] [bbotk]              -2.477972                         0.8610406
INFO  [18:11:52.560] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:11:52.560] [bbotk]                         0.9421812            -8.00429              -5.150802
INFO  [18:11:52.560] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:11:52.560] [bbotk]                          6                     362                 0.1116476
INFO  [18:11:52.560] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:11:52.560] [bbotk]  0.01586813 <list[8]>              FALSE      0.2166057        0      0
INFO  [18:11:52.560] [bbotk]  runtime_learners                                uhash
INFO  [18:11:52.560] [bbotk]            57.035 c53faea5-37c8-4f11-bf21-05a78aea3cae
INFO  [18:11:53.910] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 55 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:12:00.014] [bbotk] Evaluating 1 configuration(s)
INFO  [18:12:00.200] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:12:00.296] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -323.0288
[1] 3.465087
[1] -257.5893
[1] 85.40144
[1] -121.1337
[1] 35.5395
[1] -128.4601
[1] 19.31061
[1] 6.364251
[1] 219.7557
INFO  [18:12:32.547] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -573.0287
[1] -14.17473
[1] -255.8681
[1] -3.967516
[1] -133.025
[1] 278.9252
[1] -173.9051
[1] 161.209
[1] 5.156718
[1] 204.8836
INFO  [18:12:55.228] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -274.1157
[1] 64.6197
[1] 5.366348
[1] 249.7273
[1] -119.1715
[1] 36.64747
[1] -178.1812
[1] 48.14854
[1] 4.538348
[1] 205.7953
INFO  [18:13:19.335] [mlr3] Finished benchmark
INFO  [18:13:19.960] [bbotk] Result of batch 25:
INFO  [18:13:20.151] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:13:20.151] [bbotk]               2.961568                         0.2379323
INFO  [18:13:20.151] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:13:20.151] [bbotk]                         0.2552191          -0.8985921               1.416314
INFO  [18:13:20.151] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:13:20.151] [bbotk]                          4                    1513                 0.9944538
INFO  [18:13:20.151] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:13:20.151] [bbotk]  0.04005422 <list[8]>              FALSE      0.0394263        0      0
INFO  [18:13:20.151] [bbotk]  runtime_learners                                uhash
INFO  [18:13:20.151] [bbotk]            78.248 3fe8ac5f-bfea-4030-9fc8-6f4732345925
INFO  [18:13:22.717] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 56 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:13:28.157] [bbotk] Evaluating 1 configuration(s)
INFO  [18:13:28.616] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:13:29.571] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -37.35335
[1] 58.45944
[1] -103.0266
[1] 13.58957
[1] -13094.8
[1] -354.1183
[1] -47.66523
[1] 48.68123
[1] -146.1905
[1] 5.553288
INFO  [18:14:19.229] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -60.58712
[1] 16.34802
[1] -2493.265
[1] -54.54386
[1] -16.42923
[1] 171.2611
[1] -210.0205
[1] 37.19101
[1] -56.57308
[1] 25.26952
INFO  [18:15:27.559] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -103.6181
[1] 258.0642
[1] -45.47218
[1] 136.1871
[1] -332.6978
[1] 3.476123
[1] -55.02962
[1] 21.15441
[1] 115.5846
[1] 4261.006
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:16:37.778] [mlr3] Finished benchmark
INFO  [18:16:38.099] [bbotk] Result of batch 26:
INFO  [18:16:38.449] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:16:38.449] [bbotk]              0.1644592                         0.3513985
INFO  [18:16:38.449] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:16:38.449] [bbotk]                         0.9765515           -5.791217              -5.850965
INFO  [18:16:38.449] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:16:38.449] [bbotk]                          9                    4287                 0.4303482
INFO  [18:16:38.449] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:16:38.449] [bbotk]  0.03946419 <list[8]>              FALSE     0.02432738        0      0
INFO  [18:16:38.449] [bbotk]  runtime_learners                                uhash
INFO  [18:16:38.449] [bbotk]           186.352 802ff4f2-0fdb-4687-a359-37a2df1c5595
INFO  [18:16:40.077] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 57 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:16:51.993] [bbotk] Evaluating 1 configuration(s)
INFO  [18:16:52.264] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:16:52.428] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -85.90968
[1] 20.71626
[1] -57.57831
[1] 57.93208
[1] -115.1345
[1] -3.823417
[1] -38.97103
[1] 103.4113
[1] -40.56051
[1] 39.86901
INFO  [18:17:11.314] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -344.6426
[1] 5.683118
[1] -55.38985
[1] 72.46981
[1] -88.89607
[1] 23.27144
[1] -74.63086
[1] 17.65858
[1] -64.7906
[1] 155.0509
INFO  [18:17:36.144] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -53.13923
[1] 107.1954
[1] -76.31246
[1] 62.74116
[1] -409.0286
[1] 17.56712
[1] -68.04342
[1] 33.40169
[1] -129.7713
[1] -4.118329
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:17:55.158] [mlr3] Finished benchmark
INFO  [18:17:55.321] [bbotk] Result of batch 27:
INFO  [18:17:55.366] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:17:55.366] [bbotk]             -0.5531404                          0.628975
INFO  [18:17:55.366] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:17:55.366] [bbotk]                         0.2822825           -6.461249              -1.773778
INFO  [18:17:55.366] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:17:55.366] [bbotk]                          3                    3100                 0.8651198
INFO  [18:17:55.366] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:17:55.366] [bbotk]  0.05160336 <list[8]>              FALSE     0.02916502        0      0
INFO  [18:17:55.366] [bbotk]  runtime_learners                                uhash
INFO  [18:17:55.366] [bbotk]            62.231 8dd19782-424b-4654-bfbf-c1ec545500d7
INFO  [18:17:56.245] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 58 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:18:07.254] [bbotk] Evaluating 1 configuration(s)
INFO  [18:18:07.432] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:18:07.511] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -88.82343
[1] 114.4092
[1] -153.221
[1] -0.1284983
[1] -73.2157
[1] 70.45033
[1] -145.572
[1] 24.80142
[1] -66.05522
[1] 55.31785
INFO  [18:18:41.839] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -89.29077
[1] 43.91722
[1] -53.07021
[1] 25.00857
[1] -7523.939
[1] -137.972
[1] -46.43536
[1] 85.06561
[1] -89.00695
[1] 46.48974
INFO  [18:19:18.534] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 150.5003
[1] 4389.526
[1] -370.5823
[1] -4.104991
[1] -136.7589
[1] 11.31481
[1] -129.537
[1] 150.4039
[1] -46.38307
[1] 56.27514
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:20:03.168] [mlr3] Finished benchmark
INFO  [18:20:03.356] [bbotk] Result of batch 28:
INFO  [18:20:03.402] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:20:03.402] [bbotk]              -4.585869                         0.7696996
INFO  [18:20:03.402] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:20:03.402] [bbotk]                         0.7008581           -1.076369                5.16188
INFO  [18:20:03.402] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:20:03.402] [bbotk]                         11                    3336                 0.1205485
INFO  [18:20:03.402] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:20:03.402] [bbotk]  0.03503857 <list[8]>              FALSE     0.03031322        0      0
INFO  [18:20:03.402] [bbotk]  runtime_learners                                uhash
INFO  [18:20:03.402] [bbotk]           114.577 c062ed67-4605-44f4-a3a4-6514dd272036
INFO  [18:20:05.536] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 59 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:20:11.383] [bbotk] Evaluating 1 configuration(s)
INFO  [18:20:11.430] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:20:11.515] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -36.06363
[1] 88.54099
[1] -247.6669
[1] 8.132577
[1] -59.07623
[1] 12.64241
[1] -58.40622
[1] 4.26095
[1] -127.8573
[1] 10.62828
INFO  [18:20:49.483] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 3.577981
[1] 55.60645
[1] -67.29278
[1] 48.13649
[1] -97.73486
[1] 103.6139
[1] -64.3539
[1] 23.59296
[1] -1049.098
[1] -29.97085
INFO  [18:21:42.288] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -77.46364
[1] 66.89598
[1] -42.53163
[1] 53.29253
[1] -54.9254
[1] 424.053
[1] -86.30374
[1] 64.45188
[1] -57.14795
[1] 15.0138
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:22:16.257] [mlr3] Finished benchmark
INFO  [18:22:16.418] [bbotk] Result of batch 29:
INFO  [18:22:16.478] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:22:16.478] [bbotk]              -5.253509                         0.6579574
INFO  [18:22:16.478] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:22:16.478] [bbotk]                         0.5872762           -2.737766              -1.149704
INFO  [18:22:16.478] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:22:16.478] [bbotk]                         15                    4465                 0.1846927
INFO  [18:22:16.478] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:22:16.478] [bbotk]  0.02754296 <list[8]>              FALSE     0.02342463        0      0
INFO  [18:22:16.478] [bbotk]  runtime_learners                                uhash
INFO  [18:22:16.478] [bbotk]           124.006 2418c6b3-63c1-448d-b6c9-8f227dc447a6
INFO  [18:22:20.372] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 60 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:22:28.006] [bbotk] Evaluating 1 configuration(s)
INFO  [18:22:28.226] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:22:28.498] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -2128.592
[1] -84.63279
[1] -51.18744
[1] 35.30865
[1] -65.4957
[1] 29.29707
[1] -36.80455
[1] 46.35494
[1] -111.0631
[1] -3.552589
INFO  [18:23:29.286] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -83.04105
[1] 30.12284
[1] -89.94046
[1] 6.277181
[1] -36.35122
[1] 133.0559
[1] -32.86189
[1] 50.73063
[1] -41.70411
[1] 93.0506
INFO  [18:24:16.527] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -63.20292
[1] 42.08878
[1] -59.8452
[1] 33.68412
[1] -19.09884
[1] 82.97201
[1] -64.49406
[1] 64.38341
[1] -125.6118
[1] -3.628783
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:25:36.180] [mlr3] Finished benchmark
INFO  [18:25:36.411] [bbotk] Result of batch 30:
INFO  [18:25:36.467] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:25:36.467] [bbotk]              0.4941851                         0.6602813
INFO  [18:25:36.467] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:25:36.467] [bbotk]                         0.8649439           -6.378308              -1.466136
INFO  [18:25:36.467] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:25:36.467] [bbotk]                          7                    4620                  0.680424
INFO  [18:25:36.467] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:25:36.467] [bbotk]  0.02826003 <list[8]>              FALSE     0.02684742        0      0
INFO  [18:25:36.467] [bbotk]  runtime_learners                                uhash
INFO  [18:25:36.467] [bbotk]           186.875 cb2cb5ff-e4fd-4baf-a70d-886d701defd2
INFO  [18:25:37.925] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 61 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:25:45.197] [bbotk] Evaluating 1 configuration(s)
INFO  [18:25:45.500] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:25:45.680] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -34.92764
[1] 32.6943
[1] -24.57227
[1] 35.30991
[1] -59.23499
[1] 14.14411
[1] -29.04415
[1] 53.96605
[1] -4302.41
[1] -107.6269
INFO  [18:26:15.353] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -60.46126
[1] 29.11243
[1] -827.7161
[1] -31.67059
[1] -76.18609
[1] 23.19809
[1] -28.46972
[1] 28.87207
[1] -85.32351
[1] 35.68878
INFO  [18:26:45.747] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -37.07194
[1] 64.64138
[1] -30.53037
[1] 29.73081
[1] -48.81457
[1] 54.25071
[1] -57.8081
[1] 55.6003
[1] -63.68258
[1] 7.043977
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:27:27.052] [mlr3] Finished benchmark
INFO  [18:27:27.173] [bbotk] Result of batch 31:
INFO  [18:27:27.371] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:27:27.371] [bbotk]              -4.920508                         0.2599854
INFO  [18:27:27.371] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:27:27.371] [bbotk]                          0.311512           -4.950375              -2.898127
INFO  [18:27:27.371] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:27:27.371] [bbotk]                          6                    2210                 0.8010676
INFO  [18:27:27.371] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:27:27.371] [bbotk]  0.02876781 <list[8]>              FALSE     0.02574548        0      0
INFO  [18:27:27.371] [bbotk]  runtime_learners                                uhash
INFO  [18:27:27.371] [bbotk]           100.196 e3d7ed08-f1af-4699-becc-97ea6c47e937
INFO  [18:27:29.265] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 62 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:27:36.911] [bbotk] Evaluating 1 configuration(s)
INFO  [18:27:37.051] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:27:37.237] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -99.22661
[1] 132.8873
[1] -93.66368
[1] 79.47233
[1] -141.3119
[1] 110.0078
[1] -123.7324
[1] -3.01618
[1] -76.29604
[1] 33.26206
INFO  [18:28:17.436] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1920.899
[1] -41.09153
[1] -164.5289
[1] 6.859024
[1] -42.9494
[1] 42.75488
[1] -4321.326
[1] -109.1159
[1] -52.29542
[1] 36.65341
INFO  [18:28:53.523] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -93.20958
[1] 24.16052
[1] -275.5239
[1] 5.377428
[1] -52.67296
[1] 140.9522
[1] -244.2153
[1] 77.97077
[1] -84.84392
[1] 11.86384
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:29:25.104] [mlr3] Finished benchmark
INFO  [18:29:25.275] [bbotk] Result of batch 32:
INFO  [18:29:25.669] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:29:25.669] [bbotk]               1.613223                         0.5492671
INFO  [18:29:25.669] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:29:25.669] [bbotk]                         0.4068673           -3.077659              -5.355527
INFO  [18:29:25.669] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:29:25.669] [bbotk]                          6                    3013                  0.997043
INFO  [18:29:25.669] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:29:25.669] [bbotk]  0.02361588 <list[8]>              FALSE     0.03052659        0      0
INFO  [18:29:25.669] [bbotk]  runtime_learners                                uhash
INFO  [18:29:25.669] [bbotk]           107.438 c827bf7c-f889-41f1-84a6-d9611e85d31f
INFO  [18:29:27.426] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 63 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:29:33.491] [bbotk] Evaluating 1 configuration(s)
INFO  [18:29:33.571] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:29:33.684] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 403.8278
[1] 16511.67
[1] -146.7718
[1] -4.040389
[1] -172.1295
[1] -4.15559
[1] -51.61196
[1] 142.8304
[1] -42.96182
[1] 25.06545
INFO  [18:30:07.035] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -37.68493
[1] 53.78589
[1] -52.97279
[1] 34.48155
[1] -17.93466
[1] 59.07287
[1] -135.4105
[1] 51.44409
[1] -4426.195
[1] -103.6259
INFO  [18:30:42.904] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -222.5724
[1] -4.060354
[1] -43.56369
[1] 79.89182
[1] -106.9841
[1] 38.27441
[1] 1870.625
[1] 53189.46
[1] -71.61903
[1] 49.59174
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:31:23.944] [mlr3] Finished benchmark
INFO  [18:31:24.201] [bbotk] Result of batch 33:
INFO  [18:31:24.319] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:31:24.319] [bbotk]             -0.2304326                         0.7015618
INFO  [18:31:24.319] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:31:24.319] [bbotk]                         0.9809852           -4.145168              -1.274456
INFO  [18:31:24.319] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:31:24.319] [bbotk]                          8                    3021                 0.1359202
INFO  [18:31:24.319] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:31:24.319] [bbotk]  0.02622411 <list[8]>              FALSE     0.02712582        0      0
INFO  [18:31:24.319] [bbotk]  runtime_learners                                uhash
INFO  [18:31:24.319] [bbotk]           109.568 59c5fd07-7b3c-43ad-aa8d-936781860082
INFO  [18:31:26.172] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 64 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:31:33.726] [bbotk] Evaluating 1 configuration(s)
INFO  [18:31:34.018] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:31:34.771] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -61.48917
[1] 19.59141
[1] -36.4905
[1] 5.9982
[1] -50.439
[1] 18.70246
[1] -74.09861
[1] 33.24342
[1] -527.059
[1] -29.62337
INFO  [18:32:13.556] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -31.05616
[1] 16.09716
[1] -20.33542
[1] 190.6751
[1] -252.7949
[1] 20.49858
[1] 275.6154
[1] 7296.604
[1] -26.13616
[1] 534.802
INFO  [18:33:04.251] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 44.40239
[1] 1078.037
[1] -40.25278
[1] 38.62567
[1] -27.3847
[1] 34.44385
[1] -651.7342
[1] -3.507381
[1] -7972.919
[1] -189.1113
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:33:57.755] [mlr3] Finished benchmark
INFO  [18:33:58.038] [bbotk] Result of batch 34:
INFO  [18:33:58.105] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:33:58.105] [bbotk]              -3.275841                         0.7046727
INFO  [18:33:58.105] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:33:58.105] [bbotk]                         0.8645268           -2.440098             -0.5722725
INFO  [18:33:58.105] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:33:58.105] [bbotk]                         11                    4757                 0.3484625
INFO  [18:33:58.105] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:33:58.105] [bbotk]  0.02705079 <list[8]>              FALSE     0.02357444        0      0
INFO  [18:33:58.105] [bbotk]  runtime_learners                                uhash
INFO  [18:33:58.105] [bbotk]           141.051 d6d36ab4-6ebf-4840-bf63-8232eb42044b
INFO  [18:33:59.453] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 65 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:34:03.960] [bbotk] Evaluating 1 configuration(s)
INFO  [18:34:04.130] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:34:04.449] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -82.29501
[1] 14.28378
[1] -40.68033
[1] 55.11413
[1] -38.2281
[1] 5.057727
[1] -21.06865
[1] 31.82253
[1] -25.49526
[1] 93.85006
INFO  [18:34:35.398] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -111.237
[1] 7.129978
[1] -50.63931
[1] 65.58485
[1] -969.4654
[1] -64.25052
[1] -45.9166
[1] 15.91017
[1] -27.31051
[1] 48.84304
INFO  [18:35:09.587] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -171.0433
[1] 26.12346
[1] -69.38255
[1] 34.06927
[1] -92.05804
[1] -3.900502
[1] -45.14161
[1] 143.388
[1] -24.27312
[1] 46.48937
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:35:34.101] [mlr3] Finished benchmark
INFO  [18:35:34.462] [bbotk] Result of batch 35:
INFO  [18:35:34.544] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:35:34.544] [bbotk]              -6.199458                         0.8178139
INFO  [18:35:34.544] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:35:34.544] [bbotk]                         0.8247477           -4.107965               -1.78352
INFO  [18:35:34.544] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:35:34.544] [bbotk]                         12                    1717                 0.5817255
INFO  [18:35:34.544] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:35:34.544] [bbotk]  0.01903765 <list[8]>              FALSE     0.02079287        0      0
INFO  [18:35:34.544] [bbotk]  runtime_learners                                uhash
INFO  [18:35:34.544] [bbotk]            88.663 9de7c16e-1d37-4d4a-88da-196c6cf03b8e
INFO  [18:35:37.712] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 66 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:35:44.447] [bbotk] Evaluating 1 configuration(s)
INFO  [18:35:44.771] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:35:45.211] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 11.35368
[1] 489.8943
[1] 9.663066
[1] 444.3701
[1] -733.0162
[1] 1187.674
[1] -315.7882
[1] 396.1143
[1] -670.1223
[1] -9.875286
INFO  [18:35:51.841] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 12.57214
[1] 650.1454
[1] -740.321
[1] -9.903797
[1] 12.59361
[1] 505.1003
[1] 12.80692
[1] 490.5155
[1] 14.35148
[1] 554.9369
INFO  [18:36:00.057] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -542.0019
[1] -8.496629
[1] 20.13624
[1] 904.8576
[1] 13.65761
[1] 598.0612
[1] -920.7607
[1] 1785.785
[1] -524.2502
[1] 199.5385
INFO  [18:36:07.529] [mlr3] Finished benchmark
INFO  [18:36:07.665] [bbotk] Result of batch 36:
INFO  [18:36:07.807] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:36:07.807] [bbotk]               1.928921                         0.1573197
INFO  [18:36:07.807] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:36:07.807] [bbotk]                         0.3632988          -0.6714443               1.001038
INFO  [18:36:07.807] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:36:07.807] [bbotk]                          3                      24                 0.1340928
INFO  [18:36:07.807] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:36:07.807] [bbotk]  0.02532324 <list[8]>              FALSE     0.07999729        0      0
INFO  [18:36:07.807] [bbotk]  runtime_learners                                uhash
INFO  [18:36:07.807] [bbotk]            21.988 27aed69b-094b-46b9-b506-3f706e44cdd0
INFO  [18:36:10.486] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 67 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:36:18.722] [bbotk] Evaluating 1 configuration(s)
INFO  [18:36:18.861] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:36:19.015] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -79.99994
[1] -0.1901028
[1] -81.59865
[1] 10.54673
[1] -21.12222
[1] 60.12678
[1] -38.01066
[1] 102.3259
[1] -58.44867
[1] 15.68573
INFO  [18:37:09.283] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -88.41528
[1] 17.10173
[1] -88.08442
[1] 33.4587
[1] -36.30677
[1] 97.39873
[1] -5131.779
[1] -91.81623
[1] 27.10942
[1] 565.5991
INFO  [18:38:02.835] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -45.43593
[1] 12.92098
[1] -2.540949e+16
[1] 1.122253e+16
[1] -47.92409
[1] 44.10735
[1] -60.35139
[1] 23.07738
[1] -36.67099
[1] 14.05963
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:39:01.037] [mlr3] Finished benchmark
INFO  [18:39:01.171] [bbotk] Result of batch 37:
INFO  [18:39:01.197] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:39:01.197] [bbotk]              -1.659679                         0.6700659
INFO  [18:39:01.197] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:39:01.197] [bbotk]                         0.2637676           -2.832101              0.4522253
INFO  [18:39:01.197] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:39:01.197] [bbotk]                         14                    4286                 0.7468354
INFO  [18:39:01.197] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:39:01.197] [bbotk]  0.02243187 <list[8]>              FALSE     0.02149559        0      0
INFO  [18:39:01.197] [bbotk]  runtime_learners                                uhash
INFO  [18:39:01.197] [bbotk]           161.371 94e7acf4-f452-4970-82ce-ac9d07b15e1d
WARN  [18:39:03.493] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:39:03.552] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 68 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:39:12.111] [bbotk] Evaluating 1 configuration(s)
INFO  [18:39:12.266] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:39:12.570] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -118.5934
[1] 41.65958
[1] -48.33231
[1] 44.8609
[1] -68.72663
[1] 12.49886
[1] -164.0947
[1] -3.334579
[1] -51.07888
[1] 51.52006
INFO  [18:39:35.443] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -109.7683
[1] 92.41899
[1] -52.64344
[1] 54.44825
[1] -42.11249
[1] 42.86925
[1] -61.20895
[1] 27.93152
[1] -34.99709
[1] 43.89155
INFO  [18:40:32.989] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -46.20532
[1] 27.89785
[1] -32.6357
[1] 116.3601
[1] -160.4646
[1] -3.973742
[1] 47.92924
[1] 1098.478
[1] -51.26145
[1] 61.26601
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:41:06.700] [mlr3] Finished benchmark
INFO  [18:41:06.904] [bbotk] Result of batch 38:
INFO  [18:41:06.962] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:41:06.962] [bbotk]              -4.763965                           0.92849
INFO  [18:41:06.962] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:41:06.962] [bbotk]                         0.8614544            -3.29289              -6.486918
INFO  [18:41:06.962] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:41:06.962] [bbotk]                          3                    2768                 0.2039191
INFO  [18:41:06.962] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:41:06.962] [bbotk]  0.02032398 <list[8]>              FALSE     0.02501589        0      0
INFO  [18:41:06.962] [bbotk]  runtime_learners                                uhash
INFO  [18:41:06.962] [bbotk]           113.579 1d67fae0-e9d8-47fe-90ca-cf8cec57ea8b
WARN  [18:41:08.946] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:41:09.004] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 69 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:41:15.551] [bbotk] Evaluating 1 configuration(s)
INFO  [18:41:15.610] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:41:15.660] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -159.7996
[1] 30.7328
[1] 187.1111
[1] 7314.181
[1] -41.34912
[1] 126.3162
[1] -3615.045
[1] -108.3254
[1] -77.518
[1] 107.4264
INFO  [18:42:30.389] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -504.8776
[1] 12.78598
[1] -273.8869
[1] 10.41636
[1] -134.3263
[1] 28.3186
[1] 21.71994
[1] 826.0427
[1] -296.1961
[1] 78.47797
INFO  [18:43:35.984] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -114.2742
[1] 54.45814
[1] -140.6387
[1] 57.63163
[1] -7.209564e+15
[1] 9.459116e+16
[1] -66.84286
[1] 162.153
[1] -115.522
[1] 81.40372
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:44:48.239] [mlr3] Finished benchmark
INFO  [18:44:48.326] [bbotk] Result of batch 39:
INFO  [18:44:48.346] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:44:48.346] [bbotk]              -4.617178                         0.1182369
INFO  [18:44:48.346] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:44:48.346] [bbotk]                         0.2053371           -7.634028              -4.633143
INFO  [18:44:48.346] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:44:48.346] [bbotk]                          7                    4033                 0.9962293
INFO  [18:44:48.346] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:44:48.346] [bbotk]  0.02607664 <list[8]>              FALSE     0.03153959        0      0
INFO  [18:44:48.346] [bbotk]  runtime_learners                                uhash
INFO  [18:44:48.346] [bbotk]           212.137 ae13f32a-13cc-478f-96a7-592be9c97507
WARN  [18:44:50.866] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:44:50.882] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 70 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:44:55.104] [bbotk] Evaluating 1 configuration(s)
INFO  [18:44:55.187] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:44:55.265] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -41.40123
[1] 43.86378
[1] -96.91155
[1] 43.79974
[1] -223.0556
[1] 20.81539
[1] -430.9667
[1] -4.058572
[1] -38.26375
[1] 14.14123
INFO  [18:45:30.051] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -37.75324
[1] 37.03693
[1] -189.6312
[1] 35.86025
[1] -6967.741
[1] -87.75329
[1] -33.00595
[1] 29.1947
[1] -26.46082
[1] 19.38574
INFO  [18:46:29.858] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -104.0145
[1] 26.73617
[1] -161.2294
[1] 48.48892
[1] -53.51223
[1] 1.99468
[1] -17527.84
[1] -582.2569
[1] -25.31265
[1] 53.01987
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:47:43.095] [mlr3] Finished benchmark
INFO  [18:47:43.279] [bbotk] Result of batch 40:
INFO  [18:47:43.313] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:47:43.313] [bbotk]             -0.6738646                         0.6910506
INFO  [18:47:43.313] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:47:43.313] [bbotk]                         0.9886602           -4.069633               1.067976
INFO  [18:47:43.313] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:47:43.313] [bbotk]                          2                    4581                 0.7708433
INFO  [18:47:43.313] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:47:43.313] [bbotk]  0.01873142 <list[8]>              FALSE     0.02211566        0      0
INFO  [18:47:43.313] [bbotk]  runtime_learners                                uhash
INFO  [18:47:43.313] [bbotk]           166.775 428f27b4-7dc3-4fd9-9883-ea4e3b503923
INFO  [18:47:46.351] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 71 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:47:51.795] [bbotk] Evaluating 1 configuration(s)
INFO  [18:47:52.013] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:47:52.220] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -223.3514
[1] -4.536282
[1] -7277.691
[1] -176.2494
[1] -17.76303
[1] 82.12216
[1] -172.3702
[1] 6.281638
[1] -58.86431
[1] 90.79502
INFO  [18:48:55.783] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -165.6268
[1] 36.04439
[1] -225.9846
[1] -4.371765
[1] -42.2762
[1] 95.99704
[1] -161.9627
[1] -4.363005
[1] -83.46635
[1] 67.92868
INFO  [18:49:50.831] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -184.707
[1] 64.66874
[1] -81.04369
[1] 97.28984
[1] -229.2827
[1] 54.77692
[1] -122.5395
[1] 15.03106
[1] -176.5616
[1] 46.21073
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:50:27.794] [mlr3] Finished benchmark
INFO  [18:50:28.075] [bbotk] Result of batch 41:
INFO  [18:50:28.099] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:50:28.099] [bbotk]               2.304085                         0.8678971
INFO  [18:50:28.099] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:50:28.099] [bbotk]                         0.7412013          -0.2192967               4.025667
INFO  [18:50:28.099] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:50:28.099] [bbotk]                         12                    3440                 0.8396788
INFO  [18:50:28.099] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:50:28.099] [bbotk]  0.02442295 <list[8]>              FALSE     0.03527557        0      0
INFO  [18:50:28.099] [bbotk]  runtime_learners                                uhash
INFO  [18:50:28.099] [bbotk]           154.551 f0e8f13c-ef2d-4048-befd-3fda42ee16f2
INFO  [18:50:34.045] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 72 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:50:47.924] [bbotk] Evaluating 1 configuration(s)
INFO  [18:50:48.409] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:50:48.505] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -33.73675
[1] 49.56113
[1] -47.81149
[1] 3.434051
[1] -16.38401
[1] 52.44491
[1] -100.5848
[1] -0.4186107
[1] -85.1251
[1] 19.19989
INFO  [18:51:08.839] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1437.279
[1] -38.55163
[1] -32.52188
[1] 36.71827
[1] -20.02057
[1] 69.05032
[1] -35.94587
[1] 29.05572
[1] -820.1873
[1] -39.34382
INFO  [18:51:45.576] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -21.65698
[1] 70.38817
[1] -35.18264
[1] 13.92215
[1] -44.52143
[1] 33.62587
[1] -42.95782
[1] 9.964622
[1] -89.10588
[1] 177.6583
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:52:24.738] [mlr3] Finished benchmark
INFO  [18:52:25.920] [bbotk] Result of batch 42:
INFO  [18:52:25.965] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:52:25.965] [bbotk]              -1.008012                         0.8260761
INFO  [18:52:25.965] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:52:25.965] [bbotk]                         0.9228788           -3.160516              -2.829671
INFO  [18:52:25.965] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:52:25.965] [bbotk]                          8                    1719                  0.810804
INFO  [18:52:25.965] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:52:25.965] [bbotk]  0.02434384 <list[8]>              FALSE     0.02210852        0      0
INFO  [18:52:25.965] [bbotk]  runtime_learners                                uhash
INFO  [18:52:25.965] [bbotk]            95.999 5b023cf7-023c-4565-9334-9d3a3bbae8bd
INFO  [18:52:29.321] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 73 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:52:43.031] [bbotk] Evaluating 1 configuration(s)
INFO  [18:52:43.449] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:52:43.480] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -68.71746
[1] 33.92686
[1] -70.50931
[1] 37.68601
[1] -113.4395
[1] 120.8125
[1] -73.77715
[1] 59.63081
[1] -75.07041
[1] 26.20184
INFO  [18:53:29.030] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -67.87971
[1] 50.26421
[1] -73.77662
[1] 23.21035
[1] -278.8725
[1] 55.76018
[1] -161.6427
[1] 14.33511
[1] -76.49703
[1] 38.93629
INFO  [18:54:35.522] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2068.962
[1] -64.32999
[1] -34.16849
[1] 58.22434
[1] -37.40867
[1] 112.8026
[1] -12.91197
[1] 74.86603
[1] -114.3721
[1] -3.253245
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:55:17.848] [mlr3] Finished benchmark
INFO  [18:55:18.444] [bbotk] Result of batch 43:
INFO  [18:55:18.454] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:55:18.454] [bbotk]               1.144499                         0.2996701
INFO  [18:55:18.454] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:55:18.454] [bbotk]                         0.8818343           -2.931189               -4.48485
INFO  [18:55:18.454] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:55:18.454] [bbotk]                         20                    4293                 0.9337733
INFO  [18:55:18.454] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:55:18.454] [bbotk]  0.02276865 <list[8]>              FALSE     0.03057077        0      0
INFO  [18:55:18.454] [bbotk]  runtime_learners                                uhash
INFO  [18:55:18.454] [bbotk]           153.973 e799f2b6-2963-40b6-9497-78c42339c285
INFO  [18:55:23.682] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 74 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:55:39.669] [bbotk] Evaluating 1 configuration(s)
INFO  [18:55:39.766] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:55:39.851] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -747.7389
[1] 41.94915
[1] -35.89988
[1] 42.40925
[1] -82.24681
[1] -2.731321
[1] -88.06457
[1] 3.807902
[1] -97.71779
[1] 1.654013
INFO  [18:56:34.968] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -14.5965
[1] 27.72912
[1] -77901.7
[1] -3403.481
[1] -1653.64
[1] -48.09305
[1] -76.6281
[1] 18.23167
[1] -42.3669
[1] 266.7506
INFO  [18:57:47.445] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -48.65311
[1] 9.828247
[1] -35.33583
[1] 67.3079
[1] -17.06543
[1] 52.885
[1] -20.26595
[1] 46.45596
[1] -116.9481
[1] 2.408328
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:58:39.451] [mlr3] Finished benchmark
INFO  [18:58:39.651] [bbotk] Result of batch 44:
INFO  [18:58:39.677] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:58:39.677] [bbotk]             -0.2893867                         0.6372131
INFO  [18:58:39.677] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:58:39.677] [bbotk]                         0.8095301           -2.333396              -5.816819
INFO  [18:58:39.677] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:58:39.677] [bbotk]                          5                    4698                  0.462549
INFO  [18:58:39.677] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:58:39.677] [bbotk]  0.01749416 <list[8]>              FALSE     0.02207298        0      0
INFO  [18:58:39.677] [bbotk]  runtime_learners                                uhash
INFO  [18:58:39.677] [bbotk]           179.163 7ba26c10-ad7e-4213-9c94-4359c60cf150
INFO  [18:58:41.032] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 75 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:58:49.484] [bbotk] Evaluating 1 configuration(s)
INFO  [18:58:49.546] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:58:49.602] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -95.91518
[1] 12.54478
[1] -81.92832
[1] 93.81534
[1] -38.01703
[1] 29.7447
[1] -44.67751
[1] 132.0416
[1] -177.244
[1] -3.044768
INFO  [18:59:41.217] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 2049.053
[1] 38504.88
[1] -64.20188
[1] 39.9372
[1] -88.43289
[1] 12.91664
[1] -17946.08
[1] -508.5989
[1] -76.29747
[1] 29.95827
INFO  [19:00:34.543] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -440.8592
[1] -3.844927
[1] -128.649
[1] 33.85774
[1] -5554.755
[1] -109.4803
[1] -131.9692
[1] 13.05811
[1] -29.63676
[1] 45.7571
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:01:18.034] [mlr3] Finished benchmark
INFO  [19:01:18.096] [bbotk] Result of batch 45:
INFO  [19:01:18.118] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:01:18.118] [bbotk]             -0.7667192                         0.1211762
INFO  [19:01:18.118] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:01:18.118] [bbotk]                         0.7377219           -3.179787               2.926234
INFO  [19:01:18.118] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:01:18.118] [bbotk]                          4                    2518                  0.607084
INFO  [19:01:18.118] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:01:18.118] [bbotk]  0.01545882 <list[8]>              FALSE     0.02554453        0      0
INFO  [19:01:18.118] [bbotk]  runtime_learners                                uhash
INFO  [19:01:18.118] [bbotk]           147.605 da4c3c0c-5006-4f84-8a36-917a1f0a8d24
INFO  [19:01:28.025] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 76 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:01:42.538] [bbotk] Evaluating 1 configuration(s)
INFO  [19:01:42.681] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:01:42.729] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -290.5108
[1] -4.11087
[1] -75.48745
[1] 54.61773
[1] -156.7597
[1] 193.8093
[1] -23.99254
[1] 63.85293
[1] -103.372
[1] 7.420427
INFO  [19:03:02.098] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -179.5587
[1] 3.18263
[1] -26.4664
[1] 70.12298
[1] -62.14598
[1] 66.99897
[1] -93.01662
[1] 47.68676
[1] -59.26789
[1] 39.83395
INFO  [19:03:48.996] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -33.08465
[1] 193.2548
[1] -1434.833
[1] 2.150342
[1] -46.77045
[1] 99.96899
[1] -2142.713
[1] -44.42576
[1] -75.48468
[1] 3.831397
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:04:44.743] [mlr3] Finished benchmark
INFO  [19:04:46.932] [bbotk] Result of batch 46:
INFO  [19:04:47.016] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:04:47.016] [bbotk]              -3.740098                         0.6912952
INFO  [19:04:47.016] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:04:47.016] [bbotk]                          0.823213            -2.98289              -4.059312
INFO  [19:04:47.016] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:04:47.016] [bbotk]                         11                    3809                 0.1037097
INFO  [19:04:47.016] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:04:47.016] [bbotk]  0.01680613 <list[8]>              FALSE     0.02736205        0      0
INFO  [19:04:47.016] [bbotk]  runtime_learners                                uhash
INFO  [19:04:47.016] [bbotk]           181.385 1bb9171b-993c-498c-88c8-cae133e328b6
INFO  [19:04:52.982] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 77 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:05:10.833] [bbotk] Evaluating 1 configuration(s)
INFO  [19:05:11.221] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:05:11.299] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 91.91362
[1] 4327.34
[1] -326.4392
[1] 68.19024
[1] -269.09
[1] -4.961783
[1] -160.45
[1] -3.060708
[1] -34.70092
[1] 200.4219
INFO  [19:06:01.100] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -110.7534
[1] 88.76665
[1] -101.3019
[1] 100.9283
[1] -4185.653
[1] -123.4621
[1] -58.41906
[1] 167.9179
[1] 189.0873
[1] 8625.044
INFO  [19:07:02.299] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -319.9728
[1] 419.0661
[1] -13221.95
[1] -254.048
[1] -118.0335
[1] 101.8763
[1] -77.16688
[1] 156.3518
[1] -99.14263
[1] 38.17073
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:08:15.112] [mlr3] Finished benchmark
INFO  [19:08:15.332] [bbotk] Result of batch 47:
INFO  [19:08:15.354] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:08:15.354] [bbotk]              0.8403073                         0.2110671
INFO  [19:08:15.354] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:08:15.354] [bbotk]                         0.9205973           -7.852567              -5.659588
INFO  [19:08:15.354] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:08:15.354] [bbotk]                          4                    3341                 0.7886667
INFO  [19:08:15.354] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:08:15.354] [bbotk]  0.01973301 <list[8]>              FALSE     0.03721438        0      0
INFO  [19:08:15.354] [bbotk]  runtime_learners                                uhash
INFO  [19:08:15.354] [bbotk]           183.643 425067e9-5787-4a77-a0b9-f6a99d199ffd
INFO  [19:08:17.952] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 78 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:08:27.986] [bbotk] Evaluating 1 configuration(s)
INFO  [19:08:28.147] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:08:28.225] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -156.6228
[1] 1.822861
[1] -68.85588
[1] 23.71903
[1] -46925.83
[1] -1017.332
[1] -2360.591
[1] -38.05865
[1] -81.78227
[1] 60.16692
INFO  [19:09:35.681] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -149.8705
[1] 15.7235
[1] -76.80115
[1] 73.25453
[1] -133.4831
[1] 14.81365
[1] -125.8207
[1] 62.57287
[1] -94.75604
[1] 33.39113
INFO  [19:10:25.347] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -45.67567
[1] 156.6529
[1] -175.4627
[1] 9.735573
[1] -1925755
[1] -48264.3
[1] -27.779
[1] 74.0526
[1] -42.55273
[1] 85.12281
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:11:37.031] [mlr3] Finished benchmark
INFO  [19:11:38.421] [bbotk] Result of batch 48:
INFO  [19:11:38.471] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:11:38.471] [bbotk]               1.339468                         0.1274679
INFO  [19:11:38.471] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:11:38.471] [bbotk]                         0.9727575           -4.045759              -5.461077
INFO  [19:11:38.471] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:11:38.471] [bbotk]                         12                    4004                 0.4840888
INFO  [19:11:38.471] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:11:38.471] [bbotk]  0.0178343 <list[8]>              FALSE     0.03202136        0      0
INFO  [19:11:38.471] [bbotk]  runtime_learners                                uhash
INFO  [19:11:38.471] [bbotk]           188.156 a8dddda6-148e-4fe5-b6fe-46dd58cc34d0
INFO  [19:11:42.167] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 79 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:11:52.955] [bbotk] Evaluating 1 configuration(s)
INFO  [19:11:53.505] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:11:54.075] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -82.39933
[1] 7.87643
[1] -94.13475
[1] 68.76427
[1] -72.88433
[1] 24.14364
[1] -31.70047
[1] 99.40111
[1] -48.5988
[1] 41.54451
INFO  [19:12:59.246] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -99.27618
[1] 32.17018
[1] 1292.399
[1] 27130.43
[1] -154.8931
[1] 28.77034
[1] -74.57448
[1] 18.54456
[1] -97.22589
[1] 167.9522
INFO  [19:13:47.086] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -71.73073
[1] 18.91148
[1] -66.49426
[1] 20.84525
[1] -62.83617
[1] 104.0595
[1] -1.652436e+15
[1] 4.322457e+16
[1] -112.6888
[1] 22.01503
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:14:38.494] [mlr3] Finished benchmark
INFO  [19:14:38.594] [bbotk] Result of batch 49:
INFO  [19:14:38.761] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:14:38.761] [bbotk]               1.142216                         0.7224222
INFO  [19:14:38.761] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:14:38.761] [bbotk]                         0.7443248          -0.9000289              -0.404706
INFO  [19:14:38.761] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:14:38.761] [bbotk]                         10                    2162                 0.9899542
INFO  [19:14:38.761] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:14:38.761] [bbotk]  0.01755886 <list[8]>              FALSE     0.02946431        0      0
INFO  [19:14:38.761] [bbotk]  runtime_learners                                uhash
INFO  [19:14:38.761] [bbotk]           163.501 77b0ea04-1761-4e5c-bc4e-b4ec948d1b6f
INFO  [19:14:43.072] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 80 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:14:57.294] [bbotk] Evaluating 1 configuration(s)
INFO  [19:14:58.192] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:14:58.233] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -407.862
[1] -4.374596
[1] -149.5791
[1] 19.99545
[1] -4757.787
[1] -159.9168
[1] -482.7592
[1] -0.5290888
[1] -115.7509
[1] 129.4162
INFO  [19:16:06.046] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -196.9038
[1] 29.5889
[1] -197.8775
[1] 0.6622454
[1] -199.5435
[1] -4.148211
[1] -90.21282
[1] 130.5683
[1] -116.1019
[1] 105.3592
INFO  [19:17:31.166] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -81.26896
[1] 97.87007
[1] -90.1048
[1] 97.22489
[1] -1.525183e+16
[1] 1.156153e+17
[1] -190.3378
[1] 131.9164
[1] -134.0956
[1] -3.380402
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:18:47.156] [mlr3] Finished benchmark
INFO  [19:18:47.389] [bbotk] Result of batch 50:
INFO  [19:18:47.399] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:18:47.399] [bbotk]               2.642519                         0.7605901
INFO  [19:18:47.399] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:18:47.399] [bbotk]                         0.3183385             -5.7388              -6.064404
INFO  [19:18:47.399] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:18:47.399] [bbotk]                          6                    3765                 0.9832749
INFO  [19:18:47.399] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:18:47.399] [bbotk]  0.01669492 <list[8]>              FALSE     0.03601537        0      0
INFO  [19:18:47.399] [bbotk]  runtime_learners                                uhash
INFO  [19:18:47.399] [bbotk]            228.79 5b71db31-0ff8-46d3-ab60-e8929898a3b6
INFO  [19:18:48.535] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 81 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:19:00.698] [bbotk] Evaluating 1 configuration(s)
INFO  [19:19:00.998] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:19:01.231] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -145.9721
[1] -3.577701
[1] -137.1029
[1] 37.4786
[1] -35.31562
[1] 62.38875
[1] -24.93272
[1] 189.9176
[1] -249.153
[1] 124.2837
INFO  [19:20:05.590] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -82.96077
[1] 24.2798
[1] -79.01529
[1] 29.52692
[1] -58.63807
[1] 67.22667
[1] -73.95043
[1] 55.07049
[1] -84.99482
[1] 112.32
INFO  [19:21:31.500] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -255.9669
[1] 6.805466
[1] -77.35544
[1] 47.52666
[1] -133.6636
[1] 37.3814
[1] -268
[1] -4.602523
[1] -208.5474
[1] 83.22787
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:22:54.701] [mlr3] Finished benchmark
INFO  [19:22:57.334] [bbotk] Result of batch 51:
INFO  [19:22:57.522] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:22:57.522] [bbotk]                2.07866                         0.7911188
INFO  [19:22:57.522] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:22:57.522] [bbotk]                         0.9637001           -1.515129             -0.6755507
INFO  [19:22:57.522] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:22:57.522] [bbotk]                         19                    3539                 0.9741394
INFO  [19:22:57.522] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:22:57.522] [bbotk]  0.02449861 <list[8]>              FALSE     0.03826803        0      0
INFO  [19:22:57.522] [bbotk]  runtime_learners                                uhash
INFO  [19:22:57.522] [bbotk]           232.426 c0069e9a-a7dd-498c-a61b-15785c2bbfc1
INFO  [19:23:05.949] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 82 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:23:16.227] [bbotk] Evaluating 1 configuration(s)
INFO  [19:23:16.475] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:23:16.579] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -105.8097
[1] 1.208314
[1] -69.77602
[1] 21.4421
[1] -138.0464
[1] 14.32461
[1] -108.5279
[1] 20.61864
[1] -2008.173
[1] -59.4807
INFO  [19:24:06.051] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -53.78713
[1] 56.91453
[1] -1693.545
[1] -46.06893
[1] -65.58998
[1] 27.21583
[1] -3.295305
[1] 148.816
[1] -57.12773
[1] 34.12404
INFO  [19:25:14.197] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -127.1198
[1] 99.24162
[1] -47.99457
[1] 54.0188
[1] -133.2376
[1] 93.89864
[1] -71.56135
[1] 18.38651
[1] -166.7014
[1] 14.21525
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:25:59.546] [mlr3] Finished benchmark
INFO  [19:26:00.521] [bbotk] Result of batch 52:
INFO  [19:26:00.555] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:26:00.555] [bbotk]               -5.02557                         0.7654885
INFO  [19:26:00.555] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:26:00.555] [bbotk]                         0.7775572            -3.81296               1.992477
INFO  [19:26:00.555] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:26:00.555] [bbotk]                         11                    2303                 0.2264027
INFO  [19:26:00.555] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:26:00.555] [bbotk]  0.01725035 <list[8]>              FALSE     0.02609896        0      0
INFO  [19:26:00.555] [bbotk]  runtime_learners                                uhash
INFO  [19:26:00.555] [bbotk]            162.25 298ed19b-338f-404f-bc51-93aebde01183
INFO  [19:26:02.922] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 83 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:26:12.806] [bbotk] Evaluating 1 configuration(s)
INFO  [19:26:12.946] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:26:13.064] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -74.4717
[1] 5.283883
[1] -30.89764
[1] 28.38432
[1] -24.52934
[1] 19.21386
[1] -26.97634
[1] 5.824523
[1] -17.88177
[1] 76.14265
INFO  [19:26:56.607] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -36.16796
[1] 36.75659
[1] -103.5048
[1] 23.76893
[1] -192.2066
[1] 53.50875
[1] -21.89364
[1] 22.34449
[1] -1528.555
[1] -38.54239
INFO  [19:27:40.795] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -14.44627
[1] 25.12461
[1] -20.83142
[1] 49.65772
[1] -19.36894
[1] 44.98463
[1] -144.7717
[1] 9.223386
[1] -1450.531
[1] -29.54487
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:28:22.436] [mlr3] Finished benchmark
INFO  [19:28:23.185] [bbotk] Result of batch 53:
INFO  [19:28:23.229] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:28:23.229] [bbotk]              -6.120716                         0.8885707
INFO  [19:28:23.229] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:28:23.229] [bbotk]                         0.1429722          -0.8415164               -3.57952
INFO  [19:28:23.229] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:28:23.229] [bbotk]                         18                    1917                 0.3853395
INFO  [19:28:23.229] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:28:23.229] [bbotk]  0.01583097 <list[8]>              FALSE     0.02683067        0      0
INFO  [19:28:23.229] [bbotk]  runtime_learners                                uhash
INFO  [19:28:23.229] [bbotk]           128.383 5581991e-95df-4dc4-aba6-ccbbe74866c1
INFO  [19:28:28.037] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 84 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:28:44.849] [bbotk] Evaluating 1 configuration(s)
INFO  [19:28:45.095] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:28:45.248] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1278.691
[1] -21.10786
[1] 21.17835
[1] 1036.232
[1] -1498.499
[1] 370.1326
[1] -1474.619
[1] -24.89394
[1] -1485.259
[1] -24.42409
INFO  [19:30:09.363] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 27.42777
[1] 1289.002
[1] -1539.33
[1] 7.302015
[1] 38.29938
[1] 1869.26
[1] -1580.282
[1] -25.31138
[1] -882.7234
[1] 598.7201
INFO  [19:31:18.646] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1272.054
[1] -21.56397
[1] 24.1558
[1] 1167.391
[1] -986.8518
[1] -16.75836
[1] 41.40853
[1] 1894.535
[1] 32.55806
[1] 1578.085
INFO  [19:32:18.686] [mlr3] Finished benchmark
INFO  [19:32:19.662] [bbotk] Result of batch 54:
INFO  [19:32:19.917] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:32:19.917] [bbotk]               1.464738                         0.1019745
INFO  [19:32:19.917] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:32:19.917] [bbotk]                         0.9896226           -8.690521              -4.625411
INFO  [19:32:19.917] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:32:19.917] [bbotk]                         10                    4271                 0.1313758
INFO  [19:32:19.917] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:32:19.917] [bbotk]  0.01654422 <list[8]>              FALSE      0.1448734        0      0
INFO  [19:32:19.917] [bbotk]  runtime_learners                                uhash
INFO  [19:32:19.917] [bbotk]           213.182 66de4c47-38da-4fae-8b62-e6646223f2ed
INFO  [19:32:24.022] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 85 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:32:36.010] [bbotk] Evaluating 1 configuration(s)
INFO  [19:32:36.102] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:32:36.261] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -132.8274
[1] 6.135298
[1] -72.48401
[1] 23.90178
[1] -52.7616
[1] 161.7763
[1] -123.8212
[1] 25.44105
[1] -84.72135
[1] -3.124755
INFO  [19:33:27.117] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -3605.182
[1] -65.624
[1] -42.95603
[1] 28.49617
[1] -27.27445
[1] 271.1787
[1] -22.46351
[1] 37.19785
[1] -55.13768
[1] 16.8176
INFO  [19:34:19.750] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2807.442
[1] -102.5614
[1] -228.359
[1] -3.726941
[1] -54.99816
[1] 34.44574
[1] -74.08047
[1] 8.488233
[1] 41.42119
[1] 1431.044
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:35:42.507] [mlr3] Finished benchmark
INFO  [19:35:42.828] [bbotk] Result of batch 55:
INFO  [19:35:42.849] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:35:42.849] [bbotk]              -3.252908                         0.8702324
INFO  [19:35:42.849] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:35:42.849] [bbotk]                         0.7526159          -0.8639045               2.618444
INFO  [19:35:42.849] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:35:42.849] [bbotk]                          1                    4447                  0.198017
INFO  [19:35:42.849] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:35:42.849] [bbotk]  0.0143843 <list[8]>              FALSE     0.02415954        0      0
INFO  [19:35:42.849] [bbotk]  runtime_learners                                uhash
INFO  [19:35:42.849] [bbotk]           185.803 cc7e8417-aeab-4620-b0f7-f4291c03287b
INFO  [19:35:47.288] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 86 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:36:00.522] [bbotk] Evaluating 1 configuration(s)
INFO  [19:36:00.743] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:36:00.754] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -59.67706
[1] 100.3171
[1] -92.27141
[1] 120.2958
[1] -166.8057
[1] 20.31873
[1] -282.0713
[1] 25.06389
[1] -203.5273
[1] 200.3632
INFO  [19:37:05.878] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -95.64995
[1] 206.4039
[1] -6108.998
[1] -118.744
[1] -149.9071
[1] 85.64391
[1] -196.0579
[1] 23.83958
[1] 11.59229
[1] 339.3245
INFO  [19:38:10.394] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -465.2183
[1] -6.400037
[1] -57.4066
[1] 269.0621
[1] -174.6944
[1] 40.33867
[1] -91.08755
[1] 157.6563
[1] -166.1028
[1] 27.26505
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:39:26.714] [mlr3] Finished benchmark
INFO  [19:39:27.369] [bbotk] Result of batch 56:
INFO  [19:39:27.390] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:39:27.390] [bbotk]             -0.7382461                         0.1300844
INFO  [19:39:27.390] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:39:27.390] [bbotk]                         0.2575588           -7.780366              -5.587862
INFO  [19:39:27.390] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:39:27.390] [bbotk]                         19                    4044                 0.9772294
INFO  [19:39:27.390] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:39:27.390] [bbotk]  0.02744901 <list[8]>              FALSE     0.03321521        0      0
INFO  [19:39:27.390] [bbotk]  runtime_learners                                uhash
INFO  [19:39:27.390] [bbotk]            205.61 1d4d0235-1496-4d39-8379-9634f641cb28
INFO  [19:39:30.206] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 87 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:39:38.331] [bbotk] Evaluating 1 configuration(s)
INFO  [19:39:38.631] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:39:38.685] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -540.5317
[1] -4.828208
[1] -188.8762
[1] 65.51724
[1] -295.4183
[1] -5.073643
[1] -152.3968
[1] 16.19541
[1] -161.1994
[1] 82.53713
INFO  [19:40:28.230] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -100.4737
[1] 75.20466
[1] -257.4087
[1] -4.162336
[1] -111.7717
[1] 60.1282
[1] -211.2593
[1] 43.96542
[1] -104.3363
[1] 79.57421
INFO  [19:41:08.037] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -114.1653
[1] 78.65964
[1] -185.6221
[1] 89.05372
[1] -228.6738
[1] -4.170957
[1] 5.555158
[1] 176.7748
[1] -149.6242
[1] 28.12395
INFO  [19:42:00.605] [mlr3] Finished benchmark
INFO  [19:42:01.177] [bbotk] Result of batch 57:
INFO  [19:42:01.187] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:42:01.187] [bbotk]               2.584333                         0.2119416
INFO  [19:42:01.187] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:42:01.187] [bbotk]                         0.9590504            -6.45351              -3.806497
INFO  [19:42:01.187] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:42:01.187] [bbotk]                          5                    3423                 0.9814789
INFO  [19:42:01.187] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:42:01.187] [bbotk]  0.01969456 <list[8]>              FALSE     0.03514465        0      0
INFO  [19:42:01.187] [bbotk]  runtime_learners                                uhash
INFO  [19:42:01.187] [bbotk]           141.727 46360fb2-7f92-49c5-aefc-293a71083b35
WARN  [19:42:20.063] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:42:20.068] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 88 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:42:43.639] [bbotk] Evaluating 1 configuration(s)
INFO  [19:42:44.002] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:42:44.120] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -51.9214
[1] 54.43179
[1] -99.83999
[1] 59.16409
[1] -149.3146
[1] -4.096188
[1] -72.75366
[1] 24.29337
[1] -40.48691
[1] 39.30167
INFO  [19:44:16.202] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -47.34328
[1] 43.44446
[1] -79.62556
[1] 89.99229
[1] -123.5438
[1] 10.4657
[1] -69.39151
[1] 42.8657
[1] -59.91485
[1] 60.76098
INFO  [19:46:19.536] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -44.60877
[1] 33.9112
[1] -167.061
[1] 100.5672
[1] -94.62073
[1] -1.952795
[1] -132.2304
[1] 60.46417
[1] -51.9017
[1] 91.48411
INFO  [19:48:23.338] [mlr3] Finished benchmark
INFO  [19:48:24.243] [bbotk] Result of batch 58:
INFO  [19:48:24.545] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:48:24.545] [bbotk]            -0.08112577                         0.3334425
INFO  [19:48:24.545] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:48:24.545] [bbotk]                         0.9575131           -6.675089              -1.180632
INFO  [19:48:24.545] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:48:24.545] [bbotk]                         14                    3313                 0.8966278
INFO  [19:48:24.545] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:48:24.545] [bbotk]  0.01558523 <list[8]>              FALSE     0.02974101        0      0
INFO  [19:48:24.545] [bbotk]  runtime_learners                                uhash
INFO  [19:48:24.545] [bbotk]           337.452 1119ec79-f61e-4ccb-943f-a9696803f2e6
INFO  [19:48:26.074] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 89 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:48:33.470] [bbotk] Evaluating 1 configuration(s)
INFO  [19:48:33.566] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:48:33.596] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -47.80848
[1] 36.59304
[1] -58.14001
[1] 8.798851
[1] -106.487
[1] 9.724812
[1] -106.7135
[1] 10.29649
[1] -36.08842
[1] 34.70319
INFO  [19:49:33.286] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -33.46707
[1] 18.20944
[1] -176.5677
[1] 41.49699
[1] -29.69147
[1] 88.35639
[1] -28.34317
[1] 272.1513
[1] -241941.6
[1] -8090.163
INFO  [19:50:52.984] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -22.49683
[1] 46.98487
[1] -31.39014
[1] 51.22667
[1] -288.8306
[1] -3.375404
[1] -28.09537
[1] 40.97273
[1] -67.07668
[1] 31.1919
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:53:16.888] [mlr3] Finished benchmark
INFO  [19:53:17.210] [bbotk] Result of batch 59:
INFO  [19:53:17.241] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:53:17.241] [bbotk]             -0.6621066                         0.7960411
INFO  [19:53:17.241] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:53:17.241] [bbotk]                         0.9811389           -4.128077              -2.083904
INFO  [19:53:17.241] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:53:17.241] [bbotk]                         18                    4423                 0.5229602
INFO  [19:53:17.241] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:53:17.241] [bbotk]  0.01766684 <list[8]>              FALSE     0.02167761        0      0
INFO  [19:53:17.241] [bbotk]  runtime_learners                                uhash
INFO  [19:53:17.241] [bbotk]           282.654 672f81e1-3c3d-49fb-a47f-190d06591d98
INFO  [19:53:18.972] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 90 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:53:32.058] [bbotk] Evaluating 1 configuration(s)
INFO  [19:53:32.355] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:53:32.599] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -156.4212
[1] 3.800746
[1] -109.8669
[1] 6.509254
[1] -45.2099
[1] 72.27992
[1] -3257.584
[1] -107.6082
[1] -96.2859
[1] 17.7841
INFO  [19:54:18.381] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -37.96351
[1] 46.33496
[1] -113.8588
[1] 57.41848
[1] -58.71387
[1] 12.32264
[1] -162.9303
[1] 53.36219
[1] -50.97496
[1] 99.81569
INFO  [19:56:05.419] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -33.7246
[1] 56.3881
[1] -122.2585
[1] 14.33006
[1] 131.6198
[1] 3252.421
[1] -237.126
[1] 38.78728
[1] -67.39554
[1] 13.32998
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:57:18.305] [mlr3] Finished benchmark
INFO  [19:57:18.770] [bbotk] Result of batch 60:
INFO  [19:57:18.844] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:57:18.844] [bbotk]              -3.397739                         0.7876855
INFO  [19:57:18.844] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:57:18.844] [bbotk]                         0.7954809            -4.89366               1.461715
INFO  [19:57:18.844] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:57:18.844] [bbotk]                         18                    4821                 0.1729397
INFO  [19:57:18.844] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:57:18.844] [bbotk]  0.01490118 <list[8]>              FALSE     0.02713692        0      0
INFO  [19:57:18.844] [bbotk]  runtime_learners                                uhash
INFO  [19:57:18.844] [bbotk]           224.686 5b2a93ab-11b4-4a40-b733-1fc0ca24d2ab
INFO  [19:57:32.880] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 91 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:57:46.992] [bbotk] Evaluating 1 configuration(s)
INFO  [19:57:47.324] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:57:47.454] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -94.99603
[1] 3.167569
[1] -171.4317
[1] 24.73148
[1] -209.0235
[1] 0.9672945
[1] -49.41961
[1] 60.72701
[1] -78.47264
[1] 14.80523
INFO  [19:58:30.737] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -43.26488
[1] 22.70949
[1] -59.49237
[1] 182.62
[1] -1005.853
[1] 33.93316
[1] -30.52101
[1] 27.07752
[1] -227.1279
[1] 18.42408
INFO  [19:59:52.093] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -204.9739
[1] -3.4716
[1] -34.9164
[1] 68.3014
[1] -36.8417
[1] 29.42338
[1] 61.42669
[1] 1226.607
[1] -125.5426
[1] 27.61968
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:00:44.011] [mlr3] Finished benchmark
INFO  [20:00:44.086] [bbotk] Result of batch 61:
INFO  [20:00:44.107] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:00:44.107] [bbotk]              -1.512211                         0.8194423
INFO  [20:00:44.107] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:00:44.107] [bbotk]                         0.3364134           -1.479256               2.804984
INFO  [20:00:44.107] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:00:44.107] [bbotk]                          2                    2671                 0.5665025
INFO  [20:00:44.107] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:00:44.107] [bbotk]  0.01644028 <list[8]>              FALSE     0.02315371        0      0
INFO  [20:00:44.107] [bbotk]  runtime_learners                                uhash
INFO  [20:00:44.107] [bbotk]           176.058 b94e13d7-756e-432b-8e54-f32403e80be1
INFO  [20:00:47.851] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 92 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:01:09.803] [bbotk] Evaluating 1 configuration(s)
INFO  [20:01:10.545] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:01:10.846] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -111.7493
[1] 18.2945
[1] -61.33734
[1] 64.6269
[1] -98.75159
[1] -1.73502
[1] -54.24524
[1] 15.27893
[1] -24.59879
[1] 42.99563
INFO  [20:02:28.849] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -71.63667
[1] 146.2525
[1] -43.96313
[1] 27.54104
[1] -326.2586
[1] 0.1306916
[1] -30.0965
[1] 129.8403
[1] -17.48708
[1] 30.49763
INFO  [20:03:54.644] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -50.98974
[1] 21.69382
[1] -44.64596
[1] 13.50595
[1] -45.43419
[1] 45.82421
[1] -31.02652
[1] 50.77783
[1] 107.2207
[1] 1820.174
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:05:41.154] [mlr3] Finished benchmark
INFO  [20:05:42.062] [bbotk] Result of batch 62:
INFO  [20:05:42.097] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:05:42.097] [bbotk]              -6.249308                         0.8547463
INFO  [20:05:42.097] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:05:42.097] [bbotk]                         0.3076459           -5.577631              -4.746069
INFO  [20:05:42.097] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:05:42.097] [bbotk]                         18                    3547                 0.5851652
INFO  [20:05:42.097] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:05:42.097] [bbotk]  0.01595162 <list[8]>              FALSE     0.02262474        0      0
INFO  [20:05:42.097] [bbotk]  runtime_learners                                uhash
INFO  [20:05:42.097] [bbotk]           270.076 a786c236-c3f7-4e45-8ca0-ab33dd2f540b
WARN  [20:05:59.047] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [20:05:59.055] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 93 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:06:18.980] [bbotk] Evaluating 1 configuration(s)
INFO  [20:06:19.131] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:06:19.175] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -138.0478
[1] 21.59602
[1] -362.1436
[1] 113.7651
[1] -34.78123
[1] 69.80567
[1] -303.4563
[1] 28.83395
[1] -142.9636
[1] 12.19357
INFO  [20:06:56.705] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -124.5513
[1] 51.47005
[1] -33.05873
[1] 89.84031
[1] -300.124
[1] -5.007378
[1] -158.6368
[1] 28.14456
[1] -241.8663
[1] 14.27215
INFO  [20:07:48.139] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -151.1124
[1] 93.3788
[1] -96.96838
[1] 76.32422
[1] -240.3708
[1] -4.14375
[1] -119.2256
[1] 31.14021
[1] -68.41844
[1] 87.07132
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:08:46.422] [mlr3] Finished benchmark
INFO  [20:08:46.725] [bbotk] Result of batch 63:
INFO  [20:08:46.995] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:08:46.995] [bbotk]               2.297173                         0.3026064
INFO  [20:08:46.995] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:08:46.995] [bbotk]                         0.2250695          -0.5597409               4.586326
INFO  [20:08:46.995] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:08:46.995] [bbotk]                         15                    1871                 0.9007468
INFO  [20:08:46.995] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:08:46.995] [bbotk]  0.01442269 <list[8]>              FALSE     0.03593472        0      0
INFO  [20:08:46.995] [bbotk]  runtime_learners                                uhash
INFO  [20:08:46.995] [bbotk]            146.42 2977c68d-598e-444f-8dd7-888f6e8fec94
INFO  [20:08:48.819] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 94 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:08:58.293] [bbotk] Evaluating 1 configuration(s)
INFO  [20:08:58.353] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:08:58.374] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -76.18993
[1] 48.723
[1] -123.702
[1] 2.112317
[1] -141.4603
[1] -3.41942
[1] -134.1795
[1] 39.48779
[1] -75.81912
[1] 50.52385
INFO  [20:09:24.025] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -68.93313
[1] 74.5279
[1] -68.69353
[1] 22.62847
[1] -3393.767
[1] -57.58313
[1] -134.8703
[1] 27.59534
[1] -143.6058
[1] 37.17164
INFO  [20:10:21.899] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -159.0994
[1] 18.0639
[1] 857.1548
[1] 18450.49
[1] -99.73959
[1] 52.98522
[1] -68.24174
[1] 15.34006
[1] -49.64685
[1] 89.84456
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:11:47.930] [mlr3] Finished benchmark
INFO  [20:11:48.331] [bbotk] Result of batch 64:
INFO  [20:11:48.366] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:11:48.366] [bbotk]              -1.355331                         0.9598137
INFO  [20:11:48.366] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:11:48.366] [bbotk]                         0.9710899           -3.054038               1.146464
INFO  [20:11:48.366] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:11:48.366] [bbotk]                         10                    3116                 0.1042122
INFO  [20:11:48.366] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:11:48.366] [bbotk]  0.01402387 <list[8]>              FALSE     0.02964228        0      0
INFO  [20:11:48.366] [bbotk]  runtime_learners                                uhash
INFO  [20:11:48.366] [bbotk]            168.76 ae552694-db86-479e-b943-cb79672cba4a
INFO  [20:11:52.236] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 95 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:12:01.911] [bbotk] Evaluating 1 configuration(s)
INFO  [20:12:02.096] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:12:02.147] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -103.5284
[1] 17.9962
[1] -43.75659
[1] 10.55637
[1] -920.0242
[1] -3.852522
[1] -3178.672
[1] -193.2186
[1] -108.7236
[1] 29.37039
INFO  [20:12:47.716] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -64.00021
[1] 21.69598
[1] -96.74512
[1] 36.55873
[1] -33.22498
[1] 56.44797
[1] -23.03451
[1] 25.90903
[1] -7987.745
[1] -258.9516
INFO  [20:14:29.100] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -27.38767
[1] 20.15157
[1] -46.74188
[1] 47.96923
[1] -243.0948
[1] -3.889504
[1] -43.88653
[1] 84.57764
[1] -74.68224
[1] 34.83343
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:16:02.589] [mlr3] Finished benchmark
INFO  [20:16:02.702] [bbotk] Result of batch 65:
INFO  [20:16:02.709] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:16:02.709] [bbotk]              -1.121231                         0.4619509
INFO  [20:16:02.709] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:16:02.709] [bbotk]                         0.8273184           -3.758104              -1.764691
INFO  [20:16:02.709] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:16:02.709] [bbotk]                          3                    3262                 0.6181426
INFO  [20:16:02.709] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:16:02.709] [bbotk]  0.01507036 <list[8]>              FALSE     0.02184598        0      0
INFO  [20:16:02.709] [bbotk]  runtime_learners                                uhash
INFO  [20:16:02.709] [bbotk]           240.133 fb026d75-5153-4f26-b286-96ee49e2a382
INFO  [20:16:04.724] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 96 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:16:12.585] [bbotk] Evaluating 1 configuration(s)
INFO  [20:16:12.621] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:16:12.641] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -67.59647
[1] 24.05193
[1] -1620.108
[1] -43.75006
[1] -54.53961
[1] 40.6335
[1] -128.8332
[1] -3.765487
[1] -2553.604
[1] -76.11736
INFO  [20:17:16.023] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -69177.82
[1] -1897.143
[1] -57.19239
[1] 36.77183
[1] -16.66828
[1] 103.5352
[1] -109.6901
[1] 11.77142
[1] -43.87194
[1] 31.51543
INFO  [20:18:51.856] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -81.0118
[1] 20.3788
[1] -16.18148
[1] 72.82066
[1] -60.313
[1] 82.9251
[1] -214.589
[1] -4.038886
[1] -54.71295
[1] 46.2645
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:20:22.879] [mlr3] Finished benchmark
INFO  [20:20:22.962] [bbotk] Result of batch 66:
INFO  [20:20:22.978] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:20:22.978] [bbotk]              -3.795981                         0.8998725
INFO  [20:20:22.978] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:20:22.978] [bbotk]                         0.2740305           -3.134037              -1.887733
INFO  [20:20:22.978] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:20:22.978] [bbotk]                          5                    3714                 0.1866853
INFO  [20:20:22.978] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:20:22.978] [bbotk]  0.01311548 <list[8]>              FALSE     0.02607105        0      0
INFO  [20:20:22.978] [bbotk]  runtime_learners                                uhash
INFO  [20:20:22.978] [bbotk]           250.123 6858ead3-88d7-4232-a9e7-2827f593cd5d
INFO  [20:20:31.647] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 97 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:20:44.666] [bbotk] Evaluating 1 configuration(s)
INFO  [20:20:45.080] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:20:45.571] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -73.79096
[1] 1.397517
[1] -2483.467
[1] -71.64574
[1] -112.6098
[1] -3.957999
[1] -40.20156
[1] 35.75375
[1] -561.6583
[1] 18.30154
INFO  [20:21:46.745] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -185.2957
[1] 22.75769
[1] -109.9424
[1] 6.589832
[1] -35.98758
[1] 69.20185
[1] -3425.251
[1] -99.53651
[1] -74.57424
[1] -3.553701
INFO  [20:23:33.283] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -49.86322
[1] 5.183118
[1] -23.57255
[1] 60.86392
[1] -7062.264
[1] -151.8717
[1] -19008.52
[1] -552.8836
[1] -19.46055
[1] 61.59267
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:24:27.509] [mlr3] Finished benchmark
INFO  [20:24:27.611] [bbotk] Result of batch 67:
INFO  [20:24:27.622] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:24:27.622] [bbotk]              -5.564752                         0.6327653
INFO  [20:24:27.622] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:24:27.622] [bbotk]                         0.8048924           -5.817965              -1.087498
INFO  [20:24:27.622] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:24:27.622] [bbotk]                         12                    4109                  0.542313
INFO  [20:24:27.622] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:24:27.622] [bbotk]  0.01280408 <list[8]>              FALSE      0.0220252        0      0
INFO  [20:24:27.622] [bbotk]  runtime_learners                                uhash
INFO  [20:24:27.622] [bbotk]           221.653 fe1c514c-f4c5-4b93-84bb-731eb8dfabbc
INFO  [20:24:30.868] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 98 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:24:44.113] [bbotk] Evaluating 1 configuration(s)
INFO  [20:24:44.183] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:24:44.196] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -149.6442
[1] -3.858108
[1] -52.1923
[1] 15.52126
[1] -1589.608
[1] -52.41672
[1] -48.57767
[1] 34.18727
[1] -46.46893
[1] 31.21129
INFO  [20:26:00.799] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1533.228
[1] -48.22138
[1] -34.28345
[1] 25.41166
[1] -20392.17
[1] -387.3399
[1] -95.82978
[1] 18.42045
[1] -29.67391
[1] 19.76132
INFO  [20:26:57.316] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -94.33038
[1] 15.64883
[1] -13.85241
[1] 49.42218
[1] -74.98632
[1] 6.580304
[1] -53.25357
[1] 38.79649
[1] -52.38745
[1] 38.76823
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:28:08.255] [mlr3] Finished benchmark
INFO  [20:28:08.311] [bbotk] Result of batch 68:
INFO  [20:28:08.317] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:28:08.317] [bbotk]              -5.733953                         0.7939947
INFO  [20:28:08.317] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:28:08.317] [bbotk]                         0.2512937            -5.61594               -2.63173
INFO  [20:28:08.317] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:28:08.317] [bbotk]                          8                    4521                 0.8545825
INFO  [20:28:08.317] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:28:08.317] [bbotk]  0.01225988 <list[8]>              FALSE     0.02443567        0      0
INFO  [20:28:08.317] [bbotk]  runtime_learners                                uhash
INFO  [20:28:08.317] [bbotk]           203.871 285fcae3-2d79-4024-b43d-e113234be174
INFO  [20:28:09.921] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 99 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:28:19.203] [bbotk] Evaluating 1 configuration(s)
INFO  [20:28:19.294] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:28:19.415] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -37.47279
[1] 28.02006
[1] -227.8957
[1] 0.3575684
[1] -44.94273
[1] 14.35766
[1] -48.5207
[1] 62.38102
[1] -180.8013
[1] -3.070782
INFO  [20:28:33.749] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -18.50521
[1] 30.06751
[1] 259.3307
[1] 5504.212
[1] -35.89945
[1] 59.65857
[1] -84.66258
[1] 1.407572
[1] -2374.458
[1] -65.44518
INFO  [20:28:48.526] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -75.12814
[1] 1.530808
[1] -113.2565
[1] 44.61386
[1] -1083.851
[1] 7.80715
[1] -39.51766
[1] 72.58482
[1] -34.48544
[1] 26.11562
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:29:03.859] [mlr3] Finished benchmark
INFO  [20:29:03.964] [bbotk] Result of batch 69:
INFO  [20:29:03.971] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:29:03.971] [bbotk]             -0.7454111                         0.4409919
INFO  [20:29:03.971] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:29:03.971] [bbotk]                         0.6971865           -1.987931             -0.6638207
INFO  [20:29:03.971] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:29:03.971] [bbotk]                         14                    2519                 0.6623696
INFO  [20:29:03.971] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:29:03.971] [bbotk]  0.01366939 <list[8]>              FALSE     0.02196983        0      0
INFO  [20:29:03.971] [bbotk]  runtime_learners                                uhash
INFO  [20:29:03.971] [bbotk]            44.038 08ddeafd-152b-4a5b-a4c0-097c9a068583
WARN  [20:29:07.462] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [20:29:07.479] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 100 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:29:07.550] [bbotk] Finished optimizing after 100 evaluation(s)
INFO  [20:29:07.552] [bbotk] Result:
INFO  [20:29:07.558] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:29:07.558] [bbotk]                  <num>                             <num>
INFO  [20:29:07.558] [bbotk]              -4.109243                         0.5573419
INFO  [20:29:07.558] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:29:07.558] [bbotk]                             <num>               <num>                  <num>
INFO  [20:29:07.558] [bbotk]                         0.5634787           -2.549211             -0.5854091
INFO  [20:29:07.558] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:29:07.558] [bbotk]                      <int>                   <int>                     <num>
INFO  [20:29:07.558] [bbotk]                          9                    3099                 0.7448463
INFO  [20:29:07.558] [bbotk]  learner_param_vals  x_domain classif.bbrier
INFO  [20:29:07.558] [bbotk]              <list>    <list>          <num>
INFO  [20:29:07.558] [bbotk]          <list[10]> <list[8]>     0.02038094
[1] -34.86774
[1] 22.01961
[1] -54.81634
[1] 81.62898
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] -181.8957
[1] -4.394411
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] -2546.315
[1] -87.15093
[1] -54.20434
[1] 10.47223

### [bt]: Job terminated successfully [batchtools job.id=1412]
### [bt]: Calculation finished!
