### [bt]: This is batchtools v0.9.17
### [bt]: Starting calculation of 1 jobs
### [bt]: Setting working directory to '/content/drive/MyDrive/GitHub/Mater_Thesis_Calibration'
ece.R :
Friedmann_tasks.R :
Functions.R :
ici.R :
mse_feature_effects.R :
PipeOpCalibration_TuningExperiment.R :
PipeOpCalibration.R :
PipeOpCalibrationUnion.R :
### [bt]: Memory measurement disabled
### [bt]: Starting job [batchtools job.id=1417]
### [bt]: Generating problem instance for problem '341ee781c7d79b8f' ...
### [bt]: Applying algorithm 'run_learner' on problem '341ee781c7d79b8f' for job 1417 (seed = 1540) ...
INFO  [16:06:16.115] [mlr3] Applying learner 'xgboost TwP beta' on task 'wdbc' (iter 7/10)
INFO  [16:06:17.165] [bbotk] Starting to optimize 8 parameter(s) with '<OptimizerMbo>' and '<TerminatorEvals> [n_evals=100, k=0]'
INFO  [16:06:27.096] [bbotk] Evaluating 32 configuration(s)
INFO  [16:06:27.436] [mlr3] Running benchmark with 96 resampling iterations
INFO  [16:06:27.515] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -653.4239
[1] 55.9366
[1] -995.7309
[1] 66.54713
[1] 9.326341
[1] 424.1885
[1] -570.4843
[1] -9.433548
[1] -654.0959
[1] -9.456774
INFO  [16:07:29.690] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 13.80401
[1] 610.6694
[1] -33.51357
[1] 425.7839
[1] -448.9438
[1] 277.2948
[1] -229.4433
[1] 205.7834
[1] -533.8173
[1] 996.4281
INFO  [16:07:47.884] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -237.5307
[1] 132.7638
[1] 14.62584
[1] 641.0042
[1] -669.0969
[1] -9.256929
[1] -65.88025
[1] 459.623
[1] -1010.948
[1] -13.93617
INFO  [16:08:15.247] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:08:43.388] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:09:32.871] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:10:33.837] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -139.3623
[1] 12.59467
[1] -242.7975
[1] 8.690103
[1] -190.2446
[1] 51.30703
[1] -184.7606
[1] 61.31148
[1] -83.9766
[1] 30.78163
INFO  [16:11:03.840] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -46.76645
[1] 76.89226
[1] -44.25843
[1] 81.48184
[1] -82.98878
[1] 53.85895
[1] -213.3086
[1] 5.941662
[1] -83.0409
[1] 162.3769
INFO  [16:11:40.593] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1976.673
[1] -50.39593
[1] -154.3366
[1] 17.18321
[1] -35.56112
[1] 108.0204
[1] -25.41023
[1] 77.39756
[1] -135.9724
[1] 21.16147
INFO  [16:12:08.818] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -64.72181
[1] 75.62978
[1] -55.53363
[1] 81.28723
[1] -91.87576
[1] 9.621123
[1] -63.83043
[1] 57.85204
[1] -98.03298
[1] 148.9843
INFO  [16:14:04.799] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -222.6022
[1] 121.6359
[1] -156.7502
[1] 102.4795
[1] -137.8155
[1] 70.24892
[1] -59.86705
[1] 70.59691
[1] -62.44701
[1] 48.96386
INFO  [16:16:56.639] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -41.83825
[1] 82.73255
[1] -34.84491
[1] 108.5755
[1] -149.1791
[1] 8.397544
[1] -3652.832
[1] -57.9796
[1] -172.3586
[1] -3.824988
INFO  [16:19:45.255] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:20:18.123] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:21:17.394] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:22:07.953] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -57.48237
[1] 68.54658
[1] -76.87485
[1] 291.2312
[1] -111.9244
[1] 9.670437
[1] -50.40828
[1] 65.75441
[1] -172.5792
[1] -2.887694
INFO  [16:23:13.674] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -91.61582
[1] 33.30911
[1] -87.30125
[1] 70.30084
[1] -63.05532
[1] 84.89498
[1] -35.39403
[1] 192.2352
[1] 462.4135
[1] 14852.51
INFO  [16:24:41.641] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -26.30513
[1] 124.2248
[1] -72.82264
[1] 18.76764
[1] -125.0196
[1] 29.80215
[1] -39.68808
[1] 133.3207
[1] -308.7119
[1] 69.89029
INFO  [16:25:57.717] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -173.2627
[1] 37.58502
[1] -112.8206
[1] 56.14513
[1] 4.453383
[1] 159.1754
[1] -129.408
[1] 29.47245
[1] -358.017
[1] 131.364
INFO  [16:26:19.354] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -993.6383
[1] -17.36567
[1] -52.78035
[1] 182.4084
[1] -134.0112
[1] 166.2036
[1] -190.8279
[1] 20.54962
[1] -104.6627
[1] 83.49159
INFO  [16:26:48.727] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -331.2505
[1] -5.214493
[1] -131.2507
[1] 85.18258
[1] -6940.533
[1] -88.71029
[1] -116.1923
[1] 66.92377
[1] -34.78981
[1] 112.4831
INFO  [16:27:14.405] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -214.6135
[1] -4.384667
[1] -260.4569
[1] 17.05564
[1] -306.6267
[1] -5.347947
[1] -82.55854
[1] 149.7111
[1] -93.97407
[1] 96.52706
INFO  [16:28:20.166] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -276.9121
[1] 374.0077
[1] -38.21583
[1] 155.2138
[1] -233.8179
[1] 18.56098
[1] -257.2293
[1] -4.612964
[1] 4.243075
[1] 180.4005
INFO  [16:29:28.888] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -241.1361
[1] -3.709295
[1] -7.511508
[1] 390.5553
[1] -136.1419
[1] 192.0238
[1] -22.21698
[1] 305.9135
[1] -61.09839
[1] 261.8004
INFO  [16:30:44.022] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -23.17062
[1] 58.01117
[1] -27.10593
[1] 19.31158
[1] -31.68661
[1] 9.409555
[1] -4317.699
[1] -170.3595
[1] -81.94394
[1] 14.18892
INFO  [16:31:07.972] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -29.69996
[1] 27.30143
[1] -27.60834
[1] 15.95123
[1] -47.07277
[1] 25.55158
[1] -236.9448
[1] 39.30437
[1] -1304.4
[1] -38.3359
INFO  [16:31:31.568] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -12.31242
[1] 67.3119
[1] -2735.017
[1] -43.10772
[1] -145.4721
[1] 6.848293
[1] -26.31119
[1] 15.09761
[1] 29.55857
[1] 625.614
INFO  [16:31:46.197] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:32:51.784] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:33:41.205] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:34:29.688] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 99.2783
[1] 3993.794
[1] -119.4838
[1] 50.30917
[1] -171.0126
[1] -5.118023
[1] -176.858
[1] -4.366434
[1] -36.95272
[1] 130.5933
INFO  [16:35:04.288] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 5.490476
[1] 164.5575
[1] -173.8276
[1] 59.66064
[1] -3280.481
[1] -61.7896
[1] -44.90856
[1] 130.9784
[1] -101.87
[1] 49.55086
INFO  [16:35:34.391] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -68.50424
[1] 153.0349
[1] -84.64902
[1] 53.66179
[1] -16574.26
[1] -246.0076
[1] -91.05032
[1] 115.4472
[1] -162.1386
[1] 5.024537
INFO  [16:36:10.744] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -12501.45
[1] -222.6863
[1] -76.74725
[1] 68.56448
[1] -84.39081
[1] 81.74073
[1] -51.64382
[1] 49.84529
[1] -253.2078
[1] 14.39516
INFO  [16:37:33.762] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -36.89746
[1] 138.5658
[1] -41.10353
[1] 176.4561
[1] -2934.537
[1] -65.47215
[1] -45.18684
[1] 45.24575
[1] -51.12583
[1] 60.75535
INFO  [16:38:29.509] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -30.13455
[1] 104.1091
[1] 11.98232
[1] 553.5563
[1] -71.79943
[1] 29.70326
[1] -33.96844
[1] 188.4246
[1] -74.58167
[1] 47.66623
INFO  [16:39:45.056] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -360.293
[1] 233.7526
[1] -215.4614
[1] 259.3601
[1] -330.6713
[1] 41.52087
[1] -182.4251
[1] 223.6809
[1] -457.7548
[1] 242.157
INFO  [16:40:38.491] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -9208.055
[1] -196.8538
[1] -348.4072
[1] 80.44576
[1] 8.080439
[1] 382.1159
[1] -61505.78
[1] -1057.55
[1] 9.360011
[1] 471.9912
INFO  [16:41:28.937] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 54.95577
[1] 2646.98
[1] -275.6687
[1] 46.0169
[1] -380.7317
[1] 126.7039
[1] 11.41693
[1] 575.7728
[1] -651.1624
[1] -10.20426
INFO  [16:42:10.235] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -49.2542
[1] 111.3331
[1] -76.57038
[1] 14.29308
[1] -3640.526
[1] -108.7363
[1] -311.7794
[1] 125.4038
[1] -67.11253
[1] 7.277804
INFO  [16:43:38.809] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -41.53773
[1] 113.555
[1] -3697.079
[1] -79.91867
[1] -37.29503
[1] 48.99544
[1] 59.31669
[1] 1843.042
[1] -45.38771
[1] 67.66642
INFO  [16:45:00.456] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -38.00574
[1] 89.78695
[1] -44.11875
[1] 102.3049
[1] -36.67958
[1] 90.72511
[1] -81.31863
[1] 18.16699
[1] -368.2481
[1] -4.056538
INFO  [16:46:15.333] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -332892.7
[1] -6146.326
[1] -25.25545
[1] 48.98392
[1] -17.67103
[1] 33.99091
[1] -36.96254
[1] 7.029538
[1] -47.87548
[1] 32.61232
INFO  [16:47:08.608] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -26.48976
[1] 25.97308
[1] -47.48445
[1] 78.8974
[1] -42.63394
[1] 91.45001
[1] -27.99637
[1] 57.71123
[1] -41.99491
[1] 23.00251
INFO  [16:47:49.841] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2179.933
[1] -54.54274
[1] -39.66796
[1] 24.0447
[1] -92.27381
[1] -3.886288
[1] -59.92736
[1] 111.8485
[1] -2854.206
[1] -33.83803
INFO  [16:48:26.695] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:49:01.285] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:49:19.959] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:49:42.989] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -46.37842
[1] 202.8803
[1] -432.6073
[1] -7.244383
[1] -106.9746
[1] 287.346
[1] -146.5088
[1] 113.2577
[1] -313.9966
[1] -6.822344
INFO  [16:50:51.852] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -119.0672
[1] 168.8883
[1] -373.4558
[1] 76.3444
[1] -274.0906
[1] 123.7638
[1] -171.7859
[1] 145.4632
[1] -329.318
[1] 9.631441
INFO  [16:52:19.112] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -289.251
[1] -6.316635
[1] -127.4911
[1] 167.6137
[1] -89.79901
[1] 309.6902
[1] -55.13102
[1] 225.4271
[1] -696.9488
[1] 14.32679
INFO  [16:53:39.408] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -4210.97
[1] -78.95675
[1] -399.0243
[1] -6.95717
[1] -594.5075
[1] -10.05705
[1] -809.6527
[1] -11.35955
[1] -728.5974
[1] -10.11988
INFO  [16:54:41.565] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -606.3075
[1] -10.21767
[1] 13.75722
[1] 493.7289
[1] -907.1091
[1] 244.3185
[1] -708.658
[1] -11.10615
[1] -602.8202
[1] -8.559175
INFO  [16:55:42.786] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -400.1271
[1] 71.87143
[1] 29.66254
[1] 1489.65
[1] 11.8496
[1] 533.8297
[1] 9.414169
[1] 395.9297
[1] -441.5388
[1] -5.939005
INFO  [16:56:47.814] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -256.4524
[1] 7.826848
[1] -49.23077
[1] 70.95429
[1] -179876.2
[1] -3604.783
[1] -97.03814
[1] 24.64174
[1] -65.57705
[1] 51.07662
INFO  [16:57:19.873] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -57.99116
[1] 123.9247
[1] -54.9799
[1] 69.48653
[1] -450.7863
[1] -4.496839
[1] -97.39918
[1] 33.69612
[1] -51.28027
[1] 95.65964
INFO  [16:57:43.668] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -28.90826
[1] 176.5061
[1] -23.15742
[1] 248.9572
[1] -89.43467
[1] 87.89189
[1] -56.58907
[1] 49.5716
[1] -265.2341
[1] -3.960835
INFO  [16:58:15.848] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -170.9039
[1] -4.237646
[1] -6889.993
[1] -139.3188
[1] -1835.136
[1] -52.56861
[1] -54.75206
[1] 45.52376
[1] -43.98149
[1] 71.9712
INFO  [16:59:18.814] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -23.10318
[1] 67.51367
[1] -71.22149
[1] 49.87711
[1] -39.06095
[1] 102.8538
[1] -9077.388
[1] -126.5833
[1] -66.66802
[1] 75.42895
INFO  [17:00:23.532] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -79.59478
[1] 22.84705
[1] 97.39198
[1] 3009.182
[1] -35.13583
[1] 56.17221
[1] -17.86025
[1] 101.6969
[1] -25785.64
[1] -828.6464
INFO  [17:01:20.745] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:02:07.078] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:03:10.704] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:03:54.258] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1047.837
[1] 323.245
[1] -1315.983
[1] -24.56754
[1] -1637.881
[1] -28.23375
[1] -1360.891
[1] -24.86519
[1] 46.43176
[1] 2509.309
INFO  [17:04:37.618] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 27.43857
[1] 1411.008
[1] -1459.641
[1] 46.56862
[1] -849.6612
[1] 743.6389
[1] 35.05738
[1] 1848.997
[1] 102.6259
[1] 5314.825
INFO  [17:05:13.865] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 54.17987
[1] 2712.096
[1] 21.17979
[1] 1080.912
[1] -122.6193
[1] 1208.444
[1] -1368.933
[1] -24.38487
[1] -904.8506
[1] 665.9192
INFO  [17:05:53.614] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 12.22636
[1] 569.8908
[1] -31695.6
[1] -646.1991
[1] -515.4818
[1] 428.4986
[1] -474.6892
[1] 111.3591
[1] -708.8849
[1] -13.3551
INFO  [17:06:23.498] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -530.731
[1] 343.4055
[1] -779.8679
[1] 64.96892
[1] -223.785
[1] 287.8355
[1] -272.5523
[1] 504.7013
[1] 13.60585
[1] 678.125
INFO  [17:06:49.256] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 16.49347
[1] 777.3238
[1] -633.0687
[1] -12.48262
[1] 14.05219
[1] 625.1528
[1] -1831.689
[1] -32.04446
[1] -963.1679
[1] -14.82485
INFO  [17:07:09.315] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -100.7824
[1] 78.18369
[1] -168.7213
[1] -3.114382
[1] -71.68212
[1] 106.182
[1] -75.20891
[1] 43.18386
[1] -36.09802
[1] 45.34243
INFO  [17:08:03.379] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -79.2127
[1] 26.64235
[1] -2174.015
[1] -30.55522
[1] -229.4159
[1] 5.484627
[1] -16.6361
[1] 216.8673
[1] 897.994
[1] 25063.52
INFO  [17:09:22.288] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -18.53172
[1] 126.9379
[1] -52.73626
[1] 64.02341
[1] -108.4846
[1] 2.604891
[1] -81.47811
[1] 154.3604
[1] -39.89512
[1] 30.35501
INFO  [17:10:32.165] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -37.32021
[1] 281.2496
[1] -298.0779
[1] 88.33954
[1] 371.4261
[1] 16373.18
[1] -332.461
[1] -6.267593
[1] 10.59145
[1] 592.3865
INFO  [17:11:21.076] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -20738.59
[1] -382.6371
[1] -344.6546
[1] 47.59366
[1] -171.6057
[1] 308.7908
[1] -63.25206
[1] 244.7514
[1] -185.2095
[1] 164.8345
INFO  [17:12:36.796] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 8.571672
[1] 405.2856
[1] 10.8921
[1] 492.8758
[1] -482.3313
[1] 98.69244
[1] -331.4182
[1] -5.617226
[1] -461.1278
[1] -10.00645
INFO  [17:13:52.014] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -18.5272
[1] 54.56913
[1] -76.79695
[1] 16.20175
[1] -102.7287
[1] 44.05374
[1] -58.1779
[1] 21.35183
[1] -58.67213
[1] 65.3261
INFO  [17:14:46.149] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1535.99
[1] -39.0662
[1] -209.6719
[1] 8.531507
[1] -43.96234
[1] 24.45666
[1] -5458.296
[1] -104.3823
[1] -78.46857
[1] 95.63138
INFO  [17:15:41.102] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 75.46814
[1] 1970.745
[1] -45.80243
[1] 16.91105
[1] -26.11074
[1] 48.20077
[1] -9638.814
[1] -339.5052
[1] -71.30701
[1] 18.40392
INFO  [17:16:21.053] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -155.6279
[1] 16.1795
[1] -83.44226
[1] 62.43993
[1] -144.1349
[1] 12.16881
[1] -54.70949
[1] 91.22671
[1] -46.66867
[1] 81.00315
INFO  [17:16:49.849] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -8.137515
[1] 170.6522
[1] -36.47104
[1] 102.5012
[1] -83.6447
[1] 26.21388
[1] -86.9898
[1] 128.1289
[1] -24.77712
[1] 107.2386
INFO  [17:17:06.166] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -69.01872
[1] 46.48777
[1] -501.1756
[1] -4.41762
[1] -59.20825
[1] 67.25416
[1] -3974.3
[1] -50.96314
[1] -4.271711
[1] 149.299
INFO  [17:17:22.660] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:18:05.149] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:18:43.729] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:19:28.346] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -5912.706
[1] -107.0989
[1] -23029.1
[1] -421.7881
[1] -18822.53
[1] -342.8362
[1] -4831.377
[1] -87.36391
[1] -9994.251
[1] -184.4835
INFO  [17:20:40.586] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 125.8744
[1] 6640.821
[1] -8887.112
[1] -163.5719
[1] 127.3141
[1] 6736.084
[1] 151.1082
[1] 8028.27
[1] -5540.366
[1] -100.4387
INFO  [17:21:55.876] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -6542.264
[1] -119.0488
[1] 129.7668
[1] 6872.886
[1] 122.5383
[1] 6472.506
[1] -6441.191
[1] -116.5004
[1] -10788.95
[1] -194.5587
INFO  [17:23:17.928] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -32.87632
[1] 54.21183
[1] -22843.29
[1] -1087.338
[1] -47.68378
[1] 2.844159
[1] -55.25607
[1] 43.95411
[1] -143.2426
[1] 26.59858
INFO  [17:23:53.034] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1807.755
[1] -47.74724
[1] -9164.283
[1] -103.9023
[1] -62.75802
[1] 47.71697
[1] -143.4154
[1] 6.126174
[1] -33.53937
[1] 27.51239
INFO  [17:24:21.502] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -82.99923
[1] 734.0636
[1] -21.12599
[1] 62.73735
[1] -170.2481
[1] -3.538165
[1] -32.38811
[1] 65.13037
[1] -52.67506
[1] 15.23853
INFO  [17:25:00.999] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -445.4005
[1] -13.09257
[1] -35.68527
[1] 57.80248
[1] -141.3953
[1] 57.30463
[1] -188.5268
[1] 12.77227
[1] -56.57255
[1] 31.59295
INFO  [17:25:54.146] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -83.96518
[1] 14.03818
[1] 63.49336
[1] 1275.279
[1] -1.062867e+16
[1] 3.80984e+16
[1] -31.04169
[1] 54.18433
[1] -6610.815
[1] -169.9258
INFO  [17:26:20.217] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -105.6874
[1] 9.233228
[1] -71.45114
[1] 148.5073
[1] -25.94722
[1] 121.6466
[1] -100.2908
[1] 22.45689
[1] -86.80186
[1] 60.17241
INFO  [17:27:21.085] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:27:35.658] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:27:54.896] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:28:24.675] [mlr3] Finished benchmark
INFO  [17:28:25.754] [bbotk] Result of batch 1:
INFO  [17:28:25.775] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:28:25.775] [bbotk]             -1.9634769                          0.103559
INFO  [17:28:25.775] [bbotk]              4.9442784                          0.553559
INFO  [17:28:25.775] [bbotk]              1.4904008                          0.328559
INFO  [17:28:25.775] [bbotk]             -5.4173547                          0.778559
INFO  [17:28:25.775] [bbotk]              6.6712172                          0.216059
INFO  [17:28:25.775] [bbotk]             -0.2365381                          0.666059
INFO  [17:28:25.775] [bbotk]             -3.6904159                          0.441059
INFO  [17:28:25.775] [bbotk]              3.2173396                          0.891059
INFO  [17:28:25.775] [bbotk]             -1.1000075                          0.384809
INFO  [17:28:25.775] [bbotk]              5.8077478                          0.834809
INFO  [17:28:25.775] [bbotk]              2.3538702                          0.159809
INFO  [17:28:25.775] [bbotk]             -4.5538853                          0.609809
INFO  [17:28:25.775] [bbotk]             -6.2808241                          0.272309
INFO  [17:28:25.775] [bbotk]              0.6269313                          0.722309
INFO  [17:28:25.775] [bbotk]             -2.8269463                          0.947309
INFO  [17:28:25.775] [bbotk]              4.0808090                          0.497309
INFO  [17:28:25.775] [bbotk]             -3.2586810                          0.525434
INFO  [17:28:25.775] [bbotk]              3.6490743                          0.975434
INFO  [17:28:25.775] [bbotk]             -6.7125588                          0.750434
INFO  [17:28:25.775] [bbotk]              0.1951966                          0.300434
INFO  [17:28:25.775] [bbotk]              5.3760131                          0.412934
INFO  [17:28:25.775] [bbotk]             -1.5317422                          0.862934
INFO  [17:28:25.775] [bbotk]              1.9221355                          0.637934
INFO  [17:28:25.775] [bbotk]             -4.9856200                          0.187934
INFO  [17:28:25.775] [bbotk]              1.0586661                          0.806684
INFO  [17:28:25.775] [bbotk]             -5.8490894                          0.356684
INFO  [17:28:25.775] [bbotk]             -2.3952116                          0.581684
INFO  [17:28:25.775] [bbotk]              4.5125437                          0.131684
INFO  [17:28:25.775] [bbotk]              2.7856049                          0.469184
INFO  [17:28:25.775] [bbotk]             -4.1221506                          0.919184
INFO  [17:28:25.775] [bbotk]             -0.6682728                          0.244184
INFO  [17:28:25.775] [bbotk]              6.2394825                          0.694184
INFO  [17:28:25.775] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:28:25.775] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:28:25.775] [bbotk]                         0.1996001        -4.039397850              6.6445640
INFO  [17:28:25.775] [bbotk]                         0.6496001        -8.644568173             -0.2631913
INFO  [17:28:25.775] [bbotk]                         0.4246001        -1.736812757             -3.7170687
INFO  [17:28:25.775] [bbotk]                         0.8746001        -6.341983218              3.1906864
INFO  [17:28:25.775] [bbotk]                         0.9871001        -7.493275627             -1.9901301
INFO  [17:28:25.775] [bbotk]                         0.5371001        -2.888105304              4.9176252
INFO  [17:28:25.775] [bbotk]                         0.7621001        -5.190690671              1.4637476
INFO  [17:28:25.775] [bbotk]                         0.3121001        -0.585520211             -5.4440075
INFO  [17:28:25.775] [bbotk]                         0.9308501        -0.009873937             -1.1266607
INFO  [17:28:25.775] [bbotk]                         0.4808501        -4.615044398              5.7810946
INFO  [17:28:25.775] [bbotk]                         0.7058501        -2.312459030              2.3272170
INFO  [17:28:25.775] [bbotk]                         0.2558501        -6.917629354             -4.5805381
INFO  [17:28:25.775] [bbotk]                         0.3683501        -8.068921900             -6.3074769
INFO  [17:28:25.775] [bbotk]                         0.8183501        -3.463751577              0.6002781
INFO  [17:28:25.775] [bbotk]                         0.5933501        -1.161166484             -2.8535995
INFO  [17:28:25.775] [bbotk]                         0.1433501        -5.766336944              4.0541558
INFO  [17:28:25.775] [bbotk]                         0.4527251        -7.781098764              2.7589517
INFO  [17:28:25.775] [bbotk]                         0.9027251        -3.175928440             -4.1488034
INFO  [17:28:25.775] [bbotk]                         0.6777251        -0.873343347              6.2128293
INFO  [17:28:25.775] [bbotk]                         0.2277251        -5.478513808             -0.6949260
INFO  [17:28:25.775] [bbotk]                         0.5652251        -4.327220987             -5.8757422
INFO  [17:28:25.775] [bbotk]                         0.1152251        -8.932391327              1.0320128
INFO  [17:28:25.775] [bbotk]                         0.3402251        -6.629806354             -2.4218648
INFO  [17:28:25.775] [bbotk]                         0.7902251        -2.024635894              4.4858905
INFO  [17:28:25.775] [bbotk]                         0.7339751        -7.205452490              3.6224211
INFO  [17:28:25.775] [bbotk]                         0.2839751        -2.600282167             -3.2853342
INFO  [17:28:25.775] [bbotk]                         0.9589751        -4.902867535             -6.7392117
INFO  [17:28:25.775] [bbotk]                         0.5089751        -0.297697074              0.1685434
INFO  [17:28:25.775] [bbotk]                         0.8464751        -8.356745037              5.3493599
INFO  [17:28:25.775] [bbotk]                         0.3964751        -3.751574714             -1.5583954
INFO  [17:28:25.775] [bbotk]                         0.6214751        -6.054160081             -5.0122728
INFO  [17:28:25.775] [bbotk]                         0.1714751        -1.448989621              1.8954823
INFO  [17:28:25.775] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:28:25.775] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:28:25.775] [bbotk]                          2                    2218                 0.6047733
INFO  [17:28:25.775] [bbotk]                         12                    4718                 0.1547733
INFO  [17:28:25.775] [bbotk]                         17                     968                 0.3797733
INFO  [17:28:25.775] [bbotk]                          7                    3468                 0.8297733
INFO  [17:28:25.775] [bbotk]                         19                    1593                 0.7172733
INFO  [17:28:25.775] [bbotk]                          9                    4093                 0.2672733
INFO  [17:28:25.775] [bbotk]                          4                     343                 0.4922733
INFO  [17:28:25.775] [bbotk]                         14                    2843                 0.9422733
INFO  [17:28:25.775] [bbotk]                          6                      31                 0.5485233
INFO  [17:28:25.775] [bbotk]                         16                    2531                 0.9985233
INFO  [17:28:25.775] [bbotk]                         11                    1281                 0.7735233
INFO  [17:28:25.775] [bbotk]                          1                    3781                 0.3235233
INFO  [17:28:25.775] [bbotk]                          8                    1906                 0.6610233
INFO  [17:28:25.775] [bbotk]                         18                    4406                 0.2110233
INFO  [17:28:25.775] [bbotk]                          3                    3156                 0.8860233
INFO  [17:28:25.775] [bbotk]                         13                     656                 0.4360233
INFO  [17:28:25.775] [bbotk]                         19                    4875                 0.4078983
INFO  [17:28:25.775] [bbotk]                          9                    2375                 0.8578983
INFO  [17:28:25.775] [bbotk]                         14                    1125                 0.1828983
INFO  [17:28:25.775] [bbotk]                          4                    3625                 0.6328983
INFO  [17:28:25.775] [bbotk]                          1                    4250                 0.5203983
INFO  [17:28:25.775] [bbotk]                         11                    1750                 0.9703983
INFO  [17:28:25.775] [bbotk]                          6                     500                 0.2953983
INFO  [17:28:25.775] [bbotk]                         16                    3000                 0.7453983
INFO  [17:28:25.775] [bbotk]                          3                    2062                 0.8016483
INFO  [17:28:25.775] [bbotk]                         13                    4562                 0.3516483
INFO  [17:28:25.775] [bbotk]                         18                     812                 0.1266483
INFO  [17:28:25.775] [bbotk]                          8                    3312                 0.5766483
INFO  [17:28:25.775] [bbotk]                         10                    3937                 0.4641483
INFO  [17:28:25.775] [bbotk]                         20                    1437                 0.9141483
INFO  [17:28:25.775] [bbotk]                         15                    2687                 0.6891483
INFO  [17:28:25.775] [bbotk]                          5                     187                 0.2391483
INFO  [17:28:25.775] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:28:25.775] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:28:25.775] [bbotk]      0.03752532        0      0          106.425
INFO  [17:28:25.775] [bbotk]      0.48479324        0      0          138.123
INFO  [17:28:25.775] [bbotk]      0.03058540        0      0           94.411
INFO  [17:28:25.775] [bbotk]      0.03385902        0      0          455.185
INFO  [17:28:25.775] [bbotk]      0.48479324        0      0          140.765
INFO  [17:28:25.775] [bbotk]      0.02799157        0      0          228.975
INFO  [17:28:25.775] [bbotk]      0.03845312        0      0           75.590
INFO  [17:28:25.775] [bbotk]      0.04242398        0      0          208.778
INFO  [17:28:25.775] [bbotk]      0.02159270        0      0           61.388
INFO  [17:28:25.775] [bbotk]      0.48479324        0      0          162.868
INFO  [17:28:25.775] [bbotk]      0.03822508        0      0           99.697
INFO  [17:28:25.775] [bbotk]      0.03807032        0      0          213.753
INFO  [17:28:25.775] [bbotk]      0.03620505        0      0          144.850
INFO  [17:28:25.775] [bbotk]      0.02705425        0      0          244.777
INFO  [17:28:25.775] [bbotk]      0.02296048        0      0          131.109
INFO  [17:28:25.775] [bbotk]      0.48479324        0      0           75.597
INFO  [17:28:25.775] [bbotk]      0.04094321        0      0          235.837
INFO  [17:28:25.775] [bbotk]      0.04449202        0      0          187.436
INFO  [17:28:25.775] [bbotk]      0.03449357        0      0           87.293
INFO  [17:28:25.775] [bbotk]      0.02816585        0      0          184.512
INFO  [17:28:25.775] [bbotk]      0.48479324        0      0          152.502
INFO  [17:28:25.775] [bbotk]      0.13156572        0      0          118.263
INFO  [17:28:25.775] [bbotk]      0.05024450        0      0           74.664
INFO  [17:28:25.775] [bbotk]      0.02253516        0      0          200.020
INFO  [17:28:25.775] [bbotk]      0.04567759        0      0          199.172
INFO  [17:28:25.775] [bbotk]      0.02161540        0      0          147.848
INFO  [17:28:25.775] [bbotk]      0.02657216        0      0           60.927
INFO  [17:28:25.775] [bbotk]      0.48479324        0      0          125.399
INFO  [17:28:25.775] [bbotk]      0.40631863        0      0          229.249
INFO  [17:28:25.775] [bbotk]      0.02177085        0      0          102.523
INFO  [17:28:25.775] [bbotk]      0.02697944        0      0          139.719
INFO  [17:28:25.775] [bbotk]      0.48479324        0      0           50.751
INFO  [17:28:25.775] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:28:25.775] [bbotk]                                 uhash
INFO  [17:28:25.775] [bbotk]  10fed72c-6b6a-422d-b36d-9cf371204bdc
INFO  [17:28:25.775] [bbotk]  616c8162-d301-4782-848e-94689cb49285
INFO  [17:28:25.775] [bbotk]  3d5fdde8-ee36-44e4-8cf6-3399203cdc01
INFO  [17:28:25.775] [bbotk]  1d46be4c-6673-49f9-bc54-f4beb4827714
INFO  [17:28:25.775] [bbotk]  c3713d07-a0a7-48d4-88d3-5cdac7f4c0d0
INFO  [17:28:25.775] [bbotk]  ddcc1f57-3bb9-474a-abc1-f2dd5c07bd26
INFO  [17:28:25.775] [bbotk]  c408f98f-8f3e-42a1-87b5-d6eee03e97db
INFO  [17:28:25.775] [bbotk]  e229bb21-a375-4a83-b724-f414cba5c7db
INFO  [17:28:25.775] [bbotk]  b2deb120-c371-4c03-a4d8-24ab92e8fd4d
INFO  [17:28:25.775] [bbotk]  54350e08-906e-4922-9071-6b8f05f9e343
INFO  [17:28:25.775] [bbotk]  746afa1b-6cd9-4ca4-8768-ff6f107aae96
INFO  [17:28:25.775] [bbotk]  4fc42989-4119-4a18-993a-b18a92c3a458
INFO  [17:28:25.775] [bbotk]  a22af2cc-05ec-43a3-89f0-1c5f3d076226
INFO  [17:28:25.775] [bbotk]  b5401dbd-a7c8-4114-a8b9-6c6d5e465661
INFO  [17:28:25.775] [bbotk]  4ce7a322-b001-4453-91c9-42fd2c74a291
INFO  [17:28:25.775] [bbotk]  8c985e27-d51a-4dd1-8666-90972e64f61a
INFO  [17:28:25.775] [bbotk]  7948e744-cf63-4e3c-acc3-31b48a6ef8ff
INFO  [17:28:25.775] [bbotk]  c5ac1997-0ebf-49fd-aed5-6aca3f9d9022
INFO  [17:28:25.775] [bbotk]  40ab317b-37e0-4591-aaad-344d3af4ced2
INFO  [17:28:25.775] [bbotk]  0e4ac3c8-5a3f-47dd-940c-ba7d7f7a7ff2
INFO  [17:28:25.775] [bbotk]  d1a8a96e-163a-4a5b-a0a8-2da8c520aefb
INFO  [17:28:25.775] [bbotk]  335b3996-2396-4fd5-8643-1e9c3214e3d3
INFO  [17:28:25.775] [bbotk]  5fc57a4d-e37d-4158-a053-6c59ffe2a7ee
INFO  [17:28:25.775] [bbotk]  ce97229b-061c-45a1-916c-3fcdebdbad23
INFO  [17:28:25.775] [bbotk]  07713f1a-747f-476a-b581-c01914f4745b
INFO  [17:28:25.775] [bbotk]  1dfab317-91b7-4937-a761-4281522d9697
INFO  [17:28:25.775] [bbotk]  c9750152-734d-437e-8dc4-2ff4bc6d78a6
INFO  [17:28:25.775] [bbotk]  8683a674-dc13-4781-971f-34ff1b8b1ac9
INFO  [17:28:25.775] [bbotk]  8fabd319-c438-4b14-977a-0eca7b35056d
INFO  [17:28:25.775] [bbotk]  7e54ab14-197d-476a-b1a4-139cbe454610
INFO  [17:28:25.775] [bbotk]  85d08ca4-dbb8-4d59-9b19-966636d1723c
INFO  [17:28:25.775] [bbotk]  4e03c6ff-0ffc-4437-9963-d89beeabc9f1
INFO  [17:28:25.775] [bbotk]                                 uhash
INFO  [17:28:34.768] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 32 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:28:46.270] [bbotk] Evaluating 1 configuration(s)
INFO  [17:28:46.297] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:28:46.478] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -69.47346
[1] 94.40454
[1] -78.04731
[1] -1.215084
[1] -66.40688
[1] 28.69185
[1] -63.60618
[1] 72.54737
[1] -277.198
[1] 230.6926
INFO  [17:29:08.535] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -40.51803
[1] 121.6103
[1] -54.05986
[1] 144.0556
[1] -380.0032
[1] -4.182558
[1] -44.65745
[1] 73.69689
[1] -3373.901
[1] -130.2182
INFO  [17:29:32.735] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -45.29763
[1] 29.76933
[1] -88.69215
[1] 23.22765
[1] -8.309761
[1] 108.2945
[1] -511.4916
[1] -9.053871
[1] -3940.259
[1] -84.96042
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:29:55.335] [mlr3] Finished benchmark
INFO  [17:29:55.738] [bbotk] Result of batch 2:
INFO  [17:29:55.829] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:29:55.829] [bbotk]               1.106525                          0.833911
INFO  [17:29:55.829] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:29:55.829] [bbotk]                         0.8483093           -2.522709              -5.605833
INFO  [17:29:55.829] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:29:55.829] [bbotk]                          6                     765                  0.883093
INFO  [17:29:55.829] [bbotk]    acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:29:55.829] [bbotk]  0.131129 <list[8]>              FALSE     0.02896157        0      0
INFO  [17:29:55.829] [bbotk]  runtime_learners                                uhash
INFO  [17:29:55.829] [bbotk]            67.211 14d308a3-9de9-434d-a7ac-e4dd69471f6f
INFO  [17:30:10.160] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 33 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:30:14.784] [bbotk] Evaluating 1 configuration(s)
INFO  [17:30:14.840] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:30:14.909] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -293.4669
[1] -3.497017
[1] -62.89379
[1] 49.15903
[1] -87.71291
[1] 121.7574
[1] -196.8828
[1] 43.90263
[1] -79.55536
[1] 61.22333
INFO  [17:30:39.120] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 535.8814
[1] 18850.72
[1] -80.06643
[1] 198.0504
[1] 104.802
[1] 2836.847
[1] -105.4236
[1] 23.50283
[1] -51.45558
[1] 120.7853
INFO  [17:31:06.137] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -95.42837
[1] 109.0635
[1] -50.37888
[1] 126.7917
[1] -6.172706e+16
[1] 1.244014e+16
[1] -94.74847
[1] 71.58005
[1] -97.03323
[1] 48.70378
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:31:26.852] [mlr3] Finished benchmark
INFO  [17:31:27.133] [bbotk] Result of batch 3:
INFO  [17:31:27.164] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:31:27.164] [bbotk]              0.5623657                         0.8174804
INFO  [17:31:27.164] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:31:27.164] [bbotk]                          0.361589           -3.710102               -4.96742
INFO  [17:31:27.164] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:31:27.164] [bbotk]                          3                    1347                 0.1303011
INFO  [17:31:27.164] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:31:27.164] [bbotk]  0.06335798 <list[8]>              FALSE     0.03065887        0      0
INFO  [17:31:27.164] [bbotk]  runtime_learners                                uhash
INFO  [17:31:27.164] [bbotk]            71.187 060a9a88-9c03-4ddf-a644-fa7c5ce5ff2a
INFO  [17:31:27.748] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 34 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:31:32.716] [bbotk] Evaluating 1 configuration(s)
INFO  [17:31:32.852] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:31:33.038] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -139.8848
[1] -4.013664
[1] -388.3844
[1] 23.10777
[1] -348.215
[1] -4.434065
[1] -370.9354
[1] -5.440226
[1] -82.83645
[1] 110.8504
INFO  [17:31:45.245] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -77.08201
[1] 63.21897
[1] -71.06367
[1] 107.7805
[1] -90.94921
[1] 31.36023
[1] -3916.324
[1] -69.93774
[1] -90.61911
[1] 82.32782
INFO  [17:32:05.350] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -161.9299
[1] 50.84943
[1] -127.9855
[1] 96.06787
[1] -120.3735
[1] 83.1729
[1] -288.8148
[1] -3.968337
[1] -85.85993
[1] 30.86413
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:32:18.735] [mlr3] Finished benchmark
INFO  [17:32:18.881] [bbotk] Result of batch 4:
INFO  [17:32:18.938] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:32:18.938] [bbotk]               2.492497                         0.8049217
INFO  [17:32:18.938] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:32:18.938] [bbotk]                         0.6809822           -1.095149              -2.704633
INFO  [17:32:18.938] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:32:18.938] [bbotk]                          3                     244                 0.9423219
INFO  [17:32:18.938] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:32:18.938] [bbotk]  0.06174335 <list[8]>              FALSE      0.0398275        0      0
INFO  [17:32:18.938] [bbotk]  runtime_learners                                uhash
INFO  [17:32:18.938] [bbotk]            45.273 e011f90c-8c96-4a8e-a9f6-7b1eafff8478
INFO  [17:32:19.857] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 35 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:32:24.964] [bbotk] Evaluating 1 configuration(s)
INFO  [17:32:25.024] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:32:25.077] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -121.735
[1] 44.37009
[1] -351.7892
[1] 22.85617
[1] -87.43346
[1] 9.462517
[1] -90.99821
[1] 10.09702
[1] -3696.902
[1] -77.41625
INFO  [17:32:39.968] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -60.8631
[1] 38.71303
[1] -10443.57
[1] -204.7087
[1] -34.29615
[1] 72.61387
[1] -75.14396
[1] 148.734
[1] -84.13691
[1] 168.0066
INFO  [17:32:56.101] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -67.96239
[1] 24.0936
[1] -38.5681
[1] 87.94495
[1] -67.58317
[1] 13.04242
[1] 50.40204
[1] 1924.463
[1] 66.49302
[1] 1740.722
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:33:15.321] [mlr3] Finished benchmark
INFO  [17:33:15.538] [bbotk] Result of batch 5:
INFO  [17:33:15.555] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:33:15.555] [bbotk]              0.7387082                         0.1450544
INFO  [17:33:15.555] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:33:15.555] [bbotk]                         0.7299891           -2.803568              -0.645179
INFO  [17:33:15.555] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:33:15.555] [bbotk]                         13                     342                 0.8078541
INFO  [17:33:15.555] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:33:15.555] [bbotk]  0.08785161 <list[8]>              FALSE     0.02705974        0      0
INFO  [17:33:15.555] [bbotk]  runtime_learners                                uhash
INFO  [17:33:15.555] [bbotk]            49.193 55730a19-d4aa-49a0-ba21-6c5f195675e1
INFO  [17:33:16.767] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 36 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:33:22.474] [bbotk] Evaluating 1 configuration(s)
INFO  [17:33:22.852] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:33:23.164] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -5040.936
[1] -347.1812
[1] -52.71448
[1] 22.62857
[1] -48.15386
[1] 5.510099
[1] -56.36048
[1] 21.82733
[1] -27.89825
[1] 31.41136
INFO  [17:34:14.992] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -120.5189
[1] 46.03896
[1] -24.4991
[1] 99.88421
[1] -27.92663
[1] 100.9978
[1] -45.41355
[1] 32.32304
[1] -262.906
[1] -1.05169
INFO  [17:35:01.141] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -16.9208
[1] 43.07531
[1] -26.28764
[1] 48.30987
[1] -895.9268
[1] -3.800074
[1] -3558.51
[1] -101.92
[1] -57.80016
[1] 8.847447
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:35:34.091] [mlr3] Finished benchmark
INFO  [17:35:34.349] [bbotk] Result of batch 6:
INFO  [17:35:34.514] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:35:34.514] [bbotk]              -2.683291                         0.3626108
INFO  [17:35:34.514] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:35:34.514] [bbotk]                         0.7858936           -1.009393             -0.1169869
INFO  [17:35:34.514] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:35:34.514] [bbotk]                         15                    3112                 0.7087685
INFO  [17:35:34.514] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:35:34.514] [bbotk]  0.04283615 <list[8]>              FALSE     0.02092963        0      0
INFO  [17:35:34.514] [bbotk]  runtime_learners                                uhash
INFO  [17:35:34.514] [bbotk]           129.228 6739cee7-798c-444f-b555-c2ac9d9cc6c5
INFO  [17:35:36.051] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 37 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:35:44.485] [bbotk] Evaluating 1 configuration(s)
INFO  [17:35:44.790] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:35:45.002] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -46.11729
[1] 60.1348
[1] -153.1413
[1] -4.592964
[1] 152.3972
[1] 6076.42
[1] -90.59073
[1] 28.60137
[1] -50.49133
[1] 221.3112
INFO  [17:36:29.341] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -53.52198
[1] 99.46363
[1] -253.4595
[1] -4.328978
[1] -141.7466
[1] 39.40907
[1] 1.777157
[1] 115.9438
[1] -156.6786
[1] 44.36318
INFO  [17:37:04.993] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -36.78149
[1] 93.27417
[1] -122.3397
[1] 34.62045
[1] -87.43098
[1] 200.1276
[1] -105.724
[1] 33.3758
[1] -171.5809
[1] 17.36212
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:37:34.108] [mlr3] Finished benchmark
INFO  [17:37:34.213] [bbotk] Result of batch 7:
INFO  [17:37:34.245] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:37:34.245] [bbotk]               2.125244                          0.996861
INFO  [17:37:34.245] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:37:34.245] [bbotk]                         0.7278686           -1.953864              -4.542182
INFO  [17:37:34.245] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:37:34.245] [bbotk]                         12                    1726                 0.5803243
INFO  [17:37:34.245] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:37:34.245] [bbotk]  0.05688559 <list[8]>              FALSE     0.03604253        0      0
INFO  [17:37:34.245] [bbotk]  runtime_learners                                uhash
INFO  [17:37:34.245] [bbotk]            108.18 ae8365f1-0124-4440-80b7-326c661eccf9
INFO  [17:37:35.386] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 38 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:37:41.368] [bbotk] Evaluating 1 configuration(s)
INFO  [17:37:41.446] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:37:41.607] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -86.58459
[1] 12.5104
[1] -37.38148
[1] 24.51902
[1] -7276.864
[1] -181.4208
[1] -75.65999
[1] 43.78474
[1] -187.0588
[1] 9.653941
INFO  [17:38:20.379] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 549.3191
[1] 19848.15
[1] -35.65782
[1] 24.59604
[1] 74.46049
[1] 2053.172
[1] -1100.075
[1] 41.18812
[1] -4073.682
[1] -219.3903
INFO  [17:39:01.032] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -159.7974
[1] 1.218647
[1] -2.45472e+16
[1] 1.324088e+16
[1] -42.3117
[1] 93.57905
[1] -79.52206
[1] -2.774377
[1] -31.6415
[1] 47.40792
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:39:38.035] [mlr3] Finished benchmark
INFO  [17:39:38.149] [bbotk] Result of batch 8:
INFO  [17:39:38.218] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:39:38.218] [bbotk]             -0.4790302                         0.7665845
INFO  [17:39:38.218] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:39:38.218] [bbotk]                         0.8866145           -3.037252              -5.257286
INFO  [17:39:38.218] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:39:38.218] [bbotk]                         19                    2365                 0.3174201
INFO  [17:39:38.218] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:39:38.218] [bbotk]  0.04513847 <list[8]>              FALSE     0.02341746        0      0
INFO  [17:39:38.218] [bbotk]  runtime_learners                                uhash
INFO  [17:39:38.218] [bbotk]           115.234 6f50dc68-7649-478c-939c-45ad35a8f7d8
INFO  [17:39:39.346] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 39 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:39:44.990] [bbotk] Evaluating 1 configuration(s)
INFO  [17:39:45.060] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:39:45.219] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -30.01254
[1] 17.69915
[1] -2492.683
[1] -100.36
[1] -97.51805
[1] 19.46054
[1] -51.68063
[1] 51.51175
[1] -35.11113
[1] 10.36445
INFO  [17:40:17.314] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -78.43718
[1] 9.293695
[1] 293.1169
[1] 7450.407
[1] -32.58436
[1] 37.6593
[1] 20.62107
[1] 712.8291
[1] 28.72778
[1] 1016.761
INFO  [17:41:01.510] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -34.36929
[1] 26.92261
[1] -36.07874
[1] 15.55649
[1] -33.16795
[1] 100.2818
[1] -155.8949
[1] 21.02818
[1] -3247.776
[1] -78.30426
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:41:26.584] [mlr3] Finished benchmark
INFO  [17:41:26.768] [bbotk] Result of batch 9:
INFO  [17:41:26.817] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:41:26.817] [bbotk]             -0.3781495                         0.5319162
INFO  [17:41:26.817] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:41:26.817] [bbotk]                         0.9376299           -2.390722              -2.627974
INFO  [17:41:26.817] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:41:26.817] [bbotk]                          2                    3320                 0.5028017
INFO  [17:41:26.817] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:41:26.817] [bbotk]  0.03723999 <list[8]>              FALSE     0.02049942        0      0
INFO  [17:41:26.817] [bbotk]  runtime_learners                                uhash
INFO  [17:41:26.817] [bbotk]            100.58 125dd2d5-1f3f-40f7-a6a7-26429fd67abd
INFO  [17:41:27.588] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 40 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:41:33.367] [bbotk] Evaluating 1 configuration(s)
INFO  [17:41:33.434] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:41:33.531] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -134.4005
[1] -4.578199
[1] -111.2963
[1] 31.21236
[1] -80.45032
[1] 33.70577
[1] -95.1162
[1] 73.79252
[1] -122.9636
[1] 70.17329
INFO  [17:42:18.617] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -106.7683
[1] 103.5149
[1] -69.16227
[1] 68.83377
[1] -104.0403
[1] 80.76789
[1] -96.01176
[1] 42.21107
[1] -98.5557
[1] 69.35926
INFO  [17:42:49.370] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -43.21202
[1] 108.5013
[1] -148.3931
[1] -4.609152
[1] -107.5775
[1] 41.83209
[1] -146.667
[1] 5.397076
[1] -6.617495
[1] 159.0723
INFO  [17:43:14.323] [mlr3] Finished benchmark
INFO  [17:43:14.491] [bbotk] Result of batch 10:
INFO  [17:43:14.525] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:43:14.525] [bbotk]               1.951699                         0.6067665
INFO  [17:43:14.525] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:43:14.525] [bbotk]                         0.9422444           -3.780153              -6.009842
INFO  [17:43:14.525] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:43:14.525] [bbotk]                         16                    1986                 0.7796031
INFO  [17:43:14.525] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:43:14.525] [bbotk]  0.0506607 <list[8]>              FALSE     0.03439214        0      0
INFO  [17:43:14.525] [bbotk]  runtime_learners                                uhash
INFO  [17:43:14.525] [bbotk]           100.555 e5d89c5c-a725-4174-82eb-5920f61b5076
INFO  [17:43:15.676] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 41 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:43:20.208] [bbotk] Evaluating 1 configuration(s)
INFO  [17:43:20.288] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:43:20.405] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -136.739
[1] 54.30562
[1] -218.2313
[1] 13.73675
[1] -269.036
[1] 213.5421
[1] 126.0567
[1] 5173.756
[1] -234.0106
[1] 74.08875
INFO  [17:43:35.784] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -66.04508
[1] 268.6233
[1] 9.083662
[1] 363.2665
[1] -121.7563
[1] 64.40883
[1] -208.1084
[1] 65.39979
[1] -1111.825
[1] -15.61526
INFO  [17:43:51.724] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 6.602927
[1] 267.7748
[1] -127.4804
[1] 134.166
[1] 6.077412
[1] 251.9945
[1] -436.1127
[1] -5.986745
[1] -200.4916
[1] 39.93697
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:44:07.736] [mlr3] Finished benchmark
INFO  [17:44:07.885] [bbotk] Result of batch 11:
INFO  [17:44:07.910] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:44:07.910] [bbotk]               1.633469                         0.1010302
INFO  [17:44:07.910] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:44:07.910] [bbotk]                         0.5501454           -4.339689              0.1181673
INFO  [17:44:07.910] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:44:07.910] [bbotk]                          8                     182                 0.8759621
INFO  [17:44:07.910] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:44:07.910] [bbotk]  0.04411157 <list[8]>              FALSE     0.03400699        0      0
INFO  [17:44:07.910] [bbotk]  runtime_learners                                uhash
INFO  [17:44:07.910] [bbotk]            45.757 88d6ece2-1f6f-491b-a7fd-2b3fbc38fd12
INFO  [17:44:10.079] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 42 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:44:19.389] [bbotk] Evaluating 1 configuration(s)
INFO  [17:44:19.619] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:44:19.740] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -54.20911
[1] 30.95889
[1] -26.12813
[1] 56.54342
[1] -34.93429
[1] 16.13906
[1] -66.92861
[1] 5.889971
[1] -69.85103
[1] 17.754
INFO  [17:44:49.508] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -49.7489
[1] 63.07714
[1] -47.32768
[1] 23.76309
[1] -208.0855
[1] 33.11941
[1] -177.5086
[1] 52.82004
[1] 4.450721e+14
[1] 3.145044e+16
INFO  [17:45:20.407] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -198.2968
[1] 14.59065
[1] -17.53217
[1] 84.4862
[1] -22.24519
[1] 31.59709
[1] -34.75696
[1] 70.42082
[1] -136.2866
[1] 2.132671
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:45:55.081] [mlr3] Finished benchmark
INFO  [17:45:55.294] [bbotk] Result of batch 12:
INFO  [17:45:55.322] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:45:55.322] [bbotk]              -4.325464                         0.5182984
INFO  [17:45:55.322] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:45:55.322] [bbotk]                         0.2721234            -1.68204              -5.106565
INFO  [17:45:55.322] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:45:55.322] [bbotk]                         11                    3146                 0.6589308
INFO  [17:45:55.322] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:45:55.322] [bbotk]  0.03597165 <list[8]>              FALSE     0.02067969        0      0
INFO  [17:45:55.322] [bbotk]  runtime_learners                                uhash
INFO  [17:45:55.322] [bbotk]            94.798 4663e645-7b2e-4167-9e6f-e7a66fc296a5
INFO  [17:45:56.175] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 43 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:46:03.268] [bbotk] Evaluating 1 configuration(s)
INFO  [17:46:03.566] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:46:03.746] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -76.22699
[1] 15.00856
[1] -109.2228
[1] 12.99188
[1] -81.61956
[1] 65.59042
[1] -296.4424
[1] -3.173476
[1] -9.511881
[1] 148.7033
INFO  [17:46:29.047] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -88.81678
[1] 52.22271
[1] -4.974203
[1] 94.4918
[1] -16176.53
[1] -249.6925
[1] -27.38265
[1] 180.171
[1] -216.6094
[1] -4.414363
INFO  [17:46:57.772] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 291.6313
[1] 7799.534
[1] -82.14763
[1] 8.041388
[1] -4873.634
[1] -98.49817
[1] -109.8271
[1] 46.6293
[1] -317.7641
[1] -4.376711
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:47:18.609] [mlr3] Finished benchmark
INFO  [17:47:18.730] [bbotk] Result of batch 13:
INFO  [17:47:18.767] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:47:18.767] [bbotk]               1.267524                         0.2091673
INFO  [17:47:18.767] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:47:18.767] [bbotk]                         0.8417283          -0.7168546               4.572374
INFO  [17:47:18.767] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:47:18.767] [bbotk]                         11                    1169                 0.5708953
INFO  [17:47:18.767] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:47:18.767] [bbotk]  0.03074169 <list[8]>              FALSE     0.03034871        0      0
INFO  [17:47:18.767] [bbotk]  runtime_learners                                uhash
INFO  [17:47:18.767] [bbotk]            74.095 6bc00d3b-3611-45f1-a3ad-9eb1c0e3f11e
INFO  [17:47:20.115] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 44 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:47:26.175] [bbotk] Evaluating 1 configuration(s)
INFO  [17:47:26.297] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:47:26.439] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -32.9296
[1] 139.3517
[1] -59.54757
[1] 198.9834
[1] -108.0684
[1] 9.073739
[1] -26.44299
[1] 51.47854
[1] -93.8321
[1] 5.686195
INFO  [17:47:43.857] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 239.8023
[1] 9692.838
[1] -52.79427
[1] 92.45238
[1] -312.4405
[1] -4.110762
[1] -1.650808
[1] 82.62415
[1] -28.34534
[1] 132.8707
INFO  [17:48:07.263] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -3132.395
[1] -82.30047
[1] -55.55924
[1] 64.89889
[1] -45.88835
[1] 23.7296
[1] -40.50767
[1] 86.76266
[1] -19.82948
[1] 193.1414
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:48:37.787] [mlr3] Finished benchmark
INFO  [17:48:37.907] [bbotk] Result of batch 14:
INFO  [17:48:37.933] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:48:37.933] [bbotk]               1.102773                         0.8789628
INFO  [17:48:37.933] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:48:37.933] [bbotk]                         0.8187106            -1.47233              -1.018922
INFO  [17:48:37.933] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:48:37.933] [bbotk]                         10                     937                 0.6713899
INFO  [17:48:37.933] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:48:37.933] [bbotk]  0.03364475 <list[8]>              FALSE     0.02587653        0      0
INFO  [17:48:37.933] [bbotk]  runtime_learners                                uhash
INFO  [17:48:37.933] [bbotk]            70.439 540a1f9b-aa15-42ed-b0cc-c91c4935f748
INFO  [17:48:39.603] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 45 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:48:49.480] [bbotk] Evaluating 1 configuration(s)
INFO  [17:48:49.716] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:48:49.960] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -34.56126
[1] 162.5253
[1] -113.0526
[1] 56.11558
[1] -359.8304
[1] -4.995126
[1] -106.5809
[1] 107.4634
[1] -319.9847
[1] -5.337717
INFO  [17:49:01.459] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -158.4333
[1] 56.31551
[1] -54.39664
[1] 135.1866
[1] -223.5195
[1] 32.628
[1] -100.5641
[1] 152.4397
[1] -80.21714
[1] 126.3359
INFO  [17:49:15.548] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -38.93805
[1] 180.819
[1] -69.68949
[1] 85.79137
[1] -48.51914
[1] 209.1532
[1] -84.21493
[1] 79.05846
[1] -272.456
[1] 5.344052
INFO  [17:49:29.890] [mlr3] Finished benchmark
INFO  [17:49:30.230] [bbotk] Result of batch 15:
INFO  [17:49:30.396] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:49:30.396] [bbotk]              -1.204733                         0.1758994
INFO  [17:49:30.396] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:49:30.396] [bbotk]                          0.433844           -3.482532               1.957508
INFO  [17:49:30.396] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:49:30.396] [bbotk]                         15                     168                 0.2884961
INFO  [17:49:30.396] [bbotk]    acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:49:30.396] [bbotk]  0.029789 <list[8]>              FALSE     0.03449294        0      0
INFO  [17:49:30.396] [bbotk]  runtime_learners                                uhash
INFO  [17:49:30.396] [bbotk]            39.507 6dac81cf-6e52-4af0-a8c2-35ec1646150c
WARN  [17:49:32.971] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:49:33.051] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 46 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:49:40.791] [bbotk] Evaluating 1 configuration(s)
INFO  [17:49:40.961] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:49:41.061] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -79.45634
[1] 42.4313
[1] -13089.19
[1] -203.5742
[1] -63.90348
[1] 87.98758
[1] -155.8488
[1] 52.68488
[1] -153.5476
[1] -4.515357
INFO  [17:50:12.908] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -12.82563
[1] 120.8388
[1] -108.8136
[1] 61.96058
[1] -752907.5
[1] -34554.24
[1] -132.682
[1] 52.17024
[1] -72.74826
[1] 29.9301
INFO  [17:50:42.407] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -619.278
[1] -3.695716
[1] -178.8639
[1] -5.070455
[1] -313.2711
[1] 86.70042
[1] -101.4736
[1] 56.94122
[1] -192.1395
[1] 15.71978
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:51:13.159] [mlr3] Finished benchmark
INFO  [17:51:13.265] [bbotk] Result of batch 16:
INFO  [17:51:13.324] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:51:13.324] [bbotk]                 2.0619                         0.3115509
INFO  [17:51:13.324] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:51:13.324] [bbotk]                         0.6957704           -1.083352              -4.468458
INFO  [17:51:13.324] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:51:13.324] [bbotk]                          5                    1311                 0.9332249
INFO  [17:51:13.324] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:51:13.324] [bbotk]  0.03500419 <list[8]>              FALSE     0.03322779        0      0
INFO  [17:51:13.324] [bbotk]  runtime_learners                                uhash
INFO  [17:51:13.324] [bbotk]            90.572 b8ddfd56-0161-4460-9e2a-ca341dd44f98
INFO  [17:51:14.310] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 47 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:51:23.150] [bbotk] Evaluating 1 configuration(s)
INFO  [17:51:23.273] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:51:23.353] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -45.79868
[1] 28.02776
[1] -110.892
[1] -4.235181
[1] -82.66319
[1] 79.29049
[1] -52.52756
[1] 59.51833
[1] -78.51497
[1] 21.0985
INFO  [17:51:39.049] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -798.5208
[1] -39.32932
[1] -45.6282
[1] 69.49783
[1] -43.93166
[1] 22.92637
[1] -93.74751
[1] 43.46149
[1] 103.8942
[1] 2095.406
INFO  [17:52:02.013] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -341.1653
[1] -3.760083
[1] -84.06553
[1] 167.1795
[1] -21.1974
[1] 104.7328
[1] -40.50515
[1] 30.80819
[1] -86.88451
[1] 37.39427
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:52:34.622] [mlr3] Finished benchmark
INFO  [17:52:34.757] [bbotk] Result of batch 17:
INFO  [17:52:34.911] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:52:34.911] [bbotk]              -5.552183                         0.6377847
INFO  [17:52:34.911] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:52:34.911] [bbotk]                         0.4148802           -3.818228              0.3643165
INFO  [17:52:34.911] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:52:34.911] [bbotk]                         18                    1752                 0.4629124
INFO  [17:52:34.911] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:52:34.911] [bbotk]  0.03232139 <list[8]>              FALSE     0.02224461        0      0
INFO  [17:52:34.911] [bbotk]  runtime_learners                                uhash
INFO  [17:52:34.911] [bbotk]            69.018 2a05e050-f591-405a-95b6-aa8e297aa6af
INFO  [17:52:37.421] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 48 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:52:45.919] [bbotk] Evaluating 1 configuration(s)
INFO  [17:52:46.504] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:52:46.565] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -66.93129
[1] 112.0266
[1] -73.0077
[1] 116.664
[1] -328.9975
[1] 40.68393
[1] -61.99719
[1] 156.5337
[1] -104.9956
[1] 10.46981
INFO  [17:53:34.873] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -69.08124
[1] 73.39432
[1] 5.797669
[1] 240.9788
[1] 189.706
[1] 6701.478
[1] -200.4082
[1] 22.65682
[1] -49.56455
[1] 79.35076
INFO  [17:54:19.222] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -62.42342
[1] 100.3893
[1] -181.4377
[1] 19.59193
[1] -42.0318
[1] 97.60449
[1] -49.28164
[1] 80.26499
[1] -47101.82
[1] -805.787
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:55:00.116] [mlr3] Finished benchmark
INFO  [17:55:00.293] [bbotk] Result of batch 18:
INFO  [17:55:00.350] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:55:00.350] [bbotk]              -1.131876                         0.1410561
INFO  [17:55:00.350] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:55:00.350] [bbotk]                         0.6633664            -6.77359              -2.741007
INFO  [17:55:00.350] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:55:00.350] [bbotk]                         17                    4509                 0.1085246
INFO  [17:55:00.350] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:55:00.350] [bbotk]  0.03041386 <list[8]>              FALSE     0.03435616        0      0
INFO  [17:55:00.350] [bbotk]  runtime_learners                                uhash
INFO  [17:55:00.350] [bbotk]           132.431 0b64cbbc-57a0-4413-b3a8-054f8d9bcd86
INFO  [17:55:01.946] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 49 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:55:08.071] [bbotk] Evaluating 1 configuration(s)
INFO  [17:55:08.213] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:55:08.373] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -96.34555
[1] -3.942586
[1] -20.70812
[1] 25.54545
[1] -118.6338
[1] 39.98178
[1] -85.81561
[1] 21.01616
[1] -56.00957
[1] 30.63477
INFO  [17:55:55.089] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -32.63677
[1] 210.2703
[1] -31.20716
[1] 49.00742
[1] -1103.952
[1] -26.71731
[1] -2236.178
[1] -58.09921
[1] -47.52236
[1] 34.19353
INFO  [17:56:36.360] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -50.08011
[1] 29.2905
[1] -27.24333
[1] 151.1116
[1] -36.71266
[1] 11.4103
[1] -30.31841
[1] 109.7081
[1] -21.84588
[1] 51.32335
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:57:10.838] [mlr3] Finished benchmark
INFO  [17:57:12.174] [bbotk] Result of batch 19:
INFO  [17:57:12.417] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:57:12.417] [bbotk]              -3.804958                         0.7024185
INFO  [17:57:12.417] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:57:12.417] [bbotk]                         0.9003582           -3.710614              -2.859657
INFO  [17:57:12.417] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:57:12.417] [bbotk]                         15                    2854                 0.5370955
INFO  [17:57:12.417] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:57:12.417] [bbotk]  0.02472177 <list[8]>              FALSE     0.02061032        0      0
INFO  [17:57:12.417] [bbotk]  runtime_learners                                uhash
INFO  [17:57:12.417] [bbotk]           120.514 2b4e6582-67f8-4f4c-890c-bc966668c803
INFO  [17:57:14.757] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 50 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:57:20.784] [bbotk] Evaluating 1 configuration(s)
INFO  [17:57:20.887] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:57:21.201] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -54.44665
[1] 35.6735
[1] -74.06674
[1] 18.93506
[1] -92.81353
[1] 26.74237
[1] -287.8832
[1] 5.998592
[1] -112.4012
[1] -1.735119
INFO  [17:58:07.906] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -17636.71
[1] -531.9147
[1] -50.57606
[1] 37.17619
[1] -126.1671
[1] 42.4082
[1] -39.71912
[1] 51.78205
[1] -7705.057
[1] -104.0512
INFO  [17:58:43.858] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -244.3746
[1] 11.59785
[1] -55.95322
[1] 65.43962
[1] -9742.172
[1] -214.8442
[1] -125.4935
[1] 117.259
[1] -56.84595
[1] 38.34112
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:59:34.629] [mlr3] Finished benchmark
INFO  [17:59:34.776] [bbotk] Result of batch 20:
INFO  [17:59:34.859] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:59:34.859] [bbotk]              0.9059958                          0.291574
INFO  [17:59:34.859] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:59:34.859] [bbotk]                         0.9520248          -0.6556399               5.058365
INFO  [17:59:34.859] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:59:34.859] [bbotk]                          2                    3219                 0.7813695
INFO  [17:59:34.859] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:59:34.859] [bbotk]  0.02330565 <list[8]>              FALSE     0.02695083        0      0
INFO  [17:59:34.859] [bbotk]  runtime_learners                                uhash
INFO  [17:59:34.859] [bbotk]           132.498 cda3129f-45f0-4b72-bcf9-c3e0f5992243
INFO  [17:59:36.530] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 51 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:59:43.073] [bbotk] Evaluating 1 configuration(s)
INFO  [17:59:43.179] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:59:43.260] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -846.2547
[1] -35.13345
[1] -12.50132
[1] 34.98348
[1] -34.57
[1] 11.47547
[1] -2541.408
[1] -47.92135
[1] -60338.43
[1] -1616.915
INFO  [18:00:28.174] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -2169.65
[1] -35.23751
[1] -38.25989
[1] 122.3705
[1] -54.40956
[1] 6.067968
[1] -60.16775
[1] 50.495
[1] -61.79786
[1] 21.44987
INFO  [18:00:58.892] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -15.51013
[1] 103.6277
[1] -82.80253
[1] 36.14459
[1] -39.78412
[1] 49.75539
[1] -73.45103
[1] 43.17699
[1] -77.41062
[1] -1.508793
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:01:32.580] [mlr3] Finished benchmark
INFO  [18:01:33.005] [bbotk] Result of batch 21:
INFO  [18:01:33.099] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:01:33.099] [bbotk]              -2.244607                         0.1174548
INFO  [18:01:33.099] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:01:33.099] [bbotk]                         0.7508604           -1.682294              -6.077293
INFO  [18:01:33.099] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:01:33.099] [bbotk]                          9                    3954                  0.343105
INFO  [18:01:33.099] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:01:33.099] [bbotk]  0.02281873 <list[8]>              FALSE     0.02189437        0      0
INFO  [18:01:33.099] [bbotk]  runtime_learners                                uhash
INFO  [18:01:33.099] [bbotk]           108.299 575e39b3-ac31-49ee-9704-69bf4521c89e
INFO  [18:01:35.405] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 52 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:01:43.728] [bbotk] Evaluating 1 configuration(s)
INFO  [18:01:43.781] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:01:43.991] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -58.27164
[1] 23.09848
[1] -87.91492
[1] 18.67781
[1] -79.51984
[1] 70.53346
[1] -38.58094
[1] 13.18991
[1] -42265.48
[1] -2288.742
INFO  [18:02:21.913] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 976.909
[1] 33885.65
[1] -116.4131
[1] 17.93778
[1] -42.97816
[1] 244.0319
[1] -142.7499
[1] 62.4297
[1] 85.67287
[1] 2124.244
INFO  [18:02:49.283] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 43.41557
[1] 1002.01
[1] -14.19576
[1] 95.41218
[1] -106.5509
[1] 36.14481
[1] -47.99932
[1] -3.648366
[1] -237.8562
[1] 14.94838
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:03:18.667] [mlr3] Finished benchmark
INFO  [18:03:18.844] [bbotk] Result of batch 22:
INFO  [18:03:18.859] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:03:18.859] [bbotk]             -0.4728328                          0.164048
INFO  [18:03:18.859] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:03:18.859] [bbotk]                         0.6677022          -0.1805992               3.777753
INFO  [18:03:18.859] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:03:18.859] [bbotk]                          9                    2361                 0.5752409
INFO  [18:03:18.859] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:03:18.859] [bbotk]  0.02234188 <list[8]>              FALSE     0.02079426        0      0
INFO  [18:03:18.859] [bbotk]  runtime_learners                                uhash
INFO  [18:03:18.859] [bbotk]            93.549 49776a13-18de-4a89-850f-b9922b561be2
INFO  [18:03:20.035] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 53 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:03:27.482] [bbotk] Evaluating 1 configuration(s)
INFO  [18:03:27.941] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:03:28.264] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -68.05249
[1] 20.43517
[1] -4797.356
[1] -173.0158
[1] -112.2685
[1] -3.257334
[1] -33.8961
[1] 135.8174
[1] -80.12437
[1] 36.96766
INFO  [18:03:45.357] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -143.6354
[1] 40.39282
[1] -21.6966
[1] 62.88708
[1] -100.768
[1] 41.40449
[1] -46.40925
[1] 53.8765
[1] -125.003
[1] 82.91247
INFO  [18:04:18.076] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -62.46016
[1] 45.2481
[1] -42.97876
[1] 29.27366
[1] -124.9177
[1] 6.648863
[1] -790.8391
[1] -15.67923
[1] -78.16208
[1] 43.65397
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:04:54.457] [mlr3] Finished benchmark
INFO  [18:04:54.642] [bbotk] Result of batch 23:
INFO  [18:04:54.768] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:04:54.768] [bbotk]              0.9813745                         0.6335952
INFO  [18:04:54.768] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:04:54.768] [bbotk]                         0.5978204           -3.169174              0.9785069
INFO  [18:04:54.768] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:04:54.768] [bbotk]                         13                    2024                 0.9484251
INFO  [18:04:54.768] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:04:54.768] [bbotk]  0.02553106 <list[8]>              FALSE     0.02593509        0      0
INFO  [18:04:54.768] [bbotk]  runtime_learners                                uhash
INFO  [18:04:54.768] [bbotk]            85.323 c049324b-f97f-4d61-aa88-45ebd4a570d4
INFO  [18:04:57.799] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 54 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:05:04.021] [bbotk] Evaluating 1 configuration(s)
INFO  [18:05:04.173] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:05:04.298] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1812.782
[1] -122.3413
[1] -38.74101
[1] 18.61987
[1] -96.01468
[1] 12.81811
[1] -19.59641
[1] 43.01032
[1] -29.10349
[1] 15.18044
INFO  [18:05:22.335] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -7.718231
[1] 63.54936
[1] -19.28798
[1] 62.30978
[1] -497.8997
[1] -3.912953
[1] -38.7923
[1] 46.5674
[1] -33.70355
[1] 17.61617
INFO  [18:05:38.193] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -5.3082
[1] 146.1504
[1] -13.672
[1] 38.68869
[1] -56.61658
[1] 19.50611
[1] -92.235
[1] 10.08428
[1] -19.45784
[1] 7.440344
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:05:51.238] [mlr3] Finished benchmark
INFO  [18:05:51.366] [bbotk] Result of batch 24:
INFO  [18:05:51.390] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:05:51.390] [bbotk]              -5.547784                         0.5186174
INFO  [18:05:51.390] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:05:51.390] [bbotk]                         0.7589225          -0.2007908              -4.184082
INFO  [18:05:51.390] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:05:51.390] [bbotk]                         15                     686                 0.8623355
INFO  [18:05:51.390] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:05:51.390] [bbotk]  0.02144955 <list[8]>              FALSE     0.02640387        0      0
INFO  [18:05:51.390] [bbotk]  runtime_learners                                uhash
INFO  [18:05:51.390] [bbotk]            46.289 74d9ecf0-0cbb-4b57-9adb-3a46c6d6cfdd
INFO  [18:05:53.059] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 55 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:05:59.726] [bbotk] Evaluating 1 configuration(s)
INFO  [18:05:59.815] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:05:59.948] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -86.46217
[1] 13.14179
[1] -99.24802
[1] 35.32469
[1] -103.245
[1] 37.83246
[1] 102.6609
[1] 3381.595
[1] -97.02162
[1] 33.47779
INFO  [18:06:20.568] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -166.2019
[1] 47.99659
[1] 643.76
[1] 22179.75
[1] -4561.553
[1] -71.4188
[1] -31.30678
[1] 126.9696
[1] -63.7807
[1] 17.66345
INFO  [18:06:44.411] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -305.8918
[1] 19.89506
[1] -46.34405
[1] 101.4224
[1] -150.8718
[1] -3.644625
[1] -4.40935e+16
[1] 1.048852e+16
[1] -29.26104
[1] 68.10419
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:07:12.330] [mlr3] Finished benchmark
INFO  [18:07:12.450] [bbotk] Result of batch 25:
INFO  [18:07:12.494] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:07:12.494] [bbotk]              -2.199465                         0.4027416
INFO  [18:07:12.494] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:07:12.494] [bbotk]                         0.6789125           -5.640724              -3.927072
INFO  [18:07:12.494] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:07:12.494] [bbotk]                          1                    1975                 0.4841279
INFO  [18:07:12.494] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:07:12.494] [bbotk]  0.02067967 <list[8]>              FALSE     0.02529975        0      0
INFO  [18:07:12.494] [bbotk]  runtime_learners                                uhash
INFO  [18:07:12.494] [bbotk]              71.9 454180a8-b72b-4d5a-9088-5fa94438a7c5
INFO  [18:07:14.588] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 56 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:07:24.044] [bbotk] Evaluating 1 configuration(s)
INFO  [18:07:24.158] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:07:24.265] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -162.6042
[1] 25.96985
[1] 135.8171
[1] 5896.276
[1] -84.27787
[1] 28.78343
[1] -112.6433
[1] 19.81118
[1] -118.2115
[1] 16.44849
INFO  [18:08:21.456] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -27.93275
[1] 82.28407
[1] -31.53383
[1] 64.0362
[1] -37.54741
[1] 36.21431
[1] -245.583
[1] 114.7906
[1] -179.4398
[1] -3.951978
INFO  [18:09:07.711] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -27.9025
[1] 56.75717
[1] -3768.149
[1] -99.37534
[1] -47.64765
[1] 32.88776
[1] -114.2129
[1] 130.4311
[1] -194.6449
[1] -4.247674
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:10:03.881] [mlr3] Finished benchmark
INFO  [18:10:05.000] [bbotk] Result of batch 26:
INFO  [18:10:05.036] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:10:05.036] [bbotk]              0.5006479                         0.9725688
INFO  [18:10:05.036] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:10:05.036] [bbotk]                          0.734491           -3.796295              -6.464045
INFO  [18:10:05.036] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:10:05.036] [bbotk]                          1                    4974                 0.8705373
INFO  [18:10:05.036] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:10:05.036] [bbotk]  0.02158813 <list[8]>              FALSE     0.02385721        0      0
INFO  [18:10:05.036] [bbotk]  runtime_learners                                uhash
INFO  [18:10:05.036] [bbotk]           158.681 25abcb7d-2732-44ef-a5b0-c3d494e4e442
INFO  [18:10:07.905] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 57 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:10:18.285] [bbotk] Evaluating 1 configuration(s)
INFO  [18:10:18.384] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:10:18.627] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -81.70759
[1] 43.06279
[1] -114.7585
[1] 6.984193
[1] -1999.503
[1] -68.65933
[1] -99.69398
[1] 15.88633
[1] -134.1435
[1] 2.980043
INFO  [18:10:41.955] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -59.93864
[1] 37.43671
[1] 65.25754
[1] 1927.054
[1] -29.38487
[1] 52.71763
[1] -4685.222
[1] -150.1808
[1] -87.85773
[1] 52.07649
INFO  [18:11:20.492] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -122.9358
[1] -3.257756
[1] -169.0268
[1] 23.67046
[1] -4.584602
[1] 114.4624
[1] -95.82426
[1] 102.1455
[1] -63.44189
[1] 36.27383
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:12:03.660] [mlr3] Finished benchmark
INFO  [18:12:03.982] [bbotk] Result of batch 27:
INFO  [18:12:04.041] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:12:04.041] [bbotk]              -2.239894                         0.9650334
INFO  [18:12:04.041] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:12:04.041] [bbotk]                         0.9000564           -1.813478              0.7597384
INFO  [18:12:04.041] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:12:04.041] [bbotk]                          7                    3656                 0.2170921
INFO  [18:12:04.041] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:12:04.041] [bbotk]  0.02109339 <list[8]>              FALSE     0.01799826        0      0
INFO  [18:12:04.041] [bbotk]  runtime_learners                                uhash
INFO  [18:12:04.041] [bbotk]           104.303 9a68c328-9b29-4a5c-8bf3-e9402d6a07ed
WARN  [18:12:05.455] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:12:05.638] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 58 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:12:12.256] [bbotk] Evaluating 1 configuration(s)
INFO  [18:12:12.479] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:12:12.532] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -100.4582
[1] 23.78021
[1] -68.85995
[1] 5.351923
[1] -47.6517
[1] 23.16449
[1] -45.3654
[1] 17.48395
[1] -20.42761
[1] 49.74146
INFO  [18:12:35.272] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 77.09356
[1] 1134.63
[1] -206.8
[1] -4.094248
[1] -20.00224
[1] 87.44155
[1] -5663.619
[1] -171.0572
[1] -20.67291
[1] 76.43839
INFO  [18:13:01.089] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -50.34958
[1] 4.260855
[1] -3337.656
[1] -67.89218
[1] -100.2049
[1] 36.51847
[1] -23.51372
[1] 45.52391
[1] -349.0618
[1] 12.8595
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:13:36.055] [mlr3] Finished benchmark
INFO  [18:13:36.235] [bbotk] Result of batch 28:
INFO  [18:13:36.334] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:13:36.334] [bbotk]              -6.236199                         0.3961173
INFO  [18:13:36.334] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:13:36.334] [bbotk]                         0.4098019           -1.824376              0.7221733
INFO  [18:13:36.334] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:13:36.334] [bbotk]                          5                    1492                 0.9653654
INFO  [18:13:36.334] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:13:36.334] [bbotk]  0.02118565 <list[8]>              FALSE     0.01922239        0      0
INFO  [18:13:36.334] [bbotk]  runtime_learners                                uhash
INFO  [18:13:36.334] [bbotk]            80.916 f1d0255a-c480-41f7-85b1-ce4a6a4fceff
INFO  [18:13:40.070] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 59 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:13:46.194] [bbotk] Evaluating 1 configuration(s)
INFO  [18:13:46.489] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:13:46.795] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 2.591502
[1] 124.409
[1] -15111.66
[1] -277.9147
[1] -39.77051
[1] 237.7763
[1] -70.54036
[1] 74.60674
[1] -162.6631
[1] -3.279121
INFO  [18:14:30.203] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -202.414
[1] -4.917052
[1] -352.7427
[1] -5.282379
[1] -231.7848
[1] 25.15366
[1] -172.7725
[1] -3.93743
[1] -184.1985
[1] -4.21356
INFO  [18:15:32.368] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -72.35254
[1] 100.4206
[1] -21.3604
[1] 101.5469
[1] -310.8611
[1] -5.193803
[1] -242.1785
[1] -4.714337
[1] -152.1852
[1] 151.752
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:16:15.191] [mlr3] Finished benchmark
INFO  [18:16:15.294] [bbotk] Result of batch 29:
INFO  [18:16:15.416] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:16:15.416] [bbotk]                3.02338                         0.8592416
INFO  [18:16:15.416] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:16:15.416] [bbotk]                         0.9963778           -0.094172              -6.598149
INFO  [18:16:15.416] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:16:15.416] [bbotk]                          6                    2150                 0.9251889
INFO  [18:16:15.416] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:16:15.416] [bbotk]  0.02842943 <list[8]>              FALSE     0.04191107        0      0
INFO  [18:16:15.416] [bbotk]  runtime_learners                                uhash
INFO  [18:16:15.416] [bbotk]           147.762 262dad93-ad6d-4f39-bea1-406a0dba5294
INFO  [18:16:17.451] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 60 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:16:24.860] [bbotk] Evaluating 1 configuration(s)
INFO  [18:16:24.915] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:16:25.049] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -42.24617
[1] 35.31769
[1] -169.5287
[1] -2.894724
[1] -2039.698
[1] -62.58554
[1] -1852.652
[1] -51.43001
[1] -42.68719
[1] 25.12304
INFO  [18:17:01.288] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -23.84871
[1] 79.47234
[1] -486.355
[1] 4.962174
[1] -71.82676
[1] 69.59672
[1] -1028.429
[1] -66.09061
[1] 183.7773
[1] 4193.182
INFO  [18:17:54.277] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -53.55405
[1] 26.31295
[1] -2048.889
[1] -31.72807
[1] -54.77771
[1] 7.554766
[1] -92.11571
[1] 32.18372
[1] -21.75105
[1] 90.73922
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:18:53.020] [mlr3] Finished benchmark
INFO  [18:18:53.162] [bbotk] Result of batch 30:
INFO  [18:18:53.197] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:18:53.197] [bbotk]              -4.146806                          0.938575
INFO  [18:18:53.197] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:18:53.197] [bbotk]                         0.3651709          -0.3796297               4.826705
INFO  [18:18:53.197] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:18:53.197] [bbotk]                         14                    4191                 0.4592044
INFO  [18:18:53.197] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:18:53.197] [bbotk]  0.0221197 <list[8]>              FALSE     0.02019763        0      0
INFO  [18:18:53.197] [bbotk]  runtime_learners                                uhash
INFO  [18:18:53.197] [bbotk]           146.684 f2828ee1-aea3-4e89-a10d-250674d5a1df
INFO  [18:18:55.029] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 61 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:18:58.575] [bbotk] Evaluating 1 configuration(s)
INFO  [18:18:58.619] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:18:58.656] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -2097.031
[1] -145.2382
[1] -70.28729
[1] 54.10523
[1] -50.49077
[1] 18.14012
[1] -94.34388
[1] 76.98712
[1] -67.83547
[1] 18.30925
INFO  [18:19:11.243] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -58.13938
[1] 36.64956
[1] -266.2253
[1] 5.979318
[1] -71.61509
[1] 46.80336
[1] -108.5935
[1] 100.7138
[1] -161.1746
[1] 87.59118
INFO  [18:19:33.435] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2059.531
[1] -37.46343
[1] -93.75013
[1] 38.31461
[1] -92.64844
[1] 18.71457
[1] -26.02863
[1] 55.34822
[1] -2.195021e+16
[1] 8.974434e+15
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:20:08.659] [mlr3] Finished benchmark
INFO  [18:20:08.834] [bbotk] Result of batch 31:
INFO  [18:20:08.869] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:20:08.869] [bbotk]              -6.536753                         0.5839611
INFO  [18:20:08.869] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:20:08.869] [bbotk]                         0.3358602           -1.142601               2.515689
INFO  [18:20:08.869] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:20:08.869] [bbotk]                          8                    2059                 0.5644257
INFO  [18:20:08.869] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:20:08.869] [bbotk]  0.01936809 <list[8]>              FALSE     0.02079114        0      0
INFO  [18:20:08.869] [bbotk]  runtime_learners                                uhash
INFO  [18:20:08.869] [bbotk]            68.971 499af811-6618-41b9-9887-eb6cdf5138de
WARN  [18:20:11.286] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:20:11.327] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 62 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:20:15.894] [bbotk] Evaluating 1 configuration(s)
INFO  [18:20:15.947] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:20:16.005] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 2296.776
[1] 124395.2
[1] 1342.093
[1] 72653.64
[1] -86719.76
[1] -1600.609
[1] -62820.05
[1] -1160.873
[1] -99058.72
[1] -1830.185
INFO  [18:20:26.156] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 1527.852
[1] 82799.6
[1] 1791.908
[1] 96967.67
[1] -104937.9
[1] -1937.458
[1] 1466.459
[1] 79473.97
[1] -76238.22
[1] -1407.769
INFO  [18:20:40.771] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -68682.33
[1] -1268.539
[1] -72404.71
[1] -1337.488
[1] -102420.1
[1] -1891.105
[1] 1705.886
[1] 92322.2
[1] -116668.1
[1] -2153.115
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:20:54.049] [mlr3] Finished benchmark
INFO  [18:20:54.184] [bbotk] Result of batch 32:
INFO  [18:20:54.340] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:20:54.340] [bbotk]              0.7734551                         0.8494289
INFO  [18:20:54.340] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:20:54.340] [bbotk]                         0.9975673           -6.979432              -5.345644
INFO  [18:20:54.340] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:20:54.340] [bbotk]                         11                       2                 0.4176177
INFO  [18:20:54.340] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:20:54.340] [bbotk]  0.0207595 <list[8]>              FALSE      0.4818825        0      0
INFO  [18:20:54.340] [bbotk]  runtime_learners                                uhash
INFO  [18:20:54.340] [bbotk]            37.293 f25027cb-fa25-4f68-b64a-c5db8b1e3a11
INFO  [18:20:56.036] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 63 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:21:05.480] [bbotk] Evaluating 1 configuration(s)
INFO  [18:21:05.740] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:21:05.829] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -84.03475
[1] 8.207619
[1] -67.18183
[1] 213.4644
[1] -270.1503
[1] 32.20244
[1] -20.22173
[1] 108.395
[1] -49.11071
[1] 40.09732
INFO  [18:22:06.423] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -94.05103
[1] 34.00503
[1] -69.12647
[1] 73.68126
[1] -14.9484
[1] 94.12874
[1] -6574.635
[1] -149.9017
[1] -41.45168
[1] 97.31399
INFO  [18:22:57.520] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -75.53439
[1] 38.46532
[1] -56.09299
[1] 165.0138
[1] -94.80822
[1] 50.6164
[1] -184.5517
[1] -3.827925
[1] -50.19113
[1] 82.44578
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:23:36.308] [mlr3] Finished benchmark
INFO  [18:23:36.458] [bbotk] Result of batch 33:
INFO  [18:23:36.522] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:23:36.522] [bbotk]                1.97354                         0.9724625
INFO  [18:23:36.522] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:23:36.522] [bbotk]                         0.8430842           -2.262955              -1.282298
INFO  [18:23:36.522] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:23:36.522] [bbotk]                         19                    4438                 0.8106069
INFO  [18:23:36.522] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:23:36.522] [bbotk]  0.05146592 <list[8]>              FALSE     0.03343135        0      0
INFO  [18:23:36.522] [bbotk]  runtime_learners                                uhash
INFO  [18:23:36.522] [bbotk]           149.938 8c67443c-006c-4319-9f51-ccd2c1101890
INFO  [18:23:39.156] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 64 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:23:44.561] [bbotk] Evaluating 1 configuration(s)
INFO  [18:23:44.592] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:23:44.888] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -84.61377
[1] 4.916973
[1] -201.0546
[1] -4.496082
[1] -82.95939
[1] 61.7761
[1] -37.53798
[1] 80.5291
[1] -945.6582
[1] 992.8814
INFO  [18:24:59.590] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -49.82756
[1] 219.1297
[1] 438.1263
[1] 13308.54
[1] -40.52066
[1] 93.9304
[1] -96.51637
[1] 57.44886
[1] -39.81459
[1] 58.32721
INFO  [18:26:01.565] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -78.88286
[1] 38.44699
[1] -44.14371
[1] 63.19621
[1] -93.33697
[1] 50.89853
[1] -240.4797
[1] -4.42841
[1] -39.26266
[1] 362.3838
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:26:50.460] [mlr3] Finished benchmark
INFO  [18:26:50.738] [bbotk] Result of batch 34:
INFO  [18:26:50.777] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:26:50.777] [bbotk]             -0.1453363                         0.7389719
INFO  [18:26:50.777] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:26:50.777] [bbotk]                         0.4560983           -6.759965               2.327667
INFO  [18:26:50.777] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:26:50.777] [bbotk]                          2                    3924                 0.9992448
INFO  [18:26:50.777] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:26:50.777] [bbotk]  0.07228601 <list[8]>              FALSE     0.03668208        0      0
INFO  [18:26:50.777] [bbotk]  runtime_learners                                uhash
INFO  [18:26:50.777] [bbotk]           183.697 3faf9621-86d9-4942-bc1a-a649607fa3ed
INFO  [18:26:54.022] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 65 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:27:01.373] [bbotk] Evaluating 1 configuration(s)
INFO  [18:27:01.919] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:27:02.276] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1970.737
[1] -59.10914
[1] -12.24652
[1] 39.31438
[1] -18.64044
[1] 66.02805
[1] -20.04318
[1] 58.68677
[1] -163.5196
[1] 17.74877
INFO  [18:27:53.273] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -31.93042
[1] 56.91944
[1] -84.934
[1] 12.52977
[1] -15.54911
[1] 104.1609
[1] -42.1128
[1] 51.09831
[1] -100.1432
[1] 33.15825
INFO  [18:28:28.006] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -11641.46
[1] -177.0782
[1] -29.90622
[1] 41.16054
[1] -44.48674
[1] 24.22052
[1] -27.37804
[1] 75.10588
[1] -215.7153
[1] 10.91063
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:29:10.476] [mlr3] Finished benchmark
INFO  [18:29:10.755] [bbotk] Result of batch 35:
INFO  [18:29:10.806] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:29:10.806] [bbotk]              0.9876804                         0.7908846
INFO  [18:29:10.806] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:29:10.806] [bbotk]                         0.1115357        -0.003740089              -6.709843
INFO  [18:29:10.806] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:29:10.806] [bbotk]                          8                    4240                  0.931239
INFO  [18:29:10.806] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:29:10.806] [bbotk]  0.04790838 <list[8]>              FALSE     0.02696193        0      0
INFO  [18:29:10.806] [bbotk]  runtime_learners                                uhash
INFO  [18:29:10.806] [bbotk]           126.472 888dc72b-7601-4723-84dc-26b8423d63b3
INFO  [18:29:12.592] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 66 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:29:18.006] [bbotk] Evaluating 1 configuration(s)
INFO  [18:29:18.147] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:29:18.233] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -127.9019
[1] 141.7599
[1] -155.8249
[1] 194.4486
[1] -199.5669
[1] 2640.831
[1] -152.4744
[1] 76.22365
[1] -181.8193
[1] -4.787005
INFO  [18:30:05.566] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -120.4956
[1] 83.32138
[1] -70.46203
[1] 202.0996
[1] -166.2001
[1] 76.02541
[1] -133.4454
[1] 57.94274
[1] -313.0305
[1] -4.791792
INFO  [18:30:53.572] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -309.9175
[1] -5.314301
[1] -102.6016
[1] 99.71534
[1] -240.0811
[1] -4.719764
[1] -34.02175
[1] 199.9905
[1] -45.53488
[1] 140.7697
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:32:00.709] [mlr3] Finished benchmark
INFO  [18:32:00.814] [bbotk] Result of batch 36:
INFO  [18:32:00.876] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:32:00.876] [bbotk]             -0.9794793                         0.4940497
INFO  [18:32:00.876] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:32:00.876] [bbotk]                         0.7797663           -4.123584               6.426877
INFO  [18:32:00.876] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:32:00.876] [bbotk]                         14                    3536                 0.5466747
INFO  [18:32:00.876] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:32:00.876] [bbotk]  0.04076346 <list[8]>              FALSE     0.04029075        0      0
INFO  [18:32:00.876] [bbotk]  runtime_learners                                uhash
INFO  [18:32:00.876] [bbotk]           162.223 f54f1bc6-4e1b-4f71-81ca-2dcddd16cd36
WARN  [18:32:03.167] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:32:03.215] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 67 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:32:08.436] [bbotk] Evaluating 1 configuration(s)
INFO  [18:32:08.481] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:32:08.557] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -43.3856
[1] 28.4255
[1] -288.9873
[1] 10.05511
[1] -22.60063
[1] 49.69486
[1] -22.8267
[1] 30.08417
[1] -166.9943
[1] 0.3388263
INFO  [18:32:29.806] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -32.35593
[1] 21.94943
[1] 44.74249
[1] 1342.481
[1] -95.59737
[1] 31.61256
[1] -13.14599
[1] 44.33928
[1] -25.73563
[1] 29.16965
INFO  [18:32:57.559] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -52.67903
[1] 20.94828
[1] -32.70966
[1] 65.59756
[1] -263.8005
[1] 8.715359
[1] -66.05971
[1] 39.6954
[1] -19.35597
[1] 63.40873
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:33:32.178] [mlr3] Finished benchmark
INFO  [18:33:32.286] [bbotk] Result of batch 37:
INFO  [18:33:32.390] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:33:32.390] [bbotk]              -1.083487                         0.1093648
INFO  [18:33:32.390] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:33:32.390] [bbotk]                         0.8764182          -0.6163075                -5.5515
INFO  [18:33:32.390] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:33:32.390] [bbotk]                         19                    2168                 0.1081515
INFO  [18:33:32.390] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:33:32.390] [bbotk]  0.05128177 <list[8]>              FALSE     0.03086743        0      0
INFO  [18:33:32.390] [bbotk]  runtime_learners                                uhash
INFO  [18:33:32.390] [bbotk]            83.144 181d3e53-3742-4e77-9ae2-83b06c8ea421
INFO  [18:33:34.158] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 68 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:33:38.903] [bbotk] Evaluating 1 configuration(s)
INFO  [18:33:38.941] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:33:39.038] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -51.60263
[1] 47.23513
[1] -19.01325
[1] 64.42574
[1] -36.51439
[1] 60.88207
[1] -70.47576
[1] 58.67159
[1] -191.5271
[1] 3.015013
INFO  [18:34:21.119] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -66.46328
[1] 70.23726
[1] -90.35691
[1] 51.31535
[1] -172.3732
[1] -4.182891
[1] -54.13623
[1] 57.85795
[1] -54.5387
[1] 54.19394
INFO  [18:35:09.677] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -79.20326
[1] 71.46674
[1] -14.26102
[1] 61.76592
[1] -50.19897
[1] 48.20477
[1] 2.684916
[1] 183.372
[1] -67.28896
[1] 77.34304
INFO  [18:35:57.151] [mlr3] Finished benchmark
INFO  [18:35:57.750] [bbotk] Result of batch 38:
INFO  [18:35:57.960] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:35:57.960] [bbotk]               1.798689                         0.8689481
INFO  [18:35:57.960] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:35:57.960] [bbotk]                         0.3360837          -0.5417349              -6.227704
INFO  [18:35:57.960] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:35:57.960] [bbotk]                         16                    3790                 0.8409874
INFO  [18:35:57.960] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:35:57.960] [bbotk]  0.04545376 <list[8]>              FALSE     0.03163371        0      0
INFO  [18:35:57.960] [bbotk]  runtime_learners                                uhash
INFO  [18:35:57.960] [bbotk]           137.887 1eb14748-00e6-4517-9157-ec0ab50cf126
INFO  [18:36:02.361] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 69 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:36:10.713] [bbotk] Evaluating 1 configuration(s)
INFO  [18:36:10.800] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:36:10.892] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -59.40633
[1] 38.14879
[1] -39.8128
[1] 113.3675
[1] -71.30532
[1] 99.85263
[1] -121.6063
[1] -1.976831
[1] -88.0561
[1] 52.63032
INFO  [18:36:40.361] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -133.7498
[1] 117.6854
[1] -21.126
[1] 730.0217
[1] -26.51118
[1] 73.0263
[1] -51.67657
[1] 45.74003
[1] -532.2451
[1] -4.492285
INFO  [18:37:11.871] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 326.6028
[1] 7863.709
[1] -7421.031
[1] -205.8358
[1] -21.21425
[1] 204.9892
[1] -142.3108
[1] -3.747866
[1] -77.00031
[1] 5.821657
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:37:41.535] [mlr3] Finished benchmark
INFO  [18:37:41.689] [bbotk] Result of batch 39:
INFO  [18:37:41.760] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:37:41.760] [bbotk]               1.647662                         0.4571168
INFO  [18:37:41.760] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:37:41.760] [bbotk]                         0.8168426           -3.571938              0.4475335
INFO  [18:37:41.760] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:37:41.760] [bbotk]                          5                    1555                 0.8925086
INFO  [18:37:41.760] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:37:41.760] [bbotk]  0.03766662 <list[8]>              FALSE     0.03251451        0      0
INFO  [18:37:41.760] [bbotk]  runtime_learners                                uhash
INFO  [18:37:41.760] [bbotk]            89.937 4d0530ef-f6f0-4219-b708-b9034ffc209d
INFO  [18:37:43.789] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 70 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:37:53.528] [bbotk] Evaluating 1 configuration(s)
INFO  [18:37:53.671] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:37:53.847] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 10.78156
[1] 417.6015
[1] -205.8756
[1] -4.472738
[1] -13.09514
[1] 317.0492
[1] -177.1391
[1] 136.4686
[1] -21579.23
[1] -491.3783
INFO  [18:38:23.082] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -186.3225
[1] 176.6614
[1] -633.4767
[1] 308.4253
[1] -12.86677
[1] 202.4435
[1] -177.4777
[1] 127.2957
[1] -191.5175
[1] 58.22615
INFO  [18:38:46.068] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -204.8166
[1] 74.31473
[1] -146.9679
[1] 300.9429
[1] 5.364559
[1] 262.871
[1] -172.4649
[1] 83.62944
[1] -994.1494
[1] -11.97706
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:39:24.336] [mlr3] Finished benchmark
INFO  [18:39:24.789] [bbotk] Result of batch 40:
INFO  [18:39:24.804] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:39:24.804] [bbotk]              0.8815239                         0.6152289
INFO  [18:39:24.804] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:39:24.804] [bbotk]                         0.3903352           -6.126566               3.828832
INFO  [18:39:24.804] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:39:24.804] [bbotk]                          1                    1599                 0.7277675
INFO  [18:39:24.804] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:39:24.804] [bbotk]  0.04217226 <list[8]>              FALSE     0.04629687        0      0
INFO  [18:39:24.804] [bbotk]  runtime_learners                                uhash
INFO  [18:39:24.804] [bbotk]             89.74 cc5b3b1e-cb52-4169-ad8f-1cf620a5c7a0
INFO  [18:39:27.595] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 71 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:39:35.612] [bbotk] Evaluating 1 configuration(s)
INFO  [18:39:36.347] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:39:36.517] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -101.7222
[1] 45.72986
[1] -159.6557
[1] -4.444455
[1] -147.2002
[1] -5.338837
[1] -22.82632
[1] 217.8384
[1] -152.409
[1] 34.26427
INFO  [18:39:54.507] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -164.0211
[1] 14.35304
[1] -156.1891
[1] 111.8822
[1] -39.5591
[1] 76.87925
[1] -132.294
[1] 101.6679
[1] -74.74006
[1] 58.48771
INFO  [18:40:09.669] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -4820.948
[1] -111.77
[1] -65.09052
[1] 100.2879
[1] -84.33942
[1] 107.6425
[1] -215.4346
[1] 59.12216
[1] -101.4733
[1] 16.41429
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:40:41.457] [mlr3] Finished benchmark
INFO  [18:40:41.599] [bbotk] Result of batch 41:
INFO  [18:40:41.751] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:40:41.751] [bbotk]               2.320041                         0.6896375
INFO  [18:40:41.751] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:40:41.751] [bbotk]                         0.8611133            -2.50128              -4.681761
INFO  [18:40:41.751] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:40:41.751] [bbotk]                         20                    2167                 0.9113871
INFO  [18:40:41.751] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:40:41.751] [bbotk]  0.03525882 <list[8]>              FALSE     0.03572449        0      0
INFO  [18:40:41.751] [bbotk]  runtime_learners                                uhash
INFO  [18:40:41.751] [bbotk]            64.607 6a721ef5-14fe-410b-b93e-8745cafbc640
INFO  [18:40:44.643] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 72 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:40:51.634] [bbotk] Evaluating 1 configuration(s)
INFO  [18:40:51.859] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:40:52.074] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -35.82694
[1] 102.8203
[1] -100.5939
[1] 9.971025
[1] -44.08934
[1] 112.906
[1] -2348.75
[1] -64.97917
[1] -97.40686
[1] 21.16342
INFO  [18:41:28.944] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 58.95666
[1] 1048.427
[1] -21.763
[1] 47.23352
[1] -65.30218
[1] 197.3612
[1] -2650.826
[1] -56.36425
[1] -70.1016
[1] 85.85807
INFO  [18:41:53.882] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 193.1088
[1] 5844.397
[1] -128.5997
[1] 11.78878
[1] -103.6569
[1] 9.872386
[1] -84.51921
[1] 144.0987
[1] -59.22283
[1] 34.48128
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:42:31.437] [mlr3] Finished benchmark
INFO  [18:42:32.009] [bbotk] Result of batch 42:
INFO  [18:42:32.334] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:42:32.334] [bbotk]               0.955554                         0.8300316
INFO  [18:42:32.334] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:42:32.334] [bbotk]                         0.3949244           -2.350906              -4.635647
INFO  [18:42:32.334] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:42:32.334] [bbotk]                          1                    2686                 0.9384682
INFO  [18:42:32.334] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:42:32.334] [bbotk]  0.06097629 <list[8]>              FALSE     0.02744037        0      0
INFO  [18:42:32.334] [bbotk]  runtime_learners                                uhash
INFO  [18:42:32.334] [bbotk]            98.028 8910219b-23d9-4c34-a73b-a5eef8ddd4b5
INFO  [18:42:36.101] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 73 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:42:44.116] [bbotk] Evaluating 1 configuration(s)
INFO  [18:42:44.458] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:42:44.542] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -173.7607
[1] 110.7865
[1] -295.9906
[1] -4.929888
[1] -43.36424
[1] 138.0635
[1] -355.9932
[1] 21.86305
[1] -132.3792
[1] 27.84121
INFO  [18:43:47.787] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -108.4988
[1] 29.34091
[1] -282.5644
[1] 64.03401
[1] -50.28596
[1] 114.0971
[1] -96.06959
[1] 62.7635
[1] -115.6152
[1] 66.97507
INFO  [18:44:29.469] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -127.0774
[1] 11.78524
[1] -109.9174
[1] 20.24277
[1] 3.231262
[1] 181.8029
[1] -20.12825
[1] 239.3097
[1] -12.88828
[1] 122.6419
INFO  [18:45:33.111] [mlr3] Finished benchmark
INFO  [18:45:34.886] [bbotk] Result of batch 43:
INFO  [18:45:34.975] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:45:34.975] [bbotk]               2.633012                         0.6790043
INFO  [18:45:34.975] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:45:34.975] [bbotk]                         0.9694873           -2.765885              -4.842135
INFO  [18:45:34.975] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:45:34.975] [bbotk]                          1                    3644                 0.9578394
INFO  [18:45:34.975] [bbotk]    acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:45:34.975] [bbotk]  0.033371 <list[8]>              FALSE      0.0461696        0      0
INFO  [18:45:34.975] [bbotk]  runtime_learners                                uhash
INFO  [18:45:34.975] [bbotk]           168.248 a89db776-5faa-4b84-8c28-b35a53bc771e
WARN  [18:45:38.592] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:45:38.872] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 74 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:45:48.899] [bbotk] Evaluating 1 configuration(s)
INFO  [18:45:49.032] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:45:49.148] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1293.833
[1] -33.65315
[1] -116.1585
[1] 24.80576
[1] -60.25444
[1] 12.02244
[1] -28.01505
[1] 62.51586
[1] -54.63581
[1] 10.75991
INFO  [18:46:34.222] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 77.28634
[1] 3433.804
[1] -135.762
[1] 50.05427
[1] -99.3874
[1] 45.35989
[1] -25.95567
[1] 87.40759
[1] -994.2463
[1] -67.48036
INFO  [18:47:09.535] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -5364.233
[1] -75.10065
[1] -2418.142
[1] -63.88215
[1] -23.36862
[1] 40.93386
[1] -220.072
[1] -3.682537
[1] -75.07697
[1] 24.52533
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:47:56.828] [mlr3] Finished benchmark
INFO  [18:47:57.377] [bbotk] Result of batch 44:
INFO  [18:47:57.468] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:47:57.468] [bbotk]              -2.306378                         0.9091792
INFO  [18:47:57.468] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:47:57.468] [bbotk]                         0.7284994           -2.921116              -4.649168
INFO  [18:47:57.468] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:47:57.468] [bbotk]                         19                    3450                 0.2647322
INFO  [18:47:57.468] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:47:57.468] [bbotk]  0.03254554 <list[8]>              FALSE     0.02047776        0      0
INFO  [18:47:57.468] [bbotk]  runtime_learners                                uhash
INFO  [18:47:57.468] [bbotk]           126.514 ddd8f4a8-9c97-4d24-b3d7-81a23b19f797
WARN  [18:48:00.577] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:48:00.598] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 75 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:48:06.874] [bbotk] Evaluating 1 configuration(s)
INFO  [18:48:06.941] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:48:07.067] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -46.89755
[1] 19.072
[1] -3078.928
[1] -85.07481
[1] -1080.905
[1] -60.59709
[1] -6.534262
[1] 46.47352
[1] -60.75496
[1] 14.13893
INFO  [18:48:25.854] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -25.1764
[1] 45.77887
[1] -86.02027
[1] 67.70765
[1] -25.24593
[1] 128.5518
[1] -1983.734
[1] -85.0784
[1] -353.3199
[1] 28.87108
INFO  [18:49:09.900] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -20.08211
[1] 42.64072
[1] -837.7649
[1] -27.65607
[1] -12.15342
[1] 73.39741
[1] -76.61918
[1] -1.486121
[1] -34.17672
[1] 32.69579
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:49:48.806] [mlr3] Finished benchmark
INFO  [18:49:49.079] [bbotk] Result of batch 45:
INFO  [18:49:49.151] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:49:49.151] [bbotk]              -5.535912                         0.6721878
INFO  [18:49:49.151] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:49:49.151] [bbotk]                         0.5452302           -2.505335              -1.891426
INFO  [18:49:49.151] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:49:49.151] [bbotk]                          4                    2920                  0.768335
INFO  [18:49:49.151] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:49:49.151] [bbotk]  0.02953145 <list[8]>              FALSE     0.02044645        0      0
INFO  [18:49:49.151] [bbotk]  runtime_learners                                uhash
INFO  [18:49:49.151] [bbotk]            101.08 e2fd0144-ef91-4a1d-9bf8-c1fe59068e6d
WARN  [18:49:51.418] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:49:51.431] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 76 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:50:04.790] [bbotk] Evaluating 1 configuration(s)
INFO  [18:50:04.939] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:50:05.317] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -8529.602
[1] -207.0986
[1] -128.4372
[1] -4.421356
[1] -158.7936
[1] 3.866638
[1] -66.47325
[1] 43.89128
[1] -43.73433
[1] 65.21947
INFO  [18:50:34.968] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 89.52898
[1] 4175.109
[1] -3886.59
[1] -79.01671
[1] -24.20664
[1] 120.4078
[1] -19.67611
[1] 150.8004
[1] -136.2698
[1] 35.57201
INFO  [18:51:07.193] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -69.33414
[1] 8.355898
[1] 140.1132
[1] 4302.782
[1] -199.667
[1] 26.24135
[1] -51.77211
[1] 116.9112
[1] -48.57425
[1] 95.32843
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:52:00.943] [mlr3] Finished benchmark
INFO  [18:52:02.281] [bbotk] Result of batch 46:
INFO  [18:52:02.367] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:52:02.367] [bbotk]              -1.728568                         0.2162587
INFO  [18:52:02.367] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:52:02.367] [bbotk]                         0.3767823           -5.158323              -5.386056
INFO  [18:52:02.367] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:52:02.367] [bbotk]                         17                    3583                  0.238123
INFO  [18:52:02.367] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:52:02.367] [bbotk]  0.03198371 <list[8]>              FALSE     0.02267262        0      0
INFO  [18:52:02.367] [bbotk]  runtime_learners                                uhash
INFO  [18:52:02.367] [bbotk]           115.068 be76c193-2073-4111-ae51-b3976d26db0e
INFO  [18:52:10.862] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 77 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:52:27.135] [bbotk] Evaluating 1 configuration(s)
INFO  [18:52:27.705] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:52:27.839] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -17.0693
[1] 55.15004
[1] -79.1599
[1] 31.67059
[1] -164.3089
[1] 10.22712
[1] -54.74227
[1] 11.21685
[1] 419.5907
[1] 5101.208
INFO  [18:52:53.861] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 162.8827
[1] 3475.273
[1] 58.72237
[1] 1042.521
[1] -17.09948
[1] 34.16759
[1] -71.16252
[1] 707.9256
[1] -36.81491
[1] 83.45217
INFO  [18:53:14.687] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -12.79017
[1] 69.46517
[1] -2.603315e+16
[1] 5.500654e+15
[1] -394.4503
[1] 0.8785358
[1] -40.89252
[1] 43.63871
[1] -23.26723
[1] 25.02951
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:53:35.477] [mlr3] Finished benchmark
INFO  [18:53:35.882] [bbotk] Result of batch 47:
INFO  [18:53:35.908] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:53:35.908] [bbotk]              -3.054161                         0.6195712
INFO  [18:53:35.908] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:53:35.908] [bbotk]                         0.5928592           -1.509748              -5.691411
INFO  [18:53:35.908] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:53:35.908] [bbotk]                         12                     761                 0.5032603
INFO  [18:53:35.908] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:53:35.908] [bbotk]  0.04018478 <list[8]>              FALSE     0.02458632        0      0
INFO  [18:53:35.908] [bbotk]  runtime_learners                                uhash
INFO  [18:53:35.908] [bbotk]            66.727 01838805-4f9d-4c73-8184-2c8a410d3d72
INFO  [18:53:39.214] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 78 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:53:48.055] [bbotk] Evaluating 1 configuration(s)
INFO  [18:53:48.107] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:53:48.137] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -56.95793
[1] 132.2874
[1] -50.0931
[1] 35.17516
[1] -29.57226
[1] 132.6889
[1] -54.2211
[1] 39.39647
[1] -64.58182
[1] 88.82306
INFO  [18:54:09.825] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -38.85129
[1] 55.28016
[1] -57.37297
[1] 152.9346
[1] -77.46736
[1] 64.7241
[1] -218.2098
[1] 20.36114
[1] -10.69683
[1] 119.3096
INFO  [18:54:45.741] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -94.45101
[1] 54.63946
[1] -69.16437
[1] 26.1432
[1] -357.6573
[1] -4.285559
[1] -90.66626
[1] 28.38524
[1] -69.29436
[1] 58.98274
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:55:18.053] [mlr3] Finished benchmark
INFO  [18:55:18.156] [bbotk] Result of batch 48:
INFO  [18:55:18.207] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:55:18.207] [bbotk]               1.428233                          0.786273
INFO  [18:55:18.207] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:55:18.207] [bbotk]                         0.1564263          -0.6330985              -6.662374
INFO  [18:55:18.207] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:55:18.207] [bbotk]                         19                    1653                 0.8529772
INFO  [18:55:18.207] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:55:18.207] [bbotk]  0.02711847 <list[8]>              FALSE     0.02749997        0      0
INFO  [18:55:18.207] [bbotk]  runtime_learners                                uhash
INFO  [18:55:18.207] [bbotk]            89.601 275c9b54-cfd2-4b02-a120-a6356826ac27
INFO  [18:55:32.665] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 79 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:55:42.437] [bbotk] Evaluating 1 configuration(s)
INFO  [18:55:42.471] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:55:42.565] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -67.04067
[1] 10.9161
[1] -115.0795
[1] 5.886892
[1] -125.7888
[1] 6.983321
[1] -3.76568e+16
[1] 6.315201e+15
[1] -40.53169
[1] 50.10782
INFO  [18:56:08.608] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -10.71404
[1] 62.9365
[1] -82.47887
[1] 28.10047
[1] -196.1276
[1] 4.700174
[1] -52.19564
[1] 30.66351
[1] 32.64152
[1] 923.5912
INFO  [18:56:43.675] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -25.06948
[1] 83.71817
[1] -124.202
[1] -0.8662159
[1] -100.9031
[1] 21.33392
[1] -35.79956
[1] 113.7946
[1] 16.46686
[1] 611.5006
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:57:11.644] [mlr3] Finished benchmark
INFO  [18:57:11.833] [bbotk] Result of batch 49:
INFO  [18:57:11.859] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:57:11.859] [bbotk]              -2.738794                         0.3174551
INFO  [18:57:11.859] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:57:11.859] [bbotk]                         0.8621091           -2.468141              0.7343594
INFO  [18:57:11.859] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:57:11.859] [bbotk]                         13                    1275                 0.2552277
INFO  [18:57:11.859] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:57:11.859] [bbotk]  0.02800324 <list[8]>              FALSE     0.02017373        0      0
INFO  [18:57:11.859] [bbotk]  runtime_learners                                uhash
INFO  [18:57:11.859] [bbotk]            88.637 2a4ed771-21ff-431b-9a7c-c1d8aaa576bd
INFO  [18:57:16.752] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 80 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:57:24.652] [bbotk] Evaluating 1 configuration(s)
INFO  [18:57:24.765] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:57:24.811] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -41.10837
[1] 142.3169
[1] -114.5481
[1] 68.45285
[1] -70.27743
[1] 31.55644
[1] -57.08312
[1] 21.87856
[1] -26.68306
[1] 42.00887
INFO  [18:57:57.843] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -57.35775
[1] 33.05433
[1] -75.36956
[1] 33.25593
[1] -24.22691
[1] 179.5575
[1] -46.99321
[1] 78.09896
[1] -196.8378
[1] 69.06796
INFO  [18:59:03.213] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -938.7559
[1] -4.291967
[1] -49.99409
[1] 42.64563
[1] -81.52004
[1] 93.80669
[1] -120.8205
[1] 30.97638
[1] -98.02765
[1] 77.8961
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:59:55.490] [mlr3] Finished benchmark
INFO  [18:59:55.950] [bbotk] Result of batch 50:
INFO  [18:59:56.099] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:59:56.099] [bbotk]                1.28811                         0.8158913
INFO  [18:59:56.099] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:59:56.099] [bbotk]                         0.8172302            -2.22629              -4.050783
INFO  [18:59:56.099] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:59:56.099] [bbotk]                          8                    2728                 0.9135261
INFO  [18:59:56.099] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:59:56.099] [bbotk]  0.03187613 <list[8]>              FALSE     0.02959975        0      0
INFO  [18:59:56.099] [bbotk]  runtime_learners                                uhash
INFO  [18:59:56.099] [bbotk]           150.191 819941d7-c69c-47d0-8463-5c3ccf90e7ec
INFO  [18:59:59.949] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 81 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:00:26.529] [bbotk] Evaluating 1 configuration(s)
INFO  [19:00:26.725] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:00:26.887] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -5312.813
[1] -105.4618
[1] -60.71305
[1] 12.57188
[1] -37.90146
[1] 28.05451
[1] -44.37321
[1] 22.30573
[1] -40.38047
[1] 46.88353
INFO  [19:00:55.507] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -53.07739
[1] 11.50451
[1] -1.433417
[1] 186.5857
[1] -66.55992
[1] 104.824
[1] -56.90545
[1] 32.49006
[1] -85.26378
[1] 86.73637
INFO  [19:01:17.362] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -17.46348
[1] 57.13537
[1] -20.80963
[1] 132.8515
[1] -56.93417
[1] 16.93421
[1] -33.76014
[1] 162.2909
[1] -183.7281
[1] 21.881
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:01:37.955] [mlr3] Finished benchmark
INFO  [19:01:38.278] [bbotk] Result of batch 51:
INFO  [19:01:38.374] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:01:38.374] [bbotk]             0.04585325                         0.4514024
INFO  [19:01:38.374] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:01:38.374] [bbotk]                         0.1151999          -0.4975125              -4.850701
INFO  [19:01:38.374] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:01:38.374] [bbotk]                         11                     507                 0.9979859
INFO  [19:01:38.374] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:01:38.374] [bbotk]  0.05033576 <list[8]>              FALSE      0.0257337        0      0
INFO  [19:01:38.374] [bbotk]  runtime_learners                                uhash
INFO  [19:01:38.374] [bbotk]             70.41 c9beef58-b8ff-4288-b884-c517140e7d56
INFO  [19:01:46.522] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 82 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:02:03.690] [bbotk] Evaluating 1 configuration(s)
INFO  [19:02:04.123] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:02:04.430] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -69.37594
[1] 45.32839
[1] -554.736
[1] 19.44684
[1] -62.48082
[1] 12.72733
[1] -29.93248
[1] 58.66051
[1] -98.76479
[1] -3.8737
INFO  [19:02:46.257] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -57.81656
[1] 73.80675
[1] -196.1554
[1] -3.586966
[1] -1166.597
[1] -29.29124
[1] -21.86847
[1] 95.12763
[1] 196.693
[1] 3680.37
INFO  [19:03:29.086] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -61.7079
[1] 2.471356
[1] -3.993947
[1] 85.22683
[1] -58.60628
[1] 15.81452
[1] -14.58457
[1] 78.29706
[1] -93.94743
[1] 81.05206
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:04:08.839] [mlr3] Finished benchmark
INFO  [19:04:09.626] [bbotk] Result of batch 52:
INFO  [19:04:09.645] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:04:09.645] [bbotk]              -2.233868                         0.2285061
INFO  [19:04:09.645] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:04:09.645] [bbotk]                          0.987362           -2.435617              -5.445159
INFO  [19:04:09.645] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:04:09.645] [bbotk]                         18                    2132                 0.3479922
INFO  [19:04:09.645] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:04:09.645] [bbotk]  0.0309578 <list[8]>              FALSE     0.02010641        0      0
INFO  [19:04:09.645] [bbotk]  runtime_learners                                uhash
INFO  [19:04:09.645] [bbotk]           123.758 57500e32-a44b-4d31-bbf2-a2a3e51a4631
WARN  [19:04:17.277] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:04:17.301] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 83 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:04:32.396] [bbotk] Evaluating 1 configuration(s)
INFO  [19:04:32.648] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:04:32.811] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -69.87233
[1] -4.10946
[1] -102.1229
[1] 41.80105
[1] -78.02557
[1] 8.867123
[1] -52.74064
[1] 101.0686
[1] -70.94638
[1] 20.88892
INFO  [19:05:45.086] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -55.68813
[1] 94.19351
[1] -83.53212
[1] 73.54925
[1] -16.31494
[1] 89.28933
[1] -118.8878
[1] 74.52926
[1] -160.4553
[1] 21.13125
INFO  [19:06:58.382] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -148.8369
[1] 170.2157
[1] -26.89064
[1] 73.24937
[1] -33.73155
[1] 17.67574
[1] -49.27236
[1] 33.87363
[1] -50.34437
[1] 34.30953
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:08:03.830] [mlr3] Finished benchmark
INFO  [19:08:04.625] [bbotk] Result of batch 53:
INFO  [19:08:04.727] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:08:04.727] [bbotk]             -0.3747995                         0.2890353
INFO  [19:08:04.727] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:08:04.727] [bbotk]                         0.8040871           -3.971444              -6.594813
INFO  [19:08:04.727] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:08:04.727] [bbotk]                         15                    4998                  0.926097
INFO  [19:08:04.727] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:08:04.727] [bbotk]  0.04670378 <list[8]>              FALSE     0.02212835        0      0
INFO  [19:08:04.727] [bbotk]  runtime_learners                                uhash
INFO  [19:08:04.727] [bbotk]           210.873 2cb21f5a-1f58-47dd-88bf-1a52f78d0a93
INFO  [19:08:11.855] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 84 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:08:29.486] [bbotk] Evaluating 1 configuration(s)
INFO  [19:08:29.695] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:08:29.834] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -44.82272
[1] 128.1292
[1] -34.3223
[1] 22.04204
[1] -126.9018
[1] 14.3405
[1] -70.88335
[1] 11.00914
[1] -39.40414
[1] 106.0373
INFO  [19:08:59.480] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -48.71896
[1] 89.79804
[1] -13.8978
[1] 88.42905
[1] -32.22303
[1] 50.91536
[1] -190.4749
[1] 54.78157
[1] -34.62732
[1] 57.90576
INFO  [19:09:29.356] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -27.92261
[1] 52.76741
[1] -38.22676
[1] 20.597
[1] -91.15793
[1] 46.71947
[1] 117.7923
[1] 2603.235
[1] -32.54182
[1] 182.2825
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:09:55.404] [mlr3] Finished benchmark
INFO  [19:09:56.164] [bbotk] Result of batch 54:
INFO  [19:09:56.170] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:09:56.170] [bbotk]               1.039305                         0.6567246
INFO  [19:09:56.170] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:09:56.170] [bbotk]                         0.2266459          -0.3904106              -4.129204
INFO  [19:09:56.170] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:09:56.170] [bbotk]                          1                     899                 0.9762696
INFO  [19:09:56.170] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:09:56.170] [bbotk]  0.02881818 <list[8]>              FALSE     0.02316956        0      0
INFO  [19:09:56.170] [bbotk]  runtime_learners                                uhash
INFO  [19:09:56.170] [bbotk]            84.642 d6fd60e0-ee3b-4032-9a49-eb5f6cfdb3c0
INFO  [19:09:58.959] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 85 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:10:19.161] [bbotk] Evaluating 1 configuration(s)
INFO  [19:10:19.479] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:10:19.757] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -89.17671
[1] 36.50584
[1] -103.8143
[1] 22.36476
[1] -44.68173
[1] 31.73622
[1] -73.03264
[1] 40.81693
[1] -250.6571
[1] -3.914045
INFO  [19:11:28.531] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -47.13569
[1] 88.80212
[1] -1639.642
[1] -35.74366
[1] -58.33603
[1] 113.4166
[1] -9.942798
[1] 145.3739
[1] -121.3861
[1] 28.31886
INFO  [19:12:34.113] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -48.21296
[1] 53.01642
[1] -24.45707
[1] 121.6315
[1] -438.1997
[1] -4.190575
[1] -54.63359
[1] 99.84417
[1] -153.4686
[1] 26.04995
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:13:52.061] [mlr3] Finished benchmark
INFO  [19:13:52.958] [bbotk] Result of batch 55:
INFO  [19:13:53.044] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:13:53.044] [bbotk]              -4.828063                         0.4180159
INFO  [19:13:53.044] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:13:53.044] [bbotk]                         0.6604405           -5.519935              -6.829546
INFO  [19:13:53.044] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:13:53.044] [bbotk]                         19                    3235                 0.3072568
INFO  [19:13:53.044] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:13:53.044] [bbotk]  0.02652661 <list[8]>              FALSE     0.02287465        0      0
INFO  [19:13:53.044] [bbotk]  runtime_learners                                uhash
INFO  [19:13:53.044] [bbotk]           212.009 de07799c-5370-4df0-b027-b7f6cf7fb747
INFO  [19:13:58.129] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 86 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:14:10.035] [bbotk] Evaluating 1 configuration(s)
INFO  [19:14:10.223] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:14:10.346] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -83.40853
[1] 15.82862
[1] -48.42615
[1] 41.28735
[1] -81.57499
[1] 9.069679
[1] -74.36554
[1] 103.1639
[1] -22.39877
[1] 89.35982
INFO  [19:15:06.708] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -26.28262
[1] 72.3021
[1] -47.61391
[1] 96.88021
[1] 41.48916
[1] 716.3371
[1] -149.5678
[1] 38.44137
[1] -51.79326
[1] 30.3876
INFO  [19:16:13.424] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -14.73112
[1] 123.9996
[1] -215.617
[1] 6.124922
[1] -39.37853
[1] 133.5372
[1] -17.07655
[1] 103.1072
[1] -5522.765
[1] -172.7207
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:17:16.596] [mlr3] Finished benchmark
INFO  [19:17:16.687] [bbotk] Result of batch 56:
INFO  [19:17:16.694] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:17:16.694] [bbotk]              -4.516735                         0.2215344
INFO  [19:17:16.694] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:17:16.694] [bbotk]                         0.3517443          -0.7069549               5.531861
INFO  [19:17:16.694] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:17:16.694] [bbotk]                         14                    2321                 0.9254518
INFO  [19:17:16.694] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:17:16.694] [bbotk]  0.02498284 <list[8]>              FALSE     0.02274682        0      0
INFO  [19:17:16.694] [bbotk]  runtime_learners                                uhash
INFO  [19:17:16.694] [bbotk]           185.952 900ebe54-cf6a-48c6-a4d2-3817385eeecb
WARN  [19:17:20.534] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:17:20.552] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 87 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:17:27.608] [bbotk] Evaluating 1 configuration(s)
INFO  [19:17:27.641] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:17:27.657] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -149.6316
[1] 76.2392
[1] 105.8732
[1] 4433.187
[1] -208.1712
[1] -4.431798
[1] -162.7131
[1] 15.86731
[1] -112.1279
[1] -4.238153
INFO  [19:18:09.326] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -174.1895
[1] 22.7416
[1] -42.37388
[1] 98.67615
[1] -93.19207
[1] 85.1307
[1] -67.57637
[1] 71.9228
[1] 134.4923
[1] 5547.789
INFO  [19:18:43.979] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -163.3226
[1] 29.09822
[1] -84.98458
[1] 112.4253
[1] -26.8503
[1] 143.8118
[1] -212.4182
[1] 71.76608
[1] -75.7314
[1] 50.13765
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:19:22.292] [mlr3] Finished benchmark
INFO  [19:19:22.555] [bbotk] Result of batch 57:
INFO  [19:19:22.564] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:19:22.564] [bbotk]               1.566073                         0.6951475
INFO  [19:19:22.564] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:19:22.564] [bbotk]                         0.3112973           -4.155715               -6.52747
INFO  [19:19:22.564] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:19:22.564] [bbotk]                          3                    1293                 0.4844828
INFO  [19:19:22.564] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:19:22.564] [bbotk]  0.02852574 <list[8]>              FALSE     0.03211727        0      0
INFO  [19:19:22.564] [bbotk]  runtime_learners                                uhash
INFO  [19:19:22.564] [bbotk]           113.724 65d258a8-5624-4a0d-82aa-74ab62181d0e
WARN  [19:19:36.421] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:19:36.489] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 88 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:20:01.699] [bbotk] Evaluating 1 configuration(s)
INFO  [19:20:01.868] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:20:01.925] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -105.5779
[1] -2.898105
[1] -129.2946
[1] 22.25752
[1] -23.98502
[1] 17.18349
[1] -31.37863
[1] 50.14964
[1] -33.43791
[1] 35.64781
INFO  [19:21:02.459] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -48.00069
[1] 46.35543
[1] -36.22197
[1] 46.79815
[1] -12.26628
[1] 35.40429
[1] -7.593903
[1] 55.56598
[1] -49.97376
[1] 66.35683
INFO  [19:22:03.491] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -27.84619
[1] 19.0485
[1] -34.16782
[1] 42.05213
[1] -71.7626
[1] 12.84612
[1] -817.2107
[1] -4.029151
[1] -26.57187
[1] 33.0994
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:23:20.259] [mlr3] Finished benchmark
INFO  [19:23:21.156] [bbotk] Result of batch 58:
INFO  [19:23:21.203] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:23:21.203] [bbotk]              -1.699548                         0.4618277
INFO  [19:23:21.203] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:23:21.203] [bbotk]                         0.1880528          -0.2436808            -0.06008558
INFO  [19:23:21.203] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:23:21.203] [bbotk]                          4                    4056                 0.9451457
INFO  [19:23:21.203] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:23:21.203] [bbotk]  0.02615105 <list[8]>              FALSE     0.02191913        0      0
INFO  [19:23:21.203] [bbotk]  runtime_learners                                uhash
INFO  [19:23:21.203] [bbotk]           197.685 8b329ca1-cc88-4059-80ef-26ceecb720cb
INFO  [19:23:44.636] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 89 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:23:59.901] [bbotk] Evaluating 1 configuration(s)
INFO  [19:24:00.670] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:24:00.812] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -84.67257
[1] 376.9371
[1] -240.2527
[1] -0.2227559
[1] -214.1769
[1] 63.27169
[1] -297.5716
[1] -5.646773
[1] 7.804378
[1] 284.6323
INFO  [19:24:55.678] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -165.1329
[1] 63.74836
[1] -183.6262
[1] 78.4973
[1] -292.7007
[1] 189.6023
[1] -294.6263
[1] -5.393841
[1] 5.256904
[1] 225.5128
INFO  [19:26:04.149] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -111.5669
[1] 225.3931
[1] -268.4116
[1] -4.387621
[1] -194.0951
[1] 56.96657
[1] -131.5182
[1] 209.0124
[1] 7.284582
[1] 316.8474
INFO  [19:27:20.106] [mlr3] Finished benchmark
INFO  [19:27:21.638] [bbotk] Result of batch 59:
INFO  [19:27:21.757] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:27:21.757] [bbotk]              0.8809829                         0.9123878
INFO  [19:27:21.757] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:27:21.757] [bbotk]                         0.6025707           -7.331801               2.904094
INFO  [19:27:21.757] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:27:21.757] [bbotk]                          1                    2677                 0.8422881
INFO  [19:27:21.757] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:27:21.757] [bbotk]  0.0327874 <list[8]>              FALSE     0.04809583        0      0
INFO  [19:27:21.757] [bbotk]  runtime_learners                                uhash
INFO  [19:27:21.757] [bbotk]           198.769 af149f1b-1011-4347-aa16-d26b66edb2ad
INFO  [19:27:24.333] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 90 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:27:37.036] [bbotk] Evaluating 1 configuration(s)
INFO  [19:27:37.298] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:27:37.445] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 205.1351
[1] 6316.318
[1] -36.4429
[1] 17.76152
[1] -53.15936
[1] 13.92298
[1] -1715.046
[1] -69.52501
[1] -45.66264
[1] 24.41844
INFO  [19:28:21.050] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -44171.22
[1] -1049.78
[1] 55.86077
[1] 1410.702
[1] -26.32965
[1] 45.90416
[1] -79.16203
[1] 12.92531
[1] -11.85555
[1] 180.301
INFO  [19:29:09.418] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -18.63091
[1] 74.9879
[1] -146.8407
[1] -3.93441
[1] -24.16938
[1] 78.01117
[1] -29.58735
[1] 25.55174
[1] -31.3776
[1] 41.82281
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:29:49.306] [mlr3] Finished benchmark
INFO  [19:29:49.394] [bbotk] Result of batch 60:
INFO  [19:29:49.496] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:29:49.496] [bbotk]             -0.8149574                         0.2349912
INFO  [19:29:49.496] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:29:49.496] [bbotk]                         0.6672583           -1.563419              -2.554576
INFO  [19:29:49.496] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:29:49.496] [bbotk]                          5                    1951                 0.8060218
INFO  [19:29:49.496] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:29:49.496] [bbotk]  0.02658162 <list[8]>              FALSE     0.02116316        0      0
INFO  [19:29:49.496] [bbotk]  runtime_learners                                uhash
INFO  [19:29:49.496] [bbotk]           131.518 4dd72534-389a-45ad-95ff-b7e82c136f64
INFO  [19:29:53.666] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 91 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:30:14.336] [bbotk] Evaluating 1 configuration(s)
INFO  [19:30:14.484] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:30:14.617] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -243.5061
[1] 45.11389
[1] -186.1324
[1] -3.877393
[1] -49.97042
[1] 39.1374
[1] -20.38426
[1] 42.44458
[1] -123.8931
[1] 65.96209
INFO  [19:31:33.052] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -48.33676
[1] 127.5763
[1] -109.0991
[1] 41.2783
[1] -1490.777
[1] -37.14265
[1] -57.63727
[1] 83.68719
[1] -363.1434
[1] 8.388783
INFO  [19:32:48.779] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -52.33626
[1] 116.9474
[1] -50.19615
[1] 22.01379
[1] -502.1614
[1] -4.07078
[1] 112.2471
[1] 4916.357
[1] -84.18697
[1] 2.637477
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:33:47.263] [mlr3] Finished benchmark
INFO  [19:33:47.338] [bbotk] Result of batch 61:
INFO  [19:33:47.358] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:33:47.358] [bbotk]              0.1124819                         0.9379062
INFO  [19:33:47.358] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:33:47.358] [bbotk]                         0.6907124           -1.538606              -6.317417
INFO  [19:33:47.358] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:33:47.358] [bbotk]                         17                    4709                 0.3167752
INFO  [19:33:47.358] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:33:47.358] [bbotk]  0.02452901 <list[8]>              FALSE     0.01977338        0      0
INFO  [19:33:47.358] [bbotk]  runtime_learners                                uhash
INFO  [19:33:47.358] [bbotk]           211.982 a6b09a75-65c6-4a9e-a62d-42e7a6b786c9
INFO  [19:33:54.066] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 92 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:34:16.643] [bbotk] Evaluating 1 configuration(s)
INFO  [19:34:16.834] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:34:17.010] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -25.91895
[1] 107.2747
[1] -78.50008
[1] 28.44393
[1] -3098.728
[1] -83.92149
[1] -178.217
[1] 2.114581
[1] -42.66095
[1] 68.39068
INFO  [19:34:48.217] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -58.94516
[1] 78.3444
[1] -110.6343
[1] 24.01763
[1] -37.03798
[1] 59.66198
[1] -37334.13
[1] -846.9418
[1] -219.1638
[1] 67.63022
INFO  [19:35:24.333] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -53.49888
[1] 85.53268
[1] -13.31465
[1] 127.3723
[1] -208.6896
[1] -2.959601
[1] 101.5553
[1] 2951.606
[1] -69.58402
[1] 33.03352
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:35:59.848] [mlr3] Finished benchmark
INFO  [19:36:00.172] [bbotk] Result of batch 62:
INFO  [19:36:00.268] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:36:00.268] [bbotk]              0.5039747                          0.192592
INFO  [19:36:00.268] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:36:00.268] [bbotk]                         0.1142944           -1.796161              -2.181851
INFO  [19:36:00.268] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:36:00.268] [bbotk]                          1                    1260                 0.3128311
INFO  [19:36:00.268] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:36:00.268] [bbotk]  0.02665454 <list[8]>              FALSE     0.02414206        0      0
INFO  [19:36:00.268] [bbotk]  runtime_learners                                uhash
INFO  [19:36:00.268] [bbotk]           101.964 adf60b22-e9c3-49b1-9035-a28ba1d6e501
INFO  [19:36:05.565] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 93 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:36:18.078] [bbotk] Evaluating 1 configuration(s)
INFO  [19:36:18.258] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:36:18.356] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -41.94861
[1] 28.64805
[1] -33.48705
[1] 30.65005
[1] -35.00468
[1] 23.5709
[1] -62.53856
[1] 73.58447
[1] -46.61276
[1] 26.09381
INFO  [19:37:25.765] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -42.71329
[1] 77.90584
[1] 80.58744
[1] 2572.874
[1] -259.7484
[1] -3.92396
[1] 591.7431
[1] 15002.52
[1] -29.37313
[1] 54.74405
INFO  [19:38:35.787] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -59.70008
[1] 51.49151
[1] -1539.096
[1] -69.72126
[1] -69.41206
[1] 128.8848
[1] 247.2512
[1] 7511.733
[1] -157.1086
[1] -0.7175544
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:40:38.325] [mlr3] Finished benchmark
INFO  [19:40:39.062] [bbotk] Result of batch 63:
INFO  [19:40:39.084] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:40:39.084] [bbotk]              -5.264879                         0.5930409
INFO  [19:40:39.084] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:40:39.084] [bbotk]                         0.4069456           -5.738964              0.7318123
INFO  [19:40:39.084] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:40:39.084] [bbotk]                         16                    4185                 0.9684349
INFO  [19:40:39.084] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:40:39.084] [bbotk]  0.02219409 <list[8]>              FALSE     0.02534461        0      0
INFO  [19:40:39.084] [bbotk]  runtime_learners                                uhash
INFO  [19:40:39.084] [bbotk]           259.333 8f69d519-1bc4-4fc7-8338-44e39fec85db
INFO  [19:40:56.056] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 94 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:41:07.309] [bbotk] Evaluating 1 configuration(s)
INFO  [19:41:07.702] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:41:07.880] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -166915.6
[1] -5014.539
[1] -141.1572
[1] -4.208815
[1] -40.54812
[1] 29.85613
[1] -329.2815
[1] 0.2416335
[1] -49.01403
[1] 20.67413
INFO  [19:42:10.063] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -54.08205
[1] 81.60776
[1] -21.36279
[1] 211.875
[1] -100.253
[1] 25.23007
[1] -5771.853
[1] -166.1206
[1] -42.25381
[1] 146.5412
INFO  [19:43:22.024] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2.760924e+16
[1] 1.455961e+16
[1] -95.64046
[1] 72.74146
[1] -68.76586
[1] 20.36567
[1] -176.9291
[1] -4.109818
[1] -109.8027
[1] 14.84278
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:44:20.828] [mlr3] Finished benchmark
INFO  [19:44:21.006] [bbotk] Result of batch 64:
INFO  [19:44:21.014] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:44:21.014] [bbotk]             -0.9250698                          0.401073
INFO  [19:44:21.014] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:44:21.014] [bbotk]                         0.8573853           -2.129374              -1.082884
INFO  [19:44:21.014] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:44:21.014] [bbotk]                         13                    4852                 0.1789966
INFO  [19:44:21.014] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:44:21.014] [bbotk]  0.02113942 <list[8]>              FALSE     0.01900525        0      0
INFO  [19:44:21.014] [bbotk]  runtime_learners                                uhash
INFO  [19:44:21.014] [bbotk]           192.029 0ae9e20e-28c6-4e05-8a11-a3d388df02ce
INFO  [19:44:30.254] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 95 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:44:38.464] [bbotk] Evaluating 1 configuration(s)
INFO  [19:44:38.985] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:44:39.436] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -110.6599
[1] 5.82488
[1] -12.3297
[1] 48.76903
[1] -30.51142
[1] 23.78736
[1] -50.59807
[1] 11.18748
[1] -18.7387
[1] 24.69862
INFO  [19:45:17.444] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -98.7465
[1] -4.032676
[1] -39.69849
[1] 21.92736
[1] -33.28339
[1] 48.5751
[1] -9.673758
[1] 67.80031
[1] -19.58606
[1] 49.58019
INFO  [19:46:12.033] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -20.16207
[1] 47.53777
[1] -39.73754
[1] 12.04951
[1] -10.6927
[1] 34.20112
[1] -1998.471
[1] -100.5222
[1] -79.34842
[1] 232.209
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:46:53.823] [mlr3] Finished benchmark
INFO  [19:46:54.075] [bbotk] Result of batch 65:
INFO  [19:46:54.124] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:46:54.124] [bbotk]              -2.075128                         0.5038183
INFO  [19:46:54.124] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:46:54.124] [bbotk]                         0.3048089          -0.1151712              -2.198321
INFO  [19:46:54.124] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:46:54.124] [bbotk]                          2                    1576                 0.3695666
INFO  [19:46:54.124] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:46:54.124] [bbotk]  0.02115099 <list[8]>              FALSE     0.02606216        0      0
INFO  [19:46:54.124] [bbotk]  runtime_learners                                uhash
INFO  [19:46:54.124] [bbotk]           132.634 080a6ef1-70bb-4332-a5c6-eca0ec11c4d2
INFO  [19:47:05.337] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 96 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:47:15.741] [bbotk] Evaluating 1 configuration(s)
INFO  [19:47:15.896] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:47:16.013] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -53.47752
[1] 61.60817
[1] -26.08773
[1] 54.17025
[1] -47.43341
[1] 14.32346
[1] -157.3315
[1] -3.926021
[1] -145.2542
[1] 21.64262
INFO  [19:48:25.099] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -53.55794
[1] 16.53692
[1] -3.945567e+16
[1] 6.559007e+15
[1] -15.07629
[1] 55.09378
[1] -182.6081
[1] 113.0333
[1] -29.53157
[1] 86.35034
INFO  [19:49:35.755] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -27.8394
[1] 246.6795
[1] -27.31946
[1] 58.68786
[1] -487.5013
[1] -16.41612
[1] -65.60917
[1] 80.28547
[1] -46.55277
[1] 17.22994
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:50:59.303] [mlr3] Finished benchmark
INFO  [19:51:00.462] [bbotk] Result of batch 66:
INFO  [19:51:00.501] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:51:00.501] [bbotk]              -3.178762                         0.2982023
INFO  [19:51:00.501] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:51:00.501] [bbotk]                         0.6859446           -5.931049              -1.729298
INFO  [19:51:00.501] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:51:00.501] [bbotk]                          9                    3961                 0.7273628
INFO  [19:51:00.501] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:51:00.501] [bbotk]  0.02069459 <list[8]>              FALSE     0.02426582        0      0
INFO  [19:51:00.501] [bbotk]  runtime_learners                                uhash
INFO  [19:51:00.501] [bbotk]           222.699 e621e43b-651d-479d-a569-52eb4bd48c07
INFO  [19:51:33.421] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 97 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:51:46.704] [bbotk] Evaluating 1 configuration(s)
INFO  [19:51:46.728] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:51:46.743] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -38.66692
[1] 32.77792
[1] -62.20624
[1] 38.88542
[1] -36.88017
[1] 40.77087
[1] -67.70886
[1] 15.32438
[1] -52.83993
[1] 6.307081
INFO  [19:53:15.701] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -2242.689
[1] -35.35316
[1] 362.6862
[1] 6625.801
[1] 35.45769
[1] 748.6207
[1] -34.11869
[1] 54.0144
[1] -63.17018
[1] 15.1128
INFO  [19:54:36.270] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -71.26845
[1] 74.63884
[1] -119.5669
[1] 14.21707
[1] 324.0952
[1] 5876.109
[1] -1912.176
[1] -99.55538
[1] -120.3975
[1] -3.647601
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:56:07.757] [mlr3] Finished benchmark
INFO  [19:56:07.946] [bbotk] Result of batch 67:
INFO  [19:56:08.018] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:56:08.018] [bbotk]              -5.977769                         0.5734778
INFO  [19:56:08.018] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:56:08.018] [bbotk]                         0.6683827          -0.3431832                4.13208
INFO  [19:56:08.018] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:56:08.018] [bbotk]                         15                    4770                 0.8919447
INFO  [19:56:08.018] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:56:08.018] [bbotk]  0.02035189 <list[8]>              FALSE     0.02141196        0      0
INFO  [19:56:08.018] [bbotk]  runtime_learners                                uhash
INFO  [19:56:08.018] [bbotk]           260.207 6b88bebc-3331-406f-adce-c7215f24a787
INFO  [19:56:28.760] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 98 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:56:42.123] [bbotk] Evaluating 1 configuration(s)
INFO  [19:56:42.142] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:56:42.297] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -151.1793
[1] 11.76456
[1] -129.9004
[1] 9.423332
[1] -40.10893
[1] 207.9303
[1] -196.516
[1] 5.78052
[1] -26.37774
[1] 86.62362
INFO  [19:57:58.171] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -59.8535
[1] 36.44396
[1] -59.04033
[1] 89.9751
[1] 79.39875
[1] 2415.012
[1] -39.08933
[1] 99.89784
[1] -94.44258
[1] 88.63828
INFO  [19:58:50.383] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -47.96914
[1] 47.08679
[1] -110.472
[1] 16.74704
[1] -16.35964
[1] 180.8313
[1] -78.57795
[1] 55.95012
[1] -7.122718
[1] 175.7413
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:00:08.701] [mlr3] Finished benchmark
INFO  [20:00:08.963] [bbotk] Result of batch 68:
INFO  [20:00:08.978] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:00:08.978] [bbotk]             0.02505985                         0.1104956
INFO  [20:00:08.978] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:00:08.978] [bbotk]                         0.4741786           -5.103134              -6.729123
INFO  [20:00:08.978] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:00:08.978] [bbotk]                         14                    3462                 0.1927477
INFO  [20:00:08.978] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:00:08.978] [bbotk]  0.02122365 <list[8]>              FALSE      0.0282182        0      0
INFO  [20:00:08.978] [bbotk]  runtime_learners                                uhash
INFO  [20:00:08.978] [bbotk]           205.814 5f12cbb5-27ae-41b7-ab9c-465300df9a95
INFO  [20:00:20.938] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 99 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:00:35.624] [bbotk] Evaluating 1 configuration(s)
INFO  [20:00:35.899] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:00:36.424] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -101.7649
[1] 5.981532
[1] -30.39642
[1] 25.33535
[1] -63.53425
[1] 29.27854
[1] -39.8492
[1] 39.68648
[1] -58681.77
[1] -1858.495
INFO  [20:01:49.285] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -42.90339
[1] 30.51364
[1] -26.38426
[1] 65.07851
[1] -1960.231
[1] -48.0438
[1] -39.29126
[1] 60.51135
[1] -825.1413
[1] 21.44757
INFO  [20:02:30.509] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -86.68888
[1] 42.58173
[1] -55.32331
[1] 18.52311
[1] 146.8354
[1] 2380.165
[1] -96.32466
[1] 57.40739
[1] -40.71394
[1] 13.80654
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:03:28.149] [mlr3] Finished benchmark
INFO  [20:03:28.227] [bbotk] Result of batch 69:
INFO  [20:03:28.901] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:03:28.901] [bbotk]              -5.361268                          0.738177
INFO  [20:03:28.901] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:03:28.901] [bbotk]                          0.577194          -0.6877824               6.077261
INFO  [20:03:28.901] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:03:28.901] [bbotk]                         10                    1808                 0.8529111
INFO  [20:03:28.901] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:03:28.901] [bbotk]  0.01955148 <list[8]>              FALSE     0.02295014        0      0
INFO  [20:03:28.901] [bbotk]  runtime_learners                                uhash
INFO  [20:03:28.901] [bbotk]           170.545 2dc851e8-606c-45ca-9049-ea3f660ca192
INFO  [20:03:36.703] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 100 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:03:36.877] [bbotk] Finished optimizing after 100 evaluation(s)
INFO  [20:03:36.916] [bbotk] Result:
INFO  [20:03:36.937] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:03:36.937] [bbotk]                  <num>                             <num>
INFO  [20:03:36.937] [bbotk]              -2.239894                         0.9650334
INFO  [20:03:36.937] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:03:36.937] [bbotk]                             <num>               <num>                  <num>
INFO  [20:03:36.937] [bbotk]                         0.9000564           -1.813478              0.7597384
INFO  [20:03:36.937] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:03:36.937] [bbotk]                      <int>                   <int>                     <num>
INFO  [20:03:36.937] [bbotk]                          7                    3656                 0.2170921
INFO  [20:03:36.937] [bbotk]  learner_param_vals  x_domain classif.bbrier
INFO  [20:03:36.937] [bbotk]              <list>    <list>          <num>
INFO  [20:03:36.937] [bbotk]          <list[10]> <list[8]>     0.01799826
[1] -48.24214
[1] 22.1966
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] -668.1689
[1] -3.589154
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] -105.1007
[1] 11.29667
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] -3556.112
[1] -102.3402
[1] -47.1176
[1] 30.01918

### [bt]: Job terminated successfully [batchtools job.id=1417]
### [bt]: Calculation finished!
