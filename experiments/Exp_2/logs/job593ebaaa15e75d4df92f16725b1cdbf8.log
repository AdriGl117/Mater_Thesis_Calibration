### [bt]: This is batchtools v0.9.17
### [bt]: Starting calculation of 1 jobs
### [bt]: Setting working directory to '/content/drive/MyDrive/GitHub/Mater_Thesis_Calibration'
ece.R :
Friedmann_tasks.R :
Functions.R :
ici.R :
mse_feature_effects.R :
PipeOpCalibration_TuningExperiment.R :
PipeOpCalibration.R :
PipeOpCalibrationUnion.R :
### [bt]: Memory measurement disabled
### [bt]: Starting job [batchtools job.id=1439]
### [bt]: Generating problem instance for problem '341ee781c7d79b8f' ...
### [bt]: Applying algorithm 'run_learner' on problem '341ee781c7d79b8f' for job 1439 (seed = 1562) ...
INFO  [16:16:01.292] [mlr3] Applying learner 'xgboost TwP platt' on task 'wdbc' (iter 9/10)
INFO  [16:16:02.905] [bbotk] Starting to optimize 8 parameter(s) with '<OptimizerMbo>' and '<TerminatorEvals> [n_evals=100, k=0]'
INFO  [16:16:09.199] [bbotk] Evaluating 32 configuration(s)
INFO  [16:16:09.617] [mlr3] Running benchmark with 96 resampling iterations
INFO  [16:16:09.661] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:17:09.205] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:17:51.515] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:18:37.831] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:19:23.546] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:20:32.184] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:21:55.336] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:22:21.594] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:22:53.554] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:23:13.220] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:24:00.853] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:25:03.091] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:26:01.157] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:26:44.716] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:27:22.131] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:28:00.903] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:29:06.174] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:30:11.729] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:30:55.525] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:31:54.341] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:32:47.028] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:33:45.250] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:34:46.854] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:36:07.823] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:37:22.269] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:38:14.254] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:39:32.873] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:40:19.217] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:41:24.527] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:42:52.558] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:43:42.251] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:44:23.106] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:44:53.824] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:45:52.328] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:46:46.544] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:47:25.319] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:48:10.534] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:49:04.438] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:49:35.323] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:50:08.584] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:51:28.920] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:53:03.845] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:54:19.075] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:55:26.341] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:56:39.388] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:57:39.606] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:58:14.033] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:58:43.660] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:59:14.659] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:01:21.736] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:02:30.953] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:03:35.561] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:04:24.265] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:05:14.717] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:05:56.902] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:07:32.580] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:08:47.718] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:10:15.589] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:10:53.931] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:11:30.094] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:12:10.441] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:12:54.386] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:13:50.508] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:14:36.390] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:14:57.951] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:15:23.864] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:15:44.886] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:16:12.301] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:16:46.338] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:17:21.940] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:18:36.588] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:19:28.420] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:20:24.507] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:21:12.452] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:22:00.590] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:22:36.849] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:23:07.187] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:23:35.319] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:23:55.585] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:24:15.718] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:24:37.039] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:24:55.633] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:25:36.232] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:26:13.308] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:26:53.971] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:27:30.555] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:28:08.857] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:28:32.813] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:29:27.850] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:30:18.294] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:31:22.994] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:32:12.252] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:33:22.949] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:34:26.584] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:34:45.814] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:35:13.280] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:35:43.332] [mlr3] Finished benchmark
INFO  [17:35:44.387] [bbotk] Result of batch 1:
INFO  [17:35:44.478] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:35:44.478] [bbotk]              4.0046283                         0.4118696
INFO  [17:35:44.478] [bbotk]             -2.9031270                         0.8618696
INFO  [17:35:44.478] [bbotk]              0.5507506                         0.6368696
INFO  [17:35:44.478] [bbotk]             -6.3570048                         0.1868696
INFO  [17:35:44.478] [bbotk]             -4.6300660                         0.7493696
INFO  [17:35:44.478] [bbotk]              2.2776894                         0.2993696
INFO  [17:35:44.478] [bbotk]              5.7315671                         0.9743696
INFO  [17:35:44.478] [bbotk]             -1.1761882                         0.5243696
INFO  [17:35:44.478] [bbotk]              3.1411589                         0.8056196
INFO  [17:35:44.478] [bbotk]             -3.7665966                         0.3556196
INFO  [17:35:44.478] [bbotk]              6.5950365                         0.1306196
INFO  [17:35:44.478] [bbotk]             -0.3127188                         0.5806196
INFO  [17:35:44.478] [bbotk]             -5.4935354                         0.9181196
INFO  [17:35:44.478] [bbotk]              1.4142200                         0.4681196
INFO  [17:35:44.478] [bbotk]             -2.0396576                         0.2431196
INFO  [17:35:44.478] [bbotk]              4.8680977                         0.6931196
INFO  [17:35:44.478] [bbotk]              1.8459547                         0.7212446
INFO  [17:35:44.478] [bbotk]             -5.0618007                         0.2712446
INFO  [17:35:44.478] [bbotk]             -1.6079229                         0.9462446
INFO  [17:35:44.478] [bbotk]              5.2998324                         0.4962446
INFO  [17:35:44.478] [bbotk]              3.5728936                         0.8337446
INFO  [17:35:44.478] [bbotk]             -3.3348617                         0.3837446
INFO  [17:35:44.478] [bbotk]              0.1190159                         0.1587446
INFO  [17:35:44.478] [bbotk]             -6.7887395                         0.6087446
INFO  [17:35:44.478] [bbotk]             -2.4713923                         0.6649946
INFO  [17:35:44.478] [bbotk]              4.4363630                         0.2149946
INFO  [17:35:44.478] [bbotk]             -5.9252701                         0.4399946
INFO  [17:35:44.478] [bbotk]              0.9824853                         0.8899946
INFO  [17:35:44.478] [bbotk]             -0.7444535                         0.1024946
INFO  [17:35:44.478] [bbotk]              6.1633018                         0.5524946
INFO  [17:35:44.478] [bbotk]             -4.1983313                         0.7774946
INFO  [17:35:44.478] [bbotk]              2.7094241                         0.3274946
INFO  [17:35:44.478] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:35:44.478] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:35:44.478] [bbotk]                         0.8951014          -1.3431470             -3.3001373
INFO  [17:35:44.478] [bbotk]                         0.4451014          -5.9483169              3.6076176
INFO  [17:35:44.478] [bbotk]                         0.2201014          -8.2509021             -6.7540151
INFO  [17:35:44.478] [bbotk]                         0.6701014          -3.6457321              0.1537399
INFO  [17:35:44.478] [bbotk]                         0.7826014          -2.4944396              1.8806788
INFO  [17:35:44.478] [bbotk]                         0.3326014          -7.0996096             -5.0270763
INFO  [17:35:44.478] [bbotk]                         0.5576014          -0.1918545             -1.5731985
INFO  [17:35:44.478] [bbotk]                         0.1076014          -4.7970244              5.3345564
INFO  [17:35:44.478] [bbotk]                         0.8388514          -5.3726706              1.0172094
INFO  [17:35:44.478] [bbotk]                         0.3888514          -0.7675007             -5.8905457
INFO  [17:35:44.478] [bbotk]                         0.1638514          -3.0700858              4.4710870
INFO  [17:35:44.478] [bbotk]                         0.6138514          -7.6752559             -2.4366679
INFO  [17:35:44.478] [bbotk]                         0.2763514          -1.9187933             -4.1636069
INFO  [17:35:44.478] [bbotk]                         0.7263514          -6.5239632              2.7441482
INFO  [17:35:44.478] [bbotk]                         0.9513514          -8.8265484             -0.7097291
INFO  [17:35:44.478] [bbotk]                         0.5013514          -4.2213784              6.1980258
INFO  [17:35:44.478] [bbotk]                         0.6982264          -2.2066164              4.9028217
INFO  [17:35:44.478] [bbotk]                         0.2482264          -6.8117863             -2.0049332
INFO  [17:35:44.478] [bbotk]                         0.9232264          -4.5092015             -5.4588110
INFO  [17:35:44.478] [bbotk]                         0.4732264          -9.1143715              1.4489441
INFO  [17:35:44.478] [bbotk]                         0.1357264          -7.9630790              3.1758829
INFO  [17:35:44.478] [bbotk]                         0.5857264          -3.3579090             -3.7318722
INFO  [17:35:44.478] [bbotk]                         0.8107264          -1.0553239              6.6297605
INFO  [17:35:44.478] [bbotk]                         0.3607264          -5.6604938             -0.2779944
INFO  [17:35:44.478] [bbotk]                         0.1919764          -0.4796776              0.5854746
INFO  [17:35:44.478] [bbotk]                         0.6419764          -5.0848475             -6.3222804
INFO  [17:35:44.478] [bbotk]                         0.8669764          -7.3874327              4.0393523
INFO  [17:35:44.478] [bbotk]                         0.4169764          -2.7822627             -2.8684026
INFO  [17:35:44.478] [bbotk]                         0.5294764          -1.6309701              2.3124135
INFO  [17:35:44.478] [bbotk]                         0.9794764          -6.2361401             -4.5953416
INFO  [17:35:44.478] [bbotk]                         0.7544764          -8.5387252              5.7662911
INFO  [17:35:44.478] [bbotk]                         0.3044764          -3.9335552             -1.1414638
INFO  [17:35:44.478] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:35:44.478] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:35:44.478] [bbotk]                          8                    3965                 0.9392921
INFO  [17:35:44.478] [bbotk]                         18                    1465                 0.4892921
INFO  [17:35:44.478] [bbotk]                          3                     215                 0.7142921
INFO  [17:35:44.478] [bbotk]                         13                    2715                 0.2642921
INFO  [17:35:44.478] [bbotk]                         16                     840                 0.6017921
INFO  [17:35:44.478] [bbotk]                          6                    3340                 0.1517921
INFO  [17:35:44.478] [bbotk]                          1                    2090                 0.3767921
INFO  [17:35:44.478] [bbotk]                         11                    4590                 0.8267921
INFO  [17:35:44.478] [bbotk]                         10                    2402                 0.4330421
INFO  [17:35:44.478] [bbotk]                         20                    4902                 0.8830421
INFO  [17:35:44.478] [bbotk]                          5                    3652                 0.2080421
INFO  [17:35:44.478] [bbotk]                         15                    1152                 0.6580421
INFO  [17:35:44.478] [bbotk]                         12                    1777                 0.5455421
INFO  [17:35:44.478] [bbotk]                          2                    4277                 0.9955421
INFO  [17:35:44.478] [bbotk]                         17                    3027                 0.3205421
INFO  [17:35:44.478] [bbotk]                          7                     527                 0.7705421
INFO  [17:35:44.478] [bbotk]                         11                    4746                 0.5736671
INFO  [17:35:44.478] [bbotk]                          1                    2246                 0.1236671
INFO  [17:35:44.478] [bbotk]                          6                    3496                 0.3486671
INFO  [17:35:44.478] [bbotk]                         16                     996                 0.7986671
INFO  [17:35:44.478] [bbotk]                         14                    2871                 0.4611671
INFO  [17:35:44.478] [bbotk]                          4                     371                 0.9111671
INFO  [17:35:44.478] [bbotk]                         19                    1621                 0.2361671
INFO  [17:35:44.478] [bbotk]                          9                    4121                 0.6861671
INFO  [17:35:44.478] [bbotk]                          3                    3808                 0.7424171
INFO  [17:35:44.478] [bbotk]                         13                    1308                 0.2924171
INFO  [17:35:44.478] [bbotk]                          8                      58                 0.9674171
INFO  [17:35:44.478] [bbotk]                         18                    2558                 0.5174171
INFO  [17:35:44.478] [bbotk]                         10                    1933                 0.1799171
INFO  [17:35:44.478] [bbotk]                         20                    4433                 0.6299171
INFO  [17:35:44.478] [bbotk]                          5                    3183                 0.4049171
INFO  [17:35:44.478] [bbotk]                         15                     683                 0.8549171
INFO  [17:35:44.478] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:35:44.478] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:35:44.478] [bbotk]      0.04952769        0      0          147.501
INFO  [17:35:44.478] [bbotk]      0.04397314        0      0          193.188
INFO  [17:35:44.478] [bbotk]      0.40968732        0      0           76.104
INFO  [17:35:44.478] [bbotk]      0.02787455        0      0          167.227
INFO  [17:35:44.478] [bbotk]      0.03102060        0      0          118.441
INFO  [17:35:44.478] [bbotk]      0.10979568        0      0          174.020
INFO  [17:35:44.478] [bbotk]      0.53267361        0      0          169.114
INFO  [17:35:44.478] [bbotk]      0.03833588        0      0          216.067
INFO  [17:35:44.478] [bbotk]      0.04292288        0      0          176.443
INFO  [17:35:44.478] [bbotk]      0.02873239        0      0          202.471
INFO  [17:35:44.478] [bbotk]      0.53267361        0      0          129.751
INFO  [17:35:44.478] [bbotk]      0.04741267        0      0          137.807
INFO  [17:35:44.478] [bbotk]      0.02827789        0      0          117.815
INFO  [17:35:44.478] [bbotk]      0.04469476        0      0          250.025
INFO  [17:35:44.478] [bbotk]      0.04822577        0      0          199.943
INFO  [17:35:44.478] [bbotk]      0.53267361        0      0           94.319
INFO  [17:35:44.478] [bbotk]      0.04092475        0      0          260.044
INFO  [17:35:44.478] [bbotk]      0.04368897        0      0          140.521
INFO  [17:35:44.478] [bbotk]      0.02838752        0      0          257.366
INFO  [17:35:44.478] [bbotk]      0.53267361        0      0          113.465
INFO  [17:35:44.478] [bbotk]      0.51263235        0      0          145.620
INFO  [17:35:44.478] [bbotk]      0.03335321        0      0           68.118
INFO  [17:35:44.478] [bbotk]      0.04134374        0      0           96.593
INFO  [17:35:44.478] [bbotk]      0.02888484        0      0          182.023
INFO  [17:35:44.478] [bbotk]      0.02941304        0      0          131.937
INFO  [17:35:44.478] [bbotk]      0.53267361        0      0           78.130
INFO  [17:35:44.478] [bbotk]      0.50305550        0      0           59.536
INFO  [17:35:44.478] [bbotk]      0.03270017        0      0          117.997
INFO  [17:35:44.478] [bbotk]      0.03052007        0      0           98.649
INFO  [17:35:44.478] [bbotk]      0.53267361        0      0          169.685
INFO  [17:35:44.478] [bbotk]      0.46529986        0      0          182.979
INFO  [17:35:44.478] [bbotk]      0.04301213        0      0           69.573
INFO  [17:35:44.478] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:35:44.478] [bbotk]                                 uhash
INFO  [17:35:44.478] [bbotk]  ba7d051c-d053-482f-9e6d-c6c1f4ee0180
INFO  [17:35:44.478] [bbotk]  6cfb4cd9-2ae5-4e3d-b5d6-7aaf738598ed
INFO  [17:35:44.478] [bbotk]  2bc67c66-e4ca-445e-8866-475b3e648371
INFO  [17:35:44.478] [bbotk]  face1981-d28e-467d-a864-1172ba24481b
INFO  [17:35:44.478] [bbotk]  e1aa3d38-75d1-4540-bdce-098531370c4c
INFO  [17:35:44.478] [bbotk]  29cb205a-2609-47b0-a1c0-7e8ca9a3f412
INFO  [17:35:44.478] [bbotk]  a99fe546-a618-4575-a5e4-025018e2ae3c
INFO  [17:35:44.478] [bbotk]  9a072441-a72c-4585-bed5-87c5a3f9cc6c
INFO  [17:35:44.478] [bbotk]  9d389a5c-a639-44d3-ae12-c222cba66308
INFO  [17:35:44.478] [bbotk]  ece179dd-2af3-4345-b19c-1393b0ee93d8
INFO  [17:35:44.478] [bbotk]  37f3e94f-e7dd-477d-bf27-d48e93213be3
INFO  [17:35:44.478] [bbotk]  3834e099-54f1-4cf7-856c-6996b79ac7dd
INFO  [17:35:44.478] [bbotk]  217b4d30-7052-4ac6-ae44-8b45316a8267
INFO  [17:35:44.478] [bbotk]  a34273e6-71c2-474e-9cfd-126371e783b1
INFO  [17:35:44.478] [bbotk]  5bcfb1e8-f805-4ba4-a9a6-1ab7154f5cab
INFO  [17:35:44.478] [bbotk]  9de4def6-2768-42e7-94a6-6803e1a1d0cd
INFO  [17:35:44.478] [bbotk]  5ffb5d15-2d64-4893-a27a-ef81b587d25c
INFO  [17:35:44.478] [bbotk]  35590519-8169-4b8f-9d84-2935b4b29667
INFO  [17:35:44.478] [bbotk]  39bcf76a-2140-4ec5-b7de-162c562d7c6e
INFO  [17:35:44.478] [bbotk]  5ef1de9a-c8f3-42c4-804c-ccf56bbcb695
INFO  [17:35:44.478] [bbotk]  e7c03194-b3b7-4d9f-8a13-030bed3cfe3c
INFO  [17:35:44.478] [bbotk]  64c83127-f354-436c-9d1e-9833291b9504
INFO  [17:35:44.478] [bbotk]  f909e012-2d84-402a-bc7d-2f46bb45b2e8
INFO  [17:35:44.478] [bbotk]  b3eb0305-9352-4870-bd41-dba813173a26
INFO  [17:35:44.478] [bbotk]  c680e182-9391-4a11-9b96-395a6ccd7e85
INFO  [17:35:44.478] [bbotk]  f915cda2-204c-48e7-942e-34c06ee2283a
INFO  [17:35:44.478] [bbotk]  79eb7d3e-89cc-4c63-ad65-5de5e972b724
INFO  [17:35:44.478] [bbotk]  ed0646ca-0a83-4209-b6eb-988e1405f45e
INFO  [17:35:44.478] [bbotk]  59da7534-310e-4025-a9e9-452d0070f33c
INFO  [17:35:44.478] [bbotk]  3451a3fd-f74f-4d82-81f9-b5eba3022c47
INFO  [17:35:44.478] [bbotk]  2cf74b32-e95f-4534-8c45-5925c2ad6b3a
INFO  [17:35:44.478] [bbotk]  a24d2687-40c7-4ae2-88b4-d1190adcebe3
INFO  [17:35:44.478] [bbotk]                                 uhash
INFO  [17:35:53.339] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 32 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:35:59.982] [bbotk] Evaluating 1 configuration(s)
INFO  [17:36:00.052] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:36:00.087] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:36:34.313] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:37:08.578] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:38:33.707] [mlr3] Finished benchmark
INFO  [17:38:34.039] [bbotk] Result of batch 2:
INFO  [17:38:34.269] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:38:34.269] [bbotk]               1.848117                         0.4864856
INFO  [17:38:34.269] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:38:34.269] [bbotk]                         0.9941043            -2.07226              -2.685333
INFO  [17:38:34.269] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:38:34.269] [bbotk]                         11                    4731                 0.6629589
INFO  [17:38:34.269] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:38:34.269] [bbotk]  0.1837376 <list[8]>              FALSE     0.03745037        0      0
INFO  [17:38:34.269] [bbotk]  runtime_learners                                uhash
INFO  [17:38:34.269] [bbotk]           152.712 6925b452-8fd5-45ca-8660-c9e79e8830d7
INFO  [17:38:36.186] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 33 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:38:42.673] [bbotk] Evaluating 1 configuration(s)
INFO  [17:38:42.806] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:38:42.890] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:39:20.509] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:39:57.074] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:40:16.898] [mlr3] Finished benchmark
INFO  [17:40:17.286] [bbotk] Result of batch 3:
INFO  [17:40:17.319] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:40:17.319] [bbotk]              -4.410917                         0.7547113
INFO  [17:40:17.319] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:40:17.319] [bbotk]                         0.5235488           -2.323063             -0.6998825
INFO  [17:40:17.319] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:40:17.319] [bbotk]                         20                    1700                 0.4749163
INFO  [17:40:17.319] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:40:17.319] [bbotk]  0.1273857 <list[8]>              FALSE     0.02687601        0      0
INFO  [17:40:17.319] [bbotk]  runtime_learners                                uhash
INFO  [17:40:17.319] [bbotk]            92.468 32f693eb-f8bb-45ae-84b3-fb6b33da0fee
WARN  [17:40:19.462] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:40:19.564] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 34 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:40:27.136] [bbotk] Evaluating 1 configuration(s)
INFO  [17:40:27.171] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:40:27.244] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:41:02.217] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:41:35.547] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:42:18.428] [mlr3] Finished benchmark
INFO  [17:42:18.580] [bbotk] Result of batch 4:
INFO  [17:42:18.624] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:42:18.624] [bbotk]               2.586536                         0.6074696
INFO  [17:42:18.624] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:42:18.624] [bbotk]                         0.9033109           -3.600413               -4.20242
INFO  [17:42:18.624] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:42:18.624] [bbotk]                         11                    1580                 0.9753696
INFO  [17:42:18.624] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:42:18.624] [bbotk]  0.09924875 <list[8]>              FALSE     0.04470573        0      0
INFO  [17:42:18.624] [bbotk]  runtime_learners                                uhash
INFO  [17:42:18.624] [bbotk]           110.974 ec61a9f4-4dae-4e24-bda1-a383afa39f66
INFO  [17:42:20.550] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 35 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:42:35.075] [bbotk] Evaluating 1 configuration(s)
INFO  [17:42:35.278] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:42:35.552] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:43:14.253] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:43:54.955] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:44:35.458] [mlr3] Finished benchmark
INFO  [17:44:35.782] [bbotk] Result of batch 5:
INFO  [17:44:35.812] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:44:35.812] [bbotk]             -0.5362602                          0.447659
INFO  [17:44:35.812] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:44:35.812] [bbotk]                         0.7782481           -6.378653               2.350506
INFO  [17:44:35.812] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:44:35.812] [bbotk]                         19                    3149                 0.1630344
INFO  [17:44:35.812] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:44:35.812] [bbotk]  0.09936927 <list[8]>              FALSE     0.04173221        0      0
INFO  [17:44:35.812] [bbotk]  runtime_learners                                uhash
INFO  [17:44:35.812] [bbotk]           119.348 75827f66-6beb-4418-b7fd-db088827077f
INFO  [17:44:36.569] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 36 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:44:42.893] [bbotk] Evaluating 1 configuration(s)
INFO  [17:44:43.357] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:44:43.629] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:45:31.015] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:46:27.587] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:47:09.513] [mlr3] Finished benchmark
INFO  [17:47:09.704] [bbotk] Result of batch 6:
INFO  [17:47:09.781] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:47:09.781] [bbotk]              -2.109171                         0.8142786
INFO  [17:47:09.781] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:47:09.781] [bbotk]                         0.5996414           -4.525245              -1.009369
INFO  [17:47:09.781] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:47:09.781] [bbotk]                         14                    3312                 0.4753298
INFO  [17:47:09.781] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:47:09.781] [bbotk]  0.09799936 <list[8]>              FALSE     0.03174657        0      0
INFO  [17:47:09.781] [bbotk]  runtime_learners                                uhash
INFO  [17:47:09.781] [bbotk]           145.158 ef87af53-9706-498a-a57a-48b4476ab819
INFO  [17:47:10.595] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 37 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:47:17.116] [bbotk] Evaluating 1 configuration(s)
INFO  [17:47:17.172] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:47:17.258] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:47:55.252] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:48:32.818] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:49:06.682] [mlr3] Finished benchmark
INFO  [17:49:07.097] [bbotk] Result of batch 7:
INFO  [17:49:07.392] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:49:07.392] [bbotk]              -6.356136                         0.3336842
INFO  [17:49:07.392] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:49:07.392] [bbotk]                         0.2435068           -4.706903              -3.215884
INFO  [17:49:07.392] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:49:07.392] [bbotk]                          1                    4023                  0.100007
INFO  [17:49:07.392] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:49:07.392] [bbotk]  0.07880791 <list[8]>              FALSE     0.03250952        0      0
INFO  [17:49:07.392] [bbotk]  runtime_learners                                uhash
INFO  [17:49:07.392] [bbotk]           108.745 305907f2-6116-454f-80c0-12db2fadb177
INFO  [17:49:09.951] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 38 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:49:18.697] [bbotk] Evaluating 1 configuration(s)
INFO  [17:49:18.845] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:49:19.251] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:50:07.248] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:50:51.993] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:51:54.766] [mlr3] Finished benchmark
INFO  [17:51:54.936] [bbotk] Result of batch 8:
INFO  [17:51:54.971] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:51:54.971] [bbotk]               2.482308                         0.2581455
INFO  [17:51:54.971] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:51:54.971] [bbotk]                         0.6691321           -3.076548                3.88275
INFO  [17:51:54.971] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:51:54.971] [bbotk]                          8                    3436                 0.4012652
INFO  [17:51:54.971] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:51:54.971] [bbotk]  0.06522832 <list[8]>              FALSE     0.04568121        0      0
INFO  [17:51:54.971] [bbotk]  runtime_learners                                uhash
INFO  [17:51:54.971] [bbotk]           155.181 16b3f879-0bcc-4d05-8a98-d586027d1d19
INFO  [17:51:56.740] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 39 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:52:02.640] [bbotk] Evaluating 1 configuration(s)
INFO  [17:52:02.784] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:52:03.002] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:52:32.838] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:53:19.252] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:53:58.565] [mlr3] Finished benchmark
INFO  [17:53:58.748] [bbotk] Result of batch 9:
INFO  [17:53:58.804] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:53:58.804] [bbotk]               -3.36612                         0.2522163
INFO  [17:53:58.804] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:53:58.804] [bbotk]                         0.1562215           -4.613433              -1.798441
INFO  [17:53:58.804] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:53:58.804] [bbotk]                         10                    2252                 0.6344284
INFO  [17:53:58.804] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:53:58.804] [bbotk]  0.06557764 <list[8]>              FALSE     0.02768561        0      0
INFO  [17:53:58.804] [bbotk]  runtime_learners                                uhash
INFO  [17:53:58.804] [bbotk]           113.878 75d34e56-2674-4529-8aaa-a455eb2c7733
WARN  [17:54:00.323] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:54:00.356] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 40 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:54:09.573] [bbotk] Evaluating 1 configuration(s)
INFO  [17:54:09.718] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:54:09.848] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:54:53.023] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:55:22.573] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:56:05.064] [mlr3] Finished benchmark
INFO  [17:56:05.266] [bbotk] Result of batch 10:
INFO  [17:56:05.321] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:56:05.321] [bbotk]              -1.267049                         0.6365995
INFO  [17:56:05.321] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:56:05.321] [bbotk]                         0.8929414           -5.447256              -2.660076
INFO  [17:56:05.321] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:56:05.321] [bbotk]                         18                     950                 0.7026188
INFO  [17:56:05.321] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:56:05.321] [bbotk]  0.06168988 <list[8]>              FALSE     0.03599721        0      0
INFO  [17:56:05.321] [bbotk]  runtime_learners                                uhash
INFO  [17:56:05.321] [bbotk]            114.35 73df701b-9fc4-46e4-93bd-639e3ce5f73f
INFO  [17:56:07.136] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 41 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:56:11.016] [bbotk] Evaluating 1 configuration(s)
INFO  [17:56:11.059] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:56:11.205] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:56:58.003] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:57:41.906] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:58:30.068] [mlr3] Finished benchmark
INFO  [17:58:30.188] [bbotk] Result of batch 11:
INFO  [17:58:30.242] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:58:30.242] [bbotk]               3.162642                         0.7842687
INFO  [17:58:30.242] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:58:30.242] [bbotk]                         0.9176082          -0.7353788              -2.579275
INFO  [17:58:30.242] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:58:30.242] [bbotk]                          9                    4035                 0.9165368
INFO  [17:58:30.242] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:58:30.242] [bbotk]  0.05609077 <list[8]>              FALSE     0.04404042        0      0
INFO  [17:58:30.242] [bbotk]  runtime_learners                                uhash
INFO  [17:58:30.242] [bbotk]           137.781 80aa0a89-217f-498e-ae8f-6af8eba105de
WARN  [17:58:30.877] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:58:31.014] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 42 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:58:35.133] [bbotk] Evaluating 1 configuration(s)
INFO  [17:58:35.444] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:58:35.759] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:59:07.979] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:00:01.046] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:00:32.256] [mlr3] Finished benchmark
INFO  [18:00:32.364] [bbotk] Result of batch 12:
INFO  [18:00:32.475] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:00:32.475] [bbotk]               2.221628                         0.4544344
INFO  [18:00:32.475] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:00:32.475] [bbotk]                         0.8586351           -3.435164              -1.459011
INFO  [18:00:32.475] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:00:32.475] [bbotk]                         11                    2723                 0.9407582
INFO  [18:00:32.475] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:00:32.475] [bbotk]  0.1181447 <list[8]>              FALSE     0.04685057        0      0
INFO  [18:00:32.475] [bbotk]  runtime_learners                                uhash
INFO  [18:00:32.475] [bbotk]           115.825 693780d2-5591-4ef8-bd30-577f2c79f606
INFO  [18:00:33.714] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 43 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:00:40.456] [bbotk] Evaluating 1 configuration(s)
INFO  [18:00:40.613] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:00:40.784] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:01:11.689] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:01:45.153] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:02:22.374] [mlr3] Finished benchmark
INFO  [18:02:22.501] [bbotk] Result of batch 13:
INFO  [18:02:22.581] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:02:22.581] [bbotk]              -5.648601                          0.222194
INFO  [18:02:22.581] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:02:22.581] [bbotk]                         0.4555966           -2.822612                2.38333
INFO  [18:02:22.581] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:02:22.581] [bbotk]                         12                    3724                 0.6729389
INFO  [18:02:22.581] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:02:22.581] [bbotk]  0.05334622 <list[8]>              FALSE     0.02796404        0      0
INFO  [18:02:22.581] [bbotk]  runtime_learners                                uhash
INFO  [18:02:22.581] [bbotk]           100.837 c4942a42-6085-413d-8df8-59fa804ee647
INFO  [18:02:23.725] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 44 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:02:31.267] [bbotk] Evaluating 1 configuration(s)
INFO  [18:02:31.596] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:02:31.801] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:02:54.912] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:04:04.088] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:04:53.117] [mlr3] Finished benchmark
INFO  [18:04:53.243] [bbotk] Result of batch 14:
INFO  [18:04:53.268] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:04:53.268] [bbotk]               2.016832                         0.9514122
INFO  [18:04:53.268] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:04:53.268] [bbotk]                         0.9174362           -6.409214             -0.3347819
INFO  [18:04:53.268] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:04:53.268] [bbotk]                         12                    2574                 0.3972076
INFO  [18:04:53.268] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:04:53.268] [bbotk]  0.05468239 <list[8]>              FALSE     0.04249955        0      0
INFO  [18:04:53.268] [bbotk]  runtime_learners                                uhash
INFO  [18:04:53.268] [bbotk]           140.505 69256733-981e-4d37-8377-2e7674c1a92c
INFO  [18:04:55.302] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 45 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:05:04.110] [bbotk] Evaluating 1 configuration(s)
INFO  [18:05:04.270] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:05:04.374] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:05:32.351] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:05:56.522] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:06:18.264] [mlr3] Finished benchmark
INFO  [18:06:18.462] [bbotk] Result of batch 15:
INFO  [18:06:18.514] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:06:18.514] [bbotk]              -2.989944                         0.5505354
INFO  [18:06:18.514] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:06:18.514] [bbotk]                         0.9036485          -0.7092129              -2.773343
INFO  [18:06:18.514] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:06:18.514] [bbotk]                         13                     966                 0.6046198
INFO  [18:06:18.514] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:06:18.514] [bbotk]  0.0518186 <list[8]>              FALSE     0.02825271        0      0
INFO  [18:06:18.514] [bbotk]  runtime_learners                                uhash
INFO  [18:06:18.514] [bbotk]             73.07 cb73a52e-d71a-4ce1-b035-9800fdbc1232
INFO  [18:06:19.221] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 46 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:06:24.872] [bbotk] Evaluating 1 configuration(s)
INFO  [18:06:25.090] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:06:25.200] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:07:20.056] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:08:19.073] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:09:08.995] [mlr3] Finished benchmark
INFO  [18:09:09.151] [bbotk] Result of batch 16:
INFO  [18:09:09.192] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:09:09.192] [bbotk]               2.028921                          0.119476
INFO  [18:09:09.192] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:09:09.192] [bbotk]                         0.3529694           -3.675694              -3.015102
INFO  [18:09:09.192] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:09:09.192] [bbotk]                         11                    4827                 0.5150702
INFO  [18:09:09.192] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:09:09.192] [bbotk]  0.04699548 <list[8]>              FALSE     0.03904345        0      0
INFO  [18:09:09.192] [bbotk]  runtime_learners                                uhash
INFO  [18:09:09.192] [bbotk]           163.557 104e3216-c7c2-48b9-9fda-ccecb29a7c3a
INFO  [18:09:10.898] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 47 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:09:16.645] [bbotk] Evaluating 1 configuration(s)
INFO  [18:09:16.730] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:09:16.783] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:09:55.076] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:10:30.630] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:11:03.464] [mlr3] Finished benchmark
INFO  [18:11:03.830] [bbotk] Result of batch 17:
INFO  [18:11:04.096] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:11:04.096] [bbotk]              -6.845149                         0.8224476
INFO  [18:11:04.096] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:11:04.096] [bbotk]                         0.4577752           -3.194518               -6.35265
INFO  [18:11:04.096] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:11:04.096] [bbotk]                         15                    2602                 0.5579045
INFO  [18:11:04.096] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:11:04.096] [bbotk]  0.04714086 <list[8]>              FALSE     0.02961161        0      0
INFO  [18:11:04.096] [bbotk]  runtime_learners                                uhash
INFO  [18:11:04.096] [bbotk]           105.641 2eaa1708-4759-4bab-a2bc-9aec0b8b0060
INFO  [18:11:05.542] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 48 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:11:11.652] [bbotk] Evaluating 1 configuration(s)
INFO  [18:11:11.841] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:11:12.071] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:11:24.490] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:11:47.185] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:12:08.632] [mlr3] Finished benchmark
INFO  [18:12:08.803] [bbotk] Result of batch 18:
INFO  [18:12:08.885] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:12:08.885] [bbotk]              -4.720791                         0.4054929
INFO  [18:12:08.885] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:12:08.885] [bbotk]                         0.7327093          -0.7893739              -6.719781
INFO  [18:12:08.885] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:12:08.885] [bbotk]                          9                     907                 0.3116637
INFO  [18:12:08.885] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:12:08.885] [bbotk]  0.04852853 <list[8]>              FALSE     0.03214637        0      0
INFO  [18:12:08.885] [bbotk]  runtime_learners                                uhash
INFO  [18:12:08.885] [bbotk]            56.141 de854f99-23e6-4206-a306-8984ebe7a7ea
INFO  [18:12:09.903] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 49 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:12:18.382] [bbotk] Evaluating 1 configuration(s)
INFO  [18:12:18.465] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:12:18.510] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:12:44.165] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:13:22.852] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:13:59.900] [mlr3] Finished benchmark
INFO  [18:14:00.090] [bbotk] Result of batch 19:
INFO  [18:14:00.161] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:14:00.161] [bbotk]              -1.981206                          0.308538
INFO  [18:14:00.161] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:14:00.161] [bbotk]                         0.3098397            -1.68493               5.316772
INFO  [18:14:00.161] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:14:00.161] [bbotk]                         18                    2524                 0.8462161
INFO  [18:14:00.161] [bbotk]    acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:14:00.161] [bbotk]  0.043362 <list[8]>              FALSE     0.02996796        0      0
INFO  [18:14:00.161] [bbotk]  runtime_learners                                uhash
INFO  [18:14:00.161] [bbotk]           100.496 e02a4359-46ac-4902-b48a-6ec4db8c35ed
INFO  [18:14:01.573] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 50 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:14:11.283] [bbotk] Evaluating 1 configuration(s)
INFO  [18:14:11.442] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:14:11.477] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:14:49.327] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:15:35.852] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:16:35.230] [mlr3] Finished benchmark
INFO  [18:16:35.366] [bbotk] Result of batch 20:
INFO  [18:16:35.562] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:16:35.562] [bbotk]             -0.5682353                         0.5702091
INFO  [18:16:35.562] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:16:35.562] [bbotk]                         0.5802065           -2.987833              -1.446746
INFO  [18:16:35.562] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:16:35.562] [bbotk]                         12                    4208                 0.9499319
INFO  [18:16:35.562] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:16:35.562] [bbotk]  0.04272279 <list[8]>              FALSE     0.03093511        0      0
INFO  [18:16:35.562] [bbotk]  runtime_learners                                uhash
INFO  [18:16:35.562] [bbotk]           142.892 55680b17-9612-4705-9ac3-7c7a1f54c19d
INFO  [18:16:38.003] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 51 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:16:46.035] [bbotk] Evaluating 1 configuration(s)
INFO  [18:16:46.256] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:16:46.458] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:17:35.327] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:18:16.945] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:19:05.981] [mlr3] Finished benchmark
INFO  [18:19:06.107] [bbotk] Result of batch 21:
INFO  [18:19:06.149] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:19:06.149] [bbotk]              -1.430635                         0.2775413
INFO  [18:19:06.149] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:19:06.149] [bbotk]                         0.5631443           -6.583939             -0.8485641
INFO  [18:19:06.149] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:19:06.149] [bbotk]                          8                    2710                 0.4576071
INFO  [18:19:06.149] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:19:06.149] [bbotk]  0.03692262 <list[8]>              FALSE     0.03560584        0      0
INFO  [18:19:06.149] [bbotk]  runtime_learners                                uhash
INFO  [18:19:06.149] [bbotk]           139.062 352e2ee5-347c-41fe-b4dc-7653c2b706a8
INFO  [18:19:07.504] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 52 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:19:15.004] [bbotk] Evaluating 1 configuration(s)
INFO  [18:19:15.574] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:19:15.834] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:20:03.185] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:20:50.492] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:21:38.160] [mlr3] Finished benchmark
INFO  [18:21:38.313] [bbotk] Result of batch 22:
INFO  [18:21:38.423] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:21:38.423] [bbotk]              -5.180737                         0.4857156
INFO  [18:21:38.423] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:21:38.423] [bbotk]                         0.1704917           -5.124149              -3.376343
INFO  [18:21:38.423] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:21:38.423] [bbotk]                         15                    4083                 0.2110382
INFO  [18:21:38.423] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:21:38.423] [bbotk]  0.03893889 <list[8]>              FALSE     0.02788471        0      0
INFO  [18:21:38.423] [bbotk]  runtime_learners                                uhash
INFO  [18:21:38.423] [bbotk]           141.655 fc286844-93f2-4195-91ba-4c5ff5105f8f
INFO  [18:21:39.505] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 53 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:21:46.913] [bbotk] Evaluating 1 configuration(s)
INFO  [18:21:47.041] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:21:47.100] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:22:01.726] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:22:26.421] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:22:46.943] [mlr3] Finished benchmark
INFO  [18:22:47.045] [bbotk] Result of batch 23:
INFO  [18:22:47.090] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:22:47.090] [bbotk]              -2.732584                         0.9786461
INFO  [18:22:47.090] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:22:47.090] [bbotk]                         0.3002833           -2.596696              -1.595774
INFO  [18:22:47.090] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:22:47.090] [bbotk]                          7                     483                  0.770736
INFO  [18:22:47.090] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:22:47.090] [bbotk]  0.03679692 <list[8]>              FALSE     0.02820743        0      0
INFO  [18:22:47.090] [bbotk]  runtime_learners                                uhash
INFO  [18:22:47.090] [bbotk]            59.117 93d432d8-7c15-4885-b237-9984c9ec8797
INFO  [18:22:48.918] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 54 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:22:53.437] [bbotk] Evaluating 1 configuration(s)
INFO  [18:22:53.527] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:22:53.920] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:23:34.010] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:24:16.253] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:25:01.910] [mlr3] Finished benchmark
INFO  [18:25:02.201] [bbotk] Result of batch 24:
INFO  [18:25:02.236] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:25:02.236] [bbotk]              -4.325665                          0.606204
INFO  [18:25:02.236] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:25:02.236] [bbotk]                         0.4222482           -2.145427               1.457984
INFO  [18:25:02.236] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:25:02.236] [bbotk]                         15                    2890                  0.727151
INFO  [18:25:02.236] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:25:02.236] [bbotk]  0.07830066 <list[8]>              FALSE     0.02874138        0      0
INFO  [18:25:02.236] [bbotk]  runtime_learners                                uhash
INFO  [18:25:02.236] [bbotk]           126.904 66b089ac-c8d7-47d7-bd97-c1252be5e5ce
INFO  [18:25:03.144] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 55 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:25:08.718] [bbotk] Evaluating 1 configuration(s)
INFO  [18:25:08.960] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:25:09.515] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:25:57.351] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:26:51.130] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:27:32.681] [mlr3] Finished benchmark
INFO  [18:27:32.881] [bbotk] Result of batch 25:
INFO  [18:27:32.952] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:27:32.952] [bbotk]               2.356454                         0.4487842
INFO  [18:27:32.952] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:27:32.952] [bbotk]                         0.8799107           -5.086252              -1.937542
INFO  [18:27:32.952] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:27:32.952] [bbotk]                          2                    4636                 0.5346497
INFO  [18:27:32.952] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:27:32.952] [bbotk]  0.03893964 <list[8]>              FALSE     0.04229171        0      0
INFO  [18:27:32.952] [bbotk]  runtime_learners                                uhash
INFO  [18:27:32.952] [bbotk]           142.361 68250106-110d-4b55-a64d-46ea3ee7871d
INFO  [18:27:34.881] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 56 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:27:40.922] [bbotk] Evaluating 1 configuration(s)
INFO  [18:27:41.047] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:27:41.367] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:28:17.082] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:29:05.336] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [18:29:42.669] [mlr3] Finished benchmark
INFO  [18:29:43.214] [bbotk] Result of batch 26:
INFO  [18:29:43.317] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:29:43.317] [bbotk]               1.503625                         0.5684821
INFO  [18:29:43.317] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:29:43.317] [bbotk]                         0.5569882           -4.812691               5.923697
INFO  [18:29:43.317] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:29:43.317] [bbotk]                         14                    2390                 0.5041158
INFO  [18:29:43.317] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:29:43.317] [bbotk]  0.03862504 <list[8]>              FALSE     0.04375638        0      0
INFO  [18:29:43.317] [bbotk]  runtime_learners                                uhash
INFO  [18:29:43.317] [bbotk]           121.024 10c2c261-88c8-4ffa-9bae-0a843e100c49
INFO  [18:29:45.432] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 57 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:29:51.500] [bbotk] Evaluating 1 configuration(s)
INFO  [18:29:51.552] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:29:51.641] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:30:29.064] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:31:08.958] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:31:32.595] [mlr3] Finished benchmark
INFO  [18:31:32.692] [bbotk] Result of batch 27:
INFO  [18:31:32.768] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:31:32.768] [bbotk]               1.706774                         0.1366029
INFO  [18:31:32.768] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:31:32.768] [bbotk]                         0.3341814           -1.945164              0.2863289
INFO  [18:31:32.768] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:31:32.768] [bbotk]                         18                    1761                 0.7048709
INFO  [18:31:32.768] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:31:32.768] [bbotk]  0.03568978 <list[8]>              FALSE     0.03761343        0      0
INFO  [18:31:32.768] [bbotk]  runtime_learners                                uhash
INFO  [18:31:32.768] [bbotk]           100.512 4098df14-bc69-44cb-84ac-6c8dbb9dd4ae
INFO  [18:31:34.247] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 58 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:31:40.231] [bbotk] Evaluating 1 configuration(s)
INFO  [18:31:40.261] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:31:40.396] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:32:46.830] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:33:59.005] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:35:12.850] [mlr3] Finished benchmark
INFO  [18:35:13.049] [bbotk] Result of batch 28:
INFO  [18:35:13.171] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:35:13.171] [bbotk]              0.1072383                         0.8956866
INFO  [18:35:13.171] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:35:13.171] [bbotk]                         0.9923011           -1.722337             -0.5901107
INFO  [18:35:13.171] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:35:13.171] [bbotk]                          2                    4235                  0.340748
INFO  [18:35:13.171] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:35:13.171] [bbotk]  0.03464918 <list[8]>              FALSE     0.03003955        0      0
INFO  [18:35:13.171] [bbotk]  runtime_learners                                uhash
INFO  [18:35:13.171] [bbotk]           211.084 cc500f1d-2312-4244-bf78-41825b32e63f
INFO  [18:35:15.135] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 59 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:35:19.657] [bbotk] Evaluating 1 configuration(s)
INFO  [18:35:19.812] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:35:19.906] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:35:35.735] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:35:57.920] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:36:14.341] [mlr3] Finished benchmark
INFO  [18:36:14.510] [bbotk] Result of batch 29:
INFO  [18:36:14.670] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:36:14.670] [bbotk]              -6.101869                         0.5524009
INFO  [18:36:14.670] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:36:14.670] [bbotk]                         0.3635082           -3.698982              -1.060217
INFO  [18:36:14.670] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:36:14.670] [bbotk]                         20                     510                 0.1522169
INFO  [18:36:14.670] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:36:14.670] [bbotk]  0.03360824 <list[8]>              FALSE     0.03198803        0      0
INFO  [18:36:14.670] [bbotk]  runtime_learners                                uhash
INFO  [18:36:14.670] [bbotk]            53.603 5a04c4e4-a354-4dae-b8a4-f4dbeec4ec29
INFO  [18:36:17.544] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 60 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:36:23.418] [bbotk] Evaluating 1 configuration(s)
INFO  [18:36:23.459] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:36:23.624] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:37:42.864] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:39:29.472] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [18:41:42.004] [mlr3] Finished benchmark
INFO  [18:41:42.215] [bbotk] Result of batch 30:
INFO  [18:41:42.291] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:41:42.291] [bbotk]             -0.5504121                         0.6987425
INFO  [18:41:42.291] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:41:42.291] [bbotk]                         0.9285793           -8.456826              -3.324713
INFO  [18:41:42.291] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:41:42.291] [bbotk]                         13                    4076                 0.6972958
INFO  [18:41:42.291] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:41:42.291] [bbotk]  0.03351459 <list[8]>              FALSE      0.0452111        0      0
INFO  [18:41:42.291] [bbotk]  runtime_learners                                uhash
INFO  [18:41:42.291] [bbotk]           318.103 73b18a0b-8718-4912-9d12-c747b2968aeb
INFO  [18:41:46.698] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 61 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:42:04.058] [bbotk] Evaluating 1 configuration(s)
INFO  [18:42:04.248] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:42:04.432] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:42:43.039] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:43:21.946] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:44:11.083] [mlr3] Finished benchmark
INFO  [18:44:11.359] [bbotk] Result of batch 31:
INFO  [18:44:11.409] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:44:11.409] [bbotk]              -6.323677                         0.6233322
INFO  [18:44:11.409] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:44:11.409] [bbotk]                         0.6786241           -1.364212               4.665752
INFO  [18:44:11.409] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:44:11.409] [bbotk]                         12                    4655                   0.29215
INFO  [18:44:11.409] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:44:11.409] [bbotk]  0.03230581 <list[8]>              FALSE      0.0291038        0      0
INFO  [18:44:11.409] [bbotk]  runtime_learners                                uhash
INFO  [18:44:11.409] [bbotk]           126.175 8f2e648f-e0a3-4bae-b2a0-30abd7dab8bb
WARN  [18:44:13.698] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:44:13.731] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 62 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:44:20.633] [bbotk] Evaluating 1 configuration(s)
INFO  [18:44:20.933] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:44:21.309] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:45:09.159] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:45:45.294] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:46:37.355] [mlr3] Finished benchmark
INFO  [18:46:37.602] [bbotk] Result of batch 32:
INFO  [18:46:37.724] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:46:37.724] [bbotk]               3.105534                         0.6236925
INFO  [18:46:37.724] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:46:37.724] [bbotk]                         0.9734049           -2.941322               5.637365
INFO  [18:46:37.724] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:46:37.724] [bbotk]                         11                    2727                 0.3139115
INFO  [18:46:37.724] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:46:37.724] [bbotk]  0.03248423 <list[8]>              FALSE     0.07383098        0      0
INFO  [18:46:37.724] [bbotk]  runtime_learners                                uhash
INFO  [18:46:37.724] [bbotk]           135.435 177f0156-8392-44b9-946b-a28772cfb2ff
INFO  [18:46:40.496] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 63 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:46:48.159] [bbotk] Evaluating 1 configuration(s)
INFO  [18:46:48.424] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:46:48.618] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:47:16.085] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:47:58.309] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [18:48:41.334] [mlr3] Finished benchmark
INFO  [18:48:41.459] [bbotk] Result of batch 33:
INFO  [18:48:41.522] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:48:41.522] [bbotk]               0.749231                         0.2469374
INFO  [18:48:41.522] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:48:41.522] [bbotk]                         0.8999877          -0.7878177              -4.473529
INFO  [18:48:41.522] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:48:41.522] [bbotk]                          8                    4664                 0.6421351
INFO  [18:48:41.522] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:48:41.522] [bbotk]  0.03216724 <list[8]>              FALSE     0.03285804        0      0
INFO  [18:48:41.522] [bbotk]  runtime_learners                                uhash
INFO  [18:48:41.522] [bbotk]           112.223 f9114835-a74b-4a9c-bfc8-ef64fa666586
INFO  [18:48:44.134] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 64 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:48:53.738] [bbotk] Evaluating 1 configuration(s)
INFO  [18:48:53.781] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:48:53.795] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:49:18.982] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:49:46.985] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:50:20.732] [mlr3] Finished benchmark
INFO  [18:50:21.139] [bbotk] Result of batch 34:
INFO  [18:50:21.180] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:50:21.180] [bbotk]              -2.624103                         0.5109861
INFO  [18:50:21.180] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:50:21.180] [bbotk]                           0.37318           -3.108226              -3.032513
INFO  [18:50:21.180] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:50:21.180] [bbotk]                         12                    2467                 0.3875725
INFO  [18:50:21.180] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:50:21.180] [bbotk]  0.02965757 <list[8]>              FALSE       0.027496        0      0
INFO  [18:50:21.180] [bbotk]  runtime_learners                                uhash
INFO  [18:50:21.180] [bbotk]            86.768 79c0f059-146c-4bcf-b8c2-1a501ca1806b
INFO  [18:50:24.023] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 65 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:50:30.251] [bbotk] Evaluating 1 configuration(s)
INFO  [18:50:30.311] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:50:30.361] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:50:43.584] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:51:04.714] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:51:28.256] [mlr3] Finished benchmark
INFO  [18:51:29.377] [bbotk] Result of batch 35:
INFO  [18:51:29.603] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:51:29.603] [bbotk]              -3.640858                         0.5050809
INFO  [18:51:29.603] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:51:29.603] [bbotk]                         0.6099511           -1.048172                1.59455
INFO  [18:51:29.603] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:51:29.603] [bbotk]                         16                     457                 0.7513624
INFO  [18:51:29.603] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:51:29.603] [bbotk]  0.03028042 <list[8]>              FALSE     0.02738448        0      0
INFO  [18:51:29.603] [bbotk]  runtime_learners                                uhash
INFO  [18:51:29.603] [bbotk]            56.474 3820ae8e-1390-446e-bd1e-16676cc2b808
INFO  [18:51:33.079] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 66 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:51:44.450] [bbotk] Evaluating 1 configuration(s)
INFO  [18:51:44.626] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:51:44.681] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:52:34.192] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:53:25.566] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:54:24.931] [mlr3] Finished benchmark
INFO  [18:54:25.415] [bbotk] Result of batch 36:
INFO  [18:54:25.498] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:54:25.498] [bbotk]             -0.4147726                         0.8034067
INFO  [18:54:25.498] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:54:25.498] [bbotk]                         0.3306347           -1.328109               2.346716
INFO  [18:54:25.498] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:54:25.498] [bbotk]                         17                    4588                 0.3474346
INFO  [18:54:25.498] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:54:25.498] [bbotk]  0.02904798 <list[8]>              FALSE     0.02938577        0      0
INFO  [18:54:25.498] [bbotk]  runtime_learners                                uhash
INFO  [18:54:25.498] [bbotk]           160.032 b040700e-5fc7-487c-868d-5c2af0bcda43
INFO  [18:54:28.855] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 67 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:54:40.560] [bbotk] Evaluating 1 configuration(s)
INFO  [18:54:40.664] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:54:40.685] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:55:10.350] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:55:44.073] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:56:11.097] [mlr3] Finished benchmark
INFO  [18:56:11.910] [bbotk] Result of batch 37:
INFO  [18:56:11.971] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:56:11.971] [bbotk]              -4.867249                         0.1864686
INFO  [18:56:11.971] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:56:11.971] [bbotk]                         0.2550995           -4.158162              -2.442087
INFO  [18:56:11.971] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:56:11.971] [bbotk]                          1                    1607                 0.1673115
INFO  [18:56:11.971] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:56:11.971] [bbotk]  0.02983848 <list[8]>              FALSE     0.03004029        0      0
INFO  [18:56:11.971] [bbotk]  runtime_learners                                uhash
INFO  [18:56:11.971] [bbotk]             90.22 e345197d-4b17-4041-b4cb-89bf2994917b
INFO  [18:56:14.166] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 68 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:56:26.655] [bbotk] Evaluating 1 configuration(s)
INFO  [18:56:26.689] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:56:26.707] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:57:30.741] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:58:23.176] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:59:41.969] [mlr3] Finished benchmark
INFO  [18:59:42.041] [bbotk] Result of batch 38:
INFO  [18:59:42.050] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:59:42.050] [bbotk]              0.6076232                         0.9133433
INFO  [18:59:42.050] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:59:42.050] [bbotk]                         0.7988888           -1.782144              -6.341174
INFO  [18:59:42.050] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:59:42.050] [bbotk]                         19                    4430                 0.2138048
INFO  [18:59:42.050] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:59:42.050] [bbotk]  0.02954123 <list[8]>              FALSE     0.02885483        0      0
INFO  [18:59:42.050] [bbotk]  runtime_learners                                uhash
INFO  [18:59:42.050] [bbotk]           194.936 146ff567-63f6-4582-8156-c8bb810aff07
INFO  [18:59:47.335] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 69 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:00:05.549] [bbotk] Evaluating 1 configuration(s)
INFO  [19:00:05.599] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:00:05.633] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:01:05.694] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:01:53.302] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:03:10.720] [mlr3] Finished benchmark
INFO  [19:03:12.336] [bbotk] Result of batch 39:
INFO  [19:03:12.374] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:03:12.374] [bbotk]              -6.063346                          0.593577
INFO  [19:03:12.374] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:03:12.374] [bbotk]                         0.5661619           -2.595641              -3.353398
INFO  [19:03:12.374] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:03:12.374] [bbotk]                         20                    3332                 0.1760844
INFO  [19:03:12.374] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:03:12.374] [bbotk]  0.02774381 <list[8]>              FALSE     0.02495684        0      0
INFO  [19:03:12.374] [bbotk]  runtime_learners                                uhash
INFO  [19:03:12.374] [bbotk]           184.807 d7e49c1a-73ba-4e4f-bf29-6e7859a7010a
INFO  [19:03:27.880] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 70 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:03:38.345] [bbotk] Evaluating 1 configuration(s)
INFO  [19:03:38.481] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:03:38.554] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:04:10.689] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:04:45.421] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:05:31.181] [mlr3] Finished benchmark
INFO  [19:05:31.257] [bbotk] Result of batch 40:
INFO  [19:05:31.267] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:05:31.267] [bbotk]              -4.087363                         0.6641059
INFO  [19:05:31.267] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:05:31.267] [bbotk]                         0.7699854          -0.9527928              -6.608056
INFO  [19:05:31.267] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:05:31.267] [bbotk]                         17                    2333                  0.846681
INFO  [19:05:31.267] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:05:31.267] [bbotk]  0.02602835 <list[8]>              FALSE     0.02979932        0      0
INFO  [19:05:31.267] [bbotk]  runtime_learners                                uhash
INFO  [19:05:31.267] [bbotk]           112.231 b9b48f2a-c717-498e-b13a-59c2f79b383f
INFO  [19:05:32.693] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 71 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:05:46.396] [bbotk] Evaluating 1 configuration(s)
INFO  [19:05:46.515] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:05:46.922] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:06:25.143] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:06:55.749] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:07:32.372] [mlr3] Finished benchmark
INFO  [19:07:33.328] [bbotk] Result of batch 41:
INFO  [19:07:33.352] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:07:33.352] [bbotk]              -1.421616                         0.8452256
INFO  [19:07:33.352] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:07:33.352] [bbotk]                          0.795582           -1.173453              0.2967643
INFO  [19:07:33.352] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:07:33.352] [bbotk]                         10                    2200                 0.5391086
INFO  [19:07:33.352] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:07:33.352] [bbotk]  0.02677581 <list[8]>              FALSE     0.03095353        0      0
INFO  [19:07:33.352] [bbotk]  runtime_learners                                uhash
INFO  [19:07:33.352] [bbotk]            105.01 33a5fa34-6dcf-4999-be46-457d8cce4594
INFO  [19:07:36.012] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 72 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:07:51.995] [bbotk] Evaluating 1 configuration(s)
INFO  [19:07:52.056] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:07:52.101] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:08:41.321] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:09:27.600] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:10:00.632] [mlr3] Finished benchmark
INFO  [19:10:01.454] [bbotk] Result of batch 42:
INFO  [19:10:01.463] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:10:01.463] [bbotk]              -6.721567                         0.2325134
INFO  [19:10:01.463] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:10:01.463] [bbotk]                         0.5474319           -2.318399               1.885059
INFO  [19:10:01.463] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:10:01.463] [bbotk]                         15                    3449                 0.6678839
INFO  [19:10:01.463] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:10:01.463] [bbotk]  0.02451588 <list[8]>              FALSE      0.0273249        0      0
INFO  [19:10:01.463] [bbotk]  runtime_learners                                uhash
INFO  [19:10:01.463] [bbotk]           128.213 8d099893-41af-4b69-936d-84cb51cd56b7
INFO  [19:10:03.580] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 73 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:10:12.249] [bbotk] Evaluating 1 configuration(s)
INFO  [19:10:12.396] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:10:12.452] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:11:41.509] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:13:00.460] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:14:01.569] [mlr3] Finished benchmark
INFO  [19:14:02.015] [bbotk] Result of batch 43:
INFO  [19:14:02.025] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:14:02.025] [bbotk]              -2.629798                         0.2811789
INFO  [19:14:02.025] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:14:02.025] [bbotk]                         0.9800744           -2.559936              -6.761803
INFO  [19:14:02.025] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:14:02.025] [bbotk]                          7                    4103                 0.4166586
INFO  [19:14:02.025] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:14:02.025] [bbotk]  0.02388073 <list[8]>              FALSE     0.02744886        0      0
INFO  [19:14:02.025] [bbotk]  runtime_learners                                uhash
INFO  [19:14:02.025] [bbotk]           228.918 4410a2db-5247-46b6-b520-e84734738371
INFO  [19:14:15.746] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 74 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:14:33.403] [bbotk] Evaluating 1 configuration(s)
INFO  [19:14:33.448] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:14:33.471] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:15:02.643] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:15:30.933] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [19:15:59.100] [mlr3] Finished benchmark
INFO  [19:16:00.193] [bbotk] Result of batch 44:
INFO  [19:16:00.202] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:16:00.202] [bbotk]                2.29195                         0.8105163
INFO  [19:16:00.202] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:16:00.202] [bbotk]                         0.4604444           -3.219772              -3.206293
INFO  [19:16:00.202] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:16:00.202] [bbotk]                         11                     432                 0.6947742
INFO  [19:16:00.202] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:16:00.202] [bbotk]  0.02396838 <list[8]>              FALSE     0.04245359        0      0
INFO  [19:16:00.202] [bbotk]  runtime_learners                                uhash
INFO  [19:16:00.202] [bbotk]             85.47 3364e5f0-c15e-4c4b-9e00-4f6dbf935473
INFO  [19:16:01.329] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 75 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:16:24.208] [bbotk] Evaluating 1 configuration(s)
INFO  [19:16:24.491] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:16:24.680] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:17:06.540] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:18:01.753] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:18:50.494] [mlr3] Finished benchmark
INFO  [19:18:50.712] [bbotk] Result of batch 45:
INFO  [19:18:50.817] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:18:50.817] [bbotk]              -5.979039                         0.3772387
INFO  [19:18:50.817] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:18:50.817] [bbotk]                         0.1458617           -5.292919              -2.128634
INFO  [19:18:50.817] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:18:50.817] [bbotk]                         10                    1870                 0.5490647
INFO  [19:18:50.817] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:18:50.817] [bbotk]  0.02481217 <list[8]>              FALSE     0.03412509        0      0
INFO  [19:18:50.817] [bbotk]  runtime_learners                                uhash
INFO  [19:18:50.817] [bbotk]           145.621 e649a9a1-ee33-489c-8662-b5d7369a8878
INFO  [19:18:54.349] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 76 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:19:14.403] [bbotk] Evaluating 1 configuration(s)
INFO  [19:19:14.626] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:19:14.772] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:20:04.635] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:21:10.603] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [19:21:55.246] [mlr3] Finished benchmark
INFO  [19:21:57.447] [bbotk] Result of batch 46:
INFO  [19:21:57.455] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:21:57.455] [bbotk]              -2.348432                         0.4630878
INFO  [19:21:57.455] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:21:57.455] [bbotk]                         0.2391481           -5.678581                3.25273
INFO  [19:21:57.455] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:21:57.455] [bbotk]                         19                    1461                 0.9687875
INFO  [19:21:57.455] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:21:57.455] [bbotk]  0.02472467 <list[8]>              FALSE     0.04020644        0      0
INFO  [19:21:57.455] [bbotk]  runtime_learners                                uhash
INFO  [19:21:57.455] [bbotk]           159.672 9e61f4a3-2e12-4bdb-a81f-a0ff5ae8abdc
WARN  [19:22:04.253] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:22:04.297] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 77 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:22:17.402] [bbotk] Evaluating 1 configuration(s)
INFO  [19:22:17.862] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:22:18.237] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:23:19.119] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:24:30.935] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:25:51.575] [mlr3] Finished benchmark
INFO  [19:25:51.752] [bbotk] Result of batch 47:
INFO  [19:25:51.803] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:25:51.803] [bbotk]              -6.504299                         0.9598395
INFO  [19:25:51.803] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:25:51.803] [bbotk]                         0.3287783           -4.065603               3.270427
INFO  [19:25:51.803] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:25:51.803] [bbotk]                         13                    3106                 0.4167121
INFO  [19:25:51.803] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:25:51.803] [bbotk]  0.02306498 <list[8]>              FALSE     0.03149328        0      0
INFO  [19:25:51.803] [bbotk]  runtime_learners                                uhash
INFO  [19:25:51.803] [bbotk]           212.969 e903901a-e1dd-4aeb-8d77-d1e3340b784b
INFO  [19:25:55.538] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 78 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:26:08.752] [bbotk] Evaluating 1 configuration(s)
INFO  [19:26:09.036] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:26:09.928] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:26:31.472] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:26:56.446] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:27:20.568] [mlr3] Finished benchmark
INFO  [19:27:20.705] [bbotk] Result of batch 48:
INFO  [19:27:20.715] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:27:20.715] [bbotk]              -2.837284                         0.7688341
INFO  [19:27:20.715] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:27:20.715] [bbotk]                          0.901993           -2.848706              -6.827701
INFO  [19:27:20.715] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:27:20.715] [bbotk]                         14                     232                 0.3922378
INFO  [19:27:20.715] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:27:20.715] [bbotk]  0.02302107 <list[8]>              FALSE     0.02941938        0      0
INFO  [19:27:20.715] [bbotk]  runtime_learners                                uhash
INFO  [19:27:20.715] [bbotk]            70.357 541f385f-f793-4244-ad30-338cc304b8d8
INFO  [19:27:27.099] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 79 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:27:36.661] [bbotk] Evaluating 1 configuration(s)
INFO  [19:27:37.084] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:27:37.228] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:29:10.027] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:30:18.791] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:31:08.977] [mlr3] Finished benchmark
INFO  [19:31:09.038] [bbotk] Result of batch 49:
INFO  [19:31:09.081] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:31:09.081] [bbotk]              -2.676256                          0.781425
INFO  [19:31:09.081] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:31:09.081] [bbotk]                         0.2309083           -2.961185               2.948878
INFO  [19:31:09.081] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:31:09.081] [bbotk]                         14                    4922                 0.9754071
INFO  [19:31:09.081] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:31:09.081] [bbotk]  0.02654137 <list[8]>              FALSE     0.03150528        0      0
INFO  [19:31:09.081] [bbotk]  runtime_learners                                uhash
INFO  [19:31:09.081] [bbotk]           211.227 f8dd61e4-2235-45f6-bf99-5800b5d23e31
INFO  [19:31:11.189] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 80 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:31:18.600] [bbotk] Evaluating 1 configuration(s)
INFO  [19:31:18.633] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:31:18.650] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:32:31.066] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:33:45.848] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [19:35:46.740] [mlr3] Finished benchmark
INFO  [19:35:47.047] [bbotk] Result of batch 50:
INFO  [19:35:47.134] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:35:47.134] [bbotk]                2.63921                         0.7079324
INFO  [19:35:47.134] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:35:47.134] [bbotk]                          0.749288           -6.142379               5.008205
INFO  [19:35:47.134] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:35:47.134] [bbotk]                          6                    2868                 0.7517359
INFO  [19:35:47.134] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:35:47.134] [bbotk]  0.02317763 <list[8]>              FALSE     0.04420772        0      0
INFO  [19:35:47.134] [bbotk]  runtime_learners                                uhash
INFO  [19:35:47.134] [bbotk]           267.877 80a13a4b-d9ec-460f-95f5-f022b55be060
INFO  [19:35:48.501] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 81 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:36:01.083] [bbotk] Evaluating 1 configuration(s)
INFO  [19:36:01.226] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:36:01.295] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:36:44.530] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:37:47.949] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:38:32.391] [mlr3] Finished benchmark
INFO  [19:38:32.522] [bbotk] Result of batch 51:
INFO  [19:38:32.583] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:38:32.583] [bbotk]              0.2774034                         0.6101805
INFO  [19:38:32.583] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:38:32.583] [bbotk]                         0.7213007           -2.585984               2.091025
INFO  [19:38:32.583] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:38:32.583] [bbotk]                          8                    2931                  0.245067
INFO  [19:38:32.583] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:38:32.583] [bbotk]  0.02278011 <list[8]>              FALSE     0.03162029        0      0
INFO  [19:38:32.583] [bbotk]  runtime_learners                                uhash
INFO  [19:38:32.583] [bbotk]           150.623 53fdbb7a-16d2-4374-a6cf-0971e0ac1210
INFO  [19:38:34.265] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 82 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:38:55.705] [bbotk] Evaluating 1 configuration(s)
INFO  [19:38:56.120] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:38:56.205] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:40:05.603] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:41:16.478] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:42:20.911] [mlr3] Finished benchmark
INFO  [19:42:21.537] [bbotk] Result of batch 52:
INFO  [19:42:21.555] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:42:21.555] [bbotk]              -1.414361                         0.6247178
INFO  [19:42:21.555] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:42:21.555] [bbotk]                          0.751489           -8.235979              -3.608317
INFO  [19:42:21.555] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:42:21.555] [bbotk]                         20                    2053                  0.398921
INFO  [19:42:21.555] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:42:21.555] [bbotk]  0.02265641 <list[8]>              FALSE     0.04626703        0      0
INFO  [19:42:21.555] [bbotk]  runtime_learners                                uhash
INFO  [19:42:21.555] [bbotk]           203.744 b165b60d-7365-4c47-a3d1-83b087a79fc3
INFO  [19:42:24.561] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 83 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:42:47.022] [bbotk] Evaluating 1 configuration(s)
INFO  [19:42:47.089] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:42:47.104] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:43:46.066] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:44:34.052] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:45:21.753] [mlr3] Finished benchmark
INFO  [19:45:21.873] [bbotk] Result of batch 53:
INFO  [19:45:21.896] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:45:21.896] [bbotk]              -6.780176                          0.184835
INFO  [19:45:21.896] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:45:21.896] [bbotk]                          0.438866           -4.571828              -2.933518
INFO  [19:45:21.896] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:45:21.896] [bbotk]                         12                    3820                  0.209618
INFO  [19:45:21.896] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:45:21.896] [bbotk]  0.02342274 <list[8]>              FALSE     0.02786391        0      0
INFO  [19:45:21.896] [bbotk]  runtime_learners                                uhash
INFO  [19:45:21.896] [bbotk]           154.119 28a23d1e-80bc-4937-ae25-85cbe6d8e4a5
WARN  [19:45:30.988] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:45:31.016] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 84 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:45:45.416] [bbotk] Evaluating 1 configuration(s)
INFO  [19:45:45.599] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:45:45.643] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:46:14.141] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:46:45.348] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:47:13.945] [mlr3] Finished benchmark
INFO  [19:47:14.261] [bbotk] Result of batch 54:
INFO  [19:47:14.354] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:47:14.354] [bbotk]              -5.713725                         0.6527906
INFO  [19:47:14.354] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:47:14.354] [bbotk]                         0.7213802           -1.394718             -0.1320725
INFO  [19:47:14.354] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:47:14.354] [bbotk]                         13                    1056                 0.6669415
INFO  [19:47:14.354] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:47:14.354] [bbotk]  0.02178411 <list[8]>              FALSE     0.02758872        0      0
INFO  [19:47:14.354] [bbotk]  runtime_learners                                uhash
INFO  [19:47:14.354] [bbotk]            87.854 e2eb39e3-ce40-49db-aa67-f7b40cbec3a1
INFO  [19:47:15.698] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 85 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:47:39.213] [bbotk] Evaluating 1 configuration(s)
INFO  [19:47:39.356] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:47:39.367] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:48:25.066] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:49:29.690] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:50:16.788] [mlr3] Finished benchmark
INFO  [19:50:16.872] [bbotk] Result of batch 55:
INFO  [19:50:16.892] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:50:16.892] [bbotk]              -2.173395                         0.5616105
INFO  [19:50:16.892] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:50:16.892] [bbotk]                         0.9682227           -2.559749                -2.8426
INFO  [19:50:16.892] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:50:16.892] [bbotk]                          2                    2060                 0.7172482
INFO  [19:50:16.892] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:50:16.892] [bbotk]  0.02042806 <list[8]>              FALSE     0.03282377        0      0
INFO  [19:50:16.892] [bbotk]  runtime_learners                                uhash
INFO  [19:50:16.892] [bbotk]           156.915 76c4bf2a-4865-4ef9-8f21-b81b4b9b1dae
INFO  [19:50:21.767] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 86 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:50:42.452] [bbotk] Evaluating 1 configuration(s)
INFO  [19:50:42.598] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:50:42.632] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:52:15.282] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:54:00.577] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [19:55:42.110] [mlr3] Finished benchmark
INFO  [19:55:43.090] [bbotk] Result of batch 56:
INFO  [19:55:43.269] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:55:43.269] [bbotk]                2.16656                         0.6965998
INFO  [19:55:43.269] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:55:43.269] [bbotk]                         0.6735421           -5.366821              -5.653445
INFO  [19:55:43.269] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:55:43.269] [bbotk]                         19                    3959                 0.5507316
INFO  [19:55:43.269] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:55:43.269] [bbotk]  0.02065742 <list[8]>              FALSE     0.04273379        0      0
INFO  [19:55:43.269] [bbotk]  runtime_learners                                uhash
INFO  [19:55:43.269] [bbotk]           298.935 50f52330-5c90-463e-bcbd-97075685efee
INFO  [19:55:46.244] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 87 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:55:56.204] [bbotk] Evaluating 1 configuration(s)
INFO  [19:55:56.462] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:55:56.579] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:56:52.787] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:58:37.212] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:59:39.412] [mlr3] Finished benchmark
INFO  [19:59:39.716] [bbotk] Result of batch 57:
INFO  [19:59:39.740] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:59:39.740] [bbotk]              -4.880994                         0.1958742
INFO  [19:59:39.740] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:59:39.740] [bbotk]                         0.7931815           -1.512606               1.867234
INFO  [19:59:39.740] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:59:39.740] [bbotk]                         17                    4667                  0.304575
INFO  [19:59:39.740] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:59:39.740] [bbotk]  0.02052914 <list[8]>              FALSE     0.02699615        0      0
INFO  [19:59:39.740] [bbotk]  runtime_learners                                uhash
INFO  [19:59:39.740] [bbotk]           221.722 b9ec3566-bcb4-473f-b940-a27cb12bc08e
INFO  [19:59:47.086] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 88 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:00:02.357] [bbotk] Evaluating 1 configuration(s)
INFO  [20:00:02.585] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:00:02.638] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:02:03.333] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:03:15.918] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:03:59.404] [mlr3] Finished benchmark
INFO  [20:03:59.466] [bbotk] Result of batch 58:
INFO  [20:03:59.472] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:03:59.472] [bbotk]             -0.2101454                         0.1875276
INFO  [20:03:59.472] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:03:59.472] [bbotk]                         0.7679544           -7.042783              0.8370124
INFO  [20:03:59.472] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:03:59.472] [bbotk]                         20                    3448                 0.8175534
INFO  [20:03:59.472] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:03:59.472] [bbotk]  0.02043064 <list[8]>              FALSE      0.0403191        0      0
INFO  [20:03:59.472] [bbotk]  runtime_learners                                uhash
INFO  [20:03:59.472] [bbotk]           236.038 6416d810-60b1-4f5b-8ac1-b8d11e2272ea
INFO  [20:04:03.172] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 89 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:04:16.696] [bbotk] Evaluating 1 configuration(s)
INFO  [20:04:16.717] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:04:16.782] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:04:51.810] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:05:24.563] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:06:30.175] [mlr3] Finished benchmark
INFO  [20:06:30.449] [bbotk] Result of batch 59:
INFO  [20:06:30.497] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:06:30.497] [bbotk]              -1.314228                         0.4851812
INFO  [20:06:30.497] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:06:30.497] [bbotk]                          0.986947           -2.689221              -1.537605
INFO  [20:06:30.497] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:06:30.497] [bbotk]                         15                    4237                 0.1250074
INFO  [20:06:30.497] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:06:30.497] [bbotk]  0.01979661 <list[8]>              FALSE      0.0269116        0      0
INFO  [20:06:30.497] [bbotk]  runtime_learners                                uhash
INFO  [20:06:30.497] [bbotk]           133.286 66a66fdc-ebc3-48d7-9e6c-774817a5165d
INFO  [20:06:34.119] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 90 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:06:37.330] [bbotk] Evaluating 1 configuration(s)
INFO  [20:06:38.204] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:06:38.559] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:07:16.772] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:08:09.543] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:09:15.980] [mlr3] Finished benchmark
INFO  [20:09:16.219] [bbotk] Result of batch 60:
INFO  [20:09:16.389] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:09:16.389] [bbotk]              -1.030043                         0.9355472
INFO  [20:09:16.389] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:09:16.389] [bbotk]                          0.404559           -2.944055                3.51383
INFO  [20:09:16.389] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:09:16.389] [bbotk]                         16                    1098                 0.9245136
INFO  [20:09:16.389] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:09:16.389] [bbotk]  0.01937985 <list[8]>              FALSE     0.03494767        0      0
INFO  [20:09:16.389] [bbotk]  runtime_learners                                uhash
INFO  [20:09:16.389] [bbotk]            157.07 46cd604a-a734-4a09-abb7-da27ef29170d
WARN  [20:09:22.204] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [20:09:22.232] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 91 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:09:42.962] [bbotk] Evaluating 1 configuration(s)
INFO  [20:09:46.853] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:09:46.974] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:10:34.619] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:11:21.879] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:12:24.263] [mlr3] Finished benchmark
INFO  [20:12:24.918] [bbotk] Result of batch 61:
INFO  [20:12:24.987] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:12:24.987] [bbotk]              -3.317021                         0.6136218
INFO  [20:12:24.987] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:12:24.987] [bbotk]                         0.3236236           -1.331419              -2.820705
INFO  [20:12:24.987] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:12:24.987] [bbotk]                          4                    3856                 0.8138107
INFO  [20:12:24.987] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:12:24.987] [bbotk]  0.0178795 <list[8]>              FALSE     0.02624277        0      0
INFO  [20:12:24.987] [bbotk]  runtime_learners                                uhash
INFO  [20:12:24.987] [bbotk]            156.67 9ee7f916-5eba-4a0e-9a6c-83796a3e132c
INFO  [20:12:29.643] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 92 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:12:40.357] [bbotk] Evaluating 1 configuration(s)
INFO  [20:12:40.868] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:12:41.148] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:13:47.134] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:14:54.062] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:16:07.035] [mlr3] Finished benchmark
INFO  [20:16:07.251] [bbotk] Result of batch 62:
INFO  [20:16:07.265] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:16:07.265] [bbotk]              -5.174112                         0.6780553
INFO  [20:16:07.265] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:16:07.265] [bbotk]                         0.2995425           -5.000924              -6.648946
INFO  [20:16:07.265] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:16:07.265] [bbotk]                         11                    2259                 0.6062354
INFO  [20:16:07.265] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:16:07.265] [bbotk]  0.01905683 <list[8]>              FALSE      0.0271607        0      0
INFO  [20:16:07.265] [bbotk]  runtime_learners                                uhash
INFO  [20:16:07.265] [bbotk]           201.806 3bafdeb6-fe59-4420-8b88-ad9af82e7c4e
INFO  [20:16:09.750] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 93 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:16:25.598] [bbotk] Evaluating 1 configuration(s)
INFO  [20:16:25.705] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:16:25.766] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:18:37.775] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:20:01.188] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [20:21:06.234] [mlr3] Finished benchmark
INFO  [20:21:06.311] [bbotk] Result of batch 63:
INFO  [20:21:06.318] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:21:06.318] [bbotk]                3.44345                          0.317932
INFO  [20:21:06.318] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:21:06.318] [bbotk]                         0.9668498           -2.032627              0.9612418
INFO  [20:21:06.318] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:21:06.318] [bbotk]                          1                    4511                 0.9160082
INFO  [20:21:06.318] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:21:06.318] [bbotk]  0.02003903 <list[8]>              FALSE     0.05437571        0      0
INFO  [20:21:06.318] [bbotk]  runtime_learners                                uhash
INFO  [20:21:06.318] [bbotk]           280.369 de1db2dd-96a3-42b8-8beb-3e8706e45813
INFO  [20:21:09.073] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 94 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:21:18.244] [bbotk] Evaluating 1 configuration(s)
INFO  [20:21:18.293] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:21:18.305] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:21:36.438] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:22:09.177] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [20:23:00.171] [mlr3] Finished benchmark
INFO  [20:23:00.264] [bbotk] Result of batch 64:
INFO  [20:23:00.275] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:23:00.275] [bbotk]              -1.258522                         0.2140782
INFO  [20:23:00.275] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:23:00.275] [bbotk]                         0.9455596           -6.712573              -5.769031
INFO  [20:23:00.275] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:23:00.275] [bbotk]                         13                    2350                 0.1754743
INFO  [20:23:00.275] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:23:00.275] [bbotk]  0.01841615 <list[8]>              FALSE      0.0391612        0      0
INFO  [20:23:00.275] [bbotk]  runtime_learners                                uhash
INFO  [20:23:00.275] [bbotk]           101.771 4cbc42ea-3603-42ac-ba22-7e65d3282cea
INFO  [20:23:01.771] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 95 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:23:11.370] [bbotk] Evaluating 1 configuration(s)
INFO  [20:23:11.934] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:23:12.053] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:23:53.224] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:24:36.878] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:25:10.235] [mlr3] Finished benchmark
INFO  [20:25:10.395] [bbotk] Result of batch 65:
INFO  [20:25:10.402] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:25:10.402] [bbotk]              -3.362904                         0.3540966
INFO  [20:25:10.402] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:25:10.402] [bbotk]                         0.8340855           -1.899121              -3.737324
INFO  [20:25:10.402] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:25:10.402] [bbotk]                         17                    1270                 0.6614183
INFO  [20:25:10.402] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:25:10.402] [bbotk]  0.01748388 <list[8]>              FALSE     0.02841483        0      0
INFO  [20:25:10.402] [bbotk]  runtime_learners                                uhash
INFO  [20:25:10.402] [bbotk]           117.903 d92f5fc1-9a42-4cf7-9552-cd12ff497331
INFO  [20:25:13.459] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 96 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:25:21.806] [bbotk] Evaluating 1 configuration(s)
INFO  [20:25:21.992] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:25:22.012] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:25:46.156] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:26:09.457] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:26:32.093] [mlr3] Finished benchmark
INFO  [20:26:32.190] [bbotk] Result of batch 66:
INFO  [20:26:32.198] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:26:32.198] [bbotk]              -1.221991                         0.6153405
INFO  [20:26:32.198] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:26:32.198] [bbotk]                         0.2206817           -2.266706               5.089192
INFO  [20:26:32.198] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:26:32.198] [bbotk]                          4                    4358                 0.6529654
INFO  [20:26:32.198] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:26:32.198] [bbotk]  0.01681609 <list[8]>              FALSE      0.0308145        0      0
INFO  [20:26:32.198] [bbotk]  runtime_learners                                uhash
INFO  [20:26:32.198] [bbotk]            69.888 b14a6c2d-afaf-400d-a1c1-1fe146a23b7e
INFO  [20:26:37.515] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 97 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:26:43.327] [bbotk] Evaluating 1 configuration(s)
INFO  [20:26:43.371] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:26:43.398] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:26:58.356] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:27:28.740] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:28:11.398] [mlr3] Finished benchmark
INFO  [20:28:11.530] [bbotk] Result of batch 67:
INFO  [20:28:11.549] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:28:11.549] [bbotk]              -4.896841                         0.8963128
INFO  [20:28:11.549] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:28:11.549] [bbotk]                         0.8651512           -0.423702              0.2360044
INFO  [20:28:11.549] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:28:11.549] [bbotk]                         18                    1502                 0.2461337
INFO  [20:28:11.549] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:28:11.549] [bbotk]  0.01683577 <list[8]>              FALSE     0.02459068        0      0
INFO  [20:28:11.549] [bbotk]  runtime_learners                                uhash
INFO  [20:28:11.549] [bbotk]            87.262 07d67b68-ea12-4827-9852-f26a13273ab0
INFO  [20:28:16.945] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 98 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:28:30.415] [bbotk] Evaluating 1 configuration(s)
INFO  [20:28:30.529] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:28:30.607] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:29:09.751] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:30:31.416] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [20:31:23.194] [mlr3] Finished benchmark
INFO  [20:31:23.368] [bbotk] Result of batch 68:
INFO  [20:31:23.380] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:31:23.380] [bbotk]             -0.2783329                         0.5601772
INFO  [20:31:23.380] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:31:23.380] [bbotk]                         0.9989579        -0.001200628              -4.131965
INFO  [20:31:23.380] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:31:23.380] [bbotk]                         18                    3647                 0.5310773
INFO  [20:31:23.380] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:31:23.380] [bbotk]  0.01631744 <list[8]>              FALSE     0.03388968        0      0
INFO  [20:31:23.380] [bbotk]  runtime_learners                                uhash
INFO  [20:31:23.380] [bbotk]           172.395 1815888c-c5fc-497a-b18c-42d8599ca384
INFO  [20:31:26.785] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 99 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:31:34.527] [bbotk] Evaluating 1 configuration(s)
INFO  [20:31:34.572] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:31:34.599] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:32:14.448] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:32:48.914] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:33:25.568] [mlr3] Finished benchmark
INFO  [20:33:25.836] [bbotk] Result of batch 69:
INFO  [20:33:25.853] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:33:25.853] [bbotk]             -0.6291671                         0.3830918
INFO  [20:33:25.853] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:33:25.853] [bbotk]                         0.4651856           -4.989129               6.257315
INFO  [20:33:25.853] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:33:25.853] [bbotk]                         18                    2154                 0.5915052
INFO  [20:33:25.853] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:33:25.853] [bbotk]  0.01616665 <list[8]>              FALSE     0.04323426        0      0
INFO  [20:33:25.853] [bbotk]  runtime_learners                                uhash
INFO  [20:33:25.853] [bbotk]            110.85 991a361a-35f8-4cce-92ad-809d4fe0848b
INFO  [20:33:29.701] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 100 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:33:29.796] [bbotk] Finished optimizing after 100 evaluation(s)
INFO  [20:33:29.802] [bbotk] Result:
INFO  [20:33:29.851] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:33:29.851] [bbotk]                  <num>                             <num>
INFO  [20:33:29.851] [bbotk]              -4.896841                         0.8963128
INFO  [20:33:29.851] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:33:29.851] [bbotk]                             <num>               <num>                  <num>
INFO  [20:33:29.851] [bbotk]                         0.8651512           -0.423702              0.2360044
INFO  [20:33:29.851] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:33:29.851] [bbotk]                      <int>                   <int>                     <num>
INFO  [20:33:29.851] [bbotk]                         18                    1502                 0.2461337
INFO  [20:33:29.851] [bbotk]  learner_param_vals  x_domain classif.bbrier
INFO  [20:33:29.851] [bbotk]              <list>    <list>          <num>
INFO  [20:33:29.851] [bbotk]          <list[10]> <list[8]>     0.02459068

### [bt]: Job terminated successfully [batchtools job.id=1439]
### [bt]: Calculation finished!
