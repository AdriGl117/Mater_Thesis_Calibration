### [bt]: This is batchtools v0.9.17
### [bt]: Starting calculation of 1 jobs
### [bt]: Setting working directory to '/content/drive/MyDrive/GitHub/Mater_Thesis_Calibration'
ece.R :
Friedmann_tasks.R :
Functions.R :
ici.R :
mse_feature_effects.R :
PipeOpCalibration_TuningExperiment.R :
PipeOpCalibration.R :
PipeOpCalibrationUnion.R :
### [bt]: Memory measurement disabled
### [bt]: Starting job [batchtools job.id=1440]
### [bt]: Generating problem instance for problem '341ee781c7d79b8f' ...
### [bt]: Applying algorithm 'run_learner' on problem '341ee781c7d79b8f' for job 1440 (seed = 1563) ...
INFO  [16:16:17.280] [mlr3] Applying learner 'xgboost TwP platt' on task 'wdbc' (iter 10/10)
INFO  [16:16:18.354] [bbotk] Starting to optimize 8 parameter(s) with '<OptimizerMbo>' and '<TerminatorEvals> [n_evals=100, k=0]'
INFO  [16:16:24.511] [bbotk] Evaluating 32 configuration(s)
INFO  [16:16:25.077] [mlr3] Running benchmark with 96 resampling iterations
INFO  [16:16:25.221] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:17:51.844] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:18:34.011] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:19:39.968] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:21:22.830] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:22:28.876] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:24:04.882] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:26:47.458] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:29:33.685] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:31:29.252] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:31:52.106] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:32:19.384] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:32:55.882] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:33:24.741] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:33:48.818] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:34:18.071] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:35:14.859] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:36:20.730] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:37:02.058] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:37:45.702] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:38:30.224] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:39:27.485] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:40:22.142] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:41:41.635] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:42:54.619] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:44:42.068] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:46:28.506] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:48:15.656] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:48:55.556] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:49:26.935] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:50:05.098] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:51:11.522] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:52:10.180] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:52:57.588] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:53:58.543] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:55:10.805] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:56:12.234] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:57:03.679] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:57:41.976] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:58:26.523] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:00:04.484] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:01:19.695] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:02:17.456] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:02:52.488] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:03:22.726] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:04:05.138] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:05:08.789] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:05:56.944] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:07:03.118] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:07:46.944] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:08:31.391] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:09:26.290] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:10:24.280] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:11:35.787] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:12:33.170] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:13:44.090] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:14:50.144] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:15:38.639] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:15:55.771] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:16:11.964] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:16:30.916] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:17:23.436] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:18:01.185] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:18:42.662] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:19:06.084] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:19:29.809] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:19:52.517] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:20:26.138] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:21:23.613] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:21:53.625] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:22:29.904] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:23:10.611] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:23:42.448] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:25:01.110] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:25:30.783] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:26:17.952] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:26:35.400] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:27:03.256] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:27:22.028] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:28:08.136] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:28:48.625] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:29:39.363] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:30:42.017] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:31:28.752] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:32:07.850] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:32:41.179] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:33:22.772] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:34:11.276] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:34:25.878] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:34:44.317] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:35:01.882] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:35:59.161] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:36:33.333] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:37:25.996] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:38:11.597] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:38:54.319] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:39:50.350] [mlr3] Finished benchmark
INFO  [17:39:51.510] [bbotk] Result of batch 1:
INFO  [17:39:51.638] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:39:51.638] [bbotk]             -5.3454774                         0.3213084
INFO  [17:39:51.638] [bbotk]              1.5622780                         0.7713084
INFO  [17:39:51.638] [bbotk]             -1.8916000                         0.9963084
INFO  [17:39:51.638] [bbotk]              5.0161557                         0.5463084
INFO  [17:39:51.638] [bbotk]             -0.1646612                         0.4338084
INFO  [17:39:51.638] [bbotk]              6.7430945                         0.8838084
INFO  [17:39:51.638] [bbotk]              3.2892169                         0.2088084
INFO  [17:39:51.638] [bbotk]             -3.6185386                         0.6588084
INFO  [17:39:51.638] [bbotk]             -6.2089469                         0.8275584
INFO  [17:39:51.638] [bbotk]              0.6988086                         0.3775584
INFO  [17:39:51.638] [bbotk]             -2.7550694                         0.1525584
INFO  [17:39:51.638] [bbotk]              4.1526863                         0.6025584
INFO  [17:39:51.638] [bbotk]              5.8796251                         0.2650584
INFO  [17:39:51.638] [bbotk]             -1.0281306                         0.7150584
INFO  [17:39:51.638] [bbotk]             -4.4820080                         0.4900584
INFO  [17:39:51.638] [bbotk]              2.4257474                         0.9400584
INFO  [17:39:51.638] [bbotk]             -4.9137427                         0.9119334
INFO  [17:39:51.638] [bbotk]              1.9940127                         0.4619334
INFO  [17:39:51.638] [bbotk]             -1.4598653                         0.2369334
INFO  [17:39:51.638] [bbotk]              5.4478904                         0.6869334
INFO  [17:39:51.638] [bbotk]              3.7209516                         0.1244334
INFO  [17:39:51.638] [bbotk]             -3.1868041                         0.5744334
INFO  [17:39:51.638] [bbotk]             -6.6406816                         0.3494334
INFO  [17:39:51.638] [bbotk]              0.2670739                         0.7994334
INFO  [17:39:51.638] [bbotk]              1.1305433                         0.2931834
INFO  [17:39:51.638] [bbotk]             -5.7772122                         0.7431834
INFO  [17:39:51.638] [bbotk]             -2.3233347                         0.5181834
INFO  [17:39:51.638] [bbotk]              4.5844210                         0.9681834
INFO  [17:39:51.638] [bbotk]             -4.0502733                         0.1806834
INFO  [17:39:51.638] [bbotk]              2.8574822                         0.6306834
INFO  [17:39:51.638] [bbotk]              6.3113598                         0.4056834
INFO  [17:39:51.638] [bbotk]             -0.5963959                         0.8556834
INFO  [17:39:51.638] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:39:51.638] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:39:51.638] [bbotk]                         0.4984975         -1.21969534             -0.6187082
INFO  [17:39:51.638] [bbotk]                         0.9484975         -5.82486580              6.2890471
INFO  [17:39:51.638] [bbotk]                         0.7234975         -8.12745075             -4.0725856
INFO  [17:39:51.638] [bbotk]                         0.2734975         -3.52228043              2.8351694
INFO  [17:39:51.638] [bbotk]                         0.8359975         -6.97615821             -5.7995245
INFO  [17:39:51.638] [bbotk]                         0.3859975         -2.37098788              1.1082306
INFO  [17:39:51.638] [bbotk]                         0.6109975         -4.67357325              4.5621083
INFO  [17:39:51.638] [bbotk]                         0.1609975         -0.06840279             -2.3456470
INFO  [17:39:51.638] [bbotk]                         0.8922475         -4.09792670              3.6986389
INFO  [17:39:51.638] [bbotk]                         0.4422475         -8.70309706             -3.2091164
INFO  [17:39:51.638] [bbotk]                         0.2172475         -6.40051207              0.2447612
INFO  [17:39:51.638] [bbotk]                         0.6672475         -1.79534161             -6.6629939
INFO  [17:39:51.638] [bbotk]                         0.7797475         -0.64404906             -4.9360550
INFO  [17:39:51.638] [bbotk]                         0.3297475         -5.24921953              1.9717000
INFO  [17:39:51.638] [bbotk]                         0.5547475         -2.94663416              5.4255777
INFO  [17:39:51.638] [bbotk]                         0.1047475         -7.55180448             -1.4821776
INFO  [17:39:51.638] [bbotk]                         0.4703725         -6.11268894             -5.3677898
INFO  [17:39:51.638] [bbotk]                         0.9203725         -1.50751847              1.5399653
INFO  [17:39:51.638] [bbotk]                         0.6953725         -3.81010357             -1.9139123
INFO  [17:39:51.638] [bbotk]                         0.2453725         -8.41527389              4.9938430
INFO  [17:39:51.638] [bbotk]                         0.3578725         -7.26398134              6.7207818
INFO  [17:39:51.638] [bbotk]                         0.8078725         -2.65881102             -0.1869735
INFO  [17:39:51.638] [bbotk]                         0.1328725         -4.96139639             -3.6408509
INFO  [17:39:51.638] [bbotk]                         0.5828725         -0.35622593              3.2669042
INFO  [17:39:51.638] [bbotk]                         0.1891225         -3.23445729             -6.2312592
INFO  [17:39:51.638] [bbotk]                         0.6391225         -7.83962762              0.6764959
INFO  [17:39:51.638] [bbotk]                         0.4141225         -0.93187220              4.1303736
INFO  [17:39:51.638] [bbotk]                         0.8641225         -5.53704266             -2.7773817
INFO  [17:39:51.638] [bbotk]                         0.9766225         -8.99092018              2.4034347
INFO  [17:39:51.638] [bbotk]                         0.5266225         -4.38574984             -4.5043203
INFO  [17:39:51.638] [bbotk]                         0.7516225         -6.68833521             -1.0504429
INFO  [17:39:51.638] [bbotk]                         0.3016225         -2.08316475              5.8573124
INFO  [17:39:51.638] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:39:51.638] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:39:51.638] [bbotk]                         13                    1957                 0.6019395
INFO  [17:39:51.638] [bbotk]                          3                    4457                 0.1519395
INFO  [17:39:51.638] [bbotk]                         18                    3207                 0.8269395
INFO  [17:39:51.638] [bbotk]                          8                     707                 0.3769396
INFO  [17:39:51.638] [bbotk]                         15                      82                 0.4894396
INFO  [17:39:51.638] [bbotk]                          5                    2582                 0.9394395
INFO  [17:39:51.638] [bbotk]                         10                    1332                 0.7144395
INFO  [17:39:51.638] [bbotk]                         20                    3832                 0.2644395
INFO  [17:39:51.638] [bbotk]                         14                    3520                 0.8831895
INFO  [17:39:51.638] [bbotk]                          4                    1020                 0.4331896
INFO  [17:39:51.638] [bbotk]                         19                    2270                 0.6581895
INFO  [17:39:51.638] [bbotk]                          9                    4770                 0.2081895
INFO  [17:39:51.638] [bbotk]                          2                    1645                 0.7706895
INFO  [17:39:51.638] [bbotk]                         12                    4145                 0.3206895
INFO  [17:39:51.638] [bbotk]                         17                     395                 0.5456896
INFO  [17:39:51.638] [bbotk]                          7                    2895                 0.9956895
INFO  [17:39:51.638] [bbotk]                          1                    1489                 0.9675645
INFO  [17:39:51.638] [bbotk]                         11                    3989                 0.5175646
INFO  [17:39:51.638] [bbotk]                          6                    2739                 0.7425645
INFO  [17:39:51.638] [bbotk]                         16                     239                 0.2925645
INFO  [17:39:51.638] [bbotk]                         13                    3364                 0.6300645
INFO  [17:39:51.638] [bbotk]                          3                     864                 0.1800645
INFO  [17:39:51.638] [bbotk]                          8                    4614                 0.4050646
INFO  [17:39:51.638] [bbotk]                         18                    2114                 0.8550645
INFO  [17:39:51.638] [bbotk]                         17                    3676                 0.5738145
INFO  [17:39:51.638] [bbotk]                          7                    1176                 0.1238145
INFO  [17:39:51.638] [bbotk]                          2                    4926                 0.3488146
INFO  [17:39:51.638] [bbotk]                         12                    2426                 0.7988145
INFO  [17:39:51.638] [bbotk]                          5                    3051                 0.6863145
INFO  [17:39:51.638] [bbotk]                         15                     551                 0.2363145
INFO  [17:39:51.638] [bbotk]                         20                    4301                 0.4613146
INFO  [17:39:51.638] [bbotk]                         10                    1801                 0.9113145
INFO  [17:39:51.638] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:39:51.638] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:39:51.638] [bbotk]      0.02805554        0      0          193.252
INFO  [17:39:51.638] [bbotk]      0.26508002        0      0          263.011
INFO  [17:39:51.638] [bbotk]      0.04794898        0      0          443.525
INFO  [17:39:51.638] [bbotk]      0.31494525        0      0           86.036
INFO  [17:39:51.638] [bbotk]      0.26578989        0      0           80.668
INFO  [17:39:51.638] [bbotk]      0.31494525        0      0          163.595
INFO  [17:39:51.638] [bbotk]      0.10672566        0      0          144.983
INFO  [17:39:51.638] [bbotk]      0.03109668        0      0          206.786
INFO  [17:39:51.638] [bbotk]      0.03311808        0      0          320.840
INFO  [17:39:51.638] [bbotk]      0.22712576        0      0          108.939
INFO  [17:39:51.638] [bbotk]      0.03283219        0      0          171.904
INFO  [17:39:51.638] [bbotk]      0.31494525        0      0          193.686
INFO  [17:39:51.638] [bbotk]      0.31494525        0      0          133.703
INFO  [17:39:51.638] [bbotk]      0.03026039        0      0          229.753
INFO  [17:39:51.638] [bbotk]      0.04256369        0      0          105.982
INFO  [17:39:51.638] [bbotk]      0.05581530        0      0          175.609
INFO  [17:39:51.638] [bbotk]      0.04072060        0      0          142.306
INFO  [17:39:51.638] [bbotk]      0.03738996        0      0          185.244
INFO  [17:39:51.638] [bbotk]      0.02753236        0      0          184.993
INFO  [17:39:51.638] [bbotk]      0.31494525        0      0           52.003
INFO  [17:39:51.638] [bbotk]      0.31315627        0      0          131.443
INFO  [17:39:51.638] [bbotk]      0.02767793        0      0           69.554
INFO  [17:39:51.638] [bbotk]      0.02558729        0      0          120.776
INFO  [17:39:51.638] [bbotk]      0.02983231        0      0          108.427
INFO  [17:39:51.638] [bbotk]      0.03187052        0      0          155.171
INFO  [17:39:51.638] [bbotk]      0.16781709        0      0           63.823
INFO  [17:39:51.638] [bbotk]      0.02651265        0      0          136.928
INFO  [17:39:51.638] [bbotk]      0.31494525        0      0          147.681
INFO  [17:39:51.638] [bbotk]      0.18364327        0      0          122.989
INFO  [17:39:51.638] [bbotk]      0.22605775        0      0           50.369
INFO  [17:39:51.638] [bbotk]      0.31494525        0      0          143.841
INFO  [17:39:51.638] [bbotk]      0.03130844        0      0          139.497
INFO  [17:39:51.638] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:39:51.638] [bbotk]                                 uhash
INFO  [17:39:51.638] [bbotk]  d389e18d-620b-4142-aefd-c061c0c9f4d9
INFO  [17:39:51.638] [bbotk]  388a4308-1578-49c7-8c51-1d6843201893
INFO  [17:39:51.638] [bbotk]  61a29d37-3e65-4f68-b828-b55075527f15
INFO  [17:39:51.638] [bbotk]  60c24443-fff7-4ba6-9a40-106a23e20096
INFO  [17:39:51.638] [bbotk]  50beb269-d15d-485d-8323-57465278805a
INFO  [17:39:51.638] [bbotk]  4ef7b547-568b-41fe-8d60-4725bb365528
INFO  [17:39:51.638] [bbotk]  306b4ead-b94e-4593-9eff-3487d7f28166
INFO  [17:39:51.638] [bbotk]  0634789e-5bdf-4359-b6fe-d97d5e8eca41
INFO  [17:39:51.638] [bbotk]  815a5034-dd50-4e04-8605-a03d5f37f844
INFO  [17:39:51.638] [bbotk]  d11c76c6-9ebb-478b-9dd2-a76d83cdad67
INFO  [17:39:51.638] [bbotk]  caf21bf5-dafb-4fec-8f68-968f3b1bfae9
INFO  [17:39:51.638] [bbotk]  9f823b36-8d75-4047-9c87-afac75b7500f
INFO  [17:39:51.638] [bbotk]  2641c883-23f7-4c00-b432-b85c416d3f11
INFO  [17:39:51.638] [bbotk]  c902902d-59cc-4aa2-b05f-372103dd597e
INFO  [17:39:51.638] [bbotk]  5efdf767-0498-46ce-ab37-246370ea4bf2
INFO  [17:39:51.638] [bbotk]  0dba05f9-2ee0-489c-b79f-6632a51e413b
INFO  [17:39:51.638] [bbotk]  3831402a-1556-4946-a56e-e1ab1bb1eb2c
INFO  [17:39:51.638] [bbotk]  46a9560c-4b19-4ecd-acef-068ced6444f4
INFO  [17:39:51.638] [bbotk]  b1d58db2-1a76-4c38-b06c-132f4e2e6f88
INFO  [17:39:51.638] [bbotk]  83bcc957-bbe5-4428-a24b-2c98d59eb6fc
INFO  [17:39:51.638] [bbotk]  225d2959-470f-44b0-aba7-e18a05148e88
INFO  [17:39:51.638] [bbotk]  2e69da36-c9f4-40fe-8c43-7c56ff6b3875
INFO  [17:39:51.638] [bbotk]  c55b257a-1047-4ec6-917a-4c2f72bfddf9
INFO  [17:39:51.638] [bbotk]  19b4ff02-2e3f-45c9-a4fd-c5c973b86595
INFO  [17:39:51.638] [bbotk]  3b7b2b9c-2599-45ba-9411-d7b0e7bdd72f
INFO  [17:39:51.638] [bbotk]  f7e39b08-d960-4654-8df9-2ac1dca0204a
INFO  [17:39:51.638] [bbotk]  567d0ccc-26e7-4dd8-862d-bba9a2c6bbe2
INFO  [17:39:51.638] [bbotk]  0cf93200-b905-410f-805c-a39eadbe00d1
INFO  [17:39:51.638] [bbotk]  00611ace-acdd-4f7b-b2f3-44af18c8e05e
INFO  [17:39:51.638] [bbotk]  a0b8d3ef-e05d-42af-aa60-9bfd2541fa20
INFO  [17:39:51.638] [bbotk]  1caf3f51-94c1-4d94-a88b-56847a69c670
INFO  [17:39:51.638] [bbotk]  befdca9f-058e-4637-8544-fffa7443d738
INFO  [17:39:51.638] [bbotk]                                 uhash
WARN  [17:40:02.211] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:40:02.287] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 32 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:40:17.488] [bbotk] Evaluating 1 configuration(s)
INFO  [17:40:17.728] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:40:17.798] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:41:01.952] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:41:35.976] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:42:19.109] [mlr3] Finished benchmark
INFO  [17:42:19.241] [bbotk] Result of batch 2:
INFO  [17:42:19.295] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:42:19.295] [bbotk]               1.757245                          0.229758
INFO  [17:42:19.295] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:42:19.295] [bbotk]                          0.435747          -0.5489451               1.143963
INFO  [17:42:19.295] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:42:19.295] [bbotk]                         13                    3150                 0.9484191
INFO  [17:42:19.295] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:42:19.295] [bbotk]  0.06435648 <list[8]>              FALSE     0.03525412        0      0
INFO  [17:42:19.295] [bbotk]  runtime_learners                                uhash
INFO  [17:42:19.295] [bbotk]           120.935 1ae5699b-3ea0-4e23-894b-2bda15fe39e0
INFO  [17:42:20.596] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 33 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:42:27.214] [bbotk] Evaluating 1 configuration(s)
INFO  [17:42:27.349] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:42:27.536] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:42:44.765] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:43:25.081] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:44:02.450] [mlr3] Finished benchmark
INFO  [17:44:02.540] [bbotk] Result of batch 3:
INFO  [17:44:02.590] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:44:02.590] [bbotk]              -2.712518                         0.6518232
INFO  [17:44:02.590] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:44:02.590] [bbotk]                         0.3600887            -3.91074              -1.685906
INFO  [17:44:02.590] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:44:02.590] [bbotk]                         10                    3591                 0.7167185
INFO  [17:44:02.590] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:44:02.590] [bbotk]  0.0578299 <list[8]>              FALSE     0.02583984        0      0
INFO  [17:44:02.590] [bbotk]  runtime_learners                                uhash
INFO  [17:44:02.590] [bbotk]            94.245 8b497692-aa39-4f46-8c8d-7adb9475b04a
INFO  [17:44:02.903] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 34 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:44:10.628] [bbotk] Evaluating 1 configuration(s)
INFO  [17:44:10.866] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:44:11.049] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:44:51.050] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:45:31.791] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:46:09.073] [mlr3] Finished benchmark
INFO  [17:46:09.224] [bbotk] Result of batch 4:
INFO  [17:46:09.309] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:46:09.309] [bbotk]               -1.99197                         0.5998317
INFO  [17:46:09.309] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:46:09.309] [bbotk]                         0.2697834           -2.323783               1.969321
INFO  [17:46:09.309] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:46:09.309] [bbotk]                         19                    3904                 0.6411056
INFO  [17:46:09.309] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:46:09.309] [bbotk]  0.0376246 <list[8]>              FALSE     0.02520332        0      0
INFO  [17:46:09.309] [bbotk]  runtime_learners                                uhash
INFO  [17:46:09.309] [bbotk]           117.664 c46107da-a616-4245-bcca-e8445d1cec96
INFO  [17:46:10.722] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 35 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:46:29.389] [bbotk] Evaluating 1 configuration(s)
INFO  [17:46:29.701] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:46:29.900] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:47:03.037] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:47:48.823] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:48:32.244] [mlr3] Finished benchmark
INFO  [17:48:32.534] [bbotk] Result of batch 5:
INFO  [17:48:32.593] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:48:32.593] [bbotk]              0.7602204                          0.838397
INFO  [17:48:32.593] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:48:32.593] [bbotk]                         0.1312491           -2.785595               3.523205
INFO  [17:48:32.593] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:48:32.593] [bbotk]                         10                    3299                 0.7812347
INFO  [17:48:32.593] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:48:32.593] [bbotk]  0.03427798 <list[8]>              FALSE     0.02940209        0      0
INFO  [17:48:32.593] [bbotk]  runtime_learners                                uhash
INFO  [17:48:32.593] [bbotk]           121.827 c4f2414e-c658-42e8-8001-d1a14b430e9f
INFO  [17:48:33.355] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 36 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:48:38.512] [bbotk] Evaluating 1 configuration(s)
INFO  [17:48:38.866] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:48:38.946] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:49:22.889] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:49:57.725] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:50:39.124] [mlr3] Finished benchmark
INFO  [17:50:39.416] [bbotk] Result of batch 6:
INFO  [17:50:39.477] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:50:39.477] [bbotk]              -2.730211                         0.6347814
INFO  [17:50:39.477] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:50:39.477] [bbotk]                         0.1209099           -3.472062                1.33726
INFO  [17:50:39.477] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:50:39.477] [bbotk]                         11                    3252                 0.2145998
INFO  [17:50:39.477] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:50:39.477] [bbotk]  0.02833069 <list[8]>              FALSE     0.02912004        0      0
INFO  [17:50:39.477] [bbotk]  runtime_learners                                uhash
INFO  [17:50:39.477] [bbotk]           119.641 c9017ef3-5c22-42d3-9517-dab88fc2c9e2
INFO  [17:50:45.650] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 37 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:50:55.873] [bbotk] Evaluating 1 configuration(s)
INFO  [17:50:56.012] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:50:56.359] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:51:53.489] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:52:36.220] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:53:13.909] [mlr3] Finished benchmark
INFO  [17:53:14.032] [bbotk] Result of batch 7:
INFO  [17:53:14.049] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:53:14.049] [bbotk]             -0.7023293                         0.4587896
INFO  [17:53:14.049] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:53:14.049] [bbotk]                          0.605163           -1.145966             -0.4417674
INFO  [17:53:14.049] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:53:14.049] [bbotk]                         13                    4722                 0.5488143
INFO  [17:53:14.049] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:53:14.049] [bbotk]  0.02675667 <list[8]>              FALSE     0.02569134        0      0
INFO  [17:53:14.049] [bbotk]  runtime_learners                                uhash
INFO  [17:53:14.049] [bbotk]           136.575 6572a020-72a2-471a-af8b-fdf45be54cd5
INFO  [17:53:14.823] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 38 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:53:22.459] [bbotk] Evaluating 1 configuration(s)
INFO  [17:53:22.790] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:53:22.951] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:54:07.768] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:54:54.035] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:55:58.512] [mlr3] Finished benchmark
INFO  [17:55:58.741] [bbotk] Result of batch 8:
INFO  [17:55:58.881] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:55:58.881] [bbotk]              -1.828115                         0.8836769
INFO  [17:55:58.881] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:55:58.881] [bbotk]                          0.204977            -5.36432               3.937311
INFO  [17:55:58.881] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:55:58.881] [bbotk]                         11                    3873                  0.816632
INFO  [17:55:58.881] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:55:58.881] [bbotk]  0.02835148 <list[8]>              FALSE     0.03543845        0      0
INFO  [17:55:58.881] [bbotk]  runtime_learners                                uhash
INFO  [17:55:58.881] [bbotk]           154.961 a4912eec-d917-413b-9cd2-ca78c5ef7458
INFO  [17:56:00.097] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 39 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:56:07.576] [bbotk] Evaluating 1 configuration(s)
INFO  [17:56:07.823] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:56:07.984] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:57:01.298] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:57:47.163] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:58:29.377] [mlr3] Finished benchmark
INFO  [17:58:29.475] [bbotk] Result of batch 9:
INFO  [17:58:29.554] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:58:29.554] [bbotk]              -5.539898                          0.945391
INFO  [17:58:29.554] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:58:29.554] [bbotk]                         0.2007365           -3.113862              -2.944723
INFO  [17:58:29.554] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:58:29.554] [bbotk]                          9                    4615                 0.6096419
INFO  [17:58:29.554] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:58:29.554] [bbotk]  0.02539539 <list[8]>              FALSE     0.02440111        0      0
INFO  [17:58:29.554] [bbotk]  runtime_learners                                uhash
INFO  [17:58:29.554] [bbotk]           140.919 0f4bdf48-c131-42a6-ab88-1ac34ddbcc68
INFO  [17:58:31.843] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 40 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:58:37.352] [bbotk] Evaluating 1 configuration(s)
INFO  [17:58:37.579] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:58:37.890] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:59:00.608] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:59:26.920] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:59:47.278] [mlr3] Finished benchmark
INFO  [17:59:47.571] [bbotk] Result of batch 10:
INFO  [17:59:47.734] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:59:47.734] [bbotk]               2.233532                         0.3371169
INFO  [17:59:47.734] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:59:47.734] [bbotk]                          0.479504           -3.690432               3.352085
INFO  [17:59:47.734] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:59:47.734] [bbotk]                         15                     480                 0.9114384
INFO  [17:59:47.734] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:59:47.734] [bbotk]  0.02731038 <list[8]>              FALSE     0.04090725        0      0
INFO  [17:59:47.734] [bbotk]  runtime_learners                                uhash
INFO  [17:59:47.734] [bbotk]            68.834 348c7f24-22b8-4c73-a256-45aa683b8ec1
INFO  [17:59:50.345] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 41 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:59:54.836] [bbotk] Evaluating 1 configuration(s)
INFO  [17:59:54.999] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:59:55.067] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:00:31.656] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:01:10.948] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:01:45.912] [mlr3] Finished benchmark
INFO  [18:01:46.081] [bbotk] Result of batch 11:
INFO  [18:01:46.186] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:01:46.186] [bbotk]               -5.66778                          0.432441
INFO  [18:01:46.186] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:01:46.186] [bbotk]                         0.2375835           -3.961282              -6.626581
INFO  [18:01:46.186] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:01:46.186] [bbotk]                         10                    3699                  0.985712
INFO  [18:01:46.186] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:01:46.186] [bbotk]  0.02279339 <list[8]>              FALSE     0.02723536        0      0
INFO  [18:01:46.186] [bbotk]  runtime_learners                                uhash
INFO  [18:01:46.186] [bbotk]           110.401 c2ab8443-b097-4f56-9acc-681f6318c874
INFO  [18:01:47.865] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 42 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:01:54.097] [bbotk] Evaluating 1 configuration(s)
INFO  [18:01:54.180] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:01:54.298] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:02:38.718] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:03:02.882] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:03:35.085] [mlr3] Finished benchmark
INFO  [18:03:35.360] [bbotk] Result of batch 12:
INFO  [18:03:35.381] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:03:35.381] [bbotk]              -1.663556                         0.5508492
INFO  [18:03:35.381] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:03:35.381] [bbotk]                         0.2347004           -1.966136              -2.279486
INFO  [18:03:35.381] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:03:35.381] [bbotk]                         11                    3129                 0.4243775
INFO  [18:03:35.381] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:03:35.381] [bbotk]  0.02319636 <list[8]>              FALSE     0.02577024        0      0
INFO  [18:03:35.381] [bbotk]  runtime_learners                                uhash
INFO  [18:03:35.381] [bbotk]            99.592 5205f2f8-09c9-4172-8d45-65150fda0f86
WARN  [18:03:36.770] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:03:36.909] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 43 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:03:43.027] [bbotk] Evaluating 1 configuration(s)
INFO  [18:03:43.303] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:03:43.645] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:04:20.579] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:04:56.292] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:05:37.994] [mlr3] Finished benchmark
INFO  [18:05:38.155] [bbotk] Result of batch 13:
INFO  [18:05:38.224] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:05:38.224] [bbotk]              -3.621914                            0.8077
INFO  [18:05:38.224] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:05:38.224] [bbotk]                         0.5401752          -0.5531109                1.22498
INFO  [18:05:38.224] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:05:38.224] [bbotk]                          2                    2338                 0.4649329
INFO  [18:05:38.224] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:05:38.224] [bbotk]  0.02062922 <list[8]>              FALSE     0.02832801        0      0
INFO  [18:05:38.224] [bbotk]  runtime_learners                                uhash
INFO  [18:05:38.224] [bbotk]           113.459 fb0429e5-2954-4361-8a13-0bd98e7e7d3c
WARN  [18:05:40.139] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:05:40.169] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 44 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:05:45.717] [bbotk] Evaluating 1 configuration(s)
INFO  [18:05:45.974] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:05:46.177] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:06:26.191] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:07:09.060] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:07:49.307] [mlr3] Finished benchmark
INFO  [18:07:49.486] [bbotk] Result of batch 14:
INFO  [18:07:49.533] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:07:49.533] [bbotk]               1.505072                         0.4465621
INFO  [18:07:49.533] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:07:49.533] [bbotk]                          0.576973           -2.249957              -1.976651
INFO  [18:07:49.533] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:07:49.533] [bbotk]                          1                    2807                 0.8448372
INFO  [18:07:49.533] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:07:49.533] [bbotk]  0.0207612 <list[8]>              FALSE     0.03305656        0      0
INFO  [18:07:49.533] [bbotk]  runtime_learners                                uhash
INFO  [18:07:49.533] [bbotk]           122.343 a84ab37f-8f3a-4371-b509-27fcb9114989
INFO  [18:07:50.511] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 45 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:07:55.380] [bbotk] Evaluating 1 configuration(s)
INFO  [18:07:55.559] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:07:55.712] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:08:34.190] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:09:05.963] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:09:38.127] [mlr3] Finished benchmark
INFO  [18:09:38.358] [bbotk] Result of batch 15:
INFO  [18:09:38.430] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:09:38.430] [bbotk]              -6.235325                         0.8354137
INFO  [18:09:38.430] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:09:38.430] [bbotk]                         0.3110651           -3.490575              -2.926504
INFO  [18:09:38.430] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:09:38.430] [bbotk]                         10                    2909                 0.7427472
INFO  [18:09:38.430] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:09:38.430] [bbotk]  0.02130001 <list[8]>              FALSE     0.02560274        0      0
INFO  [18:09:38.430] [bbotk]  runtime_learners                                uhash
INFO  [18:09:38.430] [bbotk]           101.293 fed19b21-71da-4e28-9e22-fb5c8319977c
INFO  [18:09:39.784] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 46 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:09:46.803] [bbotk] Evaluating 1 configuration(s)
INFO  [18:09:47.083] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:09:47.126] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:09:55.975] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:10:04.517] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:10:14.512] [mlr3] Finished benchmark
INFO  [18:10:14.961] [bbotk] Result of batch 16:
INFO  [18:10:15.006] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:10:15.006] [bbotk]              -3.529003                         0.2646739
INFO  [18:10:15.006] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:10:15.006] [bbotk]                         0.4085053           -2.407641              -6.109752
INFO  [18:10:15.006] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:10:15.006] [bbotk]                         15                     730                  0.831772
INFO  [18:10:15.006] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:10:15.006] [bbotk]  0.02016623 <list[8]>              FALSE     0.02655098        0      0
INFO  [18:10:15.006] [bbotk]  runtime_learners                                uhash
INFO  [18:10:15.006] [bbotk]            26.882 f0a836f8-4796-4dda-bb26-48c2f3fa7202
INFO  [18:10:17.690] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 47 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:10:21.297] [bbotk] Evaluating 1 configuration(s)
INFO  [18:10:21.356] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:10:21.488] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:10:39.669] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:11:06.540] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:11:57.390] [mlr3] Finished benchmark
INFO  [18:11:57.848] [bbotk] Result of batch 17:
INFO  [18:11:57.958] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:11:57.958] [bbotk]                1.14342                         0.1558479
INFO  [18:11:57.958] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:11:57.958] [bbotk]                         0.9379281           -2.942967               6.295544
INFO  [18:11:57.958] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:11:57.958] [bbotk]                         14                    2705                 0.5838386
INFO  [18:11:57.958] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:11:57.958] [bbotk]  0.04126574 <list[8]>              FALSE     0.03951379        0      0
INFO  [18:11:57.958] [bbotk]  runtime_learners                                uhash
INFO  [18:11:57.958] [bbotk]            95.421 f921d6c8-f954-441a-822b-50e9a1b8bd62
INFO  [18:11:58.808] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 48 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:12:04.744] [bbotk] Evaluating 1 configuration(s)
INFO  [18:12:05.096] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:12:05.362] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:12:47.526] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:13:22.494] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:13:53.248] [mlr3] Finished benchmark
INFO  [18:13:53.463] [bbotk] Result of batch 18:
INFO  [18:13:53.556] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:13:53.556] [bbotk]              -3.297412                         0.5197755
INFO  [18:13:53.556] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:13:53.556] [bbotk]                         0.5958983           -1.905942               1.017645
INFO  [18:13:53.556] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:13:53.556] [bbotk]                         20                    2041                 0.4564421
INFO  [18:13:53.556] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:13:53.556] [bbotk]  0.01962049 <list[8]>              FALSE     0.02644865        0      0
INFO  [18:13:53.556] [bbotk]  runtime_learners                                uhash
INFO  [18:13:53.556] [bbotk]           107.413 c8a593b4-6490-4a04-95f2-df3eb827910b
INFO  [18:13:56.601] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 49 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:14:03.701] [bbotk] Evaluating 1 configuration(s)
INFO  [18:14:03.847] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:14:04.240] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:14:49.181] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:15:28.474] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:16:06.048] [mlr3] Finished benchmark
INFO  [18:16:06.155] [bbotk] Result of batch 19:
INFO  [18:16:06.186] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:16:06.186] [bbotk]             -0.9504985                         0.2229675
INFO  [18:16:06.186] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:16:06.186] [bbotk]                         0.3489903           -3.020736                3.87078
INFO  [18:16:06.186] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:16:06.186] [bbotk]                         19                    4014                 0.6958782
INFO  [18:16:06.186] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:16:06.186] [bbotk]  0.02010284 <list[8]>              FALSE     0.02815447        0      0
INFO  [18:16:06.186] [bbotk]  runtime_learners                                uhash
INFO  [18:16:06.186] [bbotk]           121.444 c2d0e800-693a-4f22-958d-08e108f3d99d
INFO  [18:16:07.120] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 50 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:16:12.982] [bbotk] Evaluating 1 configuration(s)
INFO  [18:16:13.104] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:16:13.373] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:16:44.703] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:17:26.494] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:17:57.979] [mlr3] Finished benchmark
INFO  [18:17:58.135] [bbotk] Result of batch 20:
INFO  [18:17:58.255] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:17:58.255] [bbotk]              -2.065377                         0.3677255
INFO  [18:17:58.255] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:17:58.255] [bbotk]                         0.4577288           -4.607648               0.968713
INFO  [18:17:58.255] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:17:58.255] [bbotk]                         20                    4367                  0.301867
INFO  [18:17:58.255] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:17:58.255] [bbotk]  0.01922127 <list[8]>              FALSE     0.02700755        0      0
INFO  [18:17:58.255] [bbotk]  runtime_learners                                uhash
INFO  [18:17:58.255] [bbotk]           104.085 906d8f7e-0b53-4907-b71f-036ecaa38dd6
INFO  [18:17:59.708] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 51 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:18:05.805] [bbotk] Evaluating 1 configuration(s)
INFO  [18:18:05.893] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:18:05.970] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:18:51.526] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:19:28.546] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:20:15.324] [mlr3] Finished benchmark
INFO  [18:20:15.464] [bbotk] Result of batch 21:
INFO  [18:20:15.497] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:20:15.497] [bbotk]              -4.723603                         0.1824341
INFO  [18:20:15.497] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:20:15.497] [bbotk]                         0.6856546           -2.056874              -6.709945
INFO  [18:20:15.497] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:20:15.497] [bbotk]                          8                    4485                 0.3796125
INFO  [18:20:15.497] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:20:15.497] [bbotk]  0.02006587 <list[8]>              FALSE     0.02644661        0      0
INFO  [18:20:15.497] [bbotk]  runtime_learners                                uhash
INFO  [18:20:15.497] [bbotk]           128.781 2236eb82-e703-4847-9857-8bd5f367e727
INFO  [18:20:16.971] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 52 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:20:22.928] [bbotk] Evaluating 1 configuration(s)
INFO  [18:20:23.040] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:20:23.153] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:20:53.944] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:21:38.972] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:22:07.994] [mlr3] Finished benchmark
INFO  [18:22:08.172] [bbotk] Result of batch 22:
INFO  [18:22:08.242] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:22:08.242] [bbotk]              0.8927454                         0.1680453
INFO  [18:22:08.242] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:22:08.242] [bbotk]                         0.1660493          -0.9981763               3.696184
INFO  [18:22:08.242] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:22:08.242] [bbotk]                         17                    3245                  0.538624
INFO  [18:22:08.242] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:22:08.242] [bbotk]  0.01811785 <list[8]>              FALSE     0.03168751        0      0
INFO  [18:22:08.242] [bbotk]  runtime_learners                                uhash
INFO  [18:22:08.242] [bbotk]           104.107 bbed4e8d-7340-4ad2-b76e-8e40fe42def6
INFO  [18:22:10.372] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 53 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:22:16.581] [bbotk] Evaluating 1 configuration(s)
INFO  [18:22:16.645] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:22:16.822] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:22:47.102] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:23:26.824] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:24:01.110] [mlr3] Finished benchmark
INFO  [18:24:01.220] [bbotk] Result of batch 23:
INFO  [18:24:01.262] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:24:01.262] [bbotk]               1.215467                         0.4671062
INFO  [18:24:01.262] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:24:01.262] [bbotk]                         0.7559236           -0.845101              0.9561286
INFO  [18:24:01.262] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:24:01.262] [bbotk]                         18                    3828                 0.7563464
INFO  [18:24:01.262] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:24:01.262] [bbotk]  0.01983037 <list[8]>              FALSE     0.03074145        0      0
INFO  [18:24:01.262] [bbotk]  runtime_learners                                uhash
INFO  [18:24:01.262] [bbotk]           103.834 3350152d-d86a-420f-9e77-ebff609f66b7
INFO  [18:24:02.904] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 54 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:24:09.153] [bbotk] Evaluating 1 configuration(s)
INFO  [18:24:09.256] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:24:09.336] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:25:02.432] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:25:54.569] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:26:35.286] [mlr3] Finished benchmark
INFO  [18:26:35.744] [bbotk] Result of batch 24:
INFO  [18:26:35.792] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:26:35.792] [bbotk]              -2.833479                         0.9465687
INFO  [18:26:35.792] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:26:35.792] [bbotk]                         0.1562673           -7.109641              -6.608145
INFO  [18:26:35.792] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:26:35.792] [bbotk]                         17                    3327                 0.6071728
INFO  [18:26:35.792] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:26:35.792] [bbotk]  0.02463783 <list[8]>              FALSE     0.03222325        0      0
INFO  [18:26:35.792] [bbotk]  runtime_learners                                uhash
INFO  [18:26:35.792] [bbotk]            145.12 0c8e6ed4-c8bb-4d7d-ad1c-de034fbb6adc
INFO  [18:26:38.920] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 55 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:26:44.104] [bbotk] Evaluating 1 configuration(s)
INFO  [18:26:44.213] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:26:44.399] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:27:07.966] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:27:46.499] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:28:16.733] [mlr3] Finished benchmark
INFO  [18:28:17.020] [bbotk] Result of batch 25:
INFO  [18:28:17.089] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:28:17.089] [bbotk]              -1.654194                          0.426139
INFO  [18:28:17.089] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:28:17.089] [bbotk]                         0.7797178          -0.9021236               6.782386
INFO  [18:28:17.089] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:28:17.089] [bbotk]                          6                    1835                 0.6777433
INFO  [18:28:17.089] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:28:17.089] [bbotk]  0.01573234 <list[8]>              FALSE     0.03122056        0      0
INFO  [18:28:17.089] [bbotk]  runtime_learners                                uhash
INFO  [18:28:17.089] [bbotk]            91.434 ae5d5b57-8c8d-4f7f-a52d-4ad449f648ac
INFO  [18:28:18.329] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 56 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:28:24.147] [bbotk] Evaluating 1 configuration(s)
INFO  [18:28:24.338] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:28:24.610] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:29:06.436] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:29:49.137] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:30:39.578] [mlr3] Finished benchmark
INFO  [18:30:39.915] [bbotk] Result of batch 26:
INFO  [18:30:40.127] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:30:40.127] [bbotk]              -6.553251                          0.256575
INFO  [18:30:40.127] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:30:40.127] [bbotk]                          0.338117           -2.587022              0.8733831
INFO  [18:30:40.127] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:30:40.127] [bbotk]                         19                    4646                  0.670014
INFO  [18:30:40.127] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:30:40.127] [bbotk]  0.01815135 <list[8]>              FALSE      0.0237276        0      0
INFO  [18:30:40.127] [bbotk]  runtime_learners                                uhash
INFO  [18:30:40.127] [bbotk]           133.797 7f9f2f0d-c704-4e0a-961d-d5e2953bfbf6
INFO  [18:30:41.655] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 57 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:30:48.950] [bbotk] Evaluating 1 configuration(s)
INFO  [18:30:49.092] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:30:49.636] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:31:24.239] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:32:04.953] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:32:37.968] [mlr3] Finished benchmark
INFO  [18:32:39.950] [bbotk] Result of batch 27:
INFO  [18:32:40.439] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:32:40.439] [bbotk]               2.136119                         0.1442939
INFO  [18:32:40.439] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:32:40.439] [bbotk]                         0.5662244           -1.930763               4.968764
INFO  [18:32:40.439] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:32:40.439] [bbotk]                         14                    2735                 0.7116284
INFO  [18:32:40.439] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:32:40.439] [bbotk]  0.01678658 <list[8]>              FALSE     0.03792366        0      0
INFO  [18:32:40.439] [bbotk]  runtime_learners                                uhash
INFO  [18:32:40.439] [bbotk]           107.221 f8e5de9f-5478-4a8a-b95a-b5bfb270ee82
INFO  [18:32:52.025] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 58 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:32:58.080] [bbotk] Evaluating 1 configuration(s)
INFO  [18:32:58.239] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:32:58.386] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:33:26.907] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:33:56.060] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:34:13.202] [mlr3] Finished benchmark
INFO  [18:34:13.389] [bbotk] Result of batch 28:
INFO  [18:34:13.532] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:34:13.532] [bbotk]              -3.948519                         0.8156916
INFO  [18:34:13.532] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:34:13.532] [bbotk]                         0.1075319           -4.194517              -6.645782
INFO  [18:34:13.532] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:34:13.532] [bbotk]                         18                    1743                 0.9945134
INFO  [18:34:13.532] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:34:13.532] [bbotk]  0.01624572 <list[8]>              FALSE     0.02501011        0      0
INFO  [18:34:13.532] [bbotk]  runtime_learners                                uhash
INFO  [18:34:13.532] [bbotk]            74.031 fea37ed9-88c7-4800-8ad2-02b4fdb03130
INFO  [18:34:15.046] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 59 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:34:24.186] [bbotk] Evaluating 1 configuration(s)
INFO  [18:34:24.307] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:34:24.384] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:35:11.897] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:35:55.852] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:36:55.503] [mlr3] Finished benchmark
INFO  [18:36:55.659] [bbotk] Result of batch 29:
INFO  [18:36:55.713] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:36:55.713] [bbotk]              -6.293759                         0.4630034
INFO  [18:36:55.713] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:36:55.713] [bbotk]                         0.1590105          -0.9908939               1.165196
INFO  [18:36:55.713] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:36:55.713] [bbotk]                         10                    4956                 0.3444278
INFO  [18:36:55.713] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:36:55.713] [bbotk]  0.0145263 <list[8]>              FALSE     0.02730126        0      0
INFO  [18:36:55.713] [bbotk]  runtime_learners                                uhash
INFO  [18:36:55.713] [bbotk]           150.422 d0ab6a8f-d358-4dd5-b250-ad0338767454
INFO  [18:36:56.766] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 60 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:37:03.924] [bbotk] Evaluating 1 configuration(s)
INFO  [18:37:04.114] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:37:04.312] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:37:51.171] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:38:34.569] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:39:14.682] [mlr3] Finished benchmark
INFO  [18:39:14.803] [bbotk] Result of batch 30:
INFO  [18:39:14.854] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:39:14.854] [bbotk]              -0.946117                         0.9070955
INFO  [18:39:14.854] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:39:14.854] [bbotk]                         0.1252571           -4.282379              -3.879295
INFO  [18:39:14.854] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:39:14.854] [bbotk]                         19                    4150                 0.5245949
INFO  [18:39:14.854] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:39:14.854] [bbotk]  0.01373808 <list[8]>              FALSE     0.02593452        0      0
INFO  [18:39:14.854] [bbotk]  runtime_learners                                uhash
INFO  [18:39:14.854] [bbotk]           130.001 1a113b78-7182-49c4-a5d2-59d17ae8413f
INFO  [18:39:16.167] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 61 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:39:21.376] [bbotk] Evaluating 1 configuration(s)
INFO  [18:39:21.503] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:39:21.636] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:39:54.630] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:40:33.977] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:41:07.093] [mlr3] Finished benchmark
INFO  [18:41:07.285] [bbotk] Result of batch 31:
INFO  [18:41:07.373] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:41:07.373] [bbotk]               1.731056                         0.6049245
INFO  [18:41:07.373] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:41:07.373] [bbotk]                         0.3478673           -3.450662               6.743725
INFO  [18:41:07.373] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:41:07.373] [bbotk]                         10                    1480                 0.9579542
INFO  [18:41:07.373] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:41:07.373] [bbotk]  0.01670078 <list[8]>              FALSE     0.04518697        0      0
INFO  [18:41:07.373] [bbotk]  runtime_learners                                uhash
INFO  [18:41:07.373] [bbotk]           104.898 4f4ebe2f-fb41-4e33-acb6-b3678b252f47
INFO  [18:41:08.634] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 62 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:41:15.520] [bbotk] Evaluating 1 configuration(s)
INFO  [18:41:15.677] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:41:15.786] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:41:43.631] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:42:23.830] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:43:14.828] [mlr3] Finished benchmark
INFO  [18:43:15.088] [bbotk] Result of batch 32:
INFO  [18:43:15.190] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:43:15.190] [bbotk]              -1.480931                         0.3298113
INFO  [18:43:15.190] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:43:15.190] [bbotk]                         0.3171458           -2.823581               1.795957
INFO  [18:43:15.190] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:43:15.190] [bbotk]                          5                    4194                 0.3841774
INFO  [18:43:15.190] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:43:15.190] [bbotk]  0.01317968 <list[8]>              FALSE     0.02506422        0      0
INFO  [18:43:15.190] [bbotk]  runtime_learners                                uhash
INFO  [18:43:15.190] [bbotk]           118.235 e16c36f2-5767-403f-9c26-fcc60a4ab9f8
INFO  [18:43:17.476] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 63 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:43:26.441] [bbotk] Evaluating 1 configuration(s)
INFO  [18:43:27.032] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:43:27.380] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:44:11.434] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:45:09.108] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:45:52.417] [mlr3] Finished benchmark
INFO  [18:45:52.598] [bbotk] Result of batch 33:
INFO  [18:45:52.657] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:45:52.657] [bbotk]              -2.077904                         0.7641755
INFO  [18:45:52.657] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:45:52.657] [bbotk]                         0.8225084           -1.117637                3.89112
INFO  [18:45:52.657] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:45:52.657] [bbotk]                         11                    3581                  0.188175
INFO  [18:45:52.657] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:45:52.657] [bbotk]  0.01395302 <list[8]>              FALSE     0.02695148        0      0
INFO  [18:45:52.657] [bbotk]  runtime_learners                                uhash
INFO  [18:45:52.657] [bbotk]           144.325 9e61c238-c041-40c3-baf0-6536bfdf50bc
INFO  [18:45:54.977] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 64 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:46:01.970] [bbotk] Evaluating 1 configuration(s)
INFO  [18:46:02.102] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:46:02.228] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:46:34.558] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:47:19.105] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:48:06.796] [mlr3] Finished benchmark
INFO  [18:48:07.025] [bbotk] Result of batch 34:
INFO  [18:48:07.071] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:48:07.071] [bbotk]             -0.3534721                         0.6875835
INFO  [18:48:07.071] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:48:07.071] [bbotk]                          0.121499           -6.411349             -0.4889661
INFO  [18:48:07.071] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:48:07.071] [bbotk]                         13                    4202                 0.9088057
INFO  [18:48:07.071] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:48:07.071] [bbotk]  0.0229914 <list[8]>              FALSE     0.03118222        0      0
INFO  [18:48:07.071] [bbotk]  runtime_learners                                uhash
INFO  [18:48:07.071] [bbotk]           123.931 3df3f60e-85d3-40d9-92e4-addbf5b56b3b
WARN  [18:48:13.191] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:48:13.238] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 65 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:48:18.537] [bbotk] Evaluating 1 configuration(s)
INFO  [18:48:18.732] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:48:18.861] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:49:06.736] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:49:52.339] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:50:29.720] [mlr3] Finished benchmark
INFO  [18:50:31.086] [bbotk] Result of batch 35:
INFO  [18:50:31.177] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:50:31.177] [bbotk]              -6.486946                         0.4125254
INFO  [18:50:31.177] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:50:31.177] [bbotk]                         0.5069012           -3.364449              -5.803433
INFO  [18:50:31.177] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:50:31.177] [bbotk]                          5                    4308                 0.4545861
INFO  [18:50:31.177] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:50:31.177] [bbotk]  0.0121895 <list[8]>              FALSE     0.02670693        0      0
INFO  [18:50:31.177] [bbotk]  runtime_learners                                uhash
INFO  [18:50:31.177] [bbotk]           130.496 4c9a3f25-3bc4-43a2-8217-c616223ba7f8
INFO  [18:50:33.513] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 66 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:50:49.685] [bbotk] Evaluating 1 configuration(s)
INFO  [18:50:49.761] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:50:49.782] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:51:26.269] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:51:50.296] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:52:16.669] [mlr3] Finished benchmark
INFO  [18:52:16.787] [bbotk] Result of batch 36:
INFO  [18:52:16.798] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:52:16.798] [bbotk]              -5.757273                         0.2955289
INFO  [18:52:16.798] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:52:16.798] [bbotk]                         0.1952305           -3.119446              -6.173995
INFO  [18:52:16.798] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:52:16.798] [bbotk]                         15                    3855                 0.3867548
INFO  [18:52:16.798] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:52:16.798] [bbotk]  0.01254418 <list[8]>              FALSE     0.02509793        0      0
INFO  [18:52:16.798] [bbotk]  runtime_learners                                uhash
INFO  [18:52:16.798] [bbotk]            86.164 48ea5d32-81b2-46b3-9d66-3896b869824f
INFO  [18:52:17.782] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 67 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:52:35.758] [bbotk] Evaluating 1 configuration(s)
INFO  [18:52:35.974] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:52:36.062] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:53:16.263] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:53:56.272] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:54:30.759] [mlr3] Finished benchmark
INFO  [18:54:31.435] [bbotk] Result of batch 37:
INFO  [18:54:31.475] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:54:31.475] [bbotk]              -4.872878                         0.8696158
INFO  [18:54:31.475] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:54:31.475] [bbotk]                         0.6666795           -1.806696              -3.486347
INFO  [18:54:31.475] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:54:31.475] [bbotk]                         14                    1856                 0.9881692
INFO  [18:54:31.475] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:54:31.475] [bbotk]  0.01398945 <list[8]>              FALSE     0.03397803        0      0
INFO  [18:54:31.475] [bbotk]  runtime_learners                                uhash
INFO  [18:54:31.475] [bbotk]            114.23 f4cd586a-d5dc-483d-bdfd-f7a32c2d4c9d
INFO  [18:54:41.833] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 68 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:54:49.089] [bbotk] Evaluating 1 configuration(s)
INFO  [18:54:49.259] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:54:49.270] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:55:24.885] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [18:56:19.066] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:57:40.648] [mlr3] Finished benchmark
INFO  [18:57:40.724] [bbotk] Result of batch 38:
INFO  [18:57:40.732] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:57:40.732] [bbotk]              -1.491634                         0.7012293
INFO  [18:57:40.732] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:57:40.732] [bbotk]                         0.2070482           -6.239854              -5.156768
INFO  [18:57:40.732] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:57:40.732] [bbotk]                         15                    4930                 0.8696025
INFO  [18:57:40.732] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:57:40.732] [bbotk]  0.01334989 <list[8]>              FALSE     0.02929464        0      0
INFO  [18:57:40.732] [bbotk]  runtime_learners                                uhash
INFO  [18:57:40.732] [bbotk]           170.795 a0048239-cb40-4f05-b4ea-effc828cd4c8
INFO  [18:57:43.105] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 69 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:57:55.013] [bbotk] Evaluating 1 configuration(s)
INFO  [18:57:55.086] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:57:55.190] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [18:59:04.846] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:00:09.030] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:01:06.217] [mlr3] Finished benchmark
INFO  [19:01:07.129] [bbotk] Result of batch 39:
INFO  [19:01:07.234] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:01:07.234] [bbotk]              0.7714589                         0.1087144
INFO  [19:01:07.234] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:01:07.234] [bbotk]                         0.1823765           -3.917443               -4.09644
INFO  [19:01:07.234] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:01:07.234] [bbotk]                          5                    3592                 0.7275507
INFO  [19:01:07.234] [bbotk]    acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:01:07.234] [bbotk]  0.019212 <list[8]>              FALSE     0.02824526        0      0
INFO  [19:01:07.234] [bbotk]  runtime_learners                                uhash
INFO  [19:01:07.234] [bbotk]           190.732 0e73db1c-a155-4982-af61-a81b4736211d
INFO  [19:01:12.958] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 70 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:01:23.098] [bbotk] Evaluating 1 configuration(s)
INFO  [19:01:26.041] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:01:26.054] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:02:10.075] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:02:55.140] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:03:35.051] [mlr3] Finished benchmark
INFO  [19:03:36.712] [bbotk] Result of batch 40:
INFO  [19:03:36.911] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:03:36.911] [bbotk]              -3.526278                         0.3590102
INFO  [19:03:36.911] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:03:36.911] [bbotk]                         0.6467136          -0.3351277              -4.323646
INFO  [19:03:36.911] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:03:36.911] [bbotk]                          1                    2585                 0.2828538
INFO  [19:03:36.911] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:03:36.911] [bbotk]  0.01156235 <list[8]>              FALSE      0.0275067        0      0
INFO  [19:03:36.911] [bbotk]  runtime_learners                                uhash
INFO  [19:03:36.911] [bbotk]           128.836 f01dbeba-0349-4a6e-99f6-1798e3965f50
INFO  [19:03:42.110] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 71 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:04:09.823] [bbotk] Evaluating 1 configuration(s)
INFO  [19:04:10.428] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:04:10.751] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:04:49.149] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:05:14.683] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:05:45.890] [mlr3] Finished benchmark
INFO  [19:05:46.322] [bbotk] Result of batch 41:
INFO  [19:05:46.353] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:05:46.353] [bbotk]              0.5562094                          0.148994
INFO  [19:05:46.353] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:05:46.353] [bbotk]                         0.8897205          -0.2415127               2.842125
INFO  [19:05:46.353] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:05:46.353] [bbotk]                          9                    2974                 0.6151551
INFO  [19:05:46.353] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:05:46.353] [bbotk]  0.01409995 <list[8]>              FALSE     0.02872374        0      0
INFO  [19:05:46.353] [bbotk]  runtime_learners                                uhash
INFO  [19:05:46.353] [bbotk]            94.954 b0c156c6-c0f1-433c-83bc-4bf062f7db2a
INFO  [19:05:50.008] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 72 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:06:04.825] [bbotk] Evaluating 1 configuration(s)
INFO  [19:06:04.943] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:06:04.986] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:06:58.178] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:07:46.683] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:08:47.635] [mlr3] Finished benchmark
INFO  [19:08:47.720] [bbotk] Result of batch 42:
INFO  [19:08:47.748] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:08:47.748] [bbotk]              -4.939854                         0.2997123
INFO  [19:08:47.748] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:08:47.748] [bbotk]                         0.3527376           -1.662287             -0.2823741
INFO  [19:08:47.748] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:08:47.748] [bbotk]                          1                    4171                 0.2891931
INFO  [19:08:47.748] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:08:47.748] [bbotk]  0.009938135 <list[8]>              FALSE     0.02648395        0      0
INFO  [19:08:47.748] [bbotk]  runtime_learners                                uhash
INFO  [19:08:47.748] [bbotk]           162.175 6568aea4-5fa4-428a-87a1-d19049820fb7
WARN  [19:08:53.928] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:08:54.178] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 73 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:09:16.871] [bbotk] Evaluating 1 configuration(s)
INFO  [19:09:17.176] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:09:17.379] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:10:34.778] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:12:10.083] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:13:14.683] [mlr3] Finished benchmark
INFO  [19:13:14.756] [bbotk] Result of batch 43:
INFO  [19:13:14.799] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:13:14.799] [bbotk]              -5.840146                         0.8456873
INFO  [19:13:14.799] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:13:14.799] [bbotk]                          0.342644           -5.561874              -5.662215
INFO  [19:13:14.799] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:13:14.799] [bbotk]                         20                    4369                 0.9395691
INFO  [19:13:14.799] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:13:14.799] [bbotk]  0.01046272 <list[8]>              FALSE     0.02846822        0      0
INFO  [19:13:14.799] [bbotk]  runtime_learners                                uhash
INFO  [19:13:14.799] [bbotk]           236.907 2a610d39-03e9-4c6c-9ece-1211d57d44f3
INFO  [19:13:19.587] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 74 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:13:32.543] [bbotk] Evaluating 1 configuration(s)
INFO  [19:13:32.573] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:13:32.587] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:14:15.808] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:15:00.789] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:16:11.895] [mlr3] Finished benchmark
INFO  [19:16:13.124] [bbotk] Result of batch 44:
INFO  [19:16:13.386] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:16:13.386] [bbotk]               1.034035                         0.1679066
INFO  [19:16:13.386] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:16:13.386] [bbotk]                         0.1344374           -3.273893              -2.717367
INFO  [19:16:13.386] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:16:13.386] [bbotk]                         15                    2850                 0.9565947
INFO  [19:16:13.386] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:16:13.386] [bbotk]  0.01177273 <list[8]>              FALSE     0.03165532        0      0
INFO  [19:16:13.386] [bbotk]  runtime_learners                                uhash
INFO  [19:16:13.386] [bbotk]           159.061 7cfaf92d-5a72-4597-ad12-f5d122c8b9c8
INFO  [19:16:24.147] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 75 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:16:29.773] [bbotk] Evaluating 1 configuration(s)
INFO  [19:16:30.003] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:16:30.302] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:17:31.447] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:18:45.499] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:19:39.765] [mlr3] Finished benchmark
INFO  [19:19:41.396] [bbotk] Result of batch 45:
INFO  [19:19:41.433] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:19:41.433] [bbotk]              -4.587059                          0.341116
INFO  [19:19:41.433] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:19:41.433] [bbotk]                         0.2747827           -3.916158              -2.895177
INFO  [19:19:41.433] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:19:41.433] [bbotk]                         18                    3419                 0.6678602
INFO  [19:19:41.433] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:19:41.433] [bbotk]  0.01131107 <list[8]>              FALSE     0.02529038        0      0
INFO  [19:19:41.433] [bbotk]  runtime_learners                                uhash
INFO  [19:19:41.433] [bbotk]           188.818 94990088-97ab-4f52-82cd-3124ee12339a
INFO  [19:19:50.599] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 76 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:20:02.697] [bbotk] Evaluating 1 configuration(s)
INFO  [19:20:03.108] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:20:03.744] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:21:38.962] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:22:56.643] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:23:53.578] [mlr3] Finished benchmark
INFO  [19:23:55.767] [bbotk] Result of batch 46:
INFO  [19:23:56.128] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:23:56.128] [bbotk]              -1.912476                         0.5184351
INFO  [19:23:56.128] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:23:56.128] [bbotk]                         0.1979308           -5.690212              -5.289724
INFO  [19:23:56.128] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:23:56.128] [bbotk]                         19                    3213                 0.9024958
INFO  [19:23:56.128] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:23:56.128] [bbotk]  0.01061581 <list[8]>              FALSE     0.02902196        0      0
INFO  [19:23:56.128] [bbotk]  runtime_learners                                uhash
INFO  [19:23:56.128] [bbotk]           229.565 61e33e15-5383-40ef-b2ab-62740836cd0c
INFO  [19:24:06.499] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 77 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:24:23.349] [bbotk] Evaluating 1 configuration(s)
INFO  [19:24:23.483] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:24:23.639] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:24:56.816] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:25:19.892] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:25:45.302] [mlr3] Finished benchmark
INFO  [19:25:45.437] [bbotk] Result of batch 47:
INFO  [19:25:45.444] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:25:45.444] [bbotk]              -4.789753                         0.5656867
INFO  [19:25:45.444] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:25:45.444] [bbotk]                         0.2475348           -2.153447              -6.269391
INFO  [19:25:45.444] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:25:45.444] [bbotk]                          3                     447                 0.6245127
INFO  [19:25:45.444] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:25:45.444] [bbotk]  0.009855572 <list[8]>              FALSE      0.0242167        0      0
INFO  [19:25:45.444] [bbotk]  runtime_learners                                uhash
INFO  [19:25:45.444] [bbotk]            81.526 4aa19186-a148-4035-9c17-4e2f20b64b8d
INFO  [19:25:47.947] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 78 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:26:07.401] [bbotk] Evaluating 1 configuration(s)
INFO  [19:26:07.530] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:26:07.576] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:26:50.729] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:27:33.954] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:28:10.850] [mlr3] Finished benchmark
INFO  [19:28:11.160] [bbotk] Result of batch 48:
INFO  [19:28:11.175] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:28:11.175] [bbotk]               2.113219                         0.1686447
INFO  [19:28:11.175] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:28:11.175] [bbotk]                         0.9597568           -1.479483               3.079511
INFO  [19:28:11.175] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:28:11.175] [bbotk]                         10                    2254                  0.874631
INFO  [19:28:11.175] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:28:11.175] [bbotk]  0.01094681 <list[8]>              FALSE     0.03690671        0      0
INFO  [19:28:11.175] [bbotk]  runtime_learners                                uhash
INFO  [19:28:11.175] [bbotk]           122.752 da3f1034-ba67-4042-8959-59316074c42c
INFO  [19:28:17.127] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 79 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:28:28.722] [bbotk] Evaluating 1 configuration(s)
INFO  [19:28:29.069] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:28:29.182] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:29:13.173] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:30:17.620] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:31:33.322] [mlr3] Finished benchmark
INFO  [19:31:33.403] [bbotk] Result of batch 49:
INFO  [19:31:33.418] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:31:33.418] [bbotk]             -0.9776352                         0.6043337
INFO  [19:31:33.418] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:31:33.418] [bbotk]                         0.4773475           -2.632798               4.114732
INFO  [19:31:33.418] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:31:33.418] [bbotk]                         10                    3941                  0.548194
INFO  [19:31:33.418] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:31:33.418] [bbotk]  0.01054476 <list[8]>              FALSE     0.02731198        0      0
INFO  [19:31:33.418] [bbotk]  runtime_learners                                uhash
INFO  [19:31:33.418] [bbotk]           183.801 e4107e00-1a31-4487-8be0-5923f30f0334
INFO  [19:31:43.504] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 80 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:32:14.137] [bbotk] Evaluating 1 configuration(s)
INFO  [19:32:14.224] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:32:14.256] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:32:39.228] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:33:08.667] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:33:41.798] [mlr3] Finished benchmark
INFO  [19:33:41.902] [bbotk] Result of batch 50:
INFO  [19:33:41.924] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:33:41.924] [bbotk]              -3.246469                         0.6629224
INFO  [19:33:41.924] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:33:41.924] [bbotk]                         0.1585389            -2.69587              -1.154094
INFO  [19:33:41.924] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:33:41.924] [bbotk]                          4                     554                  0.823751
INFO  [19:33:41.924] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:33:41.924] [bbotk]  0.01011326 <list[8]>              FALSE     0.02674688        0      0
INFO  [19:33:41.924] [bbotk]  runtime_learners                                uhash
INFO  [19:33:41.924] [bbotk]             87.28 46b4da8c-aea1-4bb0-99df-882d9708a48f
INFO  [19:33:49.220] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 81 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:34:09.114] [bbotk] Evaluating 1 configuration(s)
INFO  [19:34:09.642] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:34:10.064] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:34:56.217] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:35:55.633] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:37:00.423] [mlr3] Finished benchmark
INFO  [19:37:00.648] [bbotk] Result of batch 51:
INFO  [19:37:00.853] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:37:00.853] [bbotk]             -0.3626343                         0.8800188
INFO  [19:37:00.853] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:37:00.853] [bbotk]                         0.1067933          -0.0569051               1.882268
INFO  [19:37:00.853] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:37:00.853] [bbotk]                         18                    3453                  0.867174
INFO  [19:37:00.853] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:37:00.853] [bbotk]  0.0106115 <list[8]>              FALSE     0.02726778        0      0
INFO  [19:37:00.853] [bbotk]  runtime_learners                                uhash
INFO  [19:37:00.853] [bbotk]           170.025 a1ed5785-9f21-483a-9ce5-2961ac7e840c
INFO  [19:37:04.230] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 82 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:37:30.679] [bbotk] Evaluating 1 configuration(s)
INFO  [19:37:31.526] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:37:31.777] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:38:25.741] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:39:21.376] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:40:09.400] [mlr3] Finished benchmark
INFO  [19:40:11.368] [bbotk] Result of batch 52:
INFO  [19:40:11.525] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:40:11.525] [bbotk]              -3.127143                          0.320563
INFO  [19:40:11.525] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:40:11.525] [bbotk]                         0.6094948              -2.374              -3.236037
INFO  [19:40:11.525] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:40:11.525] [bbotk]                          3                    2472                 0.4557109
INFO  [19:40:11.525] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:40:11.525] [bbotk]  0.00986943 <list[8]>              FALSE     0.02780116        0      0
INFO  [19:40:11.525] [bbotk]  runtime_learners                                uhash
INFO  [19:40:11.525] [bbotk]           157.238 10d2028f-0199-4092-896f-c338f5742af4
INFO  [19:40:16.646] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 83 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:40:28.150] [bbotk] Evaluating 1 configuration(s)
INFO  [19:40:28.481] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:40:28.586] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:41:06.639] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:41:42.712] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:42:07.338] [mlr3] Finished benchmark
INFO  [19:42:08.873] [bbotk] Result of batch 53:
INFO  [19:42:08.885] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:42:08.885] [bbotk]              -3.984496                         0.1297976
INFO  [19:42:08.885] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:42:08.885] [bbotk]                         0.1066274            -0.57593               1.965574
INFO  [19:42:08.885] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:42:08.885] [bbotk]                         10                    1049                 0.6194651
INFO  [19:42:08.885] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:42:08.885] [bbotk]  0.01296079 <list[8]>              FALSE     0.02813041        0      0
INFO  [19:42:08.885] [bbotk]  runtime_learners                                uhash
INFO  [19:42:08.885] [bbotk]            98.262 4e2226bc-cf9f-49a1-addf-a4501d5e4571
INFO  [19:42:25.682] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 84 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:42:42.164] [bbotk] Evaluating 1 configuration(s)
INFO  [19:42:42.907] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:42:43.345] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:43:50.892] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:45:07.218] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:46:23.805] [mlr3] Finished benchmark
INFO  [19:46:24.776] [bbotk] Result of batch 54:
INFO  [19:46:24.792] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:46:24.792] [bbotk]               1.159094                         0.4093679
INFO  [19:46:24.792] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:46:24.792] [bbotk]                         0.2477209          -0.4803889              -4.469569
INFO  [19:46:24.792] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:46:24.792] [bbotk]                          6                    3463                 0.6431086
INFO  [19:46:24.792] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:46:24.792] [bbotk]  0.009122716 <list[8]>              FALSE     0.02756618        0      0
INFO  [19:46:24.792] [bbotk]  runtime_learners                                uhash
INFO  [19:46:24.792] [bbotk]           219.701 9cb612ab-06f1-4e54-823d-4fd68ba6f971
INFO  [19:46:27.062] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 85 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:46:38.209] [bbotk] Evaluating 1 configuration(s)
INFO  [19:46:38.260] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:46:38.274] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:47:23.136] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:48:20.213] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:49:43.537] [mlr3] Finished benchmark
INFO  [19:49:44.539] [bbotk] Result of batch 55:
INFO  [19:49:45.010] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:49:45.010] [bbotk]              -1.566116                          0.526987
INFO  [19:49:45.010] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:49:45.010] [bbotk]                         0.5532649          -0.4883973               2.203507
INFO  [19:49:45.010] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:49:45.010] [bbotk]                         14                    2271                  0.995828
INFO  [19:49:45.010] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:49:45.010] [bbotk]  0.00968564 <list[8]>              FALSE     0.03047193        0      0
INFO  [19:49:45.010] [bbotk]  runtime_learners                                uhash
INFO  [19:49:45.010] [bbotk]           184.448 a1616361-21f4-438f-b37d-42118412343c
INFO  [19:49:48.591] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 86 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:49:55.375] [bbotk] Evaluating 1 configuration(s)
INFO  [19:49:55.610] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:49:55.733] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:50:15.174] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:50:43.374] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:51:04.785] [mlr3] Finished benchmark
INFO  [19:51:05.513] [bbotk] Result of batch 56:
INFO  [19:51:05.524] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:51:05.524] [bbotk]              -2.733451                         0.8225151
INFO  [19:51:05.524] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:51:05.524] [bbotk]                         0.2404346          -0.6631752               1.171382
INFO  [19:51:05.524] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:51:05.524] [bbotk]                         15                      39                 0.7019414
INFO  [19:51:05.524] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:51:05.524] [bbotk]  0.009615003 <list[8]>              FALSE     0.02873513        0      0
INFO  [19:51:05.524] [bbotk]  runtime_learners                                uhash
INFO  [19:51:05.524] [bbotk]            68.461 6dcd7da7-8956-40f1-8947-5720b0790031
INFO  [19:51:07.866] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 87 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:51:22.567] [bbotk] Evaluating 1 configuration(s)
INFO  [19:51:22.674] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:51:22.686] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:52:11.828] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:53:16.935] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:54:31.202] [mlr3] Finished benchmark
INFO  [19:54:33.912] [bbotk] Result of batch 57:
INFO  [19:54:34.054] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:54:34.054] [bbotk]              -1.222666                         0.2249802
INFO  [19:54:34.054] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:54:34.054] [bbotk]                          0.110245           -4.284683               1.601846
INFO  [19:54:34.054] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:54:34.054] [bbotk]                         13                    3974                 0.4509502
INFO  [19:54:34.054] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:54:34.054] [bbotk]  0.01344356 <list[8]>              FALSE     0.02973529        0      0
INFO  [19:54:34.054] [bbotk]  runtime_learners                                uhash
INFO  [19:54:34.054] [bbotk]           187.987 c5408872-cb1e-41e6-9ee7-05c214843cec
INFO  [19:54:45.289] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 88 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:55:13.036] [bbotk] Evaluating 1 configuration(s)
INFO  [19:55:13.158] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:55:13.207] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [19:56:10.559] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [19:57:19.828] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:58:32.043] [mlr3] Finished benchmark
INFO  [19:58:32.895] [bbotk] Result of batch 58:
INFO  [19:58:32.906] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:58:32.906] [bbotk]              -4.978533                         0.1839978
INFO  [19:58:32.906] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:58:32.906] [bbotk]                         0.1639035         -0.08418541              -3.561651
INFO  [19:58:32.906] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:58:32.906] [bbotk]                         16                    4857                 0.4832659
INFO  [19:58:32.906] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:58:32.906] [bbotk]  0.009495475 <list[8]>              FALSE     0.03501821        0      0
INFO  [19:58:32.906] [bbotk]  runtime_learners                                uhash
INFO  [19:58:32.906] [bbotk]           198.287 7c7d2d92-245f-40f6-bbe5-5a4f07f41a8e
INFO  [19:58:56.086] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 89 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:59:13.002] [bbotk] Evaluating 1 configuration(s)
INFO  [19:59:13.542] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:59:13.650] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:00:52.417] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:02:34.999] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:04:07.041] [mlr3] Finished benchmark
INFO  [20:04:08.320] [bbotk] Result of batch 59:
INFO  [20:04:08.459] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:04:08.459] [bbotk]              -2.670312                         0.9554983
INFO  [20:04:08.459] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:04:08.459] [bbotk]                         0.2622435           -2.741735              -6.267796
INFO  [20:04:08.459] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:04:08.459] [bbotk]                         11                    4562                 0.3574856
INFO  [20:04:08.459] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:04:08.459] [bbotk]  0.01274476 <list[8]>              FALSE     0.02651208        0      0
INFO  [20:04:08.459] [bbotk]  runtime_learners                                uhash
INFO  [20:04:08.459] [bbotk]           292.691 bc779760-3fd4-44c3-aacd-565ef087e234
INFO  [20:04:10.953] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 90 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:04:21.121] [bbotk] Evaluating 1 configuration(s)
INFO  [20:04:21.174] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:04:21.186] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:05:58.934] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:07:35.753] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:09:19.296] [mlr3] Finished benchmark
INFO  [20:09:19.776] [bbotk] Result of batch 60:
INFO  [20:09:19.936] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:09:19.936] [bbotk]              -3.601535                         0.9050405
INFO  [20:09:19.936] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:09:19.936] [bbotk]                         0.6983669            -1.20237               -1.44717
INFO  [20:09:19.936] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:09:19.936] [bbotk]                          6                    4899                 0.1333733
INFO  [20:09:19.936] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:09:19.936] [bbotk]  0.009292377 <list[8]>              FALSE     0.02790273        0      0
INFO  [20:09:19.936] [bbotk]  runtime_learners                                uhash
INFO  [20:09:19.936] [bbotk]           297.382 79fc5275-e138-4a1a-b44c-1a522007d5a7
INFO  [20:09:28.572] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 91 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:09:46.016] [bbotk] Evaluating 1 configuration(s)
INFO  [20:09:46.968] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:09:47.021] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:10:12.689] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:10:45.922] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [20:11:12.018] [mlr3] Finished benchmark
INFO  [20:11:12.273] [bbotk] Result of batch 61:
INFO  [20:11:12.289] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:11:12.289] [bbotk]               -2.72527                         0.4786112
INFO  [20:11:12.289] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:11:12.289] [bbotk]                         0.2231441         -0.01410543               5.810541
INFO  [20:11:12.289] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:11:12.289] [bbotk]                          2                     409                 0.1326005
INFO  [20:11:12.289] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:11:12.289] [bbotk]  0.008790353 <list[8]>              FALSE     0.03825639        0      0
INFO  [20:11:12.289] [bbotk]  runtime_learners                                uhash
INFO  [20:11:12.289] [bbotk]              84.5 964da810-5e00-489b-8459-13efc5612d17
INFO  [20:11:16.455] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 92 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:11:40.910] [bbotk] Evaluating 1 configuration(s)
INFO  [20:11:41.058] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:11:41.171] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:13:26.586] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:15:30.943] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:16:30.000] [mlr3] Finished benchmark
INFO  [20:16:30.646] [bbotk] Result of batch 62:
INFO  [20:16:30.758] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:16:30.758] [bbotk]              -1.601214                          0.950287
INFO  [20:16:30.758] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:16:30.758] [bbotk]                         0.1363885           -4.563228               1.445429
INFO  [20:16:30.758] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:16:30.758] [bbotk]                         11                    4564                 0.1099923
INFO  [20:16:30.758] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:16:30.758] [bbotk]  0.00920748 <list[8]>              FALSE     0.03401491        0      0
INFO  [20:16:30.758] [bbotk]  runtime_learners                                uhash
INFO  [20:16:30.758] [bbotk]           288.527 3d348b9b-32f4-4bb2-8da3-281d38e81606
WARN  [20:16:37.052] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [20:16:37.150] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 93 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:16:44.170] [bbotk] Evaluating 1 configuration(s)
INFO  [20:16:44.219] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:16:44.246] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:17:17.189] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:17:55.671] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:18:54.372] [mlr3] Finished benchmark
INFO  [20:18:54.814] [bbotk] Result of batch 63:
INFO  [20:18:54.834] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:18:54.834] [bbotk]              -4.067226                         0.8113608
INFO  [20:18:54.834] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:18:54.834] [bbotk]                         0.2265486           -2.621659              -6.153002
INFO  [20:18:54.834] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:18:54.834] [bbotk]                         12                    1555                 0.6156834
INFO  [20:18:54.834] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:18:54.834] [bbotk]  0.009417888 <list[8]>              FALSE     0.02560432        0      0
INFO  [20:18:54.834] [bbotk]  runtime_learners                                uhash
INFO  [20:18:54.834] [bbotk]           130.031 7161b752-3c42-4dd4-9427-7acaa59fece0
INFO  [20:18:59.151] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 94 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:19:08.427] [bbotk] Evaluating 1 configuration(s)
INFO  [20:19:08.581] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:19:08.674] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:20:33.209] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:21:15.959] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:21:55.212] [mlr3] Finished benchmark
INFO  [20:21:55.779] [bbotk] Result of batch 64:
INFO  [20:21:55.797] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:21:55.797] [bbotk]              -6.249412                         0.5690768
INFO  [20:21:55.797] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:21:55.797] [bbotk]                         0.1809569           -4.295649              -2.324198
INFO  [20:21:55.797] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:21:55.797] [bbotk]                         11                    4629                 0.6638107
INFO  [20:21:55.797] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:21:55.797] [bbotk]  0.009288637 <list[8]>              FALSE     0.02607393        0      0
INFO  [20:21:55.797] [bbotk]  runtime_learners                                uhash
INFO  [20:21:55.797] [bbotk]           166.232 13435aee-de75-404b-acd4-d233c0b03855
INFO  [20:21:57.526] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 95 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:22:08.215] [bbotk] Evaluating 1 configuration(s)
INFO  [20:22:08.240] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:22:08.414] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:23:44.985] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:24:47.311] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:25:47.487] [mlr3] Finished benchmark
INFO  [20:25:47.566] [bbotk] Result of batch 65:
INFO  [20:25:47.573] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:25:47.573] [bbotk]              -2.255995                         0.9985877
INFO  [20:25:47.573] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:25:47.573] [bbotk]                         0.2708015           -6.428638               -1.21837
INFO  [20:25:47.573] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:25:47.573] [bbotk]                         19                    3123                 0.8912598
INFO  [20:25:47.573] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:25:47.573] [bbotk]  0.02053947 <list[8]>              FALSE     0.03187661        0      0
INFO  [20:25:47.573] [bbotk]  runtime_learners                                uhash
INFO  [20:25:47.573] [bbotk]           218.779 7470c3a0-b8b2-44c9-8c48-e74155b98d3e
INFO  [20:25:50.534] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 96 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:26:01.039] [bbotk] Evaluating 1 configuration(s)
INFO  [20:26:01.184] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:26:01.315] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:26:21.033] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:26:43.526] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:27:08.649] [mlr3] Finished benchmark
INFO  [20:27:08.741] [bbotk] Result of batch 66:
INFO  [20:27:08.751] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:27:08.751] [bbotk]              0.1023092                          0.394659
INFO  [20:27:08.751] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:27:08.751] [bbotk]                         0.2956643           -3.148633              -4.138663
INFO  [20:27:08.751] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:27:08.751] [bbotk]                         12                    4602                 0.6820083
INFO  [20:27:08.751] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:27:08.751] [bbotk]  0.008090836 <list[8]>              FALSE     0.02765639        0      0
INFO  [20:27:08.751] [bbotk]  runtime_learners                                uhash
INFO  [20:27:08.751] [bbotk]            67.149 b2ef9f73-0f4d-43a6-8444-a64ec63a7855
INFO  [20:27:12.706] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 97 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:27:16.688] [bbotk] Evaluating 1 configuration(s)
INFO  [20:27:16.717] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:27:16.732] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:27:38.666] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:28:00.777] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:28:26.891] [mlr3] Finished benchmark
INFO  [20:28:26.955] [bbotk] Result of batch 67:
INFO  [20:28:26.962] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:28:26.962] [bbotk]                -6.8621                         0.9768985
INFO  [20:28:26.962] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:28:26.962] [bbotk]                         0.4092651           -4.019731              -6.879364
INFO  [20:28:26.962] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:28:26.962] [bbotk]                         19                    4996                 0.4714043
INFO  [20:28:26.962] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:28:26.962] [bbotk]  0.008603658 <list[8]>              FALSE     0.02575373        0      0
INFO  [20:28:26.962] [bbotk]  runtime_learners                                uhash
INFO  [20:28:26.962] [bbotk]            70.067 75ee5069-c874-4b30-953d-56b73e3615f9
INFO  [20:28:31.316] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 98 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:28:39.391] [bbotk] Evaluating 1 configuration(s)
INFO  [20:28:39.432] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:28:39.446] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:29:13.966] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:29:40.520] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:30:11.122] [mlr3] Finished benchmark
INFO  [20:30:11.439] [bbotk] Result of batch 68:
INFO  [20:30:11.482] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:30:11.482] [bbotk]              -4.571269                           0.21307
INFO  [20:30:11.482] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:30:11.482] [bbotk]                         0.2815479           -5.046606              -6.259414
INFO  [20:30:11.482] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:30:11.482] [bbotk]                         14                     811                 0.9834585
INFO  [20:30:11.482] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:30:11.482] [bbotk]  0.008175138 <list[8]>              FALSE     0.02995376        0      0
INFO  [20:30:11.482] [bbotk]  runtime_learners                                uhash
INFO  [20:30:11.482] [bbotk]            91.462 1d86b301-75f4-4b35-8bc6-d3cf3dc56ab9
INFO  [20:30:13.913] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 99 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:30:19.942] [bbotk] Evaluating 1 configuration(s)
INFO  [20:30:20.027] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:30:20.041] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [20:30:42.564] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [20:31:22.468] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:32:08.729] [mlr3] Finished benchmark
INFO  [20:32:08.943] [bbotk] Result of batch 69:
INFO  [20:32:08.952] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:32:08.952] [bbotk]              -2.069093                         0.7464075
INFO  [20:32:08.952] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:32:08.952] [bbotk]                         0.8403691           -1.909972              -1.620207
INFO  [20:32:08.952] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:32:08.952] [bbotk]                          3                    4738                 0.3433379
INFO  [20:32:08.952] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:32:08.952] [bbotk]  0.007573557 <list[8]>              FALSE     0.02733793        0      0
INFO  [20:32:08.952] [bbotk]  runtime_learners                                uhash
INFO  [20:32:08.952] [bbotk]           108.487 3866e026-3785-43d0-92ec-543c162fc142
WARN  [20:32:12.056] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [20:32:12.075] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 100 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:32:12.196] [bbotk] Finished optimizing after 100 evaluation(s)
INFO  [20:32:12.209] [bbotk] Result:
INFO  [20:32:12.230] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:32:12.230] [bbotk]                  <num>                             <num>
INFO  [20:32:12.230] [bbotk]              -6.553251                          0.256575
INFO  [20:32:12.230] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:32:12.230] [bbotk]                             <num>               <num>                  <num>
INFO  [20:32:12.230] [bbotk]                          0.338117           -2.587022              0.8733831
INFO  [20:32:12.230] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:32:12.230] [bbotk]                      <int>                   <int>                     <num>
INFO  [20:32:12.230] [bbotk]                         19                    4646                  0.670014
INFO  [20:32:12.230] [bbotk]  learner_param_vals  x_domain classif.bbrier
INFO  [20:32:12.230] [bbotk]              <list>    <list>          <num>
INFO  [20:32:12.230] [bbotk]          <list[10]> <list[8]>      0.0237276
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()

### [bt]: Job terminated successfully [batchtools job.id=1440]
### [bt]: Calculation finished!
