### [bt]: This is batchtools v0.9.17
### [bt]: Starting calculation of 1 jobs
### [bt]: Setting working directory to '/content/drive/MyDrive/GitHub/Mater_Thesis_Calibration'
ece.R :
Friedmann_tasks.R :
Functions.R :
ici.R :
mse_feature_effects.R :
PipeOpCalibration_TuningExperiment.R :
PipeOpCalibration.R :
PipeOpCalibrationUnion.R :
### [bt]: Memory measurement disabled
### [bt]: Starting job [batchtools job.id=1420]
### [bt]: Generating problem instance for problem '341ee781c7d79b8f' ...
### [bt]: Applying algorithm 'run_learner' on problem '341ee781c7d79b8f' for job 1420 (seed = 1543) ...
INFO  [16:07:21.234] [mlr3] Applying learner 'xgboost TwP beta' on task 'wdbc' (iter 10/10)
INFO  [16:07:22.073] [bbotk] Starting to optimize 8 parameter(s) with '<OptimizerMbo>' and '<TerminatorEvals> [n_evals=100, k=0]'
INFO  [16:07:30.920] [bbotk] Evaluating 32 configuration(s)
INFO  [16:07:31.809] [mlr3] Running benchmark with 96 resampling iterations
INFO  [16:07:32.093] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 81.80846
[1] 4373.217
[1] -698250.5
[1] -12753.51
[1] -3978.655
[1] -72.44422
[1] 58.2957
[1] 3062.692
[1] -874.6983
[1] 2043.886
INFO  [16:08:41.988] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -2354.918
[1] 1575.531
[1] 62.60705
[1] 3331.003
[1] 71.82467
[1] 3777.493
[1] -3017.539
[1] -54.73598
[1] -5125.042
[1] -94.99747
INFO  [16:09:18.788] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 89.99972
[1] 4755.381
[1] -6277.773
[1] -116.8589
[1] -3673.214
[1] -65.95823
[1] 45.86213
[1] 2445.834
[1] 95.99544
[1] 5121.388
INFO  [16:10:25.549] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -25.10927
[1] 225.6778
[1] -198.6789
[1] 135.905
[1] -286.6904
[1] -5.268775
[1] -5.237521
[1] 259.0249
[1] 5.659773
[1] 260.3724
INFO  [16:11:32.334] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -393.3002
[1] -5.161689
[1] -256.1525
[1] 61.5488
[1] -251.6026
[1] -2.674368
[1] -0.3203861
[1] 433.537
[1] -78.53258
[1] 116.5758
INFO  [16:12:56.564] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -280.0238
[1] 50.15676
[1] -381.8902
[1] -5.81795
[1] -242.1286
[1] 70.02644
[1] -229.2033
[1] 13.62099
[1] -146.1275
[1] 152.9392
INFO  [16:14:03.995] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -55.10133
[1] 4.808149
[1] -35.57978
[1] 22.55519
[1] -53.51481
[1] 47.36277
[1] 38.75893
[1] 759.838
[1] -114.2959
[1] 70.24278
INFO  [16:15:33.159] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -55.69363
[1] 10.44699
[1] -47.71128
[1] 17.67897
[1] -5226.808
[1] -55.53676
[1] -28.68458
[1] 44.05496
[1] -60.97095
[1] 114.1353
INFO  [16:16:45.540] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -37.95031
[1] 38.64935
[1] -157.793
[1] 7.709915
[1] -87.16122
[1] -2.677591
[1] -47.89031
[1] 21.22331
[1] -46.03889
[1] 35.22065
INFO  [16:17:52.020] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:18:35.343] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:19:08.906] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:19:57.489] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 20.0936
[1] 955.6229
[1] 82.50061
[1] 4257.814
[1] 31.20641
[1] 1432.889
[1] 39.58071
[1] 1957.01
[1] -1557.062
[1] -24.29123
INFO  [16:21:18.018] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -2318.362
[1] -38.645
[1] -1830.426
[1] -31.6541
[1] -2486.923
[1] -41.78681
[1] -1994.042
[1] -31.76321
[1] -1024.742
[1] -16.51718
INFO  [16:22:28.121] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1620.584
[1] -26.01748
[1] -103.3327
[1] 837.8154
[1] 34.67067
[1] 1708.534
[1] 23.04555
[1] 1096.491
[1] -2625.833
[1] -45.32541
INFO  [16:24:26.660] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -58.80375
[1] 67.5139
[1] -85.2185
[1] -0.5676706
[1] -6261.296
[1] -113.6361
[1] -47.57802
[1] 16.74996
[1] -13.30813
[1] 76.68953
INFO  [16:25:04.177] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -39.31132
[1] 11.1107
[1] -60.27455
[1] 57.66344
[1] 51.93922
[1] 1590.552
[1] -19.94899
[1] 57.88569
[1] -76.79384
[1] 28.11018
INFO  [16:25:52.234] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -439.3138
[1] -4.046592
[1] -28.58246
[1] 91.26196
[1] -178.2914
[1] 5.876975
[1] -24.99511
[1] 44.98736
[1] -137.1907
[1] 16.58838
INFO  [16:26:35.663] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 78.93835
[1] 4234.156
[1] 104.1277
[1] 5463.752
[1] 109.3252
[1] 5732.184
[1] -10505.31
[1] -194.6132
[1] -3544.666
[1] -65.00076
INFO  [16:27:19.382] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 166.8547
[1] 8807.17
[1] -5037.627
[1] -91.38954
[1] -3732.798
[1] -67.52888
[1] -3653.063
[1] -66.92766
[1] 82.83425
[1] 4458.002
INFO  [16:28:18.617] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -6287.303
[1] -116.0471
[1] 82.36379
[1] 4334.519
[1] 63.6056
[1] 3383.809
[1] -3571.419
[1] -65.92276
[1] 88.08056
[1] 4648.933
INFO  [16:29:07.183] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -98.83674
[1] 19.20827
[1] -17.35097
[1] 99.52624
[1] -94.29602
[1] 63.62486
[1] -2389.738
[1] -84.92208
[1] -39.79326
[1] 68.08518
INFO  [16:29:40.904] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 116.1517
[1] 3214.822
[1] -255.594
[1] 2.990085
[1] -281.582
[1] 79.58155
[1] -134.1059
[1] -4.353905
[1] -94.35348
[1] -2.557121
INFO  [16:30:21.071] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -72.88146
[1] 28.72241
[1] -113.0858
[1] 14.54261
[1] -195.7921
[1] 28.80516
[1] -151.2901
[1] 59.04471
[1] -250.1724
[1] 11.87035
INFO  [16:30:42.587] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:31:06.865] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:31:29.817] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:31:50.787] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -105.9312
[1] -3.613116
[1] -3028.896
[1] -49.62259
[1] -24.00926
[1] 48.69057
[1] -50233
[1] -673.7322
[1] 205.482
[1] 6126.798
INFO  [16:32:45.244] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -67.71721
[1] 14.78493
[1] -110.0591
[1] -1.465938
[1] 98.55994
[1] 2749.144
[1] -37.16226
[1] 32.12639
[1] -87.94187
[1] 25.15842
INFO  [16:33:30.477] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -86.46714
[1] 24.80063
[1] -40.57868
[1] 10.82033
[1] -47.53969
[1] 86.67707
[1] -3.35758e+16
[1] 9.888131e+15
[1] -61.82881
[1] 45.55579
INFO  [16:34:10.906] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -50.33554
[1] 53.40555
[1] -56.12629
[1] 101.4729
[1] -8.88108
[1] 72.86289
[1] -174.1076
[1] 250.3949
[1] -76.44753
[1] 21.41397
INFO  [16:35:37.902] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -42.87223
[1] 105.2818
[1] -103.7236
[1] 13.36937
[1] -82.05169
[1] 20.29934
[1] -64.68667
[1] 157.6183
[1] -46.09436
[1] 102.143
INFO  [16:37:39.754] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -149.5254
[1] 36.98639
[1] -129.8397
[1] 4.153972
[1] -96.26693
[1] 19.9253
[1] -48.16808
[1] 49.88967
[1] -215.9537
[1] 3.67891
INFO  [16:40:06.293] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -139.2984
[1] 269.348
[1] -327.8285
[1] -4.672635
[1] -88.46375
[1] 78.96223
[1] 2.951898
[1] 144.5017
[1] -82.26947
[1] 76.27796
INFO  [16:40:50.115] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -36.61114
[1] 227.6392
[1] -175.2361
[1] -1.0018
[1] -294.7854
[1] -4.562817
[1] -254.1465
[1] 33.12361
[1] -62.62853
[1] 130.264
INFO  [16:41:37.976] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -119.0425
[1] 71.64318
[1] -39.4463
[1] 221.2224
[1] -101.1364
[1] 87.53622
[1] -314.9613
[1] -4.441377
[1] -149.3696
[1] 22.14536
INFO  [16:42:21.102] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -25.99793
[1] 72.1426
[1] -70.61911
[1] 22.30233
[1] -34.16923
[1] 59.85929
[1] -6646.52
[1] -144.4066
[1] -41.18859
[1] 25.0239
INFO  [16:42:49.174] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -2334.487
[1] -65.55606
[1] -72.99017
[1] -3.065061
[1] -29.23374
[1] 17.39116
[1] 1596.689
[1] 31600.64
[1] -39.17976
[1] 52.91478
INFO  [16:43:30.597] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -27.67275
[1] 48.06764
[1] -47.18481
[1] 20.40782
[1] -73.94109
[1] 53.59662
[1] -33.41382
[1] 15.71401
[1] -77.64283
[1] 40.95971
INFO  [16:44:08.102] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:44:56.946] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:45:49.317] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:46:51.639] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -4.359225e+15
[1] 3.02588e+16
[1] -2411.774
[1] -101.5222
[1] -533.5487
[1] 2.564804
[1] -25.55681
[1] 55.00172
[1] -53.74082
[1] 8.20483
INFO  [16:48:25.553] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -59.75372
[1] 15.97736
[1] -28.24654
[1] 205.3187
[1] -31.01129
[1] 25.30318
[1] -325.8206
[1] 15.77423
[1] -2701.622
[1] -66.48238
INFO  [16:49:26.635] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2627.336
[1] -101.1093
[1] -20.85837
[1] 35.18254
[1] -35.0593
[1] 20.70325
[1] -1326.191
[1] 14.81166
[1] -115.4196
[1] 1.028925
INFO  [16:50:41.965] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -405.1298
[1] -6.453135
[1] 10.58932
[1] 362.2006
[1] 7.954763
[1] 340.3011
[1] -220.3028
[1] 194.2238
[1] -902.8076
[1] -16.02941
INFO  [16:51:17.729] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -410.7461
[1] -6.33355
[1] -377.4638
[1] -5.739082
[1] 791.9475
[1] 29898.36
[1] -361.0055
[1] -6.467591
[1] -6258.491
[1] -121.4226
INFO  [16:52:15.197] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 16.20337
[1] 607.8091
[1] -354.0216
[1] -6.315254
[1] -831.8385
[1] 350.6555
[1] -112.9631
[1] 217.9109
[1] -259.995
[1] 22.55723
INFO  [16:52:58.360] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -43.14498
[1] 27.90445
[1] 3.435789
[1] 125.7031
[1] -27.51114
[1] 61.52417
[1] -53.37278
[1] 2.141954
[1] -139.8012
[1] 0.363763
INFO  [16:53:43.084] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -103.5596
[1] 63.66061
[1] -31.09243
[1] 153.5549
[1] -110.4386
[1] 0.1061874
[1] -23.84946
[1] 11.99088
[1] -26.85972
[1] 26.52867
INFO  [16:54:40.554] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -9.091912
[1] 56.50181
[1] -6.864525
[1] 27.9184
[1] -46.57319
[1] -2.895666
[1] -56.77134
[1] 12.61724
[1] -24.41831
[1] 59.01019
INFO  [16:55:18.712] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -186.6567
[1] 49.32408
[1] -76.09323
[1] 202.6206
[1] -936.7554
[1] 380.9689
[1] -257.3736
[1] 145.4149
[1] -85.67935
[1] 158.7947
INFO  [16:55:58.769] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -462.3394
[1] -6.49728
[1] -161.3948
[1] 38.27637
[1] -333.3935
[1] 50.88514
[1] -227.1275
[1] 243.2879
[1] -68.0332
[1] 95.35437
INFO  [16:56:46.989] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -191.0928
[1] 16.47662
[1] -47.66027
[1] 166.0073
[1] -144.1003
[1] 98.80158
[1] -224.1164
[1] 57.79794
[1] -179.4396
[1] 160.3623
INFO  [16:57:10.745] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 51045.88
[1] 2752857
[1] 1117.915
[1] 60128.08
[1] -434268.6
[1] -8014.584
[1] 2089.776
[1] 112854.7
INFO  [16:57:55.310] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -466644.1
[1] -8612.48
[1] 2793.544
[1] 150669.9
[1] 24397.06
[1] 1320843
[1] -2899140
[1] -53536.56
INFO  [16:58:36.578] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 3688.664
[1] 199409.2
[1] -197668.2
[1] -3648.975
[1] 5782.403
[1] 312794.7
[1] 10955.49
[1] 593008.8
[1] 3094.581
[1] 167319.4
INFO  [16:59:24.223] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1010.943
[1] -19.32935
[1] 53.04147
[1] 2628.736
[1] -1869.077
[1] -34.82545
[1] 28.79633
[1] 1527.069
[1] 34.74585
[1] 1990.693
INFO  [17:00:01.105] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -16.41013
[1] 1825.358
[1] 26.31714
[1] 1447.917
[1] -969.2947
[1] -17.7079
[1] -1599.55
[1] -29.9796
[1] 36.50402
[1] 1889.852
INFO  [17:00:25.642] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 30.67762
[1] 1664.703
[1] -1142.706
[1] -20.80743
[1] -1471.318
[1] -27.57937
[1] -1768.358
[1] -33.86034
[1] -1541.819
[1] 479.1438
INFO  [17:00:47.492] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 19.43429
[1] 1028.769
[1] -140.5502
[1] 144.9402
[1] -395.1118
[1] -6.297891
[1] -69.15937
[1] 241.6988
[1] -177.0839
[1] 180.2995
INFO  [17:01:37.646] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -68.03236
[1] 591.2197
[1] 9.043992
[1] 456.7998
[1] -212.0514
[1] 69.74048
[1] -293.2502
[1] -5.217682
[1] 10.90248
[1] 556.2097
INFO  [17:02:23.933] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -338.6675
[1] -6.121011
[1] -117.432
[1] 207.7137
[1] -1.051968
[1] 294.2738
[1] -405.6215
[1] -8.276047
[1] -374.6486
[1] -6.720066
INFO  [17:03:10.677] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:03:32.378] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:03:50.233] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:04:19.223] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -53.46263
[1] 31.22125
[1] -10.44974
[1] 56.70655
[1] -43.98975
[1] 44.75364
[1] -2196.777
[1] -61.96251
[1] -160.114
[1] 16.50356
INFO  [17:05:12.988] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 160.78
[1] 3846.095
[1] -28.92469
[1] 27.43589
[1] -50.48006
[1] 6.720455
[1] -63.11918
[1] 9.085836
[1] -52.20299
[1] 48.98254
INFO  [17:05:58.139] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -37.687
[1] 15.34662
[1] -73.22052
[1] 1.801584
[1] -43.82693
[1] 12.47448
[1] -114.5834
[1] 8.805581
[1] -48.64555
[1] 37.24463
INFO  [17:06:47.220] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -133.1778
[1] 47.41543
[1] -5798.576
[1] -82.87224
[1] -35.95017
[1] 86.024
[1] 131.071
[1] 3557.233
[1] -108.5243
[1] -3.663133
INFO  [17:07:59.615] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -184.4207
[1] -4.200429
[1] -48.63572
[1] 140.828
[1] -409.9115
[1] -5.138593
[1] -131.1368
[1] 1.09404
[1] -56.6273
[1] 204.5631
INFO  [17:08:52.166] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -58.16551
[1] 53.92925
[1] -89.05041
[1] 28.34059
[1] -267.8787
[1] 712.4813
[1] -93.03256
[1] 38.30561
[1] -14.38902
[1] 368.9608
INFO  [17:10:36.615] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:11:37.970] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:13:07.340] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:14:11.617] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 48.88306
[1] 2530.995
[1] 39.90153
[1] 2005.918
[1] 140.3454
[1] 7324.47
[1] -1553.414
[1] -28.63619
[1] 45.42885
[1] 2307.907
INFO  [17:14:49.386] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 42.74406
[1] 2149.382
[1] -2120.428
[1] -38.07307
[1] -2001.977
[1] -35.98702
[1] 42.0608
[1] 2222.511
[1] -1789.029
[1] -31.12831
INFO  [17:15:36.338] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1409.712
[1] -25.73537
[1] 43.54247
[1] 2182.473
[1] -58892.27
[1] -1020.458
[1] -124557.3
[1] -2274.531
[1] -1452.693
[1] -26.33152
INFO  [17:16:20.620] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1552.655
[1] -29.26019
[1] -2543.811
[1] -47.82923
[1] 22.10635
[1] 1122.96
[1] 28.42191
[1] 1521.651
[1] -1135.406
[1] 1876.469
INFO  [17:16:46.520] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1477.28
[1] -26.6249
[1] -1628.312
[1] -29.34634
[1] -1200.222
[1] 289.6456
[1] -1407.004
[1] -27.16506
[1] -234.1569
[1] 1023.982
INFO  [17:17:22.731] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1329.409
[1] -24.74514
[1] -1552.68
[1] -29.09215
[1] -1484.068
[1] -26.99717
[1] 39.96186
[1] 2114.881
[1] -1417.152
[1] -26.08939
INFO  [17:17:58.509] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -4124.77
[1] -91.50791
[1] 77.26679
[1] 1381.871
[1] -59.04895
[1] 934.2511
[1] -15.90691
[1] 49.09437
[1] -108.7094
[1] 5.227974
INFO  [17:18:51.684] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -16.24392
[1] 67.39209
[1] -52.30265
[1] 23.11613
[1] -16.33955
[1] 142.8371
[1] -63.05978
[1] -2.609404
[1] -1136.15
[1] -38.24615
INFO  [17:19:43.971] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -103.3852
[1] 52.55467
[1] -63.10244
[1] 4.350608
[1] -76.25845
[1] 28.15854
[1] -242.8399
[1] -4.052728
[1] -31.90384
[1] 100.699
INFO  [17:20:39.864] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:21:11.958] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:21:53.679] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:22:15.236] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -4189.439
[1] -57.84102
[1] -69.47361
[1] 60.03593
[1] -63.74324
[1] 40.97379
[1] -14.41843
[1] 104.0146
[1] -93.42295
[1] 24.15978
INFO  [17:22:53.778] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -32341.57
[1] -868.4047
[1] -67.877
[1] 66.5351
[1] -59.56637
[1] 167.1372
[1] -87.71624
[1] 32.1788
[1] -403.5285
[1] -3.695964
INFO  [17:23:41.816] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -142.399
[1] 18.3356
[1] -239.5999
[1] -4.146986
[1] -361.2412
[1] -4.424637
[1] -102.2488
[1] 127.9534
[1] -86.97743
[1] 23.40576
INFO  [17:24:39.664] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -24.23429
[1] 329.3857
[1] -173.1882
[1] 149.7723
[1] 10.55831
[1] 466.9951
[1] -255.4799
[1] 96.0883
[1] -441.1374
[1] -7.113721
INFO  [17:25:24.558] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -397.0073
[1] 1.587004
[1] -200.311
[1] 117.6872
[1] 8.16814
[1] 369.0119
[1] -20892.13
[1] -423.6259
[1] -412.7828
[1] -6.648374
INFO  [17:25:59.880] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -269.4134
[1] 39.55123
[1] -385.7006
[1] -6.638395
[1] -203.2448
[1] 132.5023
[1] -333.1559
[1] 277.7656
[1] -42612.15
[1] -727.6693
INFO  [17:26:57.546] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1810.908
[1] -58.11454
[1] -20.01238
[1] 23.75625
[1] 59.04723
[1] 1150.514
[1] -82.7303
[1] 136.0259
[1] -37.9689
[1] 35.11341
INFO  [17:27:18.585] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -252.2638
[1] -4.048947
[1] -54.33867
[1] 9.656418
[1] -49.30953
[1] 57.73042
[1] -650.3585
[1] -28.83956
[1] -7383.382
[1] -162.2659
INFO  [17:27:46.168] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -67.93418
[1] 22.45254
[1] -30.15751
[1] 20.64188
[1] -36.84288
[1] 11.9433
[1] -43.7232
[1] 28.45792
[1] -233.4043
[1] 50.2075
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:28:26.652] [mlr3] Finished benchmark
INFO  [17:28:28.143] [bbotk] Result of batch 1:
INFO  [17:28:28.185] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:28:28.185] [bbotk]            -4.69230504                         0.3299738
INFO  [17:28:28.185] [bbotk]             2.21545004                         0.7799738
INFO  [17:28:28.185] [bbotk]            -1.23842719                         0.5549738
INFO  [17:28:28.185] [bbotk]             5.66932768                         0.1049738
INFO  [17:28:28.185] [bbotk]             3.94238886                         0.6674738
INFO  [17:28:28.185] [bbotk]            -2.96536601                         0.2174738
INFO  [17:28:28.185] [bbotk]            -6.41924380                         0.8924738
INFO  [17:28:28.185] [bbotk]             0.48851122                         0.4424738
INFO  [17:28:28.185] [bbotk]             4.80585827                         0.3862238
INFO  [17:28:28.185] [bbotk]            -2.10189660                         0.8362238
INFO  [17:28:28.185] [bbotk]             1.35198063                         0.6112238
INFO  [17:28:28.185] [bbotk]            -5.55577445                         0.1612238
INFO  [17:28:28.185] [bbotk]            -0.37495778                         0.4987238
INFO  [17:28:28.185] [bbotk]             6.53279709                         0.9487238
INFO  [17:28:28.185] [bbotk]            -3.82883563                         0.7237238
INFO  [17:28:28.185] [bbotk]             3.07891945                         0.2737238
INFO  [17:28:28.185] [bbotk]            -6.85097851                         0.4705988
INFO  [17:28:28.185] [bbotk]             0.05677651                         0.9205988
INFO  [17:28:28.185] [bbotk]             3.51065415                         0.2455988
INFO  [17:28:28.185] [bbotk]            -3.39710071                         0.6955988
INFO  [17:28:28.185] [bbotk]            -1.67016190                         0.1330988
INFO  [17:28:28.185] [bbotk]             5.23759297                         0.5830988
INFO  [17:28:28.185] [bbotk]            -5.12403974                         0.8080988
INFO  [17:28:28.185] [bbotk]             1.78371533                         0.3580988
INFO  [17:28:28.185] [bbotk]             6.10106238                         0.5268488
INFO  [17:28:28.185] [bbotk]            -0.80669249                         0.9768488
INFO  [17:28:28.185] [bbotk]             2.64718474                         0.7518488
INFO  [17:28:28.185] [bbotk]            -4.26057033                         0.3018488
INFO  [17:28:28.185] [bbotk]             4.37412356                         0.8643488
INFO  [17:28:28.185] [bbotk]            -2.53363130                         0.4143488
INFO  [17:28:28.185] [bbotk]             0.92024592                         0.1893488
INFO  [17:28:28.185] [bbotk]            -5.98750915                         0.6393488
INFO  [17:28:28.185] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:28:28.185] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:28:28.185] [bbotk]                          0.688608          -7.8945976             5.24945257
INFO  [17:28:28.185] [bbotk]                          0.238608          -3.2894277            -1.65830312
INFO  [17:28:28.185] [bbotk]                          0.463608          -0.9868426             1.79557493
INFO  [17:28:28.185] [bbotk]                          0.913608          -5.5920125            -5.11218076
INFO  [17:28:28.185] [bbotk]                          0.576108          -6.7433050            -6.83911957
INFO  [17:28:28.185] [bbotk]                          0.126108          -2.1381351             0.06863611
INFO  [17:28:28.185] [bbotk]                          0.801108          -9.0458901             3.52251375
INFO  [17:28:28.185] [bbotk]                          0.351108          -4.4407202            -3.38524194
INFO  [17:28:28.185] [bbotk]                          0.182358          -8.4702439             2.65904434
INFO  [17:28:28.185] [bbotk]                          0.632358          -3.8650739            -4.24871135
INFO  [17:28:28.185] [bbotk]                          0.857358          -1.5624888             6.11292198
INFO  [17:28:28.185] [bbotk]                          0.407358          -6.1676588            -0.79483371
INFO  [17:28:28.185] [bbotk]                          0.969858          -2.7137814            -5.97565017
INFO  [17:28:28.185] [bbotk]                          0.519858          -7.3189513             0.93210552
INFO  [17:28:28.185] [bbotk]                          0.294858          -5.0163662            -2.52177253
INFO  [17:28:28.185] [bbotk]                          0.744858          -0.4111963             4.38598316
INFO  [17:28:28.185] [bbotk]                          0.266733          -0.1233732            -3.81697665
INFO  [17:28:28.185] [bbotk]                          0.716733          -4.7285431             3.09077904
INFO  [17:28:28.185] [bbotk]                          0.491733          -2.4259583             6.54465668
INFO  [17:28:28.185] [bbotk]                          0.941733          -7.0311282            -0.36309901
INFO  [17:28:28.185] [bbotk]                          0.604233          -8.1824207            -2.09003783
INFO  [17:28:28.185] [bbotk]                          0.154233          -3.5772508             4.81771786
INFO  [17:28:28.185] [bbotk]                          0.379233          -1.2746657            -5.54391547
INFO  [17:28:28.185] [bbotk]                          0.829233          -5.8798356             1.36384022
INFO  [17:28:28.185] [bbotk]                          0.660483          -1.8503120            -1.22656842
INFO  [17:28:28.185] [bbotk]                          0.210483          -6.4554819             5.68118727
INFO  [17:28:28.185] [bbotk]                          0.435483          -8.7580670            -4.68044606
INFO  [17:28:28.185] [bbotk]                          0.885483          -4.1528971             2.22730963
INFO  [17:28:28.185] [bbotk]                          0.997983          -0.6990194            -2.95350724
INFO  [17:28:28.185] [bbotk]                          0.547983          -5.3041893             3.95424845
INFO  [17:28:28.185] [bbotk]                          0.322983          -7.6067744            -6.40738488
INFO  [17:28:28.185] [bbotk]                          0.772983          -3.0016045             0.50037081
INFO  [17:28:28.185] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:28:28.185] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:28:28.185] [bbotk]                          8                    1246                 0.7090845
INFO  [17:28:28.185] [bbotk]                         18                    3746                 0.2590845
INFO  [17:28:28.185] [bbotk]                          3                    4996                 0.9340845
INFO  [17:28:28.185] [bbotk]                         13                    2496                 0.4840845
INFO  [17:28:28.185] [bbotk]                         16                    4371                 0.8215845
INFO  [17:28:28.185] [bbotk]                          6                    1871                 0.3715845
INFO  [17:28:28.185] [bbotk]                          1                    3121                 0.1465845
INFO  [17:28:28.185] [bbotk]                         11                     621                 0.5965845
INFO  [17:28:28.185] [bbotk]                         19                     309                 0.6528345
INFO  [17:28:28.185] [bbotk]                          9                    2809                 0.2028345
INFO  [17:28:28.185] [bbotk]                         14                    4059                 0.8778345
INFO  [17:28:28.185] [bbotk]                          4                    1559                 0.4278345
INFO  [17:28:28.185] [bbotk]                          2                     934                 0.7653345
INFO  [17:28:28.185] [bbotk]                         12                    3434                 0.3153345
INFO  [17:28:28.185] [bbotk]                          7                    4684                 0.9903345
INFO  [17:28:28.185] [bbotk]                         17                    2184                 0.5403345
INFO  [17:28:28.185] [bbotk]                         16                    3903                 0.5684595
INFO  [17:28:28.185] [bbotk]                          6                    1403                 0.1184595
INFO  [17:28:28.185] [bbotk]                          1                    2653                 0.3434595
INFO  [17:28:28.185] [bbotk]                         11                     153                 0.7934595
INFO  [17:28:28.185] [bbotk]                         19                    3278                 0.4559595
INFO  [17:28:28.185] [bbotk]                          9                     778                 0.9059595
INFO  [17:28:28.185] [bbotk]                         14                    2028                 0.2309595
INFO  [17:28:28.185] [bbotk]                          4                    4528                 0.6809595
INFO  [17:28:28.185] [bbotk]                          7                    4840                 0.7372095
INFO  [17:28:28.185] [bbotk]                         17                    2340                 0.2872095
INFO  [17:28:28.185] [bbotk]                          2                    1090                 0.9622095
INFO  [17:28:28.185] [bbotk]                         12                    3590                 0.5122095
INFO  [17:28:28.185] [bbotk]                          5                    1715                 0.1747095
INFO  [17:28:28.185] [bbotk]                         15                    4215                 0.6247095
INFO  [17:28:28.185] [bbotk]                         10                    2965                 0.3997095
INFO  [17:28:28.185] [bbotk]                         20                     465                 0.8497095
INFO  [17:28:28.185] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:28:28.185] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:28:28.185] [bbotk]      0.04456483        0      0          172.430
INFO  [17:28:28.185] [bbotk]      0.05604369        0      0          217.971
INFO  [17:28:28.185] [bbotk]      0.02771140        0      0          226.592
INFO  [17:28:28.185] [bbotk]      0.43144735        0      0          124.040
INFO  [17:28:28.185] [bbotk]      0.07689110        0      0          267.537
INFO  [17:28:28.185] [bbotk]      0.02626787        0      0          128.810
INFO  [17:28:28.185] [bbotk]      0.04605711        0      0          150.051
INFO  [17:28:28.185] [bbotk]      0.03462580        0      0           94.895
INFO  [17:28:28.185] [bbotk]      0.43144735        0      0           66.475
INFO  [17:28:28.185] [bbotk]      0.02558156        0      0          139.774
INFO  [17:28:28.185] [bbotk]      0.03464030        0      0          354.849
INFO  [17:28:28.185] [bbotk]      0.04105382        0      0          133.948
INFO  [17:28:28.185] [bbotk]      0.02799863        0      0          105.986
INFO  [17:28:28.185] [bbotk]      0.43144735        0      0          163.045
INFO  [17:28:28.185] [bbotk]      0.02811784        0      0          229.793
INFO  [17:28:28.185] [bbotk]      0.04768468        0      0          136.098
INFO  [17:28:28.185] [bbotk]      0.02660100        0      0          139.913
INFO  [17:28:28.185] [bbotk]      0.06019805        0      0          111.351
INFO  [17:28:28.185] [bbotk]      0.41236028        0      0          132.937
INFO  [17:28:28.185] [bbotk]      0.04475076        0      0           82.367
INFO  [17:28:28.185] [bbotk]      0.04389091        0      0          142.448
INFO  [17:28:28.185] [bbotk]      0.43144735        0      0           66.743
INFO  [17:28:28.185] [bbotk]      0.02342543        0      0          145.938
INFO  [17:28:28.185] [bbotk]      0.03980927        0      0          228.041
INFO  [17:28:28.185] [bbotk]      0.43144735        0      0          214.128
INFO  [17:28:28.185] [bbotk]      0.05266740        0      0          128.290
INFO  [17:28:28.185] [bbotk]      0.04769243        0      0           97.417
INFO  [17:28:28.185] [bbotk]      0.02706816        0      0          160.702
INFO  [17:28:28.185] [bbotk]      0.43144735        0      0           94.787
INFO  [17:28:28.185] [bbotk]      0.04079499        0      0          143.955
INFO  [17:28:28.185] [bbotk]      0.05302277        0      0          137.217
INFO  [17:28:28.185] [bbotk]      0.03166726        0      0           77.789
INFO  [17:28:28.185] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:28:28.185] [bbotk]                                 uhash
INFO  [17:28:28.185] [bbotk]  c23c8f90-3be9-4d3a-9230-42c6e203e8d9
INFO  [17:28:28.185] [bbotk]  d4b961c4-7436-4727-9fd4-1c41c35f9999
INFO  [17:28:28.185] [bbotk]  748df6ef-d330-485b-925a-8489bd404ee4
INFO  [17:28:28.185] [bbotk]  563f1414-866e-471e-a87d-86183cbec8c7
INFO  [17:28:28.185] [bbotk]  f1445640-3425-4b27-8b61-7af4f7bb4e15
INFO  [17:28:28.185] [bbotk]  f1c4be1f-3b50-4e3c-bca4-0d4c095f0e35
INFO  [17:28:28.185] [bbotk]  3711b8cd-2a01-4123-b0bd-d5fe7454a0be
INFO  [17:28:28.185] [bbotk]  e439c539-61a0-496f-89fc-f00b0a0579af
INFO  [17:28:28.185] [bbotk]  a41e3ec1-b067-499c-a67b-d312a8e1b9f5
INFO  [17:28:28.185] [bbotk]  d691d0c2-2217-4240-85d8-bbc1e618f849
INFO  [17:28:28.185] [bbotk]  220e28ae-755e-4f2a-ba2a-18006f3b1357
INFO  [17:28:28.185] [bbotk]  4329fe21-ce06-42ce-96d0-4c041591ee89
INFO  [17:28:28.185] [bbotk]  274dd22f-ced9-495b-9937-7fa15e4ff86a
INFO  [17:28:28.185] [bbotk]  5db73801-eaff-4c28-8404-a995945b0a23
INFO  [17:28:28.185] [bbotk]  a78b0b94-9fcc-4540-9279-70c32ce39dac
INFO  [17:28:28.185] [bbotk]  0405bc32-cb6b-4de3-ac0d-283845ac7b8a
INFO  [17:28:28.185] [bbotk]  a0d58f87-87cb-4f7b-8c9a-d0410953badd
INFO  [17:28:28.185] [bbotk]  860c1363-3628-4006-bc49-0bf7b70c7486
INFO  [17:28:28.185] [bbotk]  952c5232-d7aa-44a7-8459-0d222f20a5dc
INFO  [17:28:28.185] [bbotk]  e15d91ff-88d2-4c85-82f4-00f3e0bd3395
INFO  [17:28:28.185] [bbotk]  8c747ebe-d8b2-456a-a9bf-49a6f7d56bb9
INFO  [17:28:28.185] [bbotk]  a919c825-1d92-4b91-8be1-53769a31c51a
INFO  [17:28:28.185] [bbotk]  3ce32399-434a-49d1-aa15-72063ab629fc
INFO  [17:28:28.185] [bbotk]  3aedd8d7-d539-412c-8cc7-d2e0d01d074a
INFO  [17:28:28.185] [bbotk]  79ab75e3-726d-4f61-98a7-86e839fb61ec
INFO  [17:28:28.185] [bbotk]  3c2316bb-b501-4c9f-b802-72b59338c95d
INFO  [17:28:28.185] [bbotk]  d6a46a5a-8acc-4c92-9923-ab792103b63f
INFO  [17:28:28.185] [bbotk]  ac37a3c1-84eb-4e72-8a5a-b721280f2310
INFO  [17:28:28.185] [bbotk]  9a711f98-848c-492f-8017-a16323b6d6e9
INFO  [17:28:28.185] [bbotk]  83397eab-ae25-4cfb-a291-76d69b345642
INFO  [17:28:28.185] [bbotk]  7833ca68-2eb2-4642-bd4b-91b86cda3f99
INFO  [17:28:28.185] [bbotk]  ff6d8282-71b1-49be-90a6-dcf56182f1db
INFO  [17:28:28.185] [bbotk]                                 uhash
INFO  [17:28:37.948] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 32 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:28:42.347] [bbotk] Evaluating 1 configuration(s)
INFO  [17:28:42.388] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:28:42.455] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -86.57626
[1] 51.41011
[1] -106.8563
[1] 163.9153
[1] 5.342582
[1] 179.1385
[1] -113.9096
[1] 75.62333
[1] -2945.274
[1] -63.6614
INFO  [17:29:37.859] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -307.5261
[1] -3.92819
[1] 11.42071
[1] 589.343
[1] -73.1965
[1] 91.45431
[1] -17.06682
[1] 302.5703
[1] -169.6925
[1] -3.155206
INFO  [17:30:29.743] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -0.08329133
[1] 204.1474
[1] -175.0077
[1] -3.676373
[1] -160.406
[1] 76.16597
[1] -245.0992
[1] -3.830853
[1] -139.3721
[1] 51.59997
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:31:17.331] [mlr3] Finished benchmark
INFO  [17:31:17.557] [bbotk] Result of batch 2:
INFO  [17:31:17.595] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:31:17.595] [bbotk]               2.812738                         0.6975179
INFO  [17:31:17.595] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:31:17.595] [bbotk]                         0.6693498           -3.448897              -5.550584
INFO  [17:31:17.595] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:31:17.595] [bbotk]                         20                    4533                 0.9318837
INFO  [17:31:17.595] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:31:17.595] [bbotk]  0.1021421 <list[8]>              FALSE     0.04368892        0      0
INFO  [17:31:17.595] [bbotk]  runtime_learners                                uhash
INFO  [17:31:17.595] [bbotk]            154.31 6f59bf4f-d945-43a2-ae12-f9669f495bc7
INFO  [17:31:18.641] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 33 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:31:24.592] [bbotk] Evaluating 1 configuration(s)
INFO  [17:31:24.732] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:31:24.796] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -256.1653
[1] 383.4356
[1] -284.7378
[1] 62.51273
[1] -788.8552
[1] 216.5682
[1] 10.00331
[1] 496.901
[1] -472.094
[1] -8.429602
INFO  [17:32:02.264] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -430.5402
[1] -8.06376
[1] -541.0275
[1] -10.70649
[1] -753.4736
[1] -12.21521
[1] 10.77868
[1] 479.2987
[1] -372.2859
[1] 55.73608
INFO  [17:33:05.690] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 8.686668
[1] 392.867
[1] -1135.751
[1] 273.3256
[1] -453.5582
[1] -8.466285
[1] -457.0002
[1] 93.10257
[1] -280.3304
[1] 316.6538
INFO  [17:33:46.618] [mlr3] Finished benchmark
INFO  [17:33:46.728] [bbotk] Result of batch 3:
INFO  [17:33:46.750] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:33:46.750] [bbotk]                1.82637                         0.2628114
INFO  [17:33:46.750] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:33:46.750] [bbotk]                          0.790659           -8.732833              -3.236556
INFO  [17:33:46.750] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:33:46.750] [bbotk]                         11                    3227                  0.933115
INFO  [17:33:46.750] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:33:46.750] [bbotk]  0.04047211 <list[8]>              FALSE     0.04481796        0      0
INFO  [17:33:46.750] [bbotk]  runtime_learners                                uhash
INFO  [17:33:46.750] [bbotk]           141.585 c7b85c87-e5d1-4e89-8517-787633161c4c
WARN  [17:33:48.561] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:33:48.650] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 34 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:33:56.409] [bbotk] Evaluating 1 configuration(s)
INFO  [17:33:56.572] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:33:56.631] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -124.5435
[1] 8.908772
[1] -46.80752
[1] 67.39
[1] -9253.847
[1] -210.7329
[1] -110.8536
[1] 152.4684
[1] -14.30801
[1] 110.9156
INFO  [17:34:44.408] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -63.45613
[1] 101.2215
[1] 178.5765
[1] 5685.599
[1] -319.5489
[1] -4.674123
[1] -108.4369
[1] -3.220772
[1] -118.0957
[1] 156.3804
INFO  [17:35:21.902] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -141.5264
[1] 19.3738
[1] -189.882
[1] 31.06996
[1] -59.15141
[1] 78.58919
[1] -101.7959
[1] 27.89195
[1] -120.2307
[1] 63.13397
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:36:24.932] [mlr3] Finished benchmark
INFO  [17:36:25.038] [bbotk] Result of batch 4:
INFO  [17:36:25.061] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:36:25.061] [bbotk]               2.052805                         0.2642466
INFO  [17:36:25.061] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:36:25.061] [bbotk]                         0.8257199           -1.021255               3.935777
INFO  [17:36:25.061] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:36:25.061] [bbotk]                         17                    3400                 0.6479709
INFO  [17:36:25.061] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:36:25.061] [bbotk]  0.03049587 <list[8]>              FALSE     0.04165557        0      0
INFO  [17:36:25.061] [bbotk]  runtime_learners                                uhash
INFO  [17:36:25.061] [bbotk]           147.112 de87ba23-66d2-4ffb-9fa9-b15746415c07
INFO  [17:36:26.460] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 35 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:36:31.014] [bbotk] Evaluating 1 configuration(s)
INFO  [17:36:31.270] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:36:31.438] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -59.21733
[1] 83.49488
[1] -74.58796
[1] 44.14193
[1] -171.3779
[1] 38.91284
[1] -98.67118
[1] 50.81012
[1] -114.5954
[1] 20.67702
INFO  [17:38:01.711] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -332.1455
[1] -3.466469
[1] -86.46026
[1] 24.78736
[1] -6446.586
[1] -155.3836
[1] -68.54309
[1] 84.17356
[1] -62.99896
[1] 83.49645
INFO  [17:38:51.689] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -88.20618
[1] 26.21327
[1] -75.34656
[1] 35.21787
[1] -44.97031
[1] 76.05846
[1] -93.25445
[1] 92.20015
[1] -153.5788
[1] 9.371709
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:40:12.202] [mlr3] Finished benchmark
INFO  [17:40:12.642] [bbotk] Result of batch 5:
INFO  [17:40:12.871] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:40:12.871] [bbotk]              0.9577801                         0.8258693
INFO  [17:40:12.871] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:40:12.871] [bbotk]                         0.6382908           -7.001471              -4.317837
INFO  [17:40:12.871] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:40:12.871] [bbotk]                          2                    4518                 0.9183132
INFO  [17:40:12.871] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:40:12.871] [bbotk]  0.04123982 <list[8]>              FALSE     0.04117624        0      0
INFO  [17:40:12.871] [bbotk]  runtime_learners                                uhash
INFO  [17:40:12.871] [bbotk]           220.108 f93c905c-b14f-4158-a59e-2e37aad7dfbd
INFO  [17:40:14.276] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 36 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:40:27.113] [bbotk] Evaluating 1 configuration(s)
INFO  [17:40:27.160] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:40:27.199] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -76.32851
[1] 0.3050953
[1] -142.9517
[1] 33.67532
[1] 43.61302
[1] 1193.029
[1] -26.57011
[1] 38.65023
[1] 36.72585
[1] 1106.711
INFO  [17:41:15.073] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -36.34552
[1] 10.28854
[1] -30.9754
[1] 18.87213
[1] 327.3013
[1] 5962.321
[1] -60.84473
[1] 2.412294
[1] -41.31729
[1] 46.48451
INFO  [17:42:16.681] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -14.89187
[1] 43.56078
[1] -65.85112
[1] 9.658333
[1] -49.2279
[1] 30.24351
[1] -23.43716
[1] 14.98289
[1] -42.40043
[1] 2.978635
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:43:15.072] [mlr3] Finished benchmark
INFO  [17:43:15.177] [bbotk] Result of batch 6:
INFO  [17:43:15.194] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:43:15.194] [bbotk]               -5.87513                         0.7800986
INFO  [17:43:15.194] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:43:15.194] [bbotk]                         0.6485045          -0.8152898              -4.409743
INFO  [17:43:15.194] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:43:15.194] [bbotk]                          9                    4738                 0.7211221
INFO  [17:43:15.194] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:43:15.194] [bbotk]  0.02887794 <list[8]>              FALSE     0.02847918        0      0
INFO  [17:43:15.194] [bbotk]  runtime_learners                                uhash
INFO  [17:43:15.194] [bbotk]           167.284 4b51b5c9-0d62-4623-86f6-c36ff9563caa
INFO  [17:43:16.417] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 37 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:43:19.537] [bbotk] Evaluating 1 configuration(s)
INFO  [17:43:19.769] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:43:20.002] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -601.2878
[1] -5.87071
[1] -176.7328
[1] 82.03841
[1] -84.09354
[1] 130.7735
[1] -56.7541
[1] 146.4701
[1] -88.6212
[1] 37.02708
INFO  [17:44:30.213] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -96.20513
[1] 70.33609
[1] -265.6319
[1] -0.2429527
[1] -267.241
[1] 77.41835
[1] -120.8139
[1] 64.01244
[1] -199.6355
[1] 84.29507
INFO  [17:45:13.587] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -154.079
[1] 32.79873
[1] -160.1892
[1] 65.26723
[1] -21250.66
[1] -424.9564
[1] -170.3009
[1] 0.162223
[1] -420.2912
[1] -5.175188
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:46:24.144] [mlr3] Finished benchmark
INFO  [17:46:24.350] [bbotk] Result of batch 7:
INFO  [17:46:24.375] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:46:24.375] [bbotk]               2.907347                         0.9093035
INFO  [17:46:24.375] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:46:24.375] [bbotk]                          0.724263           -3.027476              -2.603866
INFO  [17:46:24.375] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:46:24.375] [bbotk]                         14                    4442                 0.9448828
INFO  [17:46:24.375] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:46:24.375] [bbotk]  0.02858588 <list[8]>              FALSE     0.03946784        0      0
INFO  [17:46:24.375] [bbotk]  runtime_learners                                uhash
INFO  [17:46:24.375] [bbotk]           183.121 11b90f13-b39f-423e-8e77-872ed835c169
INFO  [17:46:26.525] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 38 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:46:38.150] [bbotk] Evaluating 1 configuration(s)
INFO  [17:46:38.318] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:46:38.435] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 9.1806
[1] 416.8446
[1] -108.2253
[1] 523.0091
[1] 9.424543
[1] 433.0275
[1] -527.2291
[1] -9.724146
[1] -689.305
[1] -11.98447
INFO  [17:47:15.322] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -402.8069
[1] 236.4476
[1] 1018.84
[1] 43381.25
[1] -634.7821
[1] -10.18862
[1] -485.8358
[1] -9.383282
[1] -315.2655
[1] 112.1335
INFO  [17:48:10.795] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -879.9952
[1] 177.5957
[1] -268.4386
[1] 260.0822
[1] -498.4355
[1] -8.998929
[1] -180.2815
[1] 409.2903
[1] -407.8498
[1] 150.1351
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:48:56.334] [mlr3] Finished benchmark
INFO  [17:48:56.477] [bbotk] Result of batch 8:
INFO  [17:48:56.551] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:48:56.551] [bbotk]              -5.830527                         0.6757287
INFO  [17:48:56.551] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:48:56.551] [bbotk]                         0.1019741           -8.168738               2.399598
INFO  [17:48:56.551] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:48:56.551] [bbotk]                         16                    4379                 0.4288076
INFO  [17:48:56.551] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:48:56.551] [bbotk]  0.0245695 <list[8]>              FALSE     0.05595338        0      0
INFO  [17:48:56.551] [bbotk]  runtime_learners                                uhash
INFO  [17:48:56.551] [bbotk]             137.3 58a30933-e683-4304-ac2a-70352e3c4ba6
INFO  [17:48:58.353] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 39 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:49:04.528] [bbotk] Evaluating 1 configuration(s)
INFO  [17:49:04.562] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:49:04.689] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -3120.765
[1] -93.1217
[1] -905.8374
[1] -3.939885
[1] -67.44827
[1] 17.65272
[1] -75.40804
[1] 7.625033
[1] -110.9148
[1] 129.079
INFO  [17:49:41.408] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -76.42665
[1] 26.74322
[1] -61.30109
[1] 15.33502
[1] -158.9202
[1] 20.21721
[1] -60.43141
[1] 14.65814
[1] -49.20103
[1] 88.51225
INFO  [17:50:21.278] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -19.21854
[1] 66.25217
[1] -55.125
[1] 5.570733
[1] -80.20701
[1] 45.38548
[1] -90.85425
[1] 3.51888
[1] -100.7544
[1] 33.59121
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:50:53.169] [mlr3] Finished benchmark
INFO  [17:50:53.331] [bbotk] Result of batch 9:
INFO  [17:50:53.389] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:50:53.389] [bbotk]               -1.20409                         0.2928566
INFO  [17:50:53.389] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:50:53.389] [bbotk]                          0.913208           -2.838054            -0.05274396
INFO  [17:50:53.389] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:50:53.389] [bbotk]                         10                    2809                 0.4769348
INFO  [17:50:53.389] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:50:53.389] [bbotk]  0.02372169 <list[8]>              FALSE     0.02797442        0      0
INFO  [17:50:53.389] [bbotk]  runtime_learners                                uhash
INFO  [17:50:53.389] [bbotk]           107.797 f566e7df-6339-442e-873c-1a39b242dc85
INFO  [17:50:54.952] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 40 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:51:01.716] [bbotk] Evaluating 1 configuration(s)
INFO  [17:51:01.833] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:51:02.106] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -98.81367
[1] 12.21129
[1] -2900.463
[1] -51.6268
[1] -28.19096
[1] 95.82052
[1] -70.22089
[1] 8.640793
[1] -44.71922
[1] 43.51497
INFO  [17:51:21.092] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -26.1382
[1] 46.56279
[1] -46.45002
[1] 194.6458
[1] -117.6179
[1] 33.07471
[1] -67.78492
[1] 15.49058
[1] -74.73837
[1] 13.76365
INFO  [17:51:55.667] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -109.8527
[1] 23.34445
[1] -63.18071
[1] 7.196
[1] -45.32359
[1] 47.03065
[1] -38.84366
[1] 22.43518
[1] -45.72023
[1] 60.35042
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:52:30.574] [mlr3] Finished benchmark
INFO  [17:52:31.141] [bbotk] Result of batch 10:
INFO  [17:52:31.471] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:52:31.471] [bbotk]              -4.150266                         0.8304204
INFO  [17:52:31.471] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:52:31.471] [bbotk]                         0.5371657            -2.35924              -2.894578
INFO  [17:52:31.471] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:52:31.471] [bbotk]                          3                    3266                 0.5110894
INFO  [17:52:31.471] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:52:31.471] [bbotk]  0.02280425 <list[8]>              FALSE      0.0283561        0      0
INFO  [17:52:31.471] [bbotk]  runtime_learners                                uhash
INFO  [17:52:31.471] [bbotk]            87.202 1cb4d4ab-aa95-4689-b5a9-dd68e7b563ac
INFO  [17:52:35.913] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 41 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:52:54.997] [bbotk] Evaluating 1 configuration(s)
INFO  [17:52:55.228] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:52:55.335] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -147.4105
[1] 122.1135
[1] -11.30155
[1] 215.9184
[1] -357.6089
[1] -6.174221
[1] -163.1001
[1] 89.76251
[1] 6.535922
[1] 301.5124
INFO  [17:53:12.375] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -176.5749
[1] 64.04857
[1] -51.58607
[1] 270.6362
[1] -46.72112
[1] 194.0448
[1] -275.0795
[1] -5.285417
[1] -474.4567
[1] -7.040602
INFO  [17:53:29.583] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -10532.08
[1] -237.6835
[1] -8.123952
[1] 297.5959
[1] -7.804596
[1] 212.5604
[1] -300.676
[1] 20.33684
[1] -370.587
[1] -5.11114
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:53:47.015] [mlr3] Finished benchmark
INFO  [17:53:47.239] [bbotk] Result of batch 11:
INFO  [17:53:47.296] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:53:47.296] [bbotk]              -1.105113                         0.6681239
INFO  [17:53:47.296] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:53:47.296] [bbotk]                         0.2059404           -7.715306               -5.39697
INFO  [17:53:47.296] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:53:47.296] [bbotk]                          5                    2474                 0.6890302
INFO  [17:53:47.296] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:53:47.296] [bbotk]  0.02265699 <list[8]>              FALSE     0.04045871        0      0
INFO  [17:53:47.296] [bbotk]  runtime_learners                                uhash
INFO  [17:53:47.296] [bbotk]            50.666 5c098117-5857-4574-b9bf-12b7716aea53
INFO  [17:53:49.756] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 42 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:53:54.134] [bbotk] Evaluating 1 configuration(s)
INFO  [17:53:54.205] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:53:54.393] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1672.611
[1] -29.61876
[1] 35.06608
[1] 1852.753
[1] 22.86446
[1] 1171.142
[1] 34.22371
[1] 1808.2
[1] 33.97175
[1] 1855.3
INFO  [17:54:13.036] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 24.55031
[1] 1292.256
[1] -1683.552
[1] -30.76429
[1] -1257.469
[1] -22.97168
[1] -1865.787
[1] -33.45286
[1] -190.2465
[1] 1124.31
INFO  [17:54:52.518] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1581.274
[1] -28.50929
[1] -1229.056
[1] -22.37536
[1] -1520.988
[1] -27.54473
[1] 38.90084
[1] 2155.337
[1] -1130.919
[1] -20.6879
INFO  [17:55:36.034] [mlr3] Finished benchmark
INFO  [17:55:36.759] [bbotk] Result of batch 12:
INFO  [17:55:36.866] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:55:36.866] [bbotk]               1.098011                         0.5511885
INFO  [17:55:36.866] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:55:36.866] [bbotk]                         0.9508588           -7.269978               5.166869
INFO  [17:55:36.866] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:55:36.866] [bbotk]                          3                    1082                 0.9914923
INFO  [17:55:36.866] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:55:36.866] [bbotk]  0.02396536 <list[8]>              FALSE     0.05238641        0      0
INFO  [17:55:36.866] [bbotk]  runtime_learners                                uhash
INFO  [17:55:36.866] [bbotk]           101.241 19d627bd-7cc3-493f-b82f-13b4579fc657
WARN  [17:55:38.548] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:55:38.745] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 43 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:55:43.106] [bbotk] Evaluating 1 configuration(s)
INFO  [17:55:43.158] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:55:43.243] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -23.59329
[1] 46.44643
[1] -3958.862
[1] -118.4505
[1] -19.20623
[1] 634.6709
[1] -182.8356
[1] 43.65795
[1] -14730.61
[1] -278.8896
INFO  [17:56:13.027] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -54.66267
[1] 55.97286
[1] -49.35509
[1] 25.02607
[1] -111.7683
[1] 11.43046
[1] -49.16661
[1] 18.87627
[1] -136.0146
[1] 100.7377
INFO  [17:56:46.475] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 31.59497
[1] 711.8229
[1] -42.31562
[1] 22.31044
[1] -83.39684
[1] 5.894953
[1] -19.13692
[1] 61.65281
[1] -40.30254
[1] 48.80248
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:57:21.609] [mlr3] Finished benchmark
INFO  [17:57:22.266] [bbotk] Result of batch 13:
INFO  [17:57:22.403] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:57:22.403] [bbotk]              -6.303148                         0.4198532
INFO  [17:57:22.403] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:57:22.403] [bbotk]                         0.9114388           -1.788453              -1.480721
INFO  [17:57:22.403] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:57:22.403] [bbotk]                         14                    1781                 0.3190572
INFO  [17:57:22.403] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:57:22.403] [bbotk]  0.02195064 <list[8]>              FALSE     0.02133715        0      0
INFO  [17:57:22.403] [bbotk]  runtime_learners                                uhash
INFO  [17:57:22.403] [bbotk]            96.929 13da37ff-30a6-4182-b460-b24cd0d6d77e
WARN  [17:57:23.802] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:57:23.839] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 44 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:57:31.172] [bbotk] Evaluating 1 configuration(s)
INFO  [17:57:31.380] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:57:31.660] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -65.29172
[1] 52.61566
[1] -42.81291
[1] 49.67701
[1] -1477.825
[1] -49.10889
[1] -10.47495
[1] 164.6038
[1] -1996.826
[1] -52.63147
INFO  [17:57:44.097] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -68.92594
[1] 23.3851
[1] 295.0104
[1] 9953.098
[1] -41.38544
[1] 11.93339
[1] -361.0566
[1] 20.39194
[1] 124.6612
[1] 2313.025
INFO  [17:57:55.299] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -18.82543
[1] 42.87088
[1] -70.8178
[1] -4.037659
[1] -1624.893
[1] -56.97625
[1] -76.85161
[1] 19.811
[1] -35.33344
[1] 20.98316
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:58:13.008] [mlr3] Finished benchmark
INFO  [17:58:13.105] [bbotk] Result of batch 14:
INFO  [17:58:13.239] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:58:13.239] [bbotk]              -4.209038                          0.554853
INFO  [17:58:13.239] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:58:13.239] [bbotk]                         0.3034658           -1.625923              -5.693504
INFO  [17:58:13.239] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:58:13.239] [bbotk]                         13                    2070                 0.6663213
INFO  [17:58:13.239] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:58:13.239] [bbotk]  0.02011899 <list[8]>              FALSE      0.0252932        0      0
INFO  [17:58:13.239] [bbotk]  runtime_learners                                uhash
INFO  [17:58:13.239] [bbotk]            37.927 4e0fdb53-e09e-4fa9-b9e6-84d5289c24fe
INFO  [17:58:14.996] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 45 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:58:31.191] [bbotk] Evaluating 1 configuration(s)
INFO  [17:58:31.396] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:58:31.588] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -131.876
[1] 34.99965
[1] -26.11099
[1] 41.59836
[1] -27.69765
[1] 36.19981
[1] -61.82008
[1] 39.20811
[1] -80.67896
[1] 9.220606
INFO  [17:59:15.531] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -141.6733
[1] 10.0528
[1] -29.45691
[1] 39.63559
[1] -15.61249
[1] 48.84556
[1] -33.70376
[1] 65.01986
[1] -38.55295
[1] 14.71144
INFO  [18:00:07.277] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -61.70702
[1] 60.24861
[1] -40.3267
[1] 3.358446
[1] -24.93699
[1] 21.69208
[1] -36.17611
[1] 47.91367
[1] -265.7285
[1] 10.35907
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:00:46.926] [mlr3] Finished benchmark
INFO  [18:00:47.012] [bbotk] Result of batch 15:
INFO  [18:00:47.116] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:00:47.116] [bbotk]              -2.698183                         0.4121491
INFO  [18:00:47.116] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:00:47.116] [bbotk]                         0.6683689          -0.7759415              -6.521871
INFO  [18:00:47.116] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:00:47.116] [bbotk]                          6                    3625                 0.6311908
INFO  [18:00:47.116] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:00:47.116] [bbotk]  0.01908648 <list[8]>              FALSE     0.02983674        0      0
INFO  [18:00:47.116] [bbotk]  runtime_learners                                uhash
INFO  [18:00:47.116] [bbotk]            134.41 6966cdf4-a81f-40b0-950d-2221f484ca26
INFO  [18:00:49.654] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 46 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:00:54.833] [bbotk] Evaluating 1 configuration(s)
INFO  [18:00:54.975] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:00:55.031] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -65.13909
[1] 12.35184
[1] -37.29059
[1] 26.65031
[1] -67.30837
[1] 65.78983
[1] -30.92607
[1] 93.31608
[1] -5403.782
[1] -41.02189
INFO  [18:01:19.138] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -28.3426
[1] 40.3239
[1] -42.80207
[1] 13.37075
[1] 151.3904
[1] 3594.861
[1] -91.62592
[1] 5.536181
[1] -60.87831
[1] 29.04972
INFO  [18:01:40.140] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -4924.604
[1] -81.12795
[1] -37.01025
[1] 77.20682
[1] -471.3716
[1] -2.66465
[1] -35.35583
[1] 24.01725
[1] -43.64776
[1] 26.87462
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:02:04.858] [mlr3] Finished benchmark
INFO  [18:02:04.989] [bbotk] Result of batch 16:
INFO  [18:02:05.009] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:02:05.009] [bbotk]              -6.626575                         0.9572076
INFO  [18:02:05.009] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:02:05.009] [bbotk]                          0.555266           -1.128042              -3.442743
INFO  [18:02:05.009] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:02:05.009] [bbotk]                         12                    1196                 0.6714375
INFO  [18:02:05.009] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:02:05.009] [bbotk]  0.01733144 <list[8]>              FALSE     0.02757308        0      0
INFO  [18:02:05.009] [bbotk]  runtime_learners                                uhash
INFO  [18:02:05.009] [bbotk]            69.373 2e8178b2-307e-4743-831a-829f66a8b9c2
INFO  [18:02:06.391] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 47 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:02:11.977] [bbotk] Evaluating 1 configuration(s)
INFO  [18:02:12.083] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:02:12.187] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -5.344242
[1] 162.8961
[1] -55.50639
[1] 65.40186
[1] -30.38621
[1] 208.5231
[1] -64.95916
[1] 395.6859
[1] -89.19831
[1] 17.28105
INFO  [18:02:52.081] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -138.9485
[1] 5.065229
[1] -18.4071
[1] 145.0298
[1] -188.0438
[1] -3.970914
[1] -250.5818
[1] -4.294758
[1] -360.534
[1] 37.16614
INFO  [18:03:27.917] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -129.1875
[1] 34.60028
[1] 4.233797
[1] 305.5847
[1] -62.66378
[1] 18.89105
[1] -308.5692
[1] -4.146115
[1] -68.31779
[1] 81.06942
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:04:09.256] [mlr3] Finished benchmark
INFO  [18:04:09.347] [bbotk] Result of batch 17:
INFO  [18:04:09.416] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:04:09.416] [bbotk]              -3.481589                          0.409388
INFO  [18:04:09.416] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:04:09.416] [bbotk]                         0.3043702           -6.553111              -6.712179
INFO  [18:04:09.416] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:04:09.416] [bbotk]                          8                    4827                 0.1148222
INFO  [18:04:09.416] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:04:09.416] [bbotk]  0.01752051 <list[8]>              FALSE     0.03843611        0      0
INFO  [18:04:09.416] [bbotk]  runtime_learners                                uhash
INFO  [18:04:09.416] [bbotk]           116.663 8b28c7c8-26a7-4c90-ba85-ce813b0b6ed1
INFO  [18:04:10.424] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 48 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:04:15.260] [bbotk] Evaluating 1 configuration(s)
INFO  [18:04:15.364] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:04:15.717] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -80.13945
[1] 16.89283
[1] -202.2349
[1] 15.55438
[1] -63.16523
[1] 167.9336
[1] 66.69732
[1] 1852.272
[1] -28.07187
[1] 37.84568
INFO  [18:04:51.654] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -104.3596
[1] 506.8086
[1] -23.44901
[1] 56.14397
[1] -83.10837
[1] 7.866366
[1] -28.3854
[1] 28.99998
[1] -36.40911
[1] 25.4284
INFO  [18:05:35.573] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -53.56897
[1] 35.75384
[1] -59.66946
[1] 28.42071
[1] -51.67135
[1] 72.84254
[1] -29.89746
[1] 77.77972
[1] -57.76507
[1] 20.09293
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:06:47.238] [mlr3] Finished benchmark
INFO  [18:06:47.382] [bbotk] Result of batch 18:
INFO  [18:06:47.439] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:06:47.439] [bbotk]            0.007180749                         0.3513021
INFO  [18:06:47.439] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:06:47.439] [bbotk]                         0.6108902           -1.739654               1.118302
INFO  [18:06:47.439] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:06:47.439] [bbotk]                          8                    4095                 0.9053485
INFO  [18:06:47.439] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:06:47.439] [bbotk]  0.01670994 <list[8]>              FALSE     0.02924589        0      0
INFO  [18:06:47.439] [bbotk]  runtime_learners                                uhash
INFO  [18:06:47.439] [bbotk]           150.975 96b18623-978f-4b6a-87bc-054ecea4641f
INFO  [18:06:48.272] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 49 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:06:54.034] [bbotk] Evaluating 1 configuration(s)
INFO  [18:06:54.094] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:06:54.263] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -73.83579
[1] 83.87331
[1] -259.9796
[1] -4.618057
[1] -67.00862
[1] 82.11691
[1] -43.93729
[1] 146.5005
[1] -65.22328
[1] 69.20915
INFO  [18:07:12.245] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -141.2387
[1] 200.5964
[1] -225.2942
[1] -4.257254
[1] -19.5953
[1] 134.336
[1] -83.67158
[1] 55.75888
[1] -357.8452
[1] -3.780124
INFO  [18:07:29.303] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -93.67179
[1] 115.6464
[1] 164.159
[1] 4898.705
[1] -85.83879
[1] 54.74466
[1] -92.02413
[1] 56.21198
[1] -181.419
[1] -3.527658
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:07:50.314] [mlr3] Finished benchmark
INFO  [18:07:50.449] [bbotk] Result of batch 19:
INFO  [18:07:50.491] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:07:50.491] [bbotk]               1.557436                         0.8794776
INFO  [18:07:50.491] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:07:50.491] [bbotk]                         0.1102642            -4.05805              -5.558373
INFO  [18:07:50.491] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:07:50.491] [bbotk]                          8                     832                 0.9199531
INFO  [18:07:50.491] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:07:50.491] [bbotk]  0.02007072 <list[8]>              FALSE     0.03904581        0      0
INFO  [18:07:50.491] [bbotk]  runtime_learners                                uhash
INFO  [18:07:50.491] [bbotk]            55.626 6c34518f-d064-438d-8cbc-1719ca15264c
INFO  [18:07:52.832] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 50 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:08:00.870] [bbotk] Evaluating 1 configuration(s)
INFO  [18:08:00.981] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:08:01.047] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -34.4116
[1] 109.0599
[1] -57.60837
[1] 108.7653
[1] -71.70277
[1] 101.3847
[1] -75.18675
[1] 125.3383
[1] -134.9835
[1] 7.382851
INFO  [18:09:19.997] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -139.5214
[1] 62.45317
[1] -137.6179
[1] 54.70663
[1] -46.23564
[1] 167.391
[1] -84.94658
[1] 51.02289
[1] -34.81201
[1] 64.55226
INFO  [18:10:41.694] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -203.6651
[1] -4.561395
[1] -6646.03
[1] -171.3882
[1] -8.392367
[1] 116.6942
[1] -174.2034
[1] 54.13409
[1] -164.0137
[1] -4.023523
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:12:14.472] [mlr3] Finished benchmark
INFO  [18:12:14.608] [bbotk] Result of batch 20:
INFO  [18:12:14.682] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:12:14.682] [bbotk]               2.062582                         0.7780969
INFO  [18:12:14.682] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:12:14.682] [bbotk]                         0.5622402           -7.048725              -2.442284
INFO  [18:12:14.682] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:12:14.682] [bbotk]                          8                    4796                 0.9011364
INFO  [18:12:14.682] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:12:14.682] [bbotk]  0.01974936 <list[8]>              FALSE     0.04239873        0      0
INFO  [18:12:14.682] [bbotk]  runtime_learners                                uhash
INFO  [18:12:14.682] [bbotk]           252.861 db0f4c06-6acf-43e8-8f89-82ea2be939b9
INFO  [18:12:15.621] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 51 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:12:20.589] [bbotk] Evaluating 1 configuration(s)
INFO  [18:12:20.827] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:12:21.013] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -89.73823
[1] 51.17115
[1] -94.22488
[1] 104.7363
[1] -114.1714
[1] 130.3401
[1] -35.04468
[1] 109.1916
[1] -10.43641
[1] 171.8075
INFO  [18:12:43.398] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -137.7248
[1] 78.77878
[1] -43.0545
[1] 138.3335
[1] -87.41495
[1] 68.29609
[1] -74.12951
[1] 60.67112
[1] -8540.599
[1] -139.9241
INFO  [18:13:04.442] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -120.6568
[1] 39.54493
[1] -47.7129
[1] 282.766
[1] -193.7199
[1] 9.200225
[1] -125.6251
[1] 20.51382
[1] -127.8715
[1] 46.89665
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:13:32.302] [mlr3] Finished benchmark
INFO  [18:13:33.243] [bbotk] Result of batch 21:
INFO  [18:13:33.383] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:13:33.383] [bbotk]               2.614136                         0.5080294
INFO  [18:13:33.383] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:13:33.383] [bbotk]                         0.6956757             -1.2871               -5.67433
INFO  [18:13:33.383] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:13:33.383] [bbotk]                         15                     539                  0.880105
INFO  [18:13:33.383] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:13:33.383] [bbotk]  0.01519735 <list[8]>              FALSE     0.03809101        0      0
INFO  [18:13:33.383] [bbotk]  runtime_learners                                uhash
INFO  [18:13:33.383] [bbotk]            69.996 71b99082-4297-457a-9d64-09dd1e70ea41
INFO  [18:13:35.928] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 52 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:13:43.399] [bbotk] Evaluating 1 configuration(s)
INFO  [18:13:43.662] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:13:44.028] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -190.3601
[1] -3.284781
[1] -176.133
[1] -4.48308
[1] -183.8167
[1] -4.92278
[1] -138.42
[1] -3.509001
[1] -3.123428
[1] 124.1005
INFO  [18:13:56.387] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -110.0224
[1] 77.37309
[1] -112.411
[1] 32.27563
[1] -170.6215
[1] 40.68464
[1] -88.45194
[1] 70.43752
[1] -147.3144
[1] 61.42367
INFO  [18:14:11.892] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -116.0919
[1] 78.90366
[1] -90.50724
[1] 35.88177
[1] -162.5272
[1] -4.465669
[1] -170.4217
[1] -4.095094
[1] -83.30143
[1] 42.00346
INFO  [18:14:28.148] [mlr3] Finished benchmark
INFO  [18:14:28.511] [bbotk] Result of batch 22:
INFO  [18:14:28.594] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:14:28.594] [bbotk]               -1.78056                         0.4715799
INFO  [18:14:28.594] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:14:28.594] [bbotk]                         0.2975879          -0.5961018              -3.305998
INFO  [18:14:28.594] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:14:28.594] [bbotk]                          7                       2                 0.4754082
INFO  [18:14:28.594] [bbotk]    acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:14:28.594] [bbotk]  0.014087 <list[8]>              FALSE     0.04343977        0      0
INFO  [18:14:28.594] [bbotk]  runtime_learners                                uhash
INFO  [18:14:28.594] [bbotk]            42.833 6f26190e-c9cb-4754-a288-24231a5481b7
INFO  [18:14:30.616] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 53 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:14:39.041] [bbotk] Evaluating 1 configuration(s)
INFO  [18:14:39.243] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:14:39.543] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -31.99114
[1] 63.40945
[1] -129.2651
[1] 30.23773
[1] -68.43755
[1] 52.0973
[1] -14.95794
[1] 83.51679
[1] 410.2202
[1] 21707.21
INFO  [18:15:07.104] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -174.9495
[1] 55.62003
[1] -51.01292
[1] 64.06489
[1] -44.05286
[1] 37.37383
[1] -35.04599
[1] 26.47456
[1] -79.4255
[1] -4.046703
INFO  [18:15:32.486] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -104.5932
[1] 37.13384
[1] -55.72446
[1] 14.93699
[1] -34.27129
[1] 49.90223
[1] -29.83525
[1] 83.58576
[1] -83.51639
[1] 20.06334
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:16:00.972] [mlr3] Finished benchmark
INFO  [18:16:01.812] [bbotk] Result of batch 23:
INFO  [18:16:01.991] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:16:01.991] [bbotk]              -5.835484                         0.7977805
INFO  [18:16:01.991] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:16:01.991] [bbotk]                         0.5593897          -0.2787795               3.241195
INFO  [18:16:01.991] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:16:01.991] [bbotk]                         11                    1486                 0.3459742
INFO  [18:16:01.991] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:16:01.991] [bbotk]  0.01381483 <list[8]>              FALSE     0.02433966        0      0
INFO  [18:16:01.991] [bbotk]  runtime_learners                                uhash
INFO  [18:16:01.991] [bbotk]            80.074 709a5f54-64a5-4dbe-930a-2712732728cf
INFO  [18:16:03.606] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 54 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:16:10.032] [bbotk] Evaluating 1 configuration(s)
INFO  [18:16:10.413] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:16:10.675] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -54.75623
[1] 234.6567
[1] -110.0798
[1] 97.43179
[1] -93.47576
[1] 69.22321
[1] -154.6523
[1] 89.65685
[1] -154.54
[1] 92.92266
INFO  [18:16:51.837] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -373.5411
[1] -6.073888
[1] -301.6737
[1] -5.168832
[1] -148.1598
[1] 254.0442
[1] -120.362
[1] 37.60163
[1] -232.3938
[1] 27.34107
INFO  [18:18:11.757] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -142.9983
[1] 61.14576
[1] -77.7954
[1] 82.09891
[1] -232.5425
[1] 19.18047
[1] -98.30742
[1] 142.4266
[1] -243.4038
[1] -5.403625
INFO  [18:19:05.223] [mlr3] Finished benchmark
INFO  [18:19:05.754] [bbotk] Result of batch 24:
INFO  [18:19:05.810] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:19:05.810] [bbotk]               -2.62133                         0.5107134
INFO  [18:19:05.810] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:19:05.810] [bbotk]                          0.669896           -6.169399               4.096186
INFO  [18:19:05.810] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:19:05.810] [bbotk]                          2                    4971                 0.3958062
INFO  [18:19:05.810] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:19:05.810] [bbotk]  0.01280138 <list[8]>              FALSE     0.04867485        0      0
INFO  [18:19:05.810] [bbotk]  runtime_learners                                uhash
INFO  [18:19:05.810] [bbotk]           174.278 e4d0b3d1-7ecd-466b-8e36-1daed0c8cd47
INFO  [18:19:06.758] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 55 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:19:12.031] [bbotk] Evaluating 1 configuration(s)
INFO  [18:19:12.065] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:19:12.136] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -59.43825
[1] 89.8203
[1] -106.6142
[1] 24.75214
[1] -46.59835
[1] 34.52435
[1] -52.40697
[1] 44.11198
[1] -1.108776
[1] 67.29619
INFO  [18:19:33.436] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -3538.525
[1] -76.78852
[1] -52.23352
[1] 27.9173
[1] -19.54903
[1] 72.55238
[1] -18.79304
[1] 163.278
[1] -82.43102
[1] 5.86415
INFO  [18:20:04.081] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -20.02869
[1] 103.204
[1] -426.2929
[1] -12.47116
[1] -93.40852
[1] 9.841183
[1] -147.8689
[1] 28.19163
[1] -24.19616
[1] 51.71097
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:20:23.042] [mlr3] Finished benchmark
INFO  [18:20:23.245] [bbotk] Result of batch 25:
INFO  [18:20:23.272] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:20:23.272] [bbotk]              -3.114768                         0.9514956
INFO  [18:20:23.272] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:20:23.272] [bbotk]                         0.3360345           -1.405437              -6.064567
INFO  [18:20:23.272] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:20:23.272] [bbotk]                         20                    1303                 0.1044954
INFO  [18:20:23.272] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:20:23.272] [bbotk]  0.01233357 <list[8]>              FALSE     0.02893487        0      0
INFO  [18:20:23.272] [bbotk]  runtime_learners                                uhash
INFO  [18:20:23.272] [bbotk]            69.672 b07ec346-ec2f-4673-95a7-d757d72c426d
WARN  [18:20:26.527] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:20:26.713] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 56 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:20:36.639] [bbotk] Evaluating 1 configuration(s)
INFO  [18:20:36.907] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:20:37.456] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -4543.901
[1] -119.3697
[1] -40.72067
[1] 76.3903
[1] -4959.758
[1] -56.05716
[1] -26.47268
[1] 127.1071
[1] -25.93272
[1] 34.7896
INFO  [18:21:11.843] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -64.74637
[1] 5.75452
[1] -3.639458e+16
[1] 5.185772e+15
[1] -130.8048
[1] 7.71318
[1] -15.47471
[1] 47.63879
[1] -176.0603
[1] 12.17378
INFO  [18:21:42.305] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -43.43313
[1] 89.72448
[1] -47.83897
[1] 32.46752
[1] -60.69186
[1] 31.20433
[1] -237.6895
[1] -4.040925
[1] -113.5562
[1] 22.45191
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:22:38.777] [mlr3] Finished benchmark
INFO  [18:22:38.991] [bbotk] Result of batch 26:
INFO  [18:22:39.027] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:22:39.027] [bbotk]              -3.664993                          0.586957
INFO  [18:22:39.027] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:22:39.027] [bbotk]                         0.3881938          -0.0921631               3.176735
INFO  [18:22:39.027] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:22:39.027] [bbotk]                          9                    3185                 0.1737837
INFO  [18:22:39.027] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:22:39.027] [bbotk]  0.01388671 <list[8]>              FALSE     0.02612186        0      0
INFO  [18:22:39.027] [bbotk]  runtime_learners                                uhash
INFO  [18:22:39.027] [bbotk]           120.037 849a1e1c-5db6-44b1-97a9-73e976adcb76
INFO  [18:22:40.057] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 57 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:22:46.324] [bbotk] Evaluating 1 configuration(s)
INFO  [18:22:46.630] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:22:46.839] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -48.26511
[1] 62.22245
[1] -263.3335
[1] -2.914559
[1] -79.87985
[1] 127.1156
[1] -63.23676
[1] 4.622355
[1] -25.63977
[1] 50.9972
INFO  [18:23:24.785] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -32.44969
[1] 35.58882
[1] -17.65824
[1] 67.64804
[1] -18.97605
[1] 26.33034
[1] 109.8607
[1] 3785.825
[1] -31.84024
[1] 46.46789
INFO  [18:24:11.273] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -27.90221
[1] 43.59056
[1] -18.94384
[1] 22.69043
[1] -223.5661
[1] -3.758941
[1] -56.82752
[1] 26.68213
[1] -27.65663
[1] 39.83898
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:24:55.342] [mlr3] Finished benchmark
INFO  [18:24:55.514] [bbotk] Result of batch 27:
INFO  [18:24:55.553] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:24:55.553] [bbotk]              -0.499445                         0.8998425
INFO  [18:24:55.553] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:24:55.553] [bbotk]                         0.8663528           -1.324169              -5.796782
INFO  [18:24:55.553] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:24:55.553] [bbotk]                         15                    4626                 0.4297979
INFO  [18:24:55.553] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:24:55.553] [bbotk]  0.0140906 <list[8]>              FALSE     0.02608579        0      0
INFO  [18:24:55.553] [bbotk]  runtime_learners                                uhash
INFO  [18:24:55.553] [bbotk]            127.88 f42a6756-2e26-47c9-b222-c3d8a4df1a59
WARN  [18:24:56.910] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:24:57.103] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 58 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:25:06.064] [bbotk] Evaluating 1 configuration(s)
INFO  [18:25:06.306] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:25:06.357] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -153.7074
[1] 75.21184
[1] -109.4398
[1] 4.884862
[1] -19.25582
[1] 68.86334
[1] -18.34616
[1] 37.20517
[1] -8295.721
[1] -407.9001
INFO  [18:25:31.685] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -250.23
[1] -4.017795
[1] -43.14808
[1] 72.49536
[1] -151.0098
[1] 6.0057
[1] -55.29105
[1] 27.49879
[1] -27.25595
[1] 56.67764
INFO  [18:26:03.858] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -45.66279
[1] 42.40215
[1] -115.45
[1] -3.724265
[1] -71.58229
[1] 33.25076
[1] -44.64036
[1] 16.11279
[1] -49.81785
[1] 44.60381
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:26:30.355] [mlr3] Finished benchmark
INFO  [18:26:30.456] [bbotk] Result of batch 28:
INFO  [18:26:30.562] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:26:30.562] [bbotk]              -0.548359                         0.9564412
INFO  [18:26:30.562] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:26:30.562] [bbotk]                         0.9382272           -1.895601              -6.368006
INFO  [18:26:30.562] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:26:30.562] [bbotk]                         17                    1453                 0.4410945
INFO  [18:26:30.562] [bbotk]    acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:26:30.562] [bbotk]  0.012986 <list[8]>              FALSE     0.02805393        0      0
INFO  [18:26:30.562] [bbotk]  runtime_learners                                uhash
INFO  [18:26:30.562] [bbotk]            83.313 24ea9223-9745-4215-aef5-ab6b61ce1f64
WARN  [18:26:32.083] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:26:32.516] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 59 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:26:38.213] [bbotk] Evaluating 1 configuration(s)
INFO  [18:26:38.657] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:26:38.727] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -87.44475
[1] 156.8532
[1] -514.2535
[1] -6.038145
[1] -163.8881
[1] 182.398
[1] -157.8945
[1] 168.0634
[1] -171.8583
[1] 254.1719
INFO  [18:27:35.818] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -315.1365
[1] 72.26794
[1] -231.6566
[1] 29.75155
[1] -296.2589
[1] -5.968026
[1] -87.48436
[1] 244.6084
[1] 8.585254
[1] 357.1572
INFO  [18:28:33.574] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -23.4566
[1] 267.2318
[1] -281.2661
[1] 16.05249
[1] -95.84015
[1] 95.52064
[1] -216.9199
[1] -4.859661
[1] -10689.91
[1] -178.6743
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:29:26.273] [mlr3] Finished benchmark
INFO  [18:29:26.435] [bbotk] Result of batch 29:
INFO  [18:29:26.608] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:29:26.608] [bbotk]               2.735062                         0.6617564
INFO  [18:29:26.608] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:29:26.608] [bbotk]                         0.9339587           -6.189412              -2.749574
INFO  [18:29:26.608] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:29:26.608] [bbotk]                         18                    3759                 0.5333864
INFO  [18:29:26.608] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:29:26.608] [bbotk]  0.01203002 <list[8]>              FALSE     0.04570631        0      0
INFO  [18:29:26.608] [bbotk]  runtime_learners                                uhash
INFO  [18:29:26.608] [bbotk]           166.923 bab0c408-cb77-4119-b8c0-62d50a6af8fb
INFO  [18:29:28.148] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 60 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:29:35.304] [bbotk] Evaluating 1 configuration(s)
INFO  [18:29:35.555] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:29:35.793] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -35.99956
[1] 6.651343
[1] -55.07906
[1] 79.36223
[1] -18.22971
[1] 34.07017
[1] -165.5585
[1] 115.1137
[1] -5.649815
[1] 196.3048
INFO  [18:30:04.825] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -54.0245
[1] 8.805775
[1] -24.6275
[1] 57.89871
[1] -14.06166
[1] 42.19939
[1] -34.76739
[1] 27.73137
[1] -6929.505
[1] -322.1288
INFO  [18:30:53.544] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -43.14786
[1] 44.75282
[1] -62.1402
[1] 11.44999
[1] -21.87016
[1] 20.68258
[1] -9.793784
[1] 106.7559
[1] -2.717648e+16
[1] 3.968908e+14
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:31:23.613] [mlr3] Finished benchmark
INFO  [18:31:23.729] [bbotk] Result of batch 30:
INFO  [18:31:23.781] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:31:23.781] [bbotk]              -1.637417                         0.7590544
INFO  [18:31:23.781] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:31:23.781] [bbotk]                         0.4923172          -0.7439349              -4.299724
INFO  [18:31:23.781] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:31:23.781] [bbotk]                         17                    3093                 0.6053529
INFO  [18:31:23.781] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:31:23.781] [bbotk]  0.01141539 <list[8]>              FALSE     0.02560128        0      0
INFO  [18:31:23.781] [bbotk]  runtime_learners                                uhash
INFO  [18:31:23.781] [bbotk]           106.913 6fe6eede-2872-4625-aa8e-be9991f676c4
INFO  [18:31:25.132] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 61 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:31:45.072] [bbotk] Evaluating 1 configuration(s)
INFO  [18:31:45.190] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:31:45.391] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -244.7083
[1] -3.735706
[1] -20.26002
[1] 16.74313
[1] -22.68016
[1] 31.34261
[1] 54.47379
[1] 1336.775
[1] 109.1537
[1] 4908.075
INFO  [18:32:27.165] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -14.71081
[1] 38.99724
[1] -665.2554
[1] -30.85982
[1] -85.80699
[1] 36.77163
[1] -126.4931
[1] 28.65056
[1] -31.7892
[1] 7.482949
INFO  [18:33:06.418] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -52.33082
[1] 19.13967
[1] -1.131663
[1] 78.92598
[1] -26.93766
[1] 40.50451
[1] -27.19816
[1] 30.13965
[1] -44.08029
[1] 14.27793
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:34:00.174] [mlr3] Finished benchmark
INFO  [18:34:00.297] [bbotk] Result of batch 31:
INFO  [18:34:00.324] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:34:00.324] [bbotk]              -5.400374                         0.9692404
INFO  [18:34:00.324] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:34:00.324] [bbotk]                         0.8741678          -0.5291493              -3.760308
INFO  [18:34:00.324] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:34:00.324] [bbotk]                         19                    2727                 0.4490558
INFO  [18:34:00.324] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:34:00.324] [bbotk]  0.01164509 <list[8]>              FALSE     0.02968627        0      0
INFO  [18:34:00.324] [bbotk]  runtime_learners                                uhash
INFO  [18:34:00.324] [bbotk]           133.459 fb272f8a-9213-427d-a707-501a0de05d10
WARN  [18:34:01.492] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:34:01.545] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 62 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:34:07.034] [bbotk] Evaluating 1 configuration(s)
INFO  [18:34:07.208] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:34:07.619] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -47.08422
[1] 24.51672
[1] -31.29924
[1] 118.0551
[1] -1201.21
[1] -42.67559
[1] -26.35658
[1] 32.23757
[1] -1127.738
[1] -30.27071
INFO  [18:34:52.730] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -89.35436
[1] 14.27187
[1] -2425.971
[1] -106.1796
[1] -117.7387
[1] 24.55849
[1] 407.7563
[1] 12387.05
[1] -35.76051
[1] 30.46523
INFO  [18:35:51.065] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -145.8731
[1] -3.175695
[1] -57.26828
[1] 9.839609
[1] -67.32321
[1] 0.3504183
[1] -28.53999
[1] 59.00685
[1] -31.33816
[1] 32.77153
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:36:46.030] [mlr3] Finished benchmark
INFO  [18:36:46.377] [bbotk] Result of batch 32:
INFO  [18:36:46.434] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:36:46.434] [bbotk]              -6.785056                         0.2132719
INFO  [18:36:46.434] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:36:46.434] [bbotk]                           0.84932           -2.081588               2.094819
INFO  [18:36:46.434] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:36:46.434] [bbotk]                         10                    4561                 0.9967387
INFO  [18:36:46.434] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:36:46.434] [bbotk]  0.01115912 <list[8]>              FALSE     0.02809982        0      0
INFO  [18:36:46.434] [bbotk]  runtime_learners                                uhash
INFO  [18:36:46.434] [bbotk]           156.419 26ed9eb3-d358-456d-97d0-5e6e86d6140f
INFO  [18:36:50.488] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 63 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:36:57.582] [bbotk] Evaluating 1 configuration(s)
INFO  [18:36:57.959] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:36:58.354] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1453.988
[1] -47.01088
[1] -29.35712
[1] 49.54857
[1] -27.4663
[1] 46.06404
[1] -42.22851
[1] 73.44584
[1] -225.9898
[1] -4.16815
INFO  [18:37:41.691] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -81.3686
[1] -4.172979
[1] -30.19293
[1] 139.6672
[1] -316.3096
[1] 27.44741
[1] -183.19
[1] -3.842999
[1] -69.42879
[1] 61.02158
INFO  [18:38:25.996] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -23.52462
[1] 218.7169
[1] -8447.41
[1] -141.9564
[1] -99.87644
[1] -3.79677
[1] -38.20168
[1] 24.53635
[1] -223.5259
[1] 41.25603
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:39:22.778] [mlr3] Finished benchmark
INFO  [18:39:23.010] [bbotk] Result of batch 33:
INFO  [18:39:23.057] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:39:23.057] [bbotk]              0.9037018                         0.2787419
INFO  [18:39:23.057] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:39:23.057] [bbotk]                         0.9766849          -0.9222698              -6.232025
INFO  [18:39:23.057] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:39:23.057] [bbotk]                          4                    3997                    0.7592
INFO  [18:39:23.057] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:39:23.057] [bbotk]  0.01063737 <list[8]>              FALSE     0.02678948        0      0
INFO  [18:39:23.057] [bbotk]  runtime_learners                                uhash
INFO  [18:39:23.057] [bbotk]           143.642 d8e29b20-83c9-40b6-af56-d62ed609ea82
INFO  [18:39:25.264] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 64 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:39:33.694] [bbotk] Evaluating 1 configuration(s)
INFO  [18:39:33.965] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:39:34.119] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -9.881006
[1] 101.1326
[1] -109.5545
[1] 52.70353
[1] -187.6543
[1] 34.09489
[1] -65.24315
[1] 30.02577
[1] 239.916
[1] 9104.986
INFO  [18:40:20.088] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -50.9166
[1] 158.1812
[1] -65.37732
[1] 21.84194
[1] -74.57655
[1] 61.30531
[1] -47.21535
[1] 45.09572
[1] -35.68118
[1] 93.83336
INFO  [18:41:01.604] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -35.13343
[1] 153.4828
[1] -58.91608
[1] 30.72195
[1] 71.51951
[1] 2092.358
[1] -51.89273
[1] 71.26469
[1] -105.1445
[1] 18.6951
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:41:44.943] [mlr3] Finished benchmark
INFO  [18:41:45.902] [bbotk] Result of batch 34:
INFO  [18:41:46.083] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:41:46.083] [bbotk]              -6.862207                         0.4195136
INFO  [18:41:46.083] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:41:46.083] [bbotk]                         0.3487882           -1.450378               2.920449
INFO  [18:41:46.083] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:41:46.083] [bbotk]                          6                    4834                 0.1211017
INFO  [18:41:46.083] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:41:46.083] [bbotk]  0.01063971 <list[8]>              FALSE     0.03116175        0      0
INFO  [18:41:46.083] [bbotk]  runtime_learners                                uhash
INFO  [18:41:46.083] [bbotk]           129.432 aa5ec067-fafe-42d7-bf5a-e7f7a8c34086
INFO  [18:41:47.682] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 65 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:41:55.576] [bbotk] Evaluating 1 configuration(s)
INFO  [18:41:55.755] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:41:55.872] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -19.36
[1] 18.24074
[1] -4350.975
[1] -89.46319
[1] -4530.296
[1] -216.4915
[1] -56.39616
[1] 8.292859
[1] -94.00679
[1] 61.01937
INFO  [18:42:43.987] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -492.0592
[1] 19.63813
[1] -65.52112
[1] 3.92907
[1] -19.25416
[1] 27.91153
[1] -20.69731
[1] 75.15949
[1] -20.8296
[1] 21.7679
INFO  [18:43:35.036] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -29.42966
[1] 25.5915
[1] -26.08775
[1] 1297.358
[1] -31.9924
[1] 94.84547
[1] -44.67316
[1] 7.6355
[1] -10051.48
[1] -3.662511
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:44:28.959] [mlr3] Finished benchmark
INFO  [18:44:29.101] [bbotk] Result of batch 35:
INFO  [18:44:29.197] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:44:29.197] [bbotk]             -0.6942758                         0.7216938
INFO  [18:44:29.197] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:44:29.197] [bbotk]                         0.8572609         -0.05238223             -0.8314138
INFO  [18:44:29.197] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:44:29.197] [bbotk]                          5                    4227                  0.569943
INFO  [18:44:29.197] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:44:29.197] [bbotk]  0.01026143 <list[8]>              FALSE     0.02923045        0      0
INFO  [18:44:29.197] [bbotk]  runtime_learners                                uhash
INFO  [18:44:29.197] [bbotk]           151.476 6fed53c7-fef1-44a3-aee0-95580d7f5a9b
INFO  [18:44:30.244] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 66 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:44:35.792] [bbotk] Evaluating 1 configuration(s)
INFO  [18:44:35.999] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:44:36.089] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -2575.851
[1] -47.30056
[1] 54.43597
[1] 2902.426
[1] -130366.3
[1] -2411.514
[1] 75.80625
[1] 4002.928
[1] -8989.751
[1] -170.6247
INFO  [18:44:53.843] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 56.06985
[1] 2996.797
[1] -3062.652
[1] -56.24957
[1] 78.28921
[1] 4200.425
[1] -2598.32
[1] -47.65488
[1] -4192.316
[1] -77.68934
INFO  [18:45:03.975] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2691.425
[1] -50.92977
[1] -3855.121
[1] -69.98013
[1] 70.44169
[1] 3864.356
[1] 64.98237
[1] 3419.801
[1] -3377.173
[1] -61.38364
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:45:21.114] [mlr3] Finished benchmark
INFO  [18:45:21.277] [bbotk] Result of batch 36:
INFO  [18:45:21.328] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:45:21.328] [bbotk]               1.474896                          0.594874
INFO  [18:45:21.328] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:45:21.328] [bbotk]                         0.7627203           -7.828481              -6.326873
INFO  [18:45:21.328] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:45:21.328] [bbotk]                          2                     161                 0.6777868
INFO  [18:45:21.328] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:45:21.328] [bbotk]  0.01120383 <list[8]>              FALSE      0.0452883        0      0
INFO  [18:45:21.328] [bbotk]  runtime_learners                                uhash
INFO  [18:45:21.328] [bbotk]            44.433 aa5f4a07-8633-4d59-a4cd-2c10046ae020
INFO  [18:45:22.551] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 67 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:45:29.777] [bbotk] Evaluating 1 configuration(s)
INFO  [18:45:29.879] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:45:29.953] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -205.6522
[1] 76.63598
[1] -6302.128
[1] -134.3104
[1] -28.50122
[1] 21.63692
[1] -50.33151
[1] 83.96655
[1] -291.6855
[1] 16.65504
INFO  [18:46:03.828] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -70.12294
[1] 35.24094
[1] -1100.799
[1] -32.38092
[1] -38.51049
[1] 20.95662
[1] -122.3438
[1] 4.962205
[1] 53.11755
[1] 1336.232
INFO  [18:46:44.873] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -206.0212
[1] -3.817747
[1] -261.0915
[1] 9.216499
[1] -16.19947
[1] 633.5547
[1] -49.21734
[1] 33.45167
[1] -124.8152
[1] 40.83058
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:47:17.986] [mlr3] Finished benchmark
INFO  [18:47:18.232] [bbotk] Result of batch 37:
INFO  [18:47:18.248] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:47:18.248] [bbotk]              -3.248462                         0.9526157
INFO  [18:47:18.248] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:47:18.248] [bbotk]                         0.2893384            -4.52859              -3.854454
INFO  [18:47:18.248] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:47:18.248] [bbotk]                         12                    2859                 0.3688575
INFO  [18:47:18.248] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:47:18.248] [bbotk]  0.01033159 <list[8]>              FALSE     0.02813316        0      0
INFO  [18:47:18.248] [bbotk]  runtime_learners                                uhash
INFO  [18:47:18.248] [bbotk]           106.958 337dc005-0f42-4569-a115-58a4f468d475
INFO  [18:47:23.285] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 68 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:47:27.976] [bbotk] Evaluating 1 configuration(s)
INFO  [18:47:28.019] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:47:28.093] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -26.72562
[1] 47.68193
[1] -79.81961
[1] 91.97873
[1] -122.04
[1] 70.70952
[1] -32.48622
[1] 73.35398
[1] -73.3503
[1] 42.51996
INFO  [18:47:51.027] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 73.67149
[1] 2668.944
[1] -53.69406
[1] 72.3552
[1] -101.9795
[1] 18.15384
[1] -115.61
[1] 15.9602
[1] -108.8603
[1] 21.16561
INFO  [18:48:08.824] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -177.0564
[1] 35.81948
[1] -37.09922
[1] 32.20171
[1] -64.54608
[1] 52.91255
[1] -51.8955
[1] 196.4347
[1] -124.0735
[1] 14.49403
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:48:27.545] [mlr3] Finished benchmark
INFO  [18:48:27.898] [bbotk] Result of batch 38:
INFO  [18:48:27.913] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:48:27.913] [bbotk]              -4.183619                         0.1979228
INFO  [18:48:27.913] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:48:27.913] [bbotk]                         0.3052582           -1.565683               1.305301
INFO  [18:48:27.913] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:48:27.913] [bbotk]                         20                     923                 0.1211226
INFO  [18:48:27.913] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:48:27.913] [bbotk]  0.01076055 <list[8]>              FALSE     0.03148434        0      0
INFO  [18:48:27.913] [bbotk]  runtime_learners                                uhash
INFO  [18:48:27.913] [bbotk]            58.958 6b6a2589-e440-4a3e-ade1-fd6f2950b7c7
INFO  [18:48:29.859] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 69 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:48:39.782] [bbotk] Evaluating 1 configuration(s)
INFO  [18:48:39.826] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:48:39.909] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -32.81197
[1] 11.08432
[1] -41.68062
[1] 60.69207
[1] -35.31672
[1] 29.28764
[1] 125.9997
[1] 1736.07
[1] -20.97627
[1] 65.36297
INFO  [18:49:03.748] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -2754.405
[1] -103.6637
[1] 35.01688
[1] 1068.391
[1] -22.7165
[1] 22.96598
[1] -2814.62
[1] -64.7904
[1] -276.8832
[1] 20.24229
INFO  [18:49:33.320] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -89.5196
[1] 106.4938
[1] -39.2728
[1] 16.79119
[1] -29.59289
[1] 20.68038
[1] -32.13537
[1] 115.9306
[1] 157.6474
[1] 2619.124
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:50:01.223] [mlr3] Finished benchmark
INFO  [18:50:01.450] [bbotk] Result of batch 39:
INFO  [18:50:01.472] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:50:01.472] [bbotk]              -6.563383                         0.2714759
INFO  [18:50:01.472] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:50:01.472] [bbotk]                         0.3130706          -0.2354918              0.3185589
INFO  [18:50:01.472] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:50:01.472] [bbotk]                          7                    2053                 0.9182716
INFO  [18:50:01.472] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:50:01.472] [bbotk]  0.009706012 <list[8]>              FALSE     0.02885293        0      0
INFO  [18:50:01.472] [bbotk]  runtime_learners                                uhash
INFO  [18:50:01.472] [bbotk]            80.774 0202f30a-1384-4fc4-98b1-97a78d0d6065
INFO  [18:50:04.420] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 70 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:50:17.837] [bbotk] Evaluating 1 configuration(s)
INFO  [18:50:17.928] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:50:17.996] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -5060.471
[1] -107.1189
[1] -27.04234
[1] 54.71094
[1] -20.70512
[1] 111.6098
[1] -62.11976
[1] 78.56677
[1] -39.33321
[1] 21.71195
INFO  [18:50:37.983] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -16.89633
[1] 255.6532
[1] -264.1207
[1] 2.751626
[1] -74.17449
[1] 135.7748
[1] -110.5292
[1] 62.61493
[1] -39.33984
[1] 31.93673
INFO  [18:51:07.825] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1402.076
[1] -40.33495
[1] -1267.233
[1] 281.7081
[1] -293.2577
[1] -4.008296
[1] -49.41546
[1] 19.34781
[1] -72.47141
[1] 49.18738
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:51:39.440] [mlr3] Finished benchmark
INFO  [18:51:40.130] [bbotk] Result of batch 40:
INFO  [18:51:40.209] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:51:40.209] [bbotk]              -3.787712                          0.106516
INFO  [18:51:40.209] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:51:40.209] [bbotk]                         0.2116005           -1.102115               5.932376
INFO  [18:51:40.209] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:51:40.209] [bbotk]                          2                    2010                 0.9176444
INFO  [18:51:40.209] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:51:40.209] [bbotk]  0.009582081 <list[8]>              FALSE     0.03141617        0      0
INFO  [18:51:40.209] [bbotk]  runtime_learners                                uhash
INFO  [18:51:40.209] [bbotk]            81.031 1fcb3978-b32d-46d9-8613-b6e12cb500d4
INFO  [18:51:43.185] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 71 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:51:54.404] [bbotk] Evaluating 1 configuration(s)
INFO  [18:51:54.563] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:51:54.645] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -40.19775
[1] 168.4184
[1] -7.364141
[1] 130.2056
[1] -68.25828
[1] 46.36486
[1] -3.591316
[1] 151.5126
[1] -38.47341
[1] 29.88104
INFO  [18:52:18.349] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -179.9753
[1] 8.327049
[1] -20.19934
[1] 316.7954
[1] -195.8997
[1] 68.10226
[1] -30.00097
[1] 41.29655
[1] -100.9217
[1] -3.105832
INFO  [18:52:47.298] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -16.3016
[1] 69.14949
[1] -30.54575
[1] 26.50413
[1] -72.17235
[1] 0.1259378
[1] -47.3459
[1] 25.19209
[1] -122.3942
[1] 76.09861
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:53:10.720] [mlr3] Finished benchmark
INFO  [18:53:11.109] [bbotk] Result of batch 41:
INFO  [18:53:11.124] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:53:11.124] [bbotk]              -3.920943                         0.4833235
INFO  [18:53:11.124] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:53:11.124] [bbotk]                          0.977831            -1.02984              -5.720195
INFO  [18:53:11.124] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:53:11.124] [bbotk]                         16                    1426                 0.1016301
INFO  [18:53:11.124] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:53:11.124] [bbotk]  0.009666957 <list[8]>              FALSE     0.03176231        0      0
INFO  [18:53:11.124] [bbotk]  runtime_learners                                uhash
INFO  [18:53:11.124] [bbotk]            75.828 e8eb0b2b-12bd-4b44-afd2-ec0246db327a
INFO  [18:53:15.892] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 72 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:53:25.645] [bbotk] Evaluating 1 configuration(s)
INFO  [18:53:25.874] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:53:26.049] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -66.21803
[1] 82.08927
[1] -39.16506
[1] 58.21273
[1] -61.2161
[1] 127.1355
[1] -71.051
[1] 28.90614
[1] -2.354823
[1] 131.253
INFO  [18:54:04.352] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -143.524
[1] 245.2223
[1] -126.2987
[1] -4.291031
[1] -33.85561
[1] 39.4847
[1] -23.83076
[1] 88.21537
[1] -61.073
[1] 29.37923
INFO  [18:54:39.227] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -67.39856
[1] 36.55049
[1] -7.124152e+15
[1] 3.739022e+16
[1] -350.9866
[1] -4.148606
[1] -59.79153
[1] 21.57825
[1] -56.42911
[1] 4.47552
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:55:33.387] [mlr3] Finished benchmark
INFO  [18:55:33.700] [bbotk] Result of batch 42:
INFO  [18:55:33.810] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:55:33.810] [bbotk]             -0.6234638                         0.4047266
INFO  [18:55:33.810] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:55:33.810] [bbotk]                         0.7026049           -1.882343              -6.697993
INFO  [18:55:33.810] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:55:33.810] [bbotk]                         13                    3324                 0.1584741
INFO  [18:55:33.810] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:55:33.810] [bbotk]  0.009357469 <list[8]>              FALSE     0.02521359        0      0
INFO  [18:55:33.810] [bbotk]  runtime_learners                                uhash
INFO  [18:55:33.810] [bbotk]           126.707 f5bb6824-18ef-499d-8e7f-5b62304615fc
INFO  [18:55:35.959] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 73 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:55:45.716] [bbotk] Evaluating 1 configuration(s)
INFO  [18:55:45.808] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:55:45.905] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -67.18885
[1] 24.92082
[1] -31.01203
[1] 8.817392
[1] -10.21383
[1] 29.7917
[1] -88.71467
[1] 21.39102
[1] -12.46641
[1] 45.92658
INFO  [18:56:37.752] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -58.10582
[1] 17.60385
[1] -35.54345
[1] 26.53764
[1] -51.47033
[1] 18.83695
[1] -27.8585
[1] 33.45955
[1] -6212.058
[1] -338.6261
INFO  [18:57:20.135] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -138.6135
[1] -1.014608
[1] 130.0975
[1] 2655.268
[1] -2.14377e+16
[1] 1.732477e+15
[1] -35.61864
[1] 24.00258
[1] -19.6246
[1] 23.11463
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:58:11.257] [mlr3] Finished benchmark
INFO  [18:58:11.412] [bbotk] Result of batch 43:
INFO  [18:58:11.422] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:58:11.422] [bbotk]                -4.8825                          0.138413
INFO  [18:58:11.422] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:58:11.422] [bbotk]                         0.5665065          -0.2531861             -0.5804058
INFO  [18:58:11.422] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:58:11.422] [bbotk]                         15                    3294                 0.8255966
INFO  [18:58:11.422] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:58:11.422] [bbotk]  0.009517327 <list[8]>              FALSE      0.0248635        0      0
INFO  [18:58:11.422] [bbotk]  runtime_learners                                uhash
INFO  [18:58:11.422] [bbotk]           144.875 6372ec83-184f-449b-90b7-b7fc29f53963
INFO  [18:58:16.800] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 74 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:58:51.432] [bbotk] Evaluating 1 configuration(s)
INFO  [18:58:51.497] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:58:51.650] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -27.32062
[1] 125.8924
[1] -46.17581
[1] 112.5559
[1] -69.80848
[1] 17.71491
[1] -3.226185e+16
[1] 2.45434e+15
[1] -47.09058
[1] 39.30943
INFO  [18:59:52.885] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -126.2941
[1] -1.168284
[1] -29.39037
[1] 54.44102
[1] -84.49884
[1] 26.70545
[1] -32.96229
[1] 253.913
[1] -41.97372
[1] 28.22875
INFO  [19:00:56.908] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -49.09724
[1] 30.99526
[1] -87.70901
[1] -4.164824
[1] -117.7674
[1] 102.7547
[1] -110.5512
[1] 68.71097
[1] -51.28521
[1] 42.38145
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:01:56.444] [mlr3] Finished benchmark
INFO  [19:01:56.686] [bbotk] Result of batch 44:
INFO  [19:01:56.796] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:01:56.796] [bbotk]              0.4334443                         0.6663056
INFO  [19:01:56.796] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:01:56.796] [bbotk]                         0.7699757          -0.1665071               2.588058
INFO  [19:01:56.796] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:01:56.796] [bbotk]                         18                    3654                 0.2571905
INFO  [19:01:56.796] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:01:56.796] [bbotk]  0.008332315 <list[8]>              FALSE     0.02914628        0      0
INFO  [19:01:56.796] [bbotk]  runtime_learners                                uhash
INFO  [19:01:56.796] [bbotk]            184.39 8625413d-99dd-4c0d-8201-5541d34aceb2
INFO  [19:01:59.382] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 75 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:02:07.239] [bbotk] Evaluating 1 configuration(s)
INFO  [19:02:07.546] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:02:07.908] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -93.69395
[1] -4.396353
[1] -856.5509
[1] -9.832416
[1] -86.47274
[1] 75.81435
[1] -3112.114
[1] -50.02319
[1] -5.147446
[1] 156.8226
INFO  [19:03:18.943] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -58.91047
[1] 68.38825
[1] -7382.048
[1] -113.6579
[1] -79.96946
[1] 50.88738
[1] -123.9236
[1] -3.311062
[1] -74.24382
[1] 204.7789
INFO  [19:04:36.413] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -49.71498
[1] 149.0597
[1] -37.59069
[1] 113.54
[1] -63.59352
[1] 55.80407
[1] -113.306
[1] 3.962073
[1] 428.1109
[1] 14208.88
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:06:02.345] [mlr3] Finished benchmark
INFO  [19:06:02.423] [bbotk] Result of batch 45:
INFO  [19:06:02.432] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:06:02.432] [bbotk]            -0.08731059                         0.2556387
INFO  [19:06:02.432] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:06:02.432] [bbotk]                         0.9762206           -6.630155              -5.340181
INFO  [19:06:02.432] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:06:02.432] [bbotk]                          7                    4988                 0.1378997
INFO  [19:06:02.432] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:06:02.432] [bbotk]  0.01200808 <list[8]>              FALSE     0.04133329        0      0
INFO  [19:06:02.432] [bbotk]  runtime_learners                                uhash
INFO  [19:06:02.432] [bbotk]           234.255 0ccf84aa-46d2-44ba-bbf1-894e5dd3d70e
INFO  [19:06:03.997] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 76 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:06:14.709] [bbotk] Evaluating 1 configuration(s)
INFO  [19:06:14.753] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:06:14.846] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -2.14677e+16
[1] 2.202146e+15
[1] -99.52115
[1] 71.05183
[1] -20.58151
[1] 20.23134
[1] -6035.557
[1] -210.635
[1] -1709.048
[1] -30.87869
INFO  [19:07:09.958] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -73.91441
[1] 15.38898
[1] -82.38926
[1] 21.40795
[1] -16.64909
[1] 54.03811
[1] -49.15559
[1] 32.86377
[1] -109.2019
[1] 60.18646
INFO  [19:07:55.274] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2598.576
[1] -53.87339
[1] -7098.958
[1] -96.83471
[1] -31.56675
[1] 35.5008
[1] -11.57876
[1] 32.12307
[1] -121.3253
[1] 11.52982
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:08:56.631] [mlr3] Finished benchmark
INFO  [19:08:58.957] [bbotk] Result of batch 46:
INFO  [19:08:59.096] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:08:59.096] [bbotk]              -1.099821                         0.1983534
INFO  [19:08:59.096] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:08:59.096] [bbotk]                         0.9117838           -3.438826              -4.996775
INFO  [19:08:59.096] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:08:59.096] [bbotk]                          1                    4092                 0.8115688
INFO  [19:08:59.096] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:08:59.096] [bbotk]  0.009403499 <list[8]>              FALSE     0.02397031        0      0
INFO  [19:08:59.096] [bbotk]  runtime_learners                                uhash
INFO  [19:08:59.096] [bbotk]            161.49 801bddaf-9f00-4f43-9834-73869d8ded12
INFO  [19:09:06.184] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 77 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:09:20.411] [bbotk] Evaluating 1 configuration(s)
INFO  [19:09:20.433] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:09:20.617] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1.920996e+16
[1] 1.357567e+16
[1] -33.98351
[1] 118.1378
[1] -28.20456
[1] 14.10454
[1] -89.8333
[1] 49.09177
[1] -47.19158
[1] 42.45027
INFO  [19:10:11.572] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -99.34659
[1] 3.656796
[1] -500.8883
[1] -3.804667
[1] -130.2937
[1] -0.2659892
[1] -23.50468
[1] 52.53555
[1] -104.1612
[1] 23.04381
INFO  [19:11:39.689] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -40.29271
[1] 10.56466
[1] -456.6209
[1] 9.113534
[1] -27.3675
[1] 15.82732
[1] -51.49525
[1] 23.99982
[1] -74.50848
[1] 285.8291
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:12:45.880] [mlr3] Finished benchmark
INFO  [19:12:47.402] [bbotk] Result of batch 47:
INFO  [19:12:47.420] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:12:47.420] [bbotk]              -4.995274                         0.1377442
INFO  [19:12:47.420] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:12:47.420] [bbotk]                         0.7176133        -0.008834143               1.118392
INFO  [19:12:47.420] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:12:47.420] [bbotk]                          4                    4833                 0.2082231
INFO  [19:12:47.420] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:12:47.420] [bbotk]  0.00780542 <list[8]>              FALSE     0.02621082        0      0
INFO  [19:12:47.420] [bbotk]  runtime_learners                                uhash
INFO  [19:12:47.420] [bbotk]           204.728 e7e56707-ccd5-4c4f-aa21-61c8956b7d1a
INFO  [19:12:49.191] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 78 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:12:57.225] [bbotk] Evaluating 1 configuration(s)
INFO  [19:12:57.301] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:12:57.343] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -200.9986
[1] 72.01241
[1] -79.81061
[1] 71.68816
[1] -13.36821
[1] 122.2907
[1] -34.45635
[1] 31.86643
[1] 70.25539
[1] 2951.829
INFO  [19:13:22.725] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -310.3775
[1] -4.403724
[1] -86.54483
[1] 25.2303
[1] -194.343
[1] 11.85519
[1] -55.55451
[1] 29.21051
[1] -60.52921
[1] 118.2095
INFO  [19:14:27.321] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -39.23735
[1] 52.24712
[1] -238.0448
[1] -4.02659
[1] -61.82637
[1] 103.5371
[1] -42.45678
[1] 38.68449
[1] -3966.331
[1] -94.33111
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:15:25.613] [mlr3] Finished benchmark
INFO  [19:15:25.918] [bbotk] Result of batch 48:
INFO  [19:15:25.932] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:15:25.932] [bbotk]              -1.705694                         0.9686373
INFO  [19:15:25.932] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:15:25.932] [bbotk]                         0.9174476            -5.51261              -6.545983
INFO  [19:15:25.932] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:15:25.932] [bbotk]                         18                    2546                  0.131467
INFO  [19:15:25.932] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:15:25.932] [bbotk]  0.008733023 <list[8]>              FALSE     0.03052385        0      0
INFO  [19:15:25.932] [bbotk]  runtime_learners                                uhash
INFO  [19:15:25.932] [bbotk]           147.574 f1b0ca05-001c-4633-a8f2-405dd8788e87
INFO  [19:15:27.536] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 79 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:15:39.270] [bbotk] Evaluating 1 configuration(s)
INFO  [19:15:39.416] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:15:39.472] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -25.07293
[1] 76.48066
[1] -129.8799
[1] 10.88103
[1] -77.43987
[1] 38.35962
[1] -23.96012
[1] 42.77413
[1] -128.4884
[1] 46.71757
INFO  [19:16:34.343] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -71.93156
[1] 7.306987
[1] 108.8824
[1] 3078.099
[1] -131.9496
[1] 108.864
[1] -117.6508
[1] 13.08817
[1] -57.69231
[1] 36.57075
INFO  [19:17:30.707] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -248.3517
[1] 26.68415
[1] -52.66987
[1] 54.76383
[1] -48.69773
[1] 32.67899
[1] -42.44307
[1] 19.45755
[1] 87.75812
[1] 2666.969
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:18:23.108] [mlr3] Finished benchmark
INFO  [19:18:23.580] [bbotk] Result of batch 49:
INFO  [19:18:23.652] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:18:23.652] [bbotk]              -4.449426                         0.3417054
INFO  [19:18:23.652] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:18:23.652] [bbotk]                         0.1186124          -0.7989673               2.065131
INFO  [19:18:23.652] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:18:23.652] [bbotk]                          6                    3420                 0.5907544
INFO  [19:18:23.652] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:18:23.652] [bbotk]  0.008283699 <list[8]>              FALSE     0.02593299        0      0
INFO  [19:18:23.652] [bbotk]  runtime_learners                                uhash
INFO  [19:18:23.652] [bbotk]           163.338 96f7bea9-6ccb-4fef-90c1-1636c5cf2c8a
INFO  [19:18:28.346] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 80 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:18:37.413] [bbotk] Evaluating 1 configuration(s)
INFO  [19:18:37.778] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:18:37.960] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -46.68611
[1] 48.44001
[1] -1935.103
[1] -41.01559
[1] -84.29871
[1] 15.37994
[1] -28.78646
[1] 13.60683
[1] -11.73164
[1] 22.1763
INFO  [19:19:46.388] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -45.5283
[1] 5.051622
[1] -70.62273
[1] 11.05212
[1] -34.30415
[1] 31.9166
[1] -21.75355
[1] 17.55921
[1] -10.85725
[1] 84.64275
INFO  [19:20:53.698] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -22.42451
[1] 18.88758
[1] -26.22988
[1] 33.41478
[1] -30.67371
[1] 10.45122
[1] 32.60179
[1] 711.4366
[1] -1153.675
[1] 19.5822
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:22:09.782] [mlr3] Finished benchmark
INFO  [19:22:09.926] [bbotk] Result of batch 50:
INFO  [19:22:09.939] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:22:09.939] [bbotk]              -6.523587                         0.2533423
INFO  [19:22:09.939] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:22:09.939] [bbotk]                           0.90075          -0.2651947              -6.851346
INFO  [19:22:09.939] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:22:09.939] [bbotk]                          3                    3826                 0.5011444
INFO  [19:22:09.939] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:22:09.939] [bbotk]  0.007928287 <list[8]>              FALSE       0.029778        0      0
INFO  [19:22:09.939] [bbotk]  runtime_learners                                uhash
INFO  [19:22:09.939] [bbotk]           211.211 a78ba4cb-890f-4c34-8dff-5c5ea407277e
INFO  [19:22:21.982] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 81 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:22:49.522] [bbotk] Evaluating 1 configuration(s)
INFO  [19:22:50.184] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:22:50.666] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -45.12599
[1] 22.52684
[1] -2.124978e+16
[1] 2.340359e+15
[1] -16.23994
[1] 51.3895
[1] -58.1252
[1] 20.73319
[1] 60.98721
[1] 1980.913
INFO  [19:23:39.671] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1.658393e+16
[1] 2.790628e+16
[1] -26.5746
[1] 33.46215
[1] -110.6751
[1] 14.93138
[1] -489.5407
[1] 9.584682
[1] -148.9264
[1] -4.028116
INFO  [19:24:42.691] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -44.77844
[1] 14.20357
[1] -24.20981
[1] 55.48488
[1] -23.53649
[1] 18.59751
[1] -75.41589
[1] 59.98854
[1] -40.85619
[1] 11.05496
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:25:30.746] [mlr3] Finished benchmark
INFO  [19:25:30.852] [bbotk] Result of batch 51:
INFO  [19:25:30.859] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:25:30.859] [bbotk]              -5.156508                         0.6594397
INFO  [19:25:30.859] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:25:30.859] [bbotk]                         0.9737376          -0.4823645             0.05236466
INFO  [19:25:30.859] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:25:30.859] [bbotk]                          3                    2514                 0.8971255
INFO  [19:25:30.859] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:25:30.859] [bbotk]  0.007599629 <list[8]>              FALSE     0.03099947        0      0
INFO  [19:25:30.859] [bbotk]  runtime_learners                                uhash
INFO  [19:25:30.859] [bbotk]           159.645 35331654-7340-4496-b6e8-cac568a66bd1
INFO  [19:25:36.264] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 82 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:25:46.203] [bbotk] Evaluating 1 configuration(s)
INFO  [19:25:46.453] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:25:47.125] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 218.6844
[1] 5853.942
[1] -79.70469
[1] 49.76328
[1] -240.8006
[1] -4.140957
[1] -92.3367
[1] 18.06066
[1] -39.38533
[1] 53.22293
INFO  [19:26:31.539] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -99.55213
[1] 4.980955
[1] -114.7382
[1] -3.740063
[1] -46.99074
[1] 53.26574
[1] -64.78416
[1] 272.4501
[1] -18.19891
[1] 106.8289
INFO  [19:27:29.360] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -87.71913
[1] 25.3311
[1] -140.8114
[1] -3.929575
[1] -107.2195
[1] 36.92078
[1] -137.2005
[1] 40.53518
[1] -45.43833
[1] 141.7417
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:28:00.494] [mlr3] Finished benchmark
INFO  [19:28:00.630] [bbotk] Result of batch 52:
INFO  [19:28:00.757] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:28:00.757] [bbotk]              -6.714981                         0.3048193
INFO  [19:28:00.757] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:28:00.757] [bbotk]                         0.6455886           -1.058469               6.299302
INFO  [19:28:00.757] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:28:00.757] [bbotk]                         19                    1949                 0.4746797
INFO  [19:28:00.757] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:28:00.757] [bbotk]  0.007383226 <list[8]>              FALSE      0.0302584        0      0
INFO  [19:28:00.757] [bbotk]  runtime_learners                                uhash
INFO  [19:28:00.757] [bbotk]           132.617 d13e528b-50c4-4696-97d1-c88877710a7e
INFO  [19:28:07.341] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 83 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:28:23.895] [bbotk] Evaluating 1 configuration(s)
INFO  [19:28:24.019] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:28:24.071] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -59.13925
[1] 78.88162
[1] -6.472395
[1] 132.1747
[1] -7614.885
[1] -79.13367
[1] -43.279
[1] 17.80604
[1] -84.85538
[1] 184.062
INFO  [19:29:21.756] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -43.43931
[1] 33.23918
[1] -96.68825
[1] 25.67622
[1] -50.61507
[1] 15.79247
[1] -83.57867
[1] 59.77262
[1] -254.3794
[1] 60.01519
INFO  [19:30:03.993] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -137.1901
[1] -4.098659
[1] -25.33933
[1] 24.05552
[1] -33.57409
[1] 80.75486
[1] -751.5982
[1] -24.30386
[1] -154.8828
[1] 15.94486
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:30:50.157] [mlr3] Finished benchmark
INFO  [19:30:50.264] [bbotk] Result of batch 53:
INFO  [19:30:50.373] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:30:50.373] [bbotk]              -6.208852                         0.2147042
INFO  [19:30:50.373] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:30:50.373] [bbotk]                         0.9804304           -1.057219               6.195426
INFO  [19:30:50.373] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:30:50.373] [bbotk]                          1                    4331                 0.9057312
INFO  [19:30:50.373] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:30:50.373] [bbotk]  0.006923803 <list[8]>              FALSE     0.02735428        0      0
INFO  [19:30:50.373] [bbotk]  runtime_learners                                uhash
INFO  [19:30:50.373] [bbotk]           145.735 14bf47f9-320d-49a9-bf18-cdfbdda14b5a
INFO  [19:30:53.953] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 84 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:31:11.498] [bbotk] Evaluating 1 configuration(s)
INFO  [19:31:11.757] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:31:11.975] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -87.4412
[1] 164.6777
[1] -133.3136
[1] 270.8395
[1] -420.269
[1] -9.311521
[1] 5.502479
[1] 205.213
[1] -1.126587
[1] 218.7292
INFO  [19:32:02.741] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -102.113
[1] 124.6187
[1] -312.562
[1] -6.186284
[1] -83.98391
[1] 185.6803
[1] -126.8271
[1] 158.1011
[1] -194.5476
[1] -3.644973
INFO  [19:32:57.567] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -212.3206
[1] 34.08449
[1] -188.8644
[1] 55.3809
[1] -419.5703
[1] -6.31031
[1] -252.122
[1] 262.828
[1] -304.3392
[1] -0.3887584
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:33:51.382] [mlr3] Finished benchmark
INFO  [19:33:52.176] [bbotk] Result of batch 54:
INFO  [19:33:52.189] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:33:52.189] [bbotk]               2.991728                         0.2740785
INFO  [19:33:52.189] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:33:52.189] [bbotk]                          0.962787          -0.5959422              -5.075061
INFO  [19:33:52.189] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:33:52.189] [bbotk]                         18                    4799                 0.5664492
INFO  [19:33:52.189] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:33:52.189] [bbotk]  0.007525243 <list[8]>              FALSE     0.04504798        0      0
INFO  [19:33:52.189] [bbotk]  runtime_learners                                uhash
INFO  [19:33:52.189] [bbotk]           158.878 f329550f-a7d5-4319-b203-e97eed8dae05
INFO  [19:33:58.333] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 85 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:34:14.106] [bbotk] Evaluating 1 configuration(s)
INFO  [19:34:14.162] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:34:14.295] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1010.823
[1] -38.20335
[1] -46.45614
[1] 18.40651
[1] -59.35062
[1] 8.888261
[1] 28.68565
[1] 640.0551
[1] -24.1261
[1] 80.18651
INFO  [19:35:14.422] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -68.15836
[1] 3.066947
[1] -103.5613
[1] 12.51102
[1] -1929.29
[1] -42.36615
[1] -173.8437
[1] 107.8078
[1] -66.12239
[1] 20.36959
INFO  [19:36:12.781] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 3477.236
[1] 93708.34
[1] -38.3093
[1] 6.967893
[1] -44.59993
[1] 24.83251
[1] -2553.769
[1] -51.79698
[1] -8.348459
[1] 43.76267
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:37:10.421] [mlr3] Finished benchmark
INFO  [19:37:10.723] [bbotk] Result of batch 55:
INFO  [19:37:10.751] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:37:10.751] [bbotk]              -6.371404                         0.4794229
INFO  [19:37:10.751] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:37:10.751] [bbotk]                         0.7529363          -0.9341629               2.482429
INFO  [19:37:10.751] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:37:10.751] [bbotk]                          7                    2690                 0.5729901
INFO  [19:37:10.751] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:37:10.751] [bbotk]  0.007349199 <list[8]>              FALSE     0.02585617        0      0
INFO  [19:37:10.751] [bbotk]  runtime_learners                                uhash
INFO  [19:37:10.751] [bbotk]           175.811 1b3553da-c809-49eb-9f75-969d8d2dfe3b
INFO  [19:37:13.021] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 86 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:37:22.500] [bbotk] Evaluating 1 configuration(s)
INFO  [19:37:22.585] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:37:22.696] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -15.51628
[1] 118.4811
[1] -17.2314
[1] 21.07456
[1] -3227.083
[1] -83.92912
[1] -10.28771
[1] 21.06399
[1] 4.134843
[1] 38.03397
INFO  [19:37:43.760] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -28.77313
[1] 9.906268
[1] -29.93802
[1] 3.35529
[1] -936.3851
[1] -49.22255
[1] -46.83128
[1] 20.21693
[1] -14.94248
[1] 31.66957
INFO  [19:38:06.423] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -19.69986
[1] 37.13297
[1] -26.57492
[1] 12.85448
[1] -112.736
[1] 7.502037
[1] -38.11402
[1] 14.70248
[1] -44.06476
[1] 4.867128
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:38:33.276] [mlr3] Finished benchmark
INFO  [19:38:33.773] [bbotk] Result of batch 56:
INFO  [19:38:33.812] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:38:33.812] [bbotk]              -6.294884                         0.4345613
INFO  [19:38:33.812] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:38:33.812] [bbotk]                         0.5081202         -0.07303444               -2.45994
INFO  [19:38:33.812] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:38:33.812] [bbotk]                         16                     277                 0.3561439
INFO  [19:38:33.812] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:38:33.812] [bbotk]  0.007336822 <list[8]>              FALSE     0.02910061        0      0
INFO  [19:38:33.812] [bbotk]  runtime_learners                                uhash
INFO  [19:38:33.812] [bbotk]            69.484 c6c127c0-ce02-411c-add8-674332d4a038
INFO  [19:38:38.577] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 87 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:38:56.598] [bbotk] Evaluating 1 configuration(s)
INFO  [19:38:56.632] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:38:56.784] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -126.7345
[1] 60.76559
[1] -68.14087
[1] 76.82638
[1] -2021.681
[1] -35.92246
[1] -95.08301
[1] 32.42496
[1] -44.07563
[1] 19.92847
INFO  [19:39:30.885] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -57.60609
[1] 197.4686
[1] -80.39758
[1] 14.8896
[1] -146.4966
[1] 10.85548
[1] -84.58335
[1] 23.25888
[1] -52.01648
[1] 60.29959
INFO  [19:40:25.350] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -108.6341
[1] 14.92235
[1] -86.72642
[1] 30.46741
[1] -68.17175
[1] 15.51348
[1] -2721.419
[1] -65.51278
[1] -76.35076
[1] 16.10065
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:41:38.027] [mlr3] Finished benchmark
INFO  [19:41:39.535] [bbotk] Result of batch 57:
INFO  [19:41:39.846] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:41:39.846] [bbotk]              -4.809819                         0.8129579
INFO  [19:41:39.846] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:41:39.846] [bbotk]                          0.860946         -0.03931118               5.496344
INFO  [19:41:39.846] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:41:39.846] [bbotk]                         17                    1662                 0.3189488
INFO  [19:41:39.846] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:41:39.846] [bbotk]  0.007090627 <list[8]>              FALSE     0.02861309        0      0
INFO  [19:41:39.846] [bbotk]  runtime_learners                                uhash
INFO  [19:41:39.846] [bbotk]           160.972 76f4c2b2-f566-4b46-ac43-7eee29279794
INFO  [19:41:46.200] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 88 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:42:04.541] [bbotk] Evaluating 1 configuration(s)
INFO  [19:42:04.859] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:42:05.112] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 47.46289
[1] 2264.857
[1] 1290.579
[1] 63805.32
[1] -774.0091
[1] -12.63981
[1] -78.90647
[1] 566.59
[1] -120.8817
[1] 580.4175
INFO  [19:42:28.967] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -2452.303
[1] -44.4473
[1] -440.1349
[1] 349.7736
[1] -717.3679
[1] -12.40003
[1] -451.9461
[1] 12.71851
[1] -536.7678
[1] -10.55149
INFO  [19:42:54.613] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 13.66877
[1] 715.4732
[1] -1206.677
[1] -20.98329
[1] -368.3088
[1] 216.7163
[1] -422.3445
[1] -7.212747
[1] -145.7599
[1] 910.6558
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:43:29.374] [mlr3] Finished benchmark
INFO  [19:43:30.854] [bbotk] Result of batch 58:
INFO  [19:43:30.969] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:43:30.969] [bbotk]              -6.833097                         0.8576456
INFO  [19:43:30.969] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:43:30.969] [bbotk]                         0.8609336           -6.673978              -0.948475
INFO  [19:43:30.969] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:43:30.969] [bbotk]                         19                     351                   0.11312
INFO  [19:43:30.969] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:43:30.969] [bbotk]  0.006828688 <list[8]>              FALSE     0.05317166        0      0
INFO  [19:43:30.969] [bbotk]  runtime_learners                                uhash
INFO  [19:43:30.969] [bbotk]            83.512 86e68478-11d7-4e9d-80d4-f4548c697631
INFO  [19:43:50.925] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 89 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:44:11.567] [bbotk] Evaluating 1 configuration(s)
INFO  [19:44:11.838] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:44:11.952] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -30.29434
[1] 119.2589
[1] -72.66891
[1] 54.80155
[1] -409.9878
[1] -4.38933
[1] -46.93157
[1] 73.5295
[1] -594.3475
[1] 7.032429
INFO  [19:45:31.995] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -45.53226
[1] 114.6478
[1] -31.83468
[1] 189.5185
[1] -254.5792
[1] -4.321241
[1] -49.09162
[1] 78.79178
[1] -89.78017
[1] 21.20751
INFO  [19:46:50.237] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -215.2438
[1] 21.95801
[1] -41246.5
[1] -745.0761
[1] -166.2428
[1] 10.52708
[1] -55.45796
[1] 63.50961
[1] -64.24793
[1] 90.77473
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:48:08.620] [mlr3] Finished benchmark
INFO  [19:48:10.914] [bbotk] Result of batch 59:
INFO  [19:48:11.055] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:48:11.055] [bbotk]              -5.942486                         0.1519235
INFO  [19:48:11.055] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:48:11.055] [bbotk]                         0.6061846          -0.8819674               6.120612
INFO  [19:48:11.055] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:48:11.055] [bbotk]                         14                    4960                 0.1000993
INFO  [19:48:11.055] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:48:11.055] [bbotk]  0.007061118 <list[8]>              FALSE     0.04442057        0      0
INFO  [19:48:11.055] [bbotk]  runtime_learners                                uhash
INFO  [19:48:11.055] [bbotk]            236.27 e3b1cdc3-33a3-482d-8d92-cae029ff38a0
INFO  [19:48:20.119] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 90 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:48:55.959] [bbotk] Evaluating 1 configuration(s)
INFO  [19:48:56.116] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:48:56.162] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -112.5531
[1] 14.67444
[1] -129.6144
[1] 10.08596
[1] 43.71361
[1] 1355.655
[1] 3.703423
[1] 107.9959
[1] -654.1131
[1] -29.19554
INFO  [19:49:44.543] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -17.07945
[1] 23.38453
[1] -123.4969
[1] -3.95734
[1] -176.4109
[1] 13.17697
[1] -25.79338
[1] 37.63265
[1] -37.06641
[1] 33.86952
INFO  [19:50:51.273] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -35.87353
[1] 10.54177
[1] -166.2718
[1] 5.280064
[1] -50.67447
[1] 31.13304
[1] -30.85704
[1] 30.85472
[1] -32.90461
[1] 23.00318
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:51:58.880] [mlr3] Finished benchmark
INFO  [19:51:59.191] [bbotk] Result of batch 60:
INFO  [19:51:59.220] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:51:59.220] [bbotk]              -4.858786                         0.2895539
INFO  [19:51:59.220] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:51:59.220] [bbotk]                         0.5481101            -2.79318              -5.484788
INFO  [19:51:59.220] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:51:59.220] [bbotk]                          1                    4414                 0.9939261
INFO  [19:51:59.220] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:51:59.220] [bbotk]  0.007266455 <list[8]>              FALSE     0.02323327        0      0
INFO  [19:51:59.220] [bbotk]  runtime_learners                                uhash
INFO  [19:51:59.220] [bbotk]           182.318 47583159-06bf-404a-8543-19ed4f13b302
INFO  [19:52:02.193] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 91 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:52:32.839] [bbotk] Evaluating 1 configuration(s)
INFO  [19:52:33.166] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:52:33.530] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -58.8246
[1] 139.4126
[1] -37.1192
[1] 75.13727
[1] 3.346137
[1] 138.926
[1] -199.1609
[1] 71.40867
[1] -96.05445
[1] 65.746
INFO  [19:53:19.894] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -111.4356
[1] 90.86979
[1] -294.7752
[1] 9.210566
[1] -4.719942
[1] 98.2143
[1] -120.5349
[1] 65.21222
[1] -295.7933
[1] -4.217227
INFO  [19:54:39.923] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -125.0461
[1] 26.10758
[1] -109.7084
[1] 24.22871
[1] -94.74607
[1] 123.3339
[1] -1235.905
[1] -25.89721
[1] -247.0696
[1] -4.859338
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:55:28.748] [mlr3] Finished benchmark
INFO  [19:55:28.821] [bbotk] Result of batch 61:
INFO  [19:55:28.885] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:55:28.885] [bbotk]                2.82831                         0.7410989
INFO  [19:55:28.885] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:55:28.885] [bbotk]                         0.5456472          -0.5161173               -5.19114
INFO  [19:55:28.885] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:55:28.885] [bbotk]                         19                    2124                 0.9406003
INFO  [19:55:28.885] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:55:28.885] [bbotk]  0.01091954 <list[8]>              FALSE     0.03553044        0      0
INFO  [19:55:28.885] [bbotk]  runtime_learners                                uhash
INFO  [19:55:28.885] [bbotk]           174.822 0b405c93-4fc6-4456-8800-0cfd2e767abc
INFO  [19:55:31.487] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 92 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:55:49.100] [bbotk] Evaluating 1 configuration(s)
INFO  [19:55:49.439] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:55:49.720] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -43.06935
[1] 56.20206
[1] -149.1388
[1] 123.5217
[1] -132.8339
[1] 44.80363
[1] -413.6861
[1] 10.01238
[1] -27.6156
[1] 158.092
INFO  [19:56:37.386] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -79.65575
[1] -0.108854
[1] -265.5696
[1] 14.27273
[1] -49.89087
[1] 65.3813
[1] -73.00798
[1] 84.88931
[1] -39.19048
[1] 96.19138
INFO  [19:57:50.231] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -165.8374
[1] 22.12512
[1] -65.8871
[1] 9.264283
[1] -131.5517
[1] 29.0168
[1] -68.33835
[1] 59.04804
[1] -188.2576
[1] -3.892276
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:58:55.561] [mlr3] Finished benchmark
INFO  [19:58:56.651] [bbotk] Result of batch 62:
INFO  [19:58:56.780] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:58:56.780] [bbotk]              -6.883974                         0.4295335
INFO  [19:58:56.780] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:58:56.780] [bbotk]                         0.5557437           -5.295134              0.8633341
INFO  [19:58:56.780] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:58:56.780] [bbotk]                          1                    4101                 0.8571772
INFO  [19:58:56.780] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:58:56.780] [bbotk]  0.007077184 <list[8]>              FALSE     0.02751538        0      0
INFO  [19:58:56.780] [bbotk]  runtime_learners                                uhash
INFO  [19:58:56.780] [bbotk]           184.393 f5f80c37-88f8-4c7b-9892-3189e47cbd92
INFO  [19:59:07.440] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 93 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:59:37.053] [bbotk] Evaluating 1 configuration(s)
INFO  [19:59:37.451] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:59:37.554] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -796.5597
[1] 43.57498
[1] -923.2227
[1] -16.59888
[1] -1553.538
[1] -23.7524
[1] -709.5291
[1] 222.8254
[1] -1851.117
[1] -32.29308
INFO  [20:01:10.614] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1472.585
[1] -28.44304
[1] -375.1306
[1] 261.613
[1] -589.8003
[1] -10.66113
[1] 26.63845
[1] 1311.662
[1] 32.40618
[1] 1746.397
INFO  [20:02:44.419] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -860.0232
[1] -14.85708
[1] -557.6231
[1] 337.2278
[1] -845.4398
[1] -15.94479
[1] 12.11489
[1] 626.6352
[1] -768.1483
[1] -14.64699
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:04:34.563] [mlr3] Finished benchmark
INFO  [20:04:34.679] [bbotk] Result of batch 63:
INFO  [20:04:34.839] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:04:34.839] [bbotk]               3.059297                         0.8843241
INFO  [20:04:34.839] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:04:34.839] [bbotk]                         0.5125057           -8.595683              -6.744125
INFO  [20:04:34.839] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:04:34.839] [bbotk]                         13                    2240                  0.949055
INFO  [20:04:34.839] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:04:34.839] [bbotk]  0.009228087 <list[8]>              FALSE      0.0468183        0      0
INFO  [20:04:34.839] [bbotk]  runtime_learners                                uhash
INFO  [20:04:34.839] [bbotk]            296.55 78615c7b-34e4-413f-b4c9-e1ebcdbdcb1d
INFO  [20:04:37.523] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 94 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:04:45.750] [bbotk] Evaluating 1 configuration(s)
INFO  [20:04:46.008] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:04:46.119] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1926.963
[1] -48.7296
[1] -28.35513
[1] 26.23299
[1] -22.49522
[1] 80.12732
[1] -146.7613
[1] 6.43233
[1] -13623.42
[1] -562.6434
INFO  [20:05:35.014] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -58.39908
[1] 110.9369
[1] -36.10335
[1] 21.61595
[1] -234.0198
[1] 0.2814652
[1] -27.17156
[1] 18.31446
[1] -5848.953
[1] -92.69197
INFO  [20:07:19.413] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -56.47178
[1] 25.41447
[1] -108.0274
[1] 10.32483
[1] -25.22595
[1] 54.32053
[1] -37.85767
[1] 12.90059
[1] -53.62039
[1] 8.895439
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:08:36.833] [mlr3] Finished benchmark
INFO  [20:08:37.697] [bbotk] Result of batch 64:
INFO  [20:08:37.800] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:08:37.800] [bbotk]               -4.08942                         0.1059469
INFO  [20:08:37.800] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:08:37.800] [bbotk]                         0.9819844           -1.173666               3.627393
INFO  [20:08:37.800] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:08:37.800] [bbotk]                          4                    4808                 0.8795912
INFO  [20:08:37.800] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:08:37.800] [bbotk]  0.006718726 <list[8]>              FALSE     0.02810958        0      0
INFO  [20:08:37.800] [bbotk]  runtime_learners                                uhash
INFO  [20:08:37.800] [bbotk]            230.24 973074a8-16af-455e-bdc2-056623108c0e
INFO  [20:08:43.135] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 95 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:09:28.843] [bbotk] Evaluating 1 configuration(s)
INFO  [20:09:29.011] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:09:29.158] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -154.2613
[1] 1.565394
[1] -231.0388
[1] 12.8922
[1] -13.13618
[1] 36.46164
[1] -22.61001
[1] 30.15367
[1] -44.68564
[1] 18.17723
INFO  [20:10:07.892] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -48.81125
[1] 86.75598
[1] -18.94826
[1] 30.03096
[1] -44.17037
[1] 9.76276
[1] -71.46971
[1] 20.44948
[1] -60.42014
[1] -4.142442
INFO  [20:11:26.124] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -49.42142
[1] 225.1846
[1] -178.1262
[1] -3.064214
[1] -52.09991
[1] 3.258407
[1] -43.46432
[1] 30.38684
[1] -46.8019
[1] 107.3791
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:12:22.658] [mlr3] Finished benchmark
INFO  [20:12:22.918] [bbotk] Result of batch 65:
INFO  [20:12:22.958] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:12:22.958] [bbotk]               -3.47177                         0.3781414
INFO  [20:12:22.958] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:12:22.958] [bbotk]                         0.2164554          -0.4288525              -1.431598
INFO  [20:12:22.958] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:12:22.958] [bbotk]                          2                    3949                 0.9354544
INFO  [20:12:22.958] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:12:22.958] [bbotk]  0.006688772 <list[8]>              FALSE     0.02726831        0      0
INFO  [20:12:22.958] [bbotk]  runtime_learners                                uhash
INFO  [20:12:22.958] [bbotk]           172.798 ebda7ce1-4752-4aaa-a2f1-684df4e30c2a
INFO  [20:12:28.206] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 96 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:12:33.701] [bbotk] Evaluating 1 configuration(s)
INFO  [20:12:33.758] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:12:33.838] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -142.8664
[1] 23.25349
[1] -77.52781
[1] 13.64864
[1] -208.0612
[1] 32.23411
[1] 12.43437
[1] 502.3726
[1] -2.994573
[1] 95.87419
INFO  [20:13:07.679] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -3426.535
[1] -54.41808
[1] -59.50587
[1] 2.583374
[1] -39.7694
[1] 36.25658
[1] -56.18874
[1] 99.966
[1] 299.0939
[1] 12722.08
INFO  [20:13:32.188] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -81.41103
[1] 67.61842
[1] -35.19835
[1] 50.53317
[1] -106.0334
[1] 6.221751
[1] -43.70816
[1] 41.53097
[1] -2245.582
[1] -58.17214
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:14:16.766] [mlr3] Finished benchmark
INFO  [20:14:17.697] [bbotk] Result of batch 66:
INFO  [20:14:18.002] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:14:18.002] [bbotk]              0.1655562                         0.4596489
INFO  [20:14:18.002] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:14:18.002] [bbotk]                         0.2056224            -2.61328               -6.55464
INFO  [20:14:18.002] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:14:18.002] [bbotk]                          1                    2086                 0.9506856
INFO  [20:14:18.002] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:14:18.002] [bbotk]  0.006091134 <list[8]>              FALSE     0.02703606        0      0
INFO  [20:14:18.002] [bbotk]  runtime_learners                                uhash
INFO  [20:14:18.002] [bbotk]           102.525 ef1b97bb-d831-4750-a0b9-c6b2d40cc7e7
INFO  [20:14:28.741] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 97 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:14:37.041] [bbotk] Evaluating 1 configuration(s)
INFO  [20:14:37.286] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:14:37.301] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -122.2855
[1] 99.64339
[1] -147.4308
[1] 14.90258
[1] -31.74779
[1] 80.00405
[1] -317.2809
[1] -4.377324
[1] 3.835871
[1] 142.2392
INFO  [20:15:38.428] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -2.129231e+16
[1] 2.608031e+16
[1] -60.19315
[1] 20.87268
[1] -71.39353
[1] 49.08608
[1] -108.3632
[1] 179.7606
[1] -41.7192
[1] 94.98992
INFO  [20:16:27.891] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -92.11475
[1] 80.21976
[1] -72.15108
[1] 105.1723
[1] -2948.003
[1] -94.05522
[1] -73.36595
[1] 22.17401
[1] -232.1988
[1] -4.050799
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:17:45.516] [mlr3] Finished benchmark
INFO  [20:17:45.598] [bbotk] Result of batch 67:
INFO  [20:17:45.637] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:17:45.637] [bbotk]               1.420553                         0.3460413
INFO  [20:17:45.637] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:17:45.637] [bbotk]                         0.3725528           -4.759795              -6.718049
INFO  [20:17:45.637] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:17:45.637] [bbotk]                          1                    2947                 0.8389669
INFO  [20:17:45.637] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:17:45.637] [bbotk]  0.005925038 <list[8]>              FALSE     0.03722877        0      0
INFO  [20:17:45.637] [bbotk]  runtime_learners                                uhash
INFO  [20:17:45.637] [bbotk]           187.969 42750545-96df-4c7f-824f-4121279cefcf
INFO  [20:17:47.391] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 98 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:18:01.736] [bbotk] Evaluating 1 configuration(s)
INFO  [20:18:02.113] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:18:02.155] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -183.8645
[1] 8.252284
[1] -33.53346
[1] 50.9829
[1] -62.72099
[1] -2.007108
[1] -18.89131
[1] 142.4373
[1] -3347.573
[1] -55.67969
INFO  [20:18:18.271] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -64.23432
[1] 66.11034
[1] 430.6434
[1] 8659.823
[1] -18.51002
[1] 23.69387
[1] -38.04085
[1] 38.16645
[1] -92.09281
[1] 9.509417
INFO  [20:19:21.797] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -68.75654
[1] -2.720994
[1] -45.47684
[1] 29.549
[1] -6128.146
[1] -105.4753
[1] -95.48819
[1] 23.98821
[1] -19.68914
[1] 22.50316
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:20:48.185] [mlr3] Finished benchmark
INFO  [20:20:49.537] [bbotk] Result of batch 68:
INFO  [20:20:49.606] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:20:49.606] [bbotk]              -1.090939                         0.6130882
INFO  [20:20:49.606] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:20:49.606] [bbotk]                         0.7274052           -1.538675              -6.719889
INFO  [20:20:49.606] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:20:49.606] [bbotk]                          6                    3477                 0.8783299
INFO  [20:20:49.606] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:20:49.606] [bbotk]  0.006560227 <list[8]>              FALSE     0.02925038        0      0
INFO  [20:20:49.606] [bbotk]  runtime_learners                                uhash
INFO  [20:20:49.606] [bbotk]           165.503 c8f4532a-d06f-4841-8658-8a045c2b0d3a
INFO  [20:20:55.859] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 99 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:21:19.895] [bbotk] Evaluating 1 configuration(s)
INFO  [20:21:20.003] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:21:20.353] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -133.3062
[1] 53.90613
[1] -115.7433
[1] 16.79016
[1] -18.35457
[1] 34.5155
[1] -85.4565
[1] 10.01882
[1] -10.31786
[1] 52.04545
INFO  [20:21:44.002] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -17.74709
[1] 18.07475
[1] -9.821557
[1] 21.5116
[1] -68.33355
[1] 9.920351
[1] 225.9553
[1] 4829.097
[1] -226.3171
[1] -3.277396
INFO  [20:22:10.059] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -33.40999
[1] -3.126079
[1] -37.29117
[1] 4.123509
[1] -9.990971
[1] 22.54799
[1] -16.35558
[1] 10.7462
[1] -101.413
[1] 17.13557
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:22:31.899] [mlr3] Finished benchmark
INFO  [20:22:32.021] [bbotk] Result of batch 69:
INFO  [20:22:32.028] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:22:32.028] [bbotk]              -6.538603                         0.8986428
INFO  [20:22:32.028] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:22:32.028] [bbotk]                         0.1952752          -0.1517153              -3.317388
INFO  [20:22:32.028] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:22:32.028] [bbotk]                          1                    3080                 0.2331811
INFO  [20:22:32.028] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:22:32.028] [bbotk]  0.006401615 <list[8]>              FALSE     0.03350439        0      0
INFO  [20:22:32.028] [bbotk]  runtime_learners                                uhash
INFO  [20:22:32.028] [bbotk]            71.396 5963ea27-93a9-4f2c-8c65-f858cfdd3cbf
INFO  [20:22:33.711] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 100 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:22:33.826] [bbotk] Finished optimizing after 100 evaluation(s)
INFO  [20:22:33.841] [bbotk] Result:
INFO  [20:22:33.847] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:22:33.847] [bbotk]                  <num>                             <num>
INFO  [20:22:33.847] [bbotk]              -6.303148                         0.4198532
INFO  [20:22:33.847] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:22:33.847] [bbotk]                             <num>               <num>                  <num>
INFO  [20:22:33.847] [bbotk]                         0.9114388           -1.788453              -1.480721
INFO  [20:22:33.847] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:22:33.847] [bbotk]                      <int>                   <int>                     <num>
INFO  [20:22:33.847] [bbotk]                         14                    1781                 0.3190572
INFO  [20:22:33.847] [bbotk]  learner_param_vals  x_domain classif.bbrier
INFO  [20:22:33.847] [bbotk]              <list>    <list>          <num>
INFO  [20:22:33.847] [bbotk]          <list[10]> <list[8]>     0.02133715
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] -70.34352
[1] 119.5006
[1] -61.66884
[1] 19.94479
[1] -41.61125
[1] 14.49772
[1] -100.3658
[1] 2.266262
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] -2256.951
[1] -103.1071

### [bt]: Job terminated successfully [batchtools job.id=1420]
### [bt]: Calculation finished!
