### [bt]: This is batchtools v0.9.17
### [bt]: Starting calculation of 1 jobs
### [bt]: Setting working directory to '/content/drive/MyDrive/GitHub/Mater_Thesis_Calibration'
ece.R :
Friedmann_tasks.R :
Functions.R :
ici.R :
mse_feature_effects.R :
PipeOpCalibration_TuningExperiment.R :
PipeOpCalibration.R :
PipeOpCalibrationUnion.R :
### [bt]: Memory measurement disabled
### [bt]: Starting job [batchtools job.id=1414]
### [bt]: Generating problem instance for problem '341ee781c7d79b8f' ...
### [bt]: Applying algorithm 'run_learner' on problem '341ee781c7d79b8f' for job 1414 (seed = 1537) ...
INFO  [16:05:54.396] [mlr3] Applying learner 'xgboost TwP beta' on task 'wdbc' (iter 4/10)
INFO  [16:05:56.243] [bbotk] Starting to optimize 8 parameter(s) with '<OptimizerMbo>' and '<TerminatorEvals> [n_evals=100, k=0]'
INFO  [16:06:54.942] [bbotk] Evaluating 32 configuration(s)
INFO  [16:06:55.553] [mlr3] Running benchmark with 96 resampling iterations
INFO  [16:06:56.059] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -138.0002
[1] 179.1893
[1] -261.7667
[1] 43.2181
[1] -124.6916
[1] 134.0064
[1] -164.6456
[1] -3.624213
[1] -145.6229
[1] 121.1337
INFO  [16:07:59.929] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -97.16053
[1] 104.7116
[1] -245.3037
[1] 192.7176
[1] -80.35877
[1] 51.00762
[1] -60.89685
[1] 150.529
[1] -393.5922
[1] -5.578905
INFO  [16:08:32.009] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -31.91068
[1] 160.1382
[1] -95.66431
[1] 115.6462
[1] -155.294
[1] -4.164796
[1] -98.54494
[1] 120.116
[1] -114.7383
[1] 74.5899
INFO  [16:09:19.670] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:09:48.938] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:10:29.807] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:11:01.826] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -92.67764
[1] 27.15943
[1] -240.0895
[1] -4.216465
[1] -2085.181
[1] -59.20567
[1] -66.23177
[1] 61.33455
[1] -65.86238
[1] 157.8948
INFO  [16:12:00.404] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -75.76478
[1] 34.62624
[1] -22.23898
[1] 395.0691
[1] -201.7705
[1] 106.8788
[1] -185.4528
[1] 16.97566
[1] -78.20537
[1] 153.1465
INFO  [16:13:31.191] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -112.917
[1] 90.73231
[1] -28.71174
[1] 109.4379
[1] -80.14295
[1] 54.887
[1] -77.37387
[1] 67.28726
[1] -107.8453
[1] 65.80541
INFO  [16:15:11.364] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -30.20229
[1] 18.71532
[1] -60.88318
[1] 82.86816
[1] -280.2399
[1] -2.318071
[1] -1792.096
[1] -71.69558
[1] -33.00611
[1] 89.96222
INFO  [16:15:57.045] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -32.14401
[1] 72.67497
[1] -208.8407
[1] -3.631165
[1] -95.83078
[1] 5.958606
[1] -35.36283
[1] 80.06155
[1] -14.88181
[1] 35.98508
INFO  [16:17:09.143] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1443.943
[1] -49.88417
[1] -28.29353
[1] 16.69302
[1] -9383.302
[1] -250.8658
[1] -51.82509
[1] 47.58605
[1] -11.66691
[1] 114.1158
INFO  [16:18:18.794] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 20.03274
[1] 921.5715
[1] 10.15117
[1] 414.6233
[1] -311.6608
[1] -5.856091
[1] -474.5412
[1] -7.194714
[1] -447.2323
[1] 23.99873
INFO  [16:18:55.124] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 5.731222
[1] 250.4209
[1] -182.0028
[1] 250.5253
[1] -317.2555
[1] 130.6617
[1] -454.4076
[1] -6.600191
[1] 8.17836
[1] 307.0933
INFO  [16:19:46.201] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -167.9476
[1] 341.0935
[1] -460.6915
[1] 4.619811
[1] -154.6442
[1] 116.6373
[1] -508.5096
[1] 313.9092
[1] -6.994825
[1] 232.7227
INFO  [16:20:22.015] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -249.5417
[1] -4.006691
[1] -68.27042
[1] 61.76014
[1] -2055.31
[1] -79.17
[1] -136.2654
[1] -3.201375
[1] -121.5367
[1] 85.83061
INFO  [16:21:55.960] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -137.2049
[1] 4.372821
[1] -49.91666
[1] 53.75442
[1] -238.9402
[1] 47.10066
[1] -127.5005
[1] 27.15535
[1] -3972.406
[1] -97.23406
INFO  [16:24:19.072] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -50.92899
[1] 68.43622
[1] -67.68746
[1] 55.2035
[1] 129.5319
[1] 3552.325
[1] -386.5623
[1] 0.1861121
[1] -47.96152
[1] 58.21227
INFO  [16:25:28.168] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:25:54.605] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:26:49.407] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:27:52.085] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -31338.49
[1] -575.2415
[1] 777.9073
[1] 42011.42
[1] -26543.28
[1] -488.2188
[1] 1129.518
[1] 60890.37
[1] -36134.83
[1] -664.1873
INFO  [16:28:15.095] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -65558.88
[1] -1203.919
[1] 1480.145
[1] 79604.08
[1] -65382.82
[1] -1199.929
[1] -28179.08
[1] -517.7538
[1] -29014.94
[1] -532.9262
INFO  [16:28:34.137] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 622.6985
[1] 33552.96
[1] 605.7518
[1] 32611.72
[1] -28683.91
[1] -526.9099
[1] -26486.13
[1] -487.1371
[1] -51504.67
[1] -946.2328
INFO  [16:28:59.994] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -58922.84
[1] -1086.137
[1] 6158.329
[1] 332866
[1] -61506.49
[1] -1133.768
[1] 2779.024
[1] 150173
[1] -107531.9
[1] -1984.329
INFO  [16:29:40.438] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 1318.717
[1] 71236.57
[1] -79187.46
[1] -1459.936
[1] 1792.034
[1] 96888.92
[1] -146994.3
[1] -2709.704
[1] -80793.67
[1] -1487.938
INFO  [16:30:25.465] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -59153.7
[1] -1090.46
[1] 45694.56
[1] 2466172
[1] 1593.704
[1] 86106.86
[1] 7071.594
[1] 382623.1
[1] 1604.217
[1] 86745.07
INFO  [16:31:00.219] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -8057.28
[1] -183.5441
[1] -1667.548
[1] -16.2437
[1] -176.6406
[1] -3.854883
[1] -14.1633
[1] 59.44338
[1] -112.7728
[1] 8.006501
INFO  [16:32:12.125] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -918.3817
[1] -3.497179
[1] -125.1166
[1] -3.956884
[1] -56.02199
[1] 39.14083
[1] -71.52388
[1] 13.41736
[1] -53.94859
[1] 28.12415
INFO  [16:32:58.538] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -34.0937
[1] 18.24134
[1] -42.85258
[1] 74.62024
[1] -46.26968
[1] 105.4262
[1] -1498.485
[1] -29.87145
[1] -27.27328
[1] 35.84354
INFO  [16:33:47.219] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:35:00.815] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:36:18.097] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:37:34.392] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -39.85173
[1] 302.4569
[1] 431.6832
[1] 6049.221
[1] -48.64951
[1] 17.38248
[1] -85.18122
[1] 6.852591
[1] -58.34351
[1] 33.64731
INFO  [16:38:26.841] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -48.47676
[1] 4.270328
[1] -2380.114
[1] -37.22427
[1] -24.70808
[1] 50.30459
[1] -45.27967
[1] 82.1547
[1] -312.2027
[1] 9.746264
INFO  [16:39:34.216] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -45.5496
[1] 35.80296
[1] -12.83245
[1] 65.9146
[1] -57.70409
[1] 41.59719
[1] -134.0558
[1] 20.80111
[1] 6.424028
[1] 290.8892
INFO  [16:40:43.593] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:41:24.899] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:42:00.978] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:42:42.658] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 81.05095
[1] 2894.872
[1] -3188.907
[1] -116.2191
[1] -189.078
[1] -4.01812
[1] -134.3489
[1] 204.1995
[1] -46.9796
[1] 23.16664
INFO  [16:44:12.223] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -187.3664
[1] -3.660728
[1] -72.19575
[1] 58.97008
[1] -112.9342
[1] 5.038725
[1] -22.24248
[1] 110.302
[1] -348.4047
[1] -4.253223
INFO  [16:46:41.771] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -59.59754
[1] 20.69535
[1] -22.5606
[1] 63.83724
[1] -65.05174
[1] 49.5215
[1] -41.2541
[1] 143.9073
[1] -55.72321
[1] 51.82302
INFO  [16:48:04.672] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -4533.79
[1] -140.3654
[1] -158.0898
[1] -4.004386
[1] -1464.4
[1] -39.0007
[1] 83.04471
[1] 2094.382
[1] -52.98906
[1] 35.87545
INFO  [16:48:27.182] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 97.81588
[1] 2522.807
[1] -101.9931
[1] 15.92094
[1] -82.73944
[1] 41.89405
[1] -8987.09
[1] -257.0844
[1] -221.6589
[1] -4.144552
INFO  [16:48:53.699] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -90.58489
[1] 45.73391
[1] -90.46634
[1] 22.22378
[1] -30.11811
[1] 69.46015
[1] 119.1203
[1] 4668.26
[1] -59.4506
[1] 66.3775
INFO  [16:49:21.935] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -2423.242
[1] -44.71913
[1] -4355.446
[1] -79.08809
[1] -3733.313
[1] -65.5441
[1] 62.04146
[1] 3280.984
[1] 40.07429
[1] 2130.123
INFO  [16:50:45.238] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 84.08099
[1] 4327.484
[1] -3149.661
[1] -58.14376
[1] -1770.597
[1] -31.99494
[1] 67.52445
[1] 3426.483
[1] 78.63145
[1] 4258.202
INFO  [16:52:28.950] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -3476.639
[1] -63.30791
[1] 41.93151
[1] 2243.014
[1] -2904.146
[1] -53.67734
[1] 57.22994
[1] 2935.949
[1] 46.086
[1] 2390.307
INFO  [16:53:50.695] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -53.99827
[1] 12.91067
[1] -2173.703
[1] -94.74685
[1] -50.40767
[1] 17.98919
[1] -82.53142
[1] -3.377804
[1] 17.4684
[1] 805.6025
INFO  [16:54:39.706] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -13.70463
[1] 70.59103
[1] -107.7836
[1] 28.58162
[1] -146.5893
[1] -3.124827
[1] -165.7119
[1] 22.42581
[1] 55.8372
[1] 1787.568
INFO  [16:55:15.325] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -58.86955
[1] 31.88773
[1] -22.61331
[1] 125.7663
[1] 206.9019
[1] 3592.752
[1] -92.01714
[1] 16.24578
[1] -1319.58
[1] -60.40417
INFO  [16:56:03.098] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -6.562855e+16
[1] 1.331551e+16
[1] -42.52814
[1] 140.6032
[1] -133.4165
[1] 10.371
[1] -186.0856
[1] 217.5707
[1] -183.4399
[1] 38.46575
INFO  [16:56:51.828] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -65.79307
[1] 89.90834
[1] -321.7767
[1] 87.77144
[1] -160.8714
[1] 64.1198
[1] -98.7183
[1] 134.3537
[1] -94.82133
[1] 27.94222
INFO  [16:57:53.947] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -140.8967
[1] 22.8326
[1] -18.45078
[1] 169.9094
[1] -114.6018
[1] 62.49717
[1] -69.53206
[1] 115.5823
[1] -31.8813
[1] 88.19272
INFO  [16:59:06.177] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -59.64809
[1] 239.2081
[1] -183.645
[1] 148.178
[1] -157.1676
[1] 195.3899
[1] -113.5314
[1] 167.0018
[1] -223.0525
[1] -3.317714
INFO  [16:59:32.887] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -13.01398
[1] 187.3789
[1] -123.0076
[1] 199.6781
[1] -221.365
[1] -4.882781
[1] -95.73231
[1] 326.0384
[1] -540.1946
[1] -5.776788
INFO  [17:00:04.114] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 6.306254
[1] 219.5284
[1] -261.7598
[1] -5.337188
[1] -34.10338
[1] 126.8742
[1] -959.2553
[1] -21.65586
[1] -16751.19
[1] -253.079
INFO  [17:00:39.964] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1275.731
[1] -19.58331
[1] -1469.327
[1] -25.10345
[1] 57.07097
[1] 2900.604
[1] -1222.594
[1] -19.87823
[1] -5648.479
[1] -98.16553
INFO  [17:01:29.067] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1476.1
[1] -23.80565
[1] 24.83495
[1] 1101.042
[1] 26.70224
[1] 1306.179
[1] -1449.513
[1] -23.97211
[1] -1465.576
[1] -24.73332
INFO  [17:02:50.296] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1262.853
[1] 185.3211
[1] 20.8978
[1] 1006.522
[1] 31.21682
[1] 1491.077
[1] -1623.031
[1] -25.57898
[1] -1136.373
[1] -17.81085
INFO  [17:04:00.354] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -196.4822
[1] 48.54146
[1] -31.0348
[1] 116.9242
[1] -2881.062
[1] -54.19476
[1] -119.8707
[1] 1.110491
[1] -277.695
[1] 71.99855
INFO  [17:05:11.446] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -202.3908
[1] 0.4691957
[1] -11.43038
[1] 169.9833
[1] -44.27582
[1] 101.9268
[1] -55.4791
[1] 145.1588
[1] -128.8581
[1] 9.593661
INFO  [17:06:21.534] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -74.99252
[1] 131.0623
[1] -86.63891
[1] 73.58715
[1] -16.70737
[1] 134.5512
[1] -11.98885
[1] 208.896
[1] -17013.24
[1] -220.4633
INFO  [17:07:18.581] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -8536.557
[1] -193.0452
[1] -205.8879
[1] -3.253372
[1] -125.1442
[1] 6.317404
[1] -6032.777
[1] -154.7646
[1] -61.19775
[1] 73.90604
INFO  [17:08:01.778] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -4.379823
[1] 122.5801
[1] -4228.138
[1] -103.2894
[1] -114.9518
[1] 32.88323
[1] -74.73681
[1] 137.2505
[1] -328.3454
[1] -3.353959
INFO  [17:09:04.234] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2123.31
[1] -54.26601
[1] -84.41786
[1] 38.21437
[1] -31.78743
[1] 46.54364
[1] -62.83477
[1] 95.78758
[1] -68.43319
[1] 36.81687
INFO  [17:09:59.238] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -477.9205
[1] 10.83307
[1] -83.44207
[1] 51.16267
[1] -25699.3
[1] -743.2539
[1] -121.6016
[1] -4.307672
[1] -252.5173
[1] -4.274547
INFO  [17:10:50.624] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -65.17311
[1] 57.23338
[1] -116.8445
[1] -3.737477
[1] -27.62134
[1] 91.64178
[1] -112.3974
[1] 45.85235
[1] -446.3545
[1] -4.278565
INFO  [17:11:50.642] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -36.74084
[1] 100.2011
[1] -62.31792
[1] 66.00647
[1] -59.45987
[1] 41.05851
[1] -80.737
[1] 17.55967
[1] -3348.071
[1] -61.63102
INFO  [17:12:35.806] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:12:54.039] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:13:14.483] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:13:34.349] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:14:05.469] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:15:03.159] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:15:45.163] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -69.10729
[1] 13.43067
[1] -66.74082
[1] 7.349976
[1] -28.08398
[1] 85.92452
[1] -31.95019
[1] 57.33799
[1] -22.76959
[1] 71.49938
INFO  [17:16:26.874] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -63.32773
[1] 133.7798
[1] -42.34006
[1] 23.71279
[1] -31.80032
[1] 34.20789
[1] -483.7473
[1] -3.975405
[1] -154.8645
[1] -4.013299
INFO  [17:17:09.482] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1165.744
[1] -36.92769
[1] -23.72212
[1] 38.96979
[1] -15.75465
[1] 23.78801
[1] -13582.31
[1] -276.4824
[1] -2376.132
[1] -58.15421
INFO  [17:17:33.919] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -190.7565
[1] -4.28482
[1] -98.71227
[1] 188.3814
[1] -353.8464
[1] -5.89755
[1] -35.66654
[1] 204.9805
[1] 8.597951
[1] 588.2745
INFO  [17:18:36.353] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 36.42809
[1] 1472.524
[1] -583.4321
[1] 113.9705
[1] -449.5267
[1] -6.241618
[1] -73.5034
[1] 97.82176
[1] -282.0777
[1] -5.653835
INFO  [17:19:18.669] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -67.02174
[1] 112.0548
[1] -185.1939
[1] 151.5916
[1] -23.37136
[1] 208.5759
[1] -144.6957
[1] 172.3379
[1] -5.469791
[1] 339.4055
INFO  [17:20:10.239] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -248.8925
[1] -3.803887
[1] -161.159
[1] 189.3559
[1] -9.27038
[1] 287.226
[1] -104.07
[1] 155.0199
[1] -183.9148
[1] 64.14215
INFO  [17:20:25.474] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -99.06255
[1] 168.4165
[1] -165.0946
[1] 135.3462
[1] -239.9648
[1] -4.259251
[1] -521.1577
[1] 93.63183
[1] 7.152958
[1] 319.1272
INFO  [17:20:47.682] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 17.98445
[1] 1136.155
[1] -172.2886
[1] 85.16642
[1] 5.320544
[1] 179.2591
[1] -162.8503
[1] 67.45223
[1] -446.3539
[1] 103.149
INFO  [17:21:13.425] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1210.392
[1] -22.22878
[1] -2290.278
[1] -38.94838
[1] 31.71282
[1] 1717.784
[1] -3969.812
[1] -75.04049
[1] -1177.687
[1] -22.51512
INFO  [17:21:48.373] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -117.7317
[1] 1698.245
[1] 45.15503
[1] 2313.359
[1] 29.83607
[1] 1560.968
[1] -1140.516
[1] -20.86522
[1] -1041.95
[1] -19.85744
INFO  [17:22:29.708] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -988.3329
[1] 364.6598
[1] 34.93531
[1] 1862.403
[1] 24.53538
[1] 1311.76
[1] 27.16062
[1] 1400.393
[1] -122.735
[1] 1199.727
INFO  [17:23:00.395] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -98.12398
[1] 60.37331
[1] -82.3012
[1] 22.08534
[1] -147.4932
[1] -3.834328
[1] -221.2734
[1] -3.68475
[1] -97.15733
[1] 43.37871
INFO  [17:23:43.539] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -98.30642
[1] -3.658606
[1] -3676.696
[1] -54.29152
[1] -47.8606
[1] 139.5371
[1] -49.87679
[1] 28.3145
[1] -530.437
[1] -3.833674
INFO  [17:24:43.751] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -53.8218
[1] 91.94282
[1] 112.2018
[1] 2567.827
[1] -109.6722
[1] 22.24466
[1] -41.52549
[1] 30.41264
[1] -26684.53
[1] -814.6011
INFO  [17:25:21.391] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -47.13786
[1] 29.01941
[1] -2339.838
[1] -37.75104
[1] -71.9546
[1] 32.62257
[1] -183.2498
[1] -3.10641
[1] 41.52508
[1] 1421.832
INFO  [17:26:07.406] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -163.7495
[1] -4.080263
[1] -38.81281
[1] 107.8565
[1] -43.99862
[1] 51.80813
[1] -9.621619
[1] 107.3857
[1] -143.933
[1] -2.364256
INFO  [17:26:47.302] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -52.42311
[1] 16.16217
[1] -1355.076
[1] -31.71049
[1] -14.42064
[1] 144.5514
[1] -13851.42
[1] -265.9779
[1] -159.9312
[1] 23.58427
INFO  [17:27:26.939] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:28:02.641] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:28:34.702] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:29:10.202] [mlr3] Finished benchmark
INFO  [17:29:11.286] [bbotk] Result of batch 1:
INFO  [17:29:11.332] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:29:11.332] [bbotk]            -2.08113160                         0.7241681
INFO  [17:29:11.332] [bbotk]             4.82662367                         0.2741681
INFO  [17:29:11.332] [bbotk]             1.37274604                         0.9491681
INFO  [17:29:11.332] [bbotk]            -5.53500945                         0.4991681
INFO  [17:29:11.332] [bbotk]             3.09968486                         0.3866681
INFO  [17:29:11.332] [bbotk]            -3.80807063                         0.8366681
INFO  [17:29:11.332] [bbotk]             6.55356249                         0.6116681
INFO  [17:29:11.332] [bbotk]            -0.35419278                         0.1616681
INFO  [17:29:11.332] [bbotk]             0.50927663                         0.1054181
INFO  [17:29:11.332] [bbotk]            -6.39847881                         0.5554181
INFO  [17:29:11.332] [bbotk]             3.96315427                         0.7804181
INFO  [17:29:11.332] [bbotk]            -2.94460101                         0.3304181
INFO  [17:29:11.332] [bbotk]             5.69009308                         0.4429181
INFO  [17:29:11.332] [bbotk]            -1.21766219                         0.8929181
INFO  [17:29:11.332] [bbotk]            -4.67154004                         0.2179181
INFO  [17:29:11.332] [bbotk]             2.23621545                         0.6679181
INFO  [17:29:11.332] [bbotk]             0.07754192                         0.5835431
INFO  [17:29:11.332] [bbotk]            -6.83021353                         0.1335431
INFO  [17:29:11.332] [bbotk]            -3.37633572                         0.8085431
INFO  [17:29:11.332] [bbotk]             3.53141956                         0.3585431
INFO  [17:29:11.332] [bbotk]             1.80448074                         0.2460431
INFO  [17:29:11.332] [bbotk]            -5.10327474                         0.6960431
INFO  [17:29:11.332] [bbotk]            -1.64939690                         0.4710431
INFO  [17:29:11.332] [bbotk]             5.25835838                         0.9210431
INFO  [17:29:11.332] [bbotk]             6.12182779                         0.1897931
INFO  [17:29:11.332] [bbotk]            -0.78592749                         0.6397931
INFO  [17:29:11.332] [bbotk]            -4.23980533                         0.4147931
INFO  [17:29:11.332] [bbotk]             2.66795015                         0.8647931
INFO  [17:29:11.332] [bbotk]            -5.96674415                         0.9772931
INFO  [17:29:11.332] [bbotk]             0.94101133                         0.5272931
INFO  [17:29:11.332] [bbotk]            -2.51286631                         0.3022931
INFO  [17:29:11.332] [bbotk]             4.39488897                         0.7522931
INFO  [17:29:11.332] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:29:11.332] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:29:11.332] [bbotk]                         0.4502936          -7.4027827             1.64770385
INFO  [17:29:11.332] [bbotk]                         0.9002936          -2.7976127            -5.26005102
INFO  [17:29:11.332] [bbotk]                         0.2252936          -5.1001975            -1.80617338
INFO  [17:29:11.332] [bbotk]                         0.6752936          -0.4950276             5.10158149
INFO  [17:29:11.332] [bbotk]                         0.3377936          -6.2514901            -0.07923456
INFO  [17:29:11.332] [bbotk]                         0.7877936          -1.6463201             6.82852031
INFO  [17:29:11.332] [bbotk]                         0.5627936          -3.9489052            -3.53311220
INFO  [17:29:11.332] [bbotk]                         0.1127936          -8.5540752             3.37464267
INFO  [17:29:11.332] [bbotk]                         0.7315436          -7.9784290             5.96505090
INFO  [17:29:11.332] [bbotk]                         0.2815436          -3.3732590            -0.94270397
INFO  [17:29:11.332] [bbotk]                         0.5065436          -1.0706739             2.51117326
INFO  [17:29:11.332] [bbotk]                         0.9565436          -5.6758438            -4.39658161
INFO  [17:29:11.332] [bbotk]                         0.1690436          -2.2219664             0.78423444
INFO  [17:29:11.332] [bbotk]                         0.6190436          -6.8271363            -6.12352043
INFO  [17:29:11.332] [bbotk]                         0.3940436          -4.5245515            -2.66964279
INFO  [17:29:11.332] [bbotk]                         0.8440436          -9.1297215             4.23811208
INFO  [17:29:11.332] [bbotk]                         0.4221686          -1.3584970            -5.69178572
INFO  [17:29:11.332] [bbotk]                         0.8721686          -5.9636669             1.21596914
INFO  [17:29:11.332] [bbotk]                         0.1971686          -3.6610821             4.66984678
INFO  [17:29:11.332] [bbotk]                         0.6471686          -8.2662521            -2.23790809
INFO  [17:29:11.332] [bbotk]                         0.3096686          -0.2072045            -3.96484690
INFO  [17:29:11.332] [bbotk]                         0.7596686          -4.8123744             2.94290796
INFO  [17:29:11.332] [bbotk]                         0.5346686          -2.5097896             6.39678560
INFO  [17:29:11.332] [bbotk]                         0.9846686          -7.1149596            -0.51096927
INFO  [17:29:11.332] [bbotk]                         0.4784186          -5.3880206             3.80637737
INFO  [17:29:11.332] [bbotk]                         0.9284186          -0.7828507            -3.10137749
INFO  [17:29:11.332] [bbotk]                         0.2534186          -7.6906059            -6.55525516
INFO  [17:29:11.332] [bbotk]                         0.7034186          -3.0854358             0.35249973
INFO  [17:29:11.332] [bbotk]                         0.3659186          -8.8418984            -4.82831631
INFO  [17:29:11.332] [bbotk]                         0.8159186          -4.2367284             2.07943855
INFO  [17:29:11.332] [bbotk]                         0.5909186          -1.9341433            -1.37443868
INFO  [17:29:11.332] [bbotk]                         0.1409186          -6.5393132             5.53331619
INFO  [17:29:11.332] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:29:11.332] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:29:11.332] [bbotk]                         14                    3376                 0.6382617
INFO  [17:29:11.332] [bbotk]                          4                     876                 0.1882617
INFO  [17:29:11.332] [bbotk]                          9                    4626                 0.4132617
INFO  [17:29:11.332] [bbotk]                         19                    2126                 0.8632617
INFO  [17:29:11.332] [bbotk]                          1                    1501                 0.9757617
INFO  [17:29:11.332] [bbotk]                         11                    4001                 0.5257617
INFO  [17:29:11.332] [bbotk]                          6                    2751                 0.7507617
INFO  [17:29:11.332] [bbotk]                         16                     251                 0.3007617
INFO  [17:29:11.332] [bbotk]                          7                    1188                 0.1320117
INFO  [17:29:11.332] [bbotk]                         17                    3688                 0.5820117
INFO  [17:29:11.332] [bbotk]                          2                    4938                 0.3570117
INFO  [17:29:11.332] [bbotk]                         12                    2438                 0.8070117
INFO  [17:29:11.332] [bbotk]                         10                    1813                 0.9195117
INFO  [17:29:11.332] [bbotk]                         20                    4313                 0.4695117
INFO  [17:29:11.332] [bbotk]                         15                     563                 0.2445117
INFO  [17:29:11.332] [bbotk]                          5                    3063                 0.6945117
INFO  [17:29:11.332] [bbotk]                         12                    1969                 0.5538867
INFO  [17:29:11.332] [bbotk]                          2                    4469                 0.1038867
INFO  [17:29:11.332] [bbotk]                          7                     719                 0.3288867
INFO  [17:29:11.332] [bbotk]                         17                    3219                 0.7788867
INFO  [17:29:11.332] [bbotk]                         19                    3844                 0.2163867
INFO  [17:29:11.332] [bbotk]                          9                    1344                 0.6663867
INFO  [17:29:11.332] [bbotk]                          4                    2594                 0.8913867
INFO  [17:29:11.332] [bbotk]                         14                      94                 0.4413867
INFO  [17:29:11.332] [bbotk]                         11                    4157                 0.2726367
INFO  [17:29:11.332] [bbotk]                          1                    1657                 0.7226367
INFO  [17:29:11.332] [bbotk]                          6                    2907                 0.9476367
INFO  [17:29:11.332] [bbotk]                         16                     407                 0.4976367
INFO  [17:29:11.332] [bbotk]                          3                    1032                 0.3851367
INFO  [17:29:11.332] [bbotk]                         13                    3532                 0.8351367
INFO  [17:29:11.332] [bbotk]                          8                    4782                 0.1601367
INFO  [17:29:11.332] [bbotk]                         18                    2282                 0.6101367
INFO  [17:29:11.332] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:29:11.332] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:29:11.332] [bbotk]      0.03833116        0      0          142.605
INFO  [17:29:11.332] [bbotk]      0.27410424        0      0          101.292
INFO  [17:29:11.332] [bbotk]      0.03387934        0      0          248.839
INFO  [17:29:11.332] [bbotk]      0.02520112        0      0          186.837
INFO  [17:29:11.332] [bbotk]      0.05216953        0      0          121.994
INFO  [17:29:11.332] [bbotk]      0.03136212        0      0          305.093
INFO  [17:29:11.332] [bbotk]      0.27410424        0      0          143.166
INFO  [17:29:11.332] [bbotk]      0.26519982        0      0           66.713
INFO  [17:29:11.332] [bbotk]      0.27051996        0      0          119.804
INFO  [17:29:11.332] [bbotk]      0.02348330        0      0          165.049
INFO  [17:29:11.332] [bbotk]      0.27410424        0      0          227.031
INFO  [17:29:11.332] [bbotk]      0.02876517        0      0          188.951
INFO  [17:29:11.332] [bbotk]      0.27410424        0      0          118.549
INFO  [17:29:11.332] [bbotk]      0.03019093        0      0          321.126
INFO  [17:29:11.332] [bbotk]      0.02774521        0      0           76.570
INFO  [17:29:11.332] [bbotk]      0.20193345        0      0          268.193
INFO  [17:29:11.332] [bbotk]      0.02378842        0      0          132.041
INFO  [17:29:11.332] [bbotk]      0.03718354        0      0          181.880
INFO  [17:29:11.332] [bbotk]      0.04124146        0      0           92.823
INFO  [17:29:11.332] [bbotk]      0.13214309        0      0          199.303
INFO  [17:29:11.332] [bbotk]      0.04354532        0      0          196.382
INFO  [17:29:11.332] [bbotk]      0.03340875        0      0          159.394
INFO  [17:29:11.332] [bbotk]      0.03320945        0      0          155.604
INFO  [17:29:11.332] [bbotk]      0.27410424        0      0           57.919
INFO  [17:29:11.332] [bbotk]      0.27410424        0      0          130.348
INFO  [17:29:11.332] [bbotk]      0.02436115        0      0          108.263
INFO  [17:29:11.332] [bbotk]      0.03096601        0      0          156.018
INFO  [17:29:11.332] [bbotk]      0.04184479        0      0           62.827
INFO  [17:29:11.332] [bbotk]      0.14214340        0      0          106.563
INFO  [17:29:11.332] [bbotk]      0.03230164        0      0          140.573
INFO  [17:29:11.332] [bbotk]      0.02302234        0      0          125.059
INFO  [17:29:11.332] [bbotk]      0.27410424        0      0           94.676
INFO  [17:29:11.332] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:29:11.332] [bbotk]                                 uhash
INFO  [17:29:11.332] [bbotk]  59447193-5c4b-4910-b50c-74d509ee716b
INFO  [17:29:11.332] [bbotk]  468a999d-dd90-462a-8de1-e6c77db60fea
INFO  [17:29:11.332] [bbotk]  44df577e-e5c4-4039-ba57-4838405ae876
INFO  [17:29:11.332] [bbotk]  1bbc6140-faab-4473-9f06-1b63f131980a
INFO  [17:29:11.332] [bbotk]  042af2b5-c671-492c-ac13-efc20f987208
INFO  [17:29:11.332] [bbotk]  8170199c-aec2-4f79-ac1e-e2ec7cc35297
INFO  [17:29:11.332] [bbotk]  c7259156-fe26-4c9f-8aa1-c51e7513c095
INFO  [17:29:11.332] [bbotk]  da9b86e5-ceae-4986-b59c-a940cdf72087
INFO  [17:29:11.332] [bbotk]  1d9caec3-e91a-4937-ba22-41757dcadc81
INFO  [17:29:11.332] [bbotk]  03c3af0c-7b37-4e13-86ba-681f11e69f0e
INFO  [17:29:11.332] [bbotk]  03c5ba0a-ab4b-4619-b76e-2c560aa69979
INFO  [17:29:11.332] [bbotk]  8ae25556-cabd-4c14-b44a-778ffa15627e
INFO  [17:29:11.332] [bbotk]  b360f716-ee00-4ba6-8543-a62ebbc4fe0c
INFO  [17:29:11.332] [bbotk]  442ce801-412f-4b14-b806-a5b91fcd0169
INFO  [17:29:11.332] [bbotk]  32132b81-7f56-4836-9c0c-cf581f7cbd46
INFO  [17:29:11.332] [bbotk]  4203911f-8005-4ecf-aa56-878596e7d0fe
INFO  [17:29:11.332] [bbotk]  b74e1011-998d-4073-8039-2c0046eca2a5
INFO  [17:29:11.332] [bbotk]  4820993e-2321-4a13-bdb0-4c7c3d90dbc3
INFO  [17:29:11.332] [bbotk]  a91a2ec6-6ab9-4b21-9caf-58782a9cd5d6
INFO  [17:29:11.332] [bbotk]  cb7a2dc2-7030-44a5-8b7c-f86806c46bea
INFO  [17:29:11.332] [bbotk]  f12fbad4-1a90-4f5c-a604-0c9a3d831fa3
INFO  [17:29:11.332] [bbotk]  f809848f-f111-4fd1-a16e-317125c554f7
INFO  [17:29:11.332] [bbotk]  244fce2c-647c-47f5-8a22-c4419bb6d8b2
INFO  [17:29:11.332] [bbotk]  c3fc6774-7904-4225-b989-f1f497fef740
INFO  [17:29:11.332] [bbotk]  2ae67e61-f30b-4a1b-82f8-5e75b4c88738
INFO  [17:29:11.332] [bbotk]  dad7e0b4-a237-40f9-9e48-d145a95e24f7
INFO  [17:29:11.332] [bbotk]  7474234f-a490-4795-b70e-308b276c9b31
INFO  [17:29:11.332] [bbotk]  9ecb2254-60db-4b13-bf75-a2044003eba7
INFO  [17:29:11.332] [bbotk]  29c6343b-f1a1-49e4-84e6-a740e6eba724
INFO  [17:29:11.332] [bbotk]  ae5c6d73-3fb8-414f-a92c-8aa3f6aa06a6
INFO  [17:29:11.332] [bbotk]  b8587931-72d2-4882-89a3-f941f8387e15
INFO  [17:29:11.332] [bbotk]  8eac286e-8dc5-49e7-8049-d06fef68bce8
INFO  [17:29:11.332] [bbotk]                                 uhash
INFO  [17:29:19.216] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 32 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:29:26.084] [bbotk] Evaluating 1 configuration(s)
INFO  [17:29:26.279] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:29:26.346] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -132.7415
[1] 57.83212
[1] -348.219
[1] -4.235016
[1] -98.03815
[1] -3.001183
[1] -45.94261
[1] 138.1148
[1] -123.0398
[1] 80.30756
INFO  [17:30:11.354] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -159.9559
[1] 141.7158
[1] -104.562
[1] 137.8436
[1] -68.06307
[1] 15.61271
[1] -145.1368
[1] 6.572556
[1] -39717.71
[1] -727.9687
INFO  [17:31:09.561] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -112.1352
[1] -4.389202
[1] -72.04664
[1] 64.05283
[1] -107.9619
[1] 19.09908
[1] -1348.127
[1] -5.709506
[1] -16.02452
[1] 114.1231
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:31:59.554] [mlr3] Finished benchmark
INFO  [17:31:59.685] [bbotk] Result of batch 2:
INFO  [17:31:59.909] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:31:59.909] [bbotk]               1.511824                         0.9207193
INFO  [17:31:59.909] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:31:59.909] [bbotk]                          0.730883           -3.763124              -5.320827
INFO  [17:31:59.909] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:31:59.909] [bbotk]                         16                    2562                  0.919637
INFO  [17:31:59.909] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:31:59.909] [bbotk]  0.04992947 <list[8]>              FALSE     0.03687633        0      0
INFO  [17:31:59.909] [bbotk]  runtime_learners                                uhash
INFO  [17:31:59.909] [bbotk]           152.571 8514754e-0c0b-41f6-b4e1-fd1b386156b8
INFO  [17:32:02.103] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 33 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:32:06.552] [bbotk] Evaluating 1 configuration(s)
INFO  [17:32:06.601] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:32:06.933] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -41.26273
[1] 25.34233
[1] -138.6432
[1] -4.062829
[1] -15194.63
[1] -325.7063
[1] -148.5508
[1] 0.3545677
[1] -70.91399
[1] 88.48105
INFO  [17:32:57.449] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -119.9333
[1] 6.14075
[1] -33.18588
[1] 71.68234
[1] -35.00442
[1] 85.24772
[1] -81.10109
[1] 14.7551
[1] -76.72284
[1] 5.335587
INFO  [17:33:35.930] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -21.20872
[1] 27.32361
[1] -36.91247
[1] 28.35505
[1] 48.68997
[1] 1968.222
[1] -23.80855
[1] 144.4071
[1] 326.1115
[1] 5610.459
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:34:25.643] [mlr3] Finished benchmark
INFO  [17:34:25.738] [bbotk] Result of batch 3:
INFO  [17:34:25.800] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:34:25.800] [bbotk]                -2.5251                         0.8276518
INFO  [17:34:25.800] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:34:25.800] [bbotk]                         0.2759997            -4.18667              -4.475866
INFO  [17:34:25.800] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:34:25.800] [bbotk]                         16                    4983                 0.5852507
INFO  [17:34:25.800] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:34:25.800] [bbotk]  0.03218752 <list[8]>              FALSE      0.0224914        0      0
INFO  [17:34:25.800] [bbotk]  runtime_learners                                uhash
INFO  [17:34:25.800] [bbotk]           137.736 a0e2cba8-e4b4-4f92-b593-96b7bdfea7d3
INFO  [17:34:27.536] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 34 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:34:33.947] [bbotk] Evaluating 1 configuration(s)
INFO  [17:34:34.274] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:34:34.597] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -85.45493
[1] 14.10254
[1] -553.1241
[1] -32.61232
[1] -162.3249
[1] -3.656079
[1] -45.34952
[1] 30.50323
[1] -215.6093
[1] 30.67624
INFO  [17:35:14.038] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -133.048
[1] -0.1493793
[1] -36.97213
[1] 81.69354
[1] -16.1774
[1] 57.88032
[1] -48.45688
[1] 88.47552
[1] -493.9853
[1] -4.096512
INFO  [17:35:57.293] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -37.08932
[1] 69.32807
[1] -27.11685
[1] 55.17341
[1] 2.115481
[1] 249.7484
[1] -256.0138
[1] 35.42392
[1] -40.65783
[1] 1016.592
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:37:12.048] [mlr3] Finished benchmark
INFO  [17:37:12.148] [bbotk] Result of batch 4:
INFO  [17:37:12.175] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:37:12.175] [bbotk]             -0.7858221                         0.8757939
INFO  [17:37:12.175] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:37:12.175] [bbotk]                         0.8789919           -2.456357              -3.350038
INFO  [17:37:12.175] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:37:12.175] [bbotk]                         20                    4776                 0.8294313
INFO  [17:37:12.175] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:37:12.175] [bbotk]  0.02503007 <list[8]>              FALSE     0.02758676        0      0
INFO  [17:37:12.175] [bbotk]  runtime_learners                                uhash
INFO  [17:37:12.175] [bbotk]            156.58 df43ba61-68a1-440a-9676-168056057bfd
INFO  [17:37:13.471] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 35 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:37:19.810] [bbotk] Evaluating 1 configuration(s)
INFO  [17:37:19.908] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:37:19.960] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1.515905e+16
[1] 2.002082e+16
[1] -1581.891
[1] -67.79863
[1] -45.67851
[1] 87.50929
[1] -263.2707
[1] -3.918226
[1] -71.7644
[1] 1.539652
INFO  [17:38:11.003] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -44.28529
[1] 77.45936
[1] -326.1652
[1] -3.930439
[1] -106.7274
[1] -4.038726
[1] -36.23048
[1] 34.5154
[1] -226.9176
[1] 73.1789
INFO  [17:39:07.665] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 70.3479
[1] 2099.615
[1] -14.10961
[1] 49.96104
[1] 19.66263
[1] 473.3539
[1] -42.66365
[1] 22.77236
[1] -52.14549
[1] 48.01899
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:39:33.310] [mlr3] Finished benchmark
INFO  [17:39:33.464] [bbotk] Result of batch 5:
INFO  [17:39:33.500] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:39:33.500] [bbotk]               -4.71637                         0.1045165
INFO  [17:39:33.500] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:39:33.500] [bbotk]                         0.3643496           -3.880469               1.723994
INFO  [17:39:33.500] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:39:33.500] [bbotk]                         17                    4145                 0.8462409
INFO  [17:39:33.500] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:39:33.500] [bbotk]  0.02546862 <list[8]>              FALSE     0.02505395        0      0
INFO  [17:39:33.500] [bbotk]  runtime_learners                                uhash
INFO  [17:39:33.500] [bbotk]           132.687 4e82a7cd-1381-4272-9c47-438e4c325ef1
INFO  [17:39:35.061] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 36 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:39:42.087] [bbotk] Evaluating 1 configuration(s)
INFO  [17:39:42.587] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:39:42.632] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -86.52171
[1] 7.462119
[1] -158.8649
[1] -3.40318
[1] -60.40169
[1] 108.9999
[1] -8510.208
[1] -142.4494
[1] -69.17475
[1] 198.5861
INFO  [17:40:07.432] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -106.0029
[1] 120.8848
[1] -149.3612
[1] 4.222988
[1] -158.3044
[1] 52.40019
[1] -65.25159
[1] 21.69467
[1] -24.7309
[1] 76.38115
INFO  [17:40:41.830] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 14.33846
[1] 513.9084
[1] -174.6572
[1] 1.834124
[1] -45.21826
[1] 22.96054
[1] -56.57114
[1] 169.8023
[1] -18.91663
[1] 79.97055
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:41:35.150] [mlr3] Finished benchmark
INFO  [17:41:35.298] [bbotk] Result of batch 6:
INFO  [17:41:35.330] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:41:35.330] [bbotk]              0.8052343                         0.1530286
INFO  [17:41:35.330] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:41:35.330] [bbotk]                         0.1014629           -2.867044              -3.197395
INFO  [17:41:35.330] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:41:35.330] [bbotk]                          3                    4734                 0.9506459
INFO  [17:41:35.330] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:41:35.330] [bbotk]  0.02390943 <list[8]>              FALSE     0.02702889        0      0
INFO  [17:41:35.330] [bbotk]  runtime_learners                                uhash
INFO  [17:41:35.330] [bbotk]             112.1 67b9c174-cda6-42f3-9ab3-437d14f5b5a1
INFO  [17:41:35.996] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 37 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:41:42.573] [bbotk] Evaluating 1 configuration(s)
INFO  [17:41:43.043] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:41:43.711] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -132.2817
[1] 18.74673
[1] -72.56925
[1] 28.01496
[1] -102.7961
[1] -3.598994
[1] -12561.77
[1] -476.5833
[1] 38.80125
[1] 1433.317
INFO  [17:42:10.104] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -59.31766
[1] 36.3014
[1] -12.96978
[1] 148.0186
[1] -443.9483
[1] 31.16668
[1] -58.1316
[1] 9.609127
[1] -110.8149
[1] 1.890392
INFO  [17:43:20.108] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -6.220303e+15
[1] 3.123281e+16
[1] -1358.443
[1] 107.3669
[1] -70.08483
[1] 5.969175
[1] -44.80622
[1] 62.03762
[1] -16.41858
[1] 180.3733
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:44:13.940] [mlr3] Finished benchmark
INFO  [17:44:14.107] [bbotk] Result of batch 7:
INFO  [17:44:14.301] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:44:14.301] [bbotk]              -1.907843                         0.8615726
INFO  [17:44:14.301] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:44:14.301] [bbotk]                         0.5722456           -4.328312              -2.216309
INFO  [17:44:14.301] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:44:14.301] [bbotk]                          5                    4986                 0.3291522
INFO  [17:44:14.301] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:44:14.301] [bbotk]  0.02106184 <list[8]>              FALSE     0.02217416        0      0
INFO  [17:44:14.301] [bbotk]  runtime_learners                                uhash
INFO  [17:44:14.301] [bbotk]           148.839 bb073eee-94b1-4482-bee5-75077ccc15f0
INFO  [17:44:15.390] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 38 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:44:19.601] [bbotk] Evaluating 1 configuration(s)
INFO  [17:44:19.747] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:44:19.821] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 8.990043
[1] 671.1143
[1] -113.8776
[1] -2.913942
[1] 331.71
[1] 10724.75
[1] -97.20755
[1] -2.551205
[1] 79.44236
[1] 2181.27
INFO  [17:44:49.446] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -92.59926
[1] 0.9846963
[1] -157.0322
[1] -3.817353
[1] -12.56513
[1] 102.2801
[1] -83.00789
[1] -4.143924
[1] 30.41106
[1] 1013.086
INFO  [17:45:21.351] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -72.89967
[1] 75.67881
[1] -8196.694
[1] -176.2321
[1] -345.5185
[1] 3.25703
[1] -4333.038
[1] -200.2928
[1] -16.28972
[1] 55.67983
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:45:54.688] [mlr3] Finished benchmark
INFO  [17:45:54.777] [bbotk] Result of batch 8:
INFO  [17:45:54.856] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:45:54.856] [bbotk]               -4.03256                         0.5319985
INFO  [17:45:54.856] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:45:54.856] [bbotk]                         0.4657324            -3.04777              -5.604928
INFO  [17:45:54.856] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:45:54.856] [bbotk]                         11                    3075                 0.3844588
INFO  [17:45:54.856] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:45:54.856] [bbotk]  0.02084228 <list[8]>              FALSE     0.02205868        0      0
INFO  [17:45:54.856] [bbotk]  runtime_learners                                uhash
INFO  [17:45:54.856] [bbotk]            92.954 068a92c4-c153-457b-8dfd-1032bea86519
INFO  [17:45:56.641] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 39 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:46:03.077] [bbotk] Evaluating 1 configuration(s)
INFO  [17:46:03.164] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:46:03.366] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -161.3908
[1] 62.92066
[1] -175.9385
[1] 48.16332
[1] -227.5148
[1] 127.1331
[1] -275.6915
[1] -5.624397
[1] -131.0315
[1] 235.0582
INFO  [17:46:20.442] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -182.8885
[1] 300.6639
[1] -316.288
[1] 18.99783
[1] -126.4773
[1] 135.9998
[1] -261.7636
[1] -4.749682
[1] -366.433
[1] 99.51477
INFO  [17:46:35.287] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -169.4044
[1] 49.09662
[1] -105.6477
[1] 118.2268
[1] -359385
[1] -5484.237
[1] -210.6317
[1] 83.84666
[1] -87.63039
[1] 117.0024
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:46:49.079] [mlr3] Finished benchmark
INFO  [17:46:49.288] [bbotk] Result of batch 9:
INFO  [17:46:49.435] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:46:49.435] [bbotk]               2.276821                         0.1478621
INFO  [17:46:49.435] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:46:49.435] [bbotk]                         0.1625595           -3.170403              0.3920418
INFO  [17:46:49.435] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:46:49.435] [bbotk]                          7                     156                 0.6848517
INFO  [17:46:49.435] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:46:49.435] [bbotk]  0.01998618 <list[8]>              FALSE     0.03953762        0      0
INFO  [17:46:49.435] [bbotk]  runtime_learners                                uhash
INFO  [17:46:49.435] [bbotk]            45.055 2cec83ae-0499-468d-98c5-09c7edf96e4b
INFO  [17:46:50.218] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 40 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:46:56.307] [bbotk] Evaluating 1 configuration(s)
INFO  [17:46:56.664] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:46:57.032] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -79.02939
[1] 26.03909
[1] 42.20455
[1] 1091.771
[1] -101.8634
[1] -3.936085
[1] -33.64969
[1] 17.29939
[1] -77.23498
[1] 25.4317
INFO  [17:47:48.668] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -57.91653
[1] 79.77557
[1] -262.5636
[1] -4.009342
[1] -4.93915
[1] 104.5438
[1] -93.62336
[1] 22.05318
[1] -63.95424
[1] 7.465148
INFO  [17:48:40.483] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -37.22149
[1] 33.09929
[1] 67.1348
[1] 2272.597
[1] -24.387
[1] 64.4507
[1] 183.7526
[1] 3134.741
[1] -100.264
[1] 5.909462
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:49:19.863] [mlr3] Finished benchmark
INFO  [17:49:21.086] [bbotk] Result of batch 10:
INFO  [17:49:21.284] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:49:21.284] [bbotk]              -1.178226                         0.5539796
INFO  [17:49:21.284] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:49:21.284] [bbotk]                         0.6010972           -1.873781               0.536653
INFO  [17:49:21.284] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:49:21.284] [bbotk]                         13                    3121                 0.6596824
INFO  [17:49:21.284] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:49:21.284] [bbotk]  0.02385681 <list[8]>              FALSE     0.02461088        0      0
INFO  [17:49:21.284] [bbotk]  runtime_learners                                uhash
INFO  [17:49:21.284] [bbotk]           140.038 49e8be2a-de07-4e21-b92e-ee179daff134
WARN  [17:49:23.889] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:49:23.948] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 41 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:49:28.455] [bbotk] Evaluating 1 configuration(s)
INFO  [17:49:28.514] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:49:28.549] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -700.1111
[1] -18.67448
[1] -124.4972
[1] 20.67233
[1] -254.7639
[1] -3.944009
[1] -718.6003
[1] -30.19175
[1] -92.26316
[1] 16.96978
INFO  [17:49:58.499] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -134.2713
[1] -4.031914
[1] -58.45526
[1] 49.96664
[1] -9525.61
[1] -179.3601
[1] -60.97977
[1] 20.62364
[1] -171.8432
[1] 5.963496
INFO  [17:50:27.426] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -32936.42
[1] -1114.483
[1] -77.03788
[1] 18.42808
[1] -183.5944
[1] 37.55241
[1] -43.82805
[1] 61.27234
[1] -3762.25
[1] -47.28852
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:50:54.920] [mlr3] Finished benchmark
INFO  [17:50:55.030] [bbotk] Result of batch 11:
INFO  [17:50:55.072] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:50:55.072] [bbotk]               -5.56907                         0.2694361
INFO  [17:50:55.072] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:50:55.072] [bbotk]                         0.5407862           -2.184981               2.005383
INFO  [17:50:55.072] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:50:55.072] [bbotk]                          7                    2791                 0.3254866
INFO  [17:50:55.072] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:50:55.072] [bbotk]  0.0188857 <list[8]>              FALSE     0.02136881        0      0
INFO  [17:50:55.072] [bbotk]  runtime_learners                                uhash
INFO  [17:50:55.072] [bbotk]            84.896 f3ee3007-423a-4094-a132-82ab5c111af2
INFO  [17:50:56.320] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 42 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:51:03.350] [bbotk] Evaluating 1 configuration(s)
INFO  [17:51:03.764] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:51:04.121] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -41.85505
[1] 116.0143
[1] -103.1839
[1] -4.05438
[1] -5880.603
[1] -162.304
[1] 130.3343
[1] 3989.613
[1] -55.61189
[1] 18.85925
INFO  [17:51:30.014] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -46.80935
[1] 56.12719
[1] -582.023
[1] 1.973201
[1] -62.21818
[1] 129.4988
[1] -94.59004
[1] 64.99444
[1] -59.42192
[1] 16.74853
INFO  [17:52:18.101] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -51.15314
[1] 42.92171
[1] -186.9836
[1] -3.913401
[1] -147.9791
[1] 128.3935
[1] -73.57377
[1] 46.48598
[1] -337.7412
[1] 36.69098
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:53:21.373] [mlr3] Finished benchmark
INFO  [17:53:21.479] [bbotk] Result of batch 12:
INFO  [17:53:21.544] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:53:21.544] [bbotk]              0.5518667                         0.7769632
INFO  [17:53:21.544] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:53:21.544] [bbotk]                         0.6411853           -1.130083               4.929164
INFO  [17:53:21.544] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:53:21.544] [bbotk]                          7                    4672                 0.4951025
INFO  [17:53:21.544] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:53:21.544] [bbotk]  0.01766882 <list[8]>              FALSE     0.02713484        0      0
INFO  [17:53:21.544] [bbotk]  runtime_learners                                uhash
INFO  [17:53:21.544] [bbotk]           136.293 65bbeec8-c983-4371-8cc5-244fdbdf656f
INFO  [17:53:23.270] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 43 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:53:28.931] [bbotk] Evaluating 1 configuration(s)
INFO  [17:53:29.050] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:53:29.193] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -87.83275
[1] 10.05575
[1] 291.2837
[1] 8103.891
[1] -5.134605
[1] 989.4546
[1] -135.2836
[1] 176.4727
[1] -11937.54
[1] -398.7966
INFO  [17:54:19.658] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -17.86959
[1] 432.445
[1] -124.6853
[1] 13.77467
[1] -55.9391
[1] 55.78002
[1] -3936.774
[1] -90.68838
[1] -128.9482
[1] -3.914421
INFO  [17:55:11.924] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -101.563
[1] 27.39898
[1] 131.7108
[1] 3719.405
[1] -46.19963
[1] 35.08756
[1] -46.54705
[1] 51.38117
[1] -2541.365
[1] -50.54705
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:55:57.278] [mlr3] Finished benchmark
INFO  [17:55:57.451] [bbotk] Result of batch 13:
INFO  [17:55:57.542] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:55:57.542] [bbotk]              -3.234296                         0.5159409
INFO  [17:55:57.542] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:55:57.542] [bbotk]                         0.5022001           -6.782444              -6.227814
INFO  [17:55:57.542] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:55:57.542] [bbotk]                         16                    4881                 0.3324923
INFO  [17:55:57.542] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:55:57.542] [bbotk]  0.01523321 <list[8]>              FALSE     0.02696148        0      0
INFO  [17:55:57.542] [bbotk]  runtime_learners                                uhash
INFO  [17:55:57.542] [bbotk]           146.099 7a6a8899-7ce5-4177-b053-0faa04ca24ac
INFO  [17:55:58.371] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 44 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:56:05.786] [bbotk] Evaluating 1 configuration(s)
INFO  [17:56:06.091] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:56:06.327] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -38.14913
[1] 58.66341
[1] -146.9575
[1] -3.791123
[1] -217.1604
[1] -4.172928
[1] -25.95089
[1] 87.69454
[1] -147.8407
[1] 33.20323
INFO  [17:56:51.586] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -37.66008
[1] 69.1536
[1] -32.36035
[1] 65.92052
[1] -293.2142
[1] 14.08231
[1] -217.4082
[1] -3.148093
[1] -3115.381
[1] -81.27936
INFO  [17:57:19.330] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2500.103
[1] -96.08318
[1] -37.79196
[1] 69.3168
[1] -52.3489
[1] 24.32873
[1] -2662.807
[1] -56.37573
[1] -76.95745
[1] 24.436
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:57:59.490] [mlr3] Finished benchmark
INFO  [17:58:00.042] [bbotk] Result of batch 14:
INFO  [17:58:00.172] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:58:00.172] [bbotk]               -6.65215                         0.1019687
INFO  [17:58:00.172] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:58:00.172] [bbotk]                         0.9794077           -2.966181             -0.3414742
INFO  [17:58:00.172] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:58:00.172] [bbotk]                         19                    3719                 0.6328537
INFO  [17:58:00.172] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:58:00.172] [bbotk]  0.01453322 <list[8]>              FALSE     0.02242015        0      0
INFO  [17:58:00.172] [bbotk]  runtime_learners                                uhash
INFO  [17:58:00.172] [bbotk]           111.771 e4b11943-0796-48c3-bce0-786751812b32
INFO  [17:58:01.852] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 45 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:58:06.366] [bbotk] Evaluating 1 configuration(s)
INFO  [17:58:06.736] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:58:07.228] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -191.5977
[1] -3.995625
[1] -129.0302
[1] 34.21225
[1] 184.2163
[1] 6881.442
[1] -189.636
[1] 73.33445
[1] -76.27291
[1] 16.91243
INFO  [17:58:50.760] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 15.31208
[1] 674.1298
[1] -199.0285
[1] -3.672878
[1] -214.7854
[1] -0.9713969
[1] 45.66346
[1] 2079.138
[1] -86.12927
[1] 24.23657
INFO  [17:59:39.563] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -15494.8
[1] -400.6671
[1] -151.7548
[1] 197.4573
[1] -76.99848
[1] 38.22478
[1] -70.9007
[1] 33.59299
[1] -3.375463e+16
[1] 4.122665e+16
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:00:14.013] [mlr3] Finished benchmark
INFO  [18:00:14.122] [bbotk] Result of batch 15:
INFO  [18:00:14.174] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:00:14.174] [bbotk]              0.7503682                         0.6893077
INFO  [18:00:14.174] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:00:14.174] [bbotk]                         0.2965094           -3.018467              -1.706121
INFO  [18:00:14.174] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:00:14.174] [bbotk]                         16                    4912                 0.2175108
INFO  [18:00:14.174] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:00:14.174] [bbotk]  0.01377983 <list[8]>              FALSE     0.02794624        0      0
INFO  [18:00:14.174] [bbotk]  runtime_learners                                uhash
INFO  [18:00:14.174] [bbotk]           125.565 c07e061a-aeb2-442b-b5d7-e047e58a42c5
WARN  [18:00:14.882] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:00:14.918] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 46 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:00:18.136] [bbotk] Evaluating 1 configuration(s)
INFO  [18:00:18.199] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:00:18.277] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -263.9239
[1] -2.819465
[1] -76.62435
[1] 27.1679
[1] -81.56514
[1] 4.883025
[1] -55.53173
[1] 32.83957
[1] -54.21064
[1] 35.52185
INFO  [18:00:47.236] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -198.5906
[1] -3.969056
[1] -15.23546
[1] 26.67312
[1] -2718.786
[1] -68.27675
[1] -62.09935
[1] 18.60145
[1] -27.40944
[1] 74.66551
INFO  [18:01:41.230] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -118.1044
[1] 38.23243
[1] -32.38172
[1] 13.74706
[1] -39.81758
[1] 28.68989
[1] 192.695
[1] 6321.764
[1] -60.57654
[1] 32.06605
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:02:55.666] [mlr3] Finished benchmark
INFO  [18:02:55.809] [bbotk] Result of batch 16:
INFO  [18:02:55.871] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:02:55.871] [bbotk]              -1.706559                         0.9098216
INFO  [18:02:55.871] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:02:55.871] [bbotk]                         0.7384156           -5.338915              -4.560082
INFO  [18:02:55.871] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:02:55.871] [bbotk]                         16                    3848                 0.9829927
INFO  [18:02:55.871] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:02:55.871] [bbotk]  0.01423365 <list[8]>              FALSE     0.03031074        0      0
INFO  [18:02:55.871] [bbotk]  runtime_learners                                uhash
INFO  [18:02:55.871] [bbotk]           156.778 321c9306-fc15-4a37-9164-98f2be1e1cb1
INFO  [18:02:56.633] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 47 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:03:02.404] [bbotk] Evaluating 1 configuration(s)
INFO  [18:03:02.555] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:03:02.632] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -2855.901
[1] -79.84093
[1] -421.858
[1] 4.09565
[1] -1303.385
[1] -54.51864
[1] -126.6027
[1] 9.680552
[1] -36.2303
[1] 81.37654
INFO  [18:03:50.990] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -258.6762
[1] 0.3737849
[1] -85.65624
[1] 94.17052
[1] -103.3331
[1] 54.76455
[1] -34.88121
[1] 15.70341
[1] -35.96762
[1] 41.67061
INFO  [18:04:24.267] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -25.49345
[1] 60.42128
[1] -16.70643
[1] 113.0104
[1] -1568.465
[1] -24.79116
[1] -57.68049
[1] 8.498781
[1] -75.14771
[1] 42.24495
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:04:57.411] [mlr3] Finished benchmark
INFO  [18:04:57.712] [bbotk] Result of batch 17:
INFO  [18:04:57.808] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:04:57.808] [bbotk]              -3.296116                         0.4779483
INFO  [18:04:57.808] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:04:57.808] [bbotk]                         0.4786303           -4.614024            0.006169983
INFO  [18:04:57.808] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:04:57.808] [bbotk]                          4                    3078                 0.6792985
INFO  [18:04:57.808] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:04:57.808] [bbotk]  0.01289738 <list[8]>              FALSE     0.02385377        0      0
INFO  [18:04:57.808] [bbotk]  runtime_learners                                uhash
INFO  [18:04:57.808] [bbotk]           113.081 84bc9b85-27d5-44ef-bf02-cde90b15c8e8
INFO  [18:04:59.506] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 48 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:05:04.634] [bbotk] Evaluating 1 configuration(s)
INFO  [18:05:04.725] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:05:05.205] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -37.40476
[1] 70.53876
[1] -50.27772
[1] 4.618383
[1] -49.27743
[1] 57.21832
[1] -164.7787
[1] -4.003696
[1] -74.23298
[1] 70.97291
INFO  [18:05:33.996] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -18.99196
[1] 68.32669
[1] -110.7571
[1] 11.85117
[1] -90.122
[1] 24.4202
[1] -135.9396
[1] -3.872928
[1] -84.02749
[1] 6.016365
INFO  [18:06:33.379] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -20.30028
[1] 30.29863
[1] -180.8922
[1] 45.49123
[1] 56.99993
[1] 1365.111
[1] -151.5627
[1] 15.05117
[1] -61.82265
[1] 129.9103
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:07:20.846] [mlr3] Finished benchmark
INFO  [18:07:21.007] [bbotk] Result of batch 18:
INFO  [18:07:21.053] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:07:21.053] [bbotk]              -0.272882                         0.7990452
INFO  [18:07:21.053] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:07:21.053] [bbotk]                         0.5286255           -2.812256              -3.668357
INFO  [18:07:21.053] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:07:21.053] [bbotk]                          2                    4690                 0.5037908
INFO  [18:07:21.053] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:07:21.053] [bbotk]  0.01216421 <list[8]>              FALSE     0.02336583        0      0
INFO  [18:07:21.053] [bbotk]  runtime_learners                                uhash
INFO  [18:07:21.053] [bbotk]           134.749 1553c98d-7355-4027-9745-cc8ee5ec5017
WARN  [18:07:22.687] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:07:22.727] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 49 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:07:26.667] [bbotk] Evaluating 1 configuration(s)
INFO  [18:07:26.844] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:07:26.921] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1725.741
[1] -36.85304
[1] -112.899
[1] 8.48779
[1] -360.6935
[1] -0.3807295
[1] -59.1753
[1] 42.17053
[1] -5934.904
[1] -232.1772
INFO  [18:07:56.391] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -117.8947
[1] 7.657068
[1] -263.8883
[1] 80.54977
[1] -36.65736
[1] 28.67875
[1] -95.14501
[1] 25.99383
[1] -182.767
[1] 22.00767
INFO  [18:08:32.588] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -16.00583
[1] 70.11373
[1] -2350.747
[1] -66.24819
[1] -164.8769
[1] 43.35041
[1] -21.04949
[1] 104.923
[1] -36.54376
[1] 29.7487
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:09:08.993] [mlr3] Finished benchmark
INFO  [18:09:09.141] [bbotk] Result of batch 19:
INFO  [18:09:09.191] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:09:09.191] [bbotk]              0.3042601                         0.2235348
INFO  [18:09:09.191] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:09:09.191] [bbotk]                         0.8640032          -0.5686297              0.8148256
INFO  [18:09:09.191] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:09:09.191] [bbotk]                         13                    4204                   0.70832
INFO  [18:09:09.191] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:09:09.191] [bbotk]  0.01114248 <list[8]>              FALSE      0.0258267        0      0
INFO  [18:09:09.191] [bbotk]  runtime_learners                                uhash
INFO  [18:09:09.191] [bbotk]           101.143 042e8d1d-ac62-486a-ad45-b2103e2653ef
INFO  [18:09:10.609] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 50 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:09:18.345] [bbotk] Evaluating 1 configuration(s)
INFO  [18:09:18.503] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:09:18.645] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -170.0183
[1] -4.360768
[1] -33.73887
[1] 56.34459
[1] -56.93127
[1] 75.72918
[1] -339.2267
[1] -4.072382
[1] -1988.201
[1] -39.15152
INFO  [18:09:57.096] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -193.6407
[1] -4.181835
[1] -138.5166
[1] 95.67376
[1] -332.0844
[1] -4.140992
[1] -287.5016
[1] 191.0106
[1] -120.8227
[1] 58.02506
INFO  [18:10:47.189] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -149.7575
[1] 76.22305
[1] 157.0119
[1] 5680.535
[1] -61.85889
[1] 53.22186
[1] -82.97331
[1] 51.27838
[1] -106.3566
[1] 21.56691
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:11:27.089] [mlr3] Finished benchmark
INFO  [18:11:27.284] [bbotk] Result of batch 20:
INFO  [18:11:27.488] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:11:27.488] [bbotk]              -5.895573                          0.405725
INFO  [18:11:27.488] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:11:27.488] [bbotk]                          0.819988           -4.101037               1.669795
INFO  [18:11:27.488] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:11:27.488] [bbotk]                         20                    4309                 0.1193636
INFO  [18:11:27.488] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:11:27.488] [bbotk]  0.01209635 <list[8]>              FALSE     0.02754334        0      0
INFO  [18:11:27.488] [bbotk]  runtime_learners                                uhash
INFO  [18:11:27.488] [bbotk]           127.564 70cd20f9-e5a1-463c-9394-3fc86812b019
INFO  [18:11:28.742] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 51 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:11:36.092] [bbotk] Evaluating 1 configuration(s)
INFO  [18:11:36.254] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:11:36.294] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -73.96045
[1] 65.66523
[1] -376.0674
[1] -3.958171
[1] -837.8986
[1] -45.6235
[1] -23.75741
[1] 34.50195
[1] -150.3052
[1] 0.3870421
INFO  [18:11:51.569] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -27.95831
[1] 20.40892
[1] 71.78242
[1] 1529.948
[1] -330.2447
[1] -3.860871
[1] -38.35019
[1] 106.3251
[1] -16.94423
[1] 193.1976
INFO  [18:12:19.759] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -14.53927
[1] 59.27422
[1] -710.6782
[1] 31.08814
[1] -92.55017
[1] 6.091722
[1] -37.97594
[1] 25.53769
[1] -24.10406
[1] 67.28888
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:12:44.333] [mlr3] Finished benchmark
INFO  [18:12:45.445] [bbotk] Result of batch 21:
INFO  [18:12:45.471] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:12:45.471] [bbotk]              -4.382162                         0.1753573
INFO  [18:12:45.471] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:12:45.471] [bbotk]                         0.8393751           -2.229023               1.467909
INFO  [18:12:45.471] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:12:45.471] [bbotk]                         10                    1144                 0.7432742
INFO  [18:12:45.471] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:12:45.471] [bbotk]  0.01059492 <list[8]>              FALSE       0.024257        0      0
INFO  [18:12:45.471] [bbotk]  runtime_learners                                uhash
INFO  [18:12:45.471] [bbotk]            66.381 b683355d-bd19-4699-8b68-8f4e0343c679
INFO  [18:12:46.339] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 52 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:12:50.522] [bbotk] Evaluating 1 configuration(s)
INFO  [18:12:50.598] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:12:50.808] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -334.8205
[1] -4.922098
[1] -91.10569
[1] 86.78634
[1] -863.1068
[1] -16.27912
[1] -170.3126
[1] 17.32753
[1] -31.9075
[1] 274.5981
INFO  [18:13:39.082] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -26.00962
[1] 154.622
[1] -270.112
[1] -2.18793
[1] -101.5124
[1] 43.8415
[1] -155.2601
[1] 184.306
[1] -110.8615
[1] 156.7747
INFO  [18:14:18.633] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 2.249766
[1] 167.2268
[1] -98.22371
[1] 130.6034
[1] -104.7467
[1] 66.69737
[1] -3566.574
[1] -107.8689
[1] -88.31137
[1] 66.06928
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:15:10.180] [mlr3] Finished benchmark
INFO  [18:15:10.319] [bbotk] Result of batch 22:
INFO  [18:15:10.365] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:15:10.365] [bbotk]               2.313752                         0.3781413
INFO  [18:15:10.365] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:15:10.365] [bbotk]                         0.1492775           -4.965897              -5.121721
INFO  [18:15:10.365] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:15:10.365] [bbotk]                         16                    4037                 0.9783186
INFO  [18:15:10.365] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:15:10.365] [bbotk]  0.01076975 <list[8]>              FALSE     0.03750819        0      0
INFO  [18:15:10.365] [bbotk]  runtime_learners                                uhash
INFO  [18:15:10.365] [bbotk]           138.377 f922ec79-fb1c-4b2e-a8cc-cf7a00967899
INFO  [18:15:12.026] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 53 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:15:17.508] [bbotk] Evaluating 1 configuration(s)
INFO  [18:15:17.546] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:15:17.636] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -42.22667
[1] 19.95084
[1] -124.805
[1] -3.865183
[1] -3593.119
[1] -50.07542
[1] -20.36352
[1] 64.26281
[1] -222.6163
[1] 8.8931
INFO  [18:15:51.480] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -27.42102
[1] 21.63149
[1] -19.7684
[1] 35.80308
[1] 91.37597
[1] 3027.343
[1] -28.74852
[1] 12.53198
[1] -114.4005
[1] 11.70699
INFO  [18:16:27.063] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -49.14608
[1] 47.50104
[1] -2168.46
[1] 65.88516
[1] -16.34915
[1] 29.80564
[1] -76.25465
[1] 28.07052
[1] -36.82771
[1] 34.07659
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:16:49.654] [mlr3] Finished benchmark
INFO  [18:16:49.782] [bbotk] Result of batch 23:
INFO  [18:16:49.812] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:16:49.812] [bbotk]              -2.279358                         0.5674855
INFO  [18:16:49.812] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:16:49.812] [bbotk]                         0.6843085           -0.370743              -4.570022
INFO  [18:16:49.812] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:16:49.812] [bbotk]                          4                    2429                 0.7743474
INFO  [18:16:49.812] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:16:49.812] [bbotk]  0.01012072 <list[8]>              FALSE     0.02724849        0      0
INFO  [18:16:49.812] [bbotk]  runtime_learners                                uhash
INFO  [18:16:49.812] [bbotk]            91.153 bfb855c1-fdc5-4c7a-9584-aee1c04a37aa
INFO  [18:16:50.597] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 54 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:16:57.884] [bbotk] Evaluating 1 configuration(s)
INFO  [18:16:57.997] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:16:58.057] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -93.74834
[1] -4.224075
[1] -40.30799
[1] 39.90976
[1] 74.48711
[1] 2161.141
[1] -49.85616
[1] 114.8748
[1] -141.3992
[1] 5.462066
INFO  [18:17:25.585] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -66.94218
[1] 180.0297
[1] -67.86282
[1] 25.50152
[1] -43.15294
[1] 19.33217
[1] -18.15984
[1] 79.69248
[1] -64.25606
[1] 85.8946
INFO  [18:17:52.848] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -42.64983
[1] 39.76193
[1] -956.6875
[1] -42.62737
[1] -66.82017
[1] 45.36283
[1] -46.34596
[1] 66.4584
[1] -47.11835
[1] 47.35706
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:18:24.408] [mlr3] Finished benchmark
INFO  [18:18:24.508] [bbotk] Result of batch 24:
INFO  [18:18:24.529] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:18:24.529] [bbotk]               1.081128                         0.6078366
INFO  [18:18:24.529] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:18:24.529] [bbotk]                         0.3871291           -1.211177             -0.9621907
INFO  [18:18:24.529] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:18:24.529] [bbotk]                          5                    2527                 0.9107145
INFO  [18:18:24.529] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:18:24.529] [bbotk]  0.01099298 <list[8]>              FALSE     0.03128495        0      0
INFO  [18:18:24.529] [bbotk]  runtime_learners                                uhash
INFO  [18:18:24.529] [bbotk]            85.791 08d078c8-554a-4245-a8ff-887fcc23c909
INFO  [18:18:26.459] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 55 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:18:32.888] [bbotk] Evaluating 1 configuration(s)
INFO  [18:18:33.004] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:18:33.326] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -219.3337
[1] -3.992435
[1] -1677.05
[1] -57.12572
[1] -155.0216
[1] 0.6154591
[1] -3.203323e+16
[1] 4.466436e+15
[1] -288.2061
[1] 14.13709
INFO  [18:19:08.215] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -56.88181
[1] 65.96725
[1] -78.24054
[1] 0.6120536
[1] -206.7439
[1] 8.710346
[1] -29.77227
[1] 281.1318
[1] -666.7133
[1] -4.009393
INFO  [18:19:40.499] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2.256008e+16
[1] 1.106426e+16
[1] -30.25616
[1] 73.95145
[1] -2549.965
[1] -78.22993
[1] -28.23849
[1] 26.42019
[1] 286.8293
[1] 9190.594
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:20:18.841] [mlr3] Finished benchmark
INFO  [18:20:19.088] [bbotk] Result of batch 25:
INFO  [18:20:19.192] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:20:19.192] [bbotk]              -5.695008                         0.2208399
INFO  [18:20:19.192] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:20:19.192] [bbotk]                         0.7079277           -3.971666              -4.075313
INFO  [18:20:19.192] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:20:19.192] [bbotk]                         10                    3774                 0.6559498
INFO  [18:20:19.192] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:20:19.192] [bbotk]  0.01002203 <list[8]>              FALSE     0.02479384        0      0
INFO  [18:20:19.192] [bbotk]  runtime_learners                                uhash
INFO  [18:20:19.192] [bbotk]           103.583 b47d284f-1567-4427-a3d3-9b445a3f3caf
INFO  [18:20:20.342] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 56 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:20:26.188] [bbotk] Evaluating 1 configuration(s)
INFO  [18:20:26.293] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:20:26.642] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -212.553
[1] 5.174974
[1] -122.0158
[1] 30.62963
[1] -5947.8
[1] -127.3663
[1] -99.62758
[1] 60.23669
[1] -69.8627
[1] 54.74088
INFO  [18:21:09.354] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -31.73014
[1] 74.05188
[1] -53.59032
[1] 71.30069
[1] -159.4958
[1] -3.356919
[1] -171.9466
[1] 160.0393
[1] -142.3265
[1] 59.02054
INFO  [18:22:10.062] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -105.2528
[1] 16.30692
[1] -111.1526
[1] 30.08957
[1] -126.3469
[1] 150.8624
[1] -68.70839
[1] 69.14592
[1] -97.0155
[1] 32.96685
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:22:49.126] [mlr3] Finished benchmark
INFO  [18:22:49.477] [bbotk] Result of batch 26:
INFO  [18:22:49.687] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:22:49.687] [bbotk]              -6.883935                         0.4026053
INFO  [18:22:49.687] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:22:49.687] [bbotk]                         0.5479878           -2.645603               6.765318
INFO  [18:22:49.687] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:22:49.687] [bbotk]                          5                    3743                 0.7365143
INFO  [18:22:49.687] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:22:49.687] [bbotk]  0.009557564 <list[8]>              FALSE     0.03452679        0      0
INFO  [18:22:49.687] [bbotk]  runtime_learners                                uhash
INFO  [18:22:49.687] [bbotk]           141.915 b83ad830-6557-4e1c-8ee1-62ef32ae3c60
INFO  [18:22:53.431] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 57 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:23:00.935] [bbotk] Evaluating 1 configuration(s)
INFO  [18:23:01.123] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:23:01.247] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 94.43774
[1] 2849.91
[1] -97.25529
[1] 38.69072
[1] -45.91116
[1] 128.7296
[1] -157.5271
[1] 30.34241
[1] -182.5108
[1] 5.038758
INFO  [18:24:14.181] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 11.05188
[1] 542.0638
[1] 125.0861
[1] 4385.724
[1] -51.76696
[1] 42.57974
[1] -252.0011
[1] -3.872941
[1] -175.3107
[1] 25.127
INFO  [18:25:06.157] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -46.4404
[1] 35.18062
[1] -61.46739
[1] 149.7697
[1] -62.36003
[1] 40.65878
[1] -1940.102
[1] 488.8011
[1] 94.45311
[1] 2722.589
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:25:51.781] [mlr3] Finished benchmark
INFO  [18:25:51.890] [bbotk] Result of batch 27:
INFO  [18:25:51.940] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:25:51.940] [bbotk]              -2.149688                         0.7981634
INFO  [18:25:51.940] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:25:51.940] [bbotk]                         0.1708468           -7.095887              -6.698591
INFO  [18:25:51.940] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:25:51.940] [bbotk]                          9                    4436                 0.7483681
INFO  [18:25:51.940] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:25:51.940] [bbotk]  0.008784928 <list[8]>              FALSE     0.03014546        0      0
INFO  [18:25:51.940] [bbotk]  runtime_learners                                uhash
INFO  [18:25:51.940] [bbotk]           169.104 615a5260-f9da-42aa-be70-b76da8b23ece
INFO  [18:25:53.034] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 58 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:25:59.748] [bbotk] Evaluating 1 configuration(s)
INFO  [18:26:00.076] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:26:00.279] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1609.357
[1] -38.43739
[1] -71.28369
[1] 9.39101
[1] -105.869
[1] 3.242853
[1] -30.54528
[1] 93.32633
[1] -21.54927
[1] 35.98023
INFO  [18:26:28.758] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -2399.057
[1] -49.67205
[1] -65.95287
[1] 19.91781
[1] -118.5129
[1] 65.86287
[1] -149.5828
[1] -3.854252
[1] -102.621
[1] 13.43584
INFO  [18:26:59.029] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 124.4573
[1] 4677.741
[1] 44.30831
[1] 744.031
[1] -49.88427
[1] 45.21104
[1] -49.77378
[1] 60.52571
[1] -250.8936
[1] -2.279096
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:27:25.078] [mlr3] Finished benchmark
INFO  [18:27:25.571] [bbotk] Result of batch 28:
INFO  [18:27:25.763] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:27:25.763] [bbotk]              -5.928425                         0.1149084
INFO  [18:27:25.763] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:27:25.763] [bbotk]                         0.6005727           -2.711107               2.430316
INFO  [18:27:25.763] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:27:25.763] [bbotk]                         17                    1237                 0.4829052
INFO  [18:27:25.763] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:27:25.763] [bbotk]  0.008816339 <list[8]>              FALSE     0.02319664        0      0
INFO  [18:27:25.763] [bbotk]  runtime_learners                                uhash
INFO  [18:27:25.763] [bbotk]            83.538 fce84b03-2230-4f18-9a20-729ad1d05d63
INFO  [18:27:26.710] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 59 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:27:31.714] [bbotk] Evaluating 1 configuration(s)
INFO  [18:27:31.747] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:27:31.854] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1019.393
[1] -52.99041
[1] -66.3608
[1] 33.11277
[1] -47.03015
[1] 71.93594
[1] -266.9801
[1] -3.640356
[1] -497.8053
[1] -4.184831
INFO  [18:28:39.356] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -331.206
[1] 58.3735
[1] -208.3857
[1] 5.980129
[1] -37.74406
[1] 29.57112
[1] -38.972
[1] 254.0968
[1] -59.57235
[1] 74.79089
INFO  [18:29:27.164] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -82.48643
[1] 67.47968
[1] -1675.949
[1] 24.11588
[1] -39.24241
[1] 40.07403
[1] -74.67674
[1] 10.32534
[1] -25.79551
[1] 39.06365
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:30:29.243] [mlr3] Finished benchmark
INFO  [18:30:29.389] [bbotk] Result of batch 29:
INFO  [18:30:29.531] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:30:29.531] [bbotk]              0.8159269                         0.5851027
INFO  [18:30:29.531] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:30:29.531] [bbotk]                         0.9984822           -2.339319              -4.321755
INFO  [18:30:29.531] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:30:29.531] [bbotk]                          4                    4070                 0.5176885
INFO  [18:30:29.531] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:30:29.531] [bbotk]  0.008322069 <list[8]>              FALSE       0.028509        0      0
INFO  [18:30:29.531] [bbotk]  runtime_learners                                uhash
INFO  [18:30:29.531] [bbotk]            176.21 46d489f0-cf49-43ee-bd85-afbce47f8cfc
INFO  [18:30:30.660] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 60 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:30:38.510] [bbotk] Evaluating 1 configuration(s)
INFO  [18:30:38.723] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:30:38.894] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -4106.45
[1] -107.9392
[1] -78.14684
[1] 33.44698
[1] -51.9419
[1] 68.98255
[1] -42.491
[1] 24.23855
[1] -14.61619
[1] 61.78575
INFO  [18:30:59.057] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -139.2657
[1] 1.957087
[1] -69.23891
[1] 140.514
[1] -67.47387
[1] 100.7937
[1] -48.81441
[1] 56.88167
[1] -12.81269
[1] 273.9038
INFO  [18:31:22.447] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -71.41549
[1] 21.42502
[1] -69.58516
[1] 43.27796
[1] -56.33226
[1] 61.2694
[1] -58.72199
[1] 59.50413
[1] -54.90746
[1] 68.24301
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:31:43.246] [mlr3] Finished benchmark
INFO  [18:31:43.399] [bbotk] Result of batch 30:
INFO  [18:31:43.467] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:31:43.467] [bbotk]               1.312784                         0.8922996
INFO  [18:31:43.467] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:31:43.467] [bbotk]                         0.9195325          -0.2218916             -0.2682996
INFO  [18:31:43.467] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:31:43.467] [bbotk]                         19                     288                 0.2439056
INFO  [18:31:43.467] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:31:43.467] [bbotk]  0.00876429 <list[8]>              FALSE     0.03708437        0      0
INFO  [18:31:43.467] [bbotk]  runtime_learners                                uhash
INFO  [18:31:43.467] [bbotk]            63.977 68ea92fb-fb6c-47bc-8eb2-59446e1ae476
INFO  [18:31:45.021] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 61 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:31:51.421] [bbotk] Evaluating 1 configuration(s)
INFO  [18:31:51.493] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:31:51.565] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -158.6203
[1] -4.041548
[1] -96.8211
[1] 21.18741
[1] -54.95474
[1] 28.2257
[1] -346.7959
[1] -1.594366
[1] -3721.69
[1] -82.34154
INFO  [18:32:35.985] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -177.2392
[1] -3.632872
[1] -85.61624
[1] 72.52499
[1] -165.9477
[1] 25.97811
[1] -1016.19
[1] -32.88588
[1] -46.75834
[1] 46.38878
INFO  [18:33:07.698] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -48.07617
[1] 80.85074
[1] -130.2155
[1] 35.92816
[1] -38.01876
[1] 84.79483
[1] -2.006703e+16
[1] 2.787321e+16
[1] -40.5036
[1] 82.10495
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:34:00.249] [mlr3] Finished benchmark
INFO  [18:34:00.349] [bbotk] Result of batch 31:
INFO  [18:34:00.400] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:34:00.400] [bbotk]               -2.43228                         0.8697847
INFO  [18:34:00.400] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:34:00.400] [bbotk]                         0.7348613           -5.219145             -0.3580268
INFO  [18:34:00.400] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:34:00.400] [bbotk]                         20                    3908                 0.1799135
INFO  [18:34:00.400] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:34:00.400] [bbotk]  0.008415399 <list[8]>              FALSE     0.02426965        0      0
INFO  [18:34:00.400] [bbotk]  runtime_learners                                uhash
INFO  [18:34:00.400] [bbotk]           127.727 60ea6c17-c005-4ddb-af12-fe83c71b4d7b
INFO  [18:34:01.616] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 62 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:34:09.959] [bbotk] Evaluating 1 configuration(s)
INFO  [18:34:10.072] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:34:10.165] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -42.32435
[1] 78.22511
[1] -45.97826
[1] 6.216528
[1] -110.4437
[1] 0.04991623
[1] -53.81682
[1] 119.3033
[1] -78.91394
[1] 41.34749
INFO  [18:34:56.468] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1258.826
[1] -39.63667
[1] -29.32372
[1] 38.1717
[1] -56.33403
[1] 2.80352
[1] -132.4995
[1] 1.428801
[1] -30.43274
[1] 81.35009
INFO  [18:35:45.263] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -61.82823
[1] 34.34211
[1] -12.94027
[1] 41.96448
[1] -38.62952
[1] 75.84949
[1] -342.0485
[1] 15.23547
[1] 66.09529
[1] 2271.407
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:36:21.380] [mlr3] Finished benchmark
INFO  [18:36:21.513] [bbotk] Result of batch 32:
INFO  [18:36:21.552] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:36:21.552] [bbotk]              -6.106976                         0.5503451
INFO  [18:36:21.552] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:36:21.552] [bbotk]                         0.6820092           -1.133578              -3.467792
INFO  [18:36:21.552] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:36:21.552] [bbotk]                         17                    4081                 0.4304259
INFO  [18:36:21.552] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:36:21.552] [bbotk]  0.008179015 <list[8]>              FALSE     0.02666671        0      0
INFO  [18:36:21.552] [bbotk]  runtime_learners                                uhash
INFO  [18:36:21.552] [bbotk]           130.259 43e11873-2100-40e4-b5aa-89b801487f85
INFO  [18:36:22.165] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 63 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:36:28.796] [bbotk] Evaluating 1 configuration(s)
INFO  [18:36:29.005] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:36:29.175] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -109.185
[1] 35.19331
[1] -191.9579
[1] -3.892582
[1] -3.282275e+16
[1] 8.297389e+15
[1] -63.59198
[1] 17.45515
[1] -30.65548
[1] 78.39971
INFO  [18:37:10.523] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -3046.878
[1] -66.81886
[1] -276.3055
[1] -2.934063
[1] -95.79735
[1] -3.169055
[1] -23.84808
[1] 54.44591
[1] -43.44741
[1] 34.40386
INFO  [18:37:49.818] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -45.70704
[1] 181.0204
[1] -89.79872
[1] 15.69117
[1] -1831.518
[1] -64.9895
[1] -38.75827
[1] 24.69476
[1] 112.662
[1] 3161.879
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:38:26.283] [mlr3] Finished benchmark
INFO  [18:38:26.498] [bbotk] Result of batch 33:
INFO  [18:38:26.544] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:38:26.544] [bbotk]              -4.059045                         0.2846041
INFO  [18:38:26.544] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:38:26.544] [bbotk]                         0.6080584           -5.483904              -2.151495
INFO  [18:38:26.544] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:38:26.544] [bbotk]                         14                    2562                  0.644636
INFO  [18:38:26.544] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:38:26.544] [bbotk]  0.008855379 <list[8]>              FALSE     0.02438989        0      0
INFO  [18:38:26.544] [bbotk]  runtime_learners                                uhash
INFO  [18:38:26.544] [bbotk]           115.757 3249b42a-4984-4bb0-bfe4-4c1d4889abd8
INFO  [18:38:27.785] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 64 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:38:33.641] [bbotk] Evaluating 1 configuration(s)
INFO  [18:38:33.754] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:38:33.861] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -138.978
[1] 5.356947
[1] -48.89292
[1] 38.06511
[1] -1512.587
[1] 97.79966
[1] -316.4431
[1] -3.70893
[1] -10902.79
[1] -412.646
INFO  [18:39:06.074] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -124.3291
[1] 44.01761
[1] -830.2834
[1] -3.832593
[1] -82.57381
[1] -4.0218
[1] -33.19623
[1] 52.65841
[1] -203.1485
[1] 11.40993
INFO  [18:39:35.432] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -18.7892
[1] 117.5931
[1] -51.96634
[1] 23.05338
[1] -43.4362
[1] 185.0034
[1] -62.35204
[1] 27.01689
[1] -55.30187
[1] 61.47786
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:40:10.550] [mlr3] Finished benchmark
INFO  [18:40:10.752] [bbotk] Result of batch 34:
INFO  [18:40:10.793] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:40:10.793] [bbotk]              -5.151667                         0.4825112
INFO  [18:40:10.793] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:40:10.793] [bbotk]                         0.1868928           -1.654146             -0.2625684
INFO  [18:40:10.793] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:40:10.793] [bbotk]                         16                    2449                 0.4962174
INFO  [18:40:10.793] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:40:10.793] [bbotk]  0.008687095 <list[8]>              FALSE     0.02249739        0      0
INFO  [18:40:10.793] [bbotk]  runtime_learners                                uhash
INFO  [18:40:10.793] [bbotk]            95.532 8bd5114f-0195-4e05-8625-2282e461f1aa
INFO  [18:40:12.793] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 65 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:40:21.036] [bbotk] Evaluating 1 configuration(s)
INFO  [18:40:21.135] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:40:21.158] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -15.97882
[1] 37.58153
[1] -43.11791
[1] 22.74071
[1] -61.9432
[1] -0.2881331
[1] -38.4886
[1] 7.527824
[1] -72.97322
[1] 9.181243
INFO  [18:40:54.048] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -18.45144
[1] 46.69489
[1] -116.5724
[1] 68.35037
[1] -98.28945
[1] 2.866845
[1] -8.257764
[1] 23.46467
[1] -16.49148
[1] 18.90433
INFO  [18:41:31.267] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -33.66091
[1] 19.01864
[1] -5.280856
[1] 30.3658
[1] -8.518906
[1] 27.30362
[1] -39.58423
[1] 92.29281
[1] -37.07916
[1] 53.26406
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:42:09.680] [mlr3] Finished benchmark
INFO  [18:42:09.930] [bbotk] Result of batch 35:
INFO  [18:42:10.039] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:42:10.039] [bbotk]              -1.109252                         0.8350785
INFO  [18:42:10.039] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:42:10.039] [bbotk]                         0.5352961         -0.02622043              -6.745056
INFO  [18:42:10.039] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:42:10.039] [bbotk]                          6                    2915                 0.1164351
INFO  [18:42:10.039] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:42:10.039] [bbotk]  0.006755195 <list[8]>              FALSE     0.03371908        0      0
INFO  [18:42:10.039] [bbotk]  runtime_learners                                uhash
INFO  [18:42:10.039] [bbotk]           108.065 de25e429-ef57-452e-98d5-70a7353b1044
WARN  [18:42:11.750] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:42:11.793] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 66 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:42:18.754] [bbotk] Evaluating 1 configuration(s)
INFO  [18:42:19.091] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:42:19.351] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1452.261
[1] -37.21344
[1] -120.8288
[1] -3.350556
[1] 44.21661
[1] 1563.692
[1] -87.25608
[1] 8.185363
[1] -36.71606
[1] 64.56751
INFO  [18:43:16.546] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -90.8669
[1] 201.0105
[1] -33.81356
[1] 211.6055
[1] -100.5205
[1] 14.90071
[1] -83.26332
[1] 60.54551
[1] -79.35288
[1] 25.10731
INFO  [18:44:23.735] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -37.95089
[1] 96.99787
[1] -36.50068
[1] 24.18442
[1] -28.62803
[1] 134.1196
[1] -855.5498
[1] 51.27033
[1] -607.4581
[1] -9.370973
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:45:30.212] [mlr3] Finished benchmark
INFO  [18:45:30.648] [bbotk] Result of batch 36:
INFO  [18:45:30.697] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:45:30.697] [bbotk]              0.5970628                         0.9313998
INFO  [18:45:30.697] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:45:30.697] [bbotk]                         0.5036166           -3.658962              0.1168051
INFO  [18:45:30.697] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:45:30.697] [bbotk]                          7                    4918                 0.8107088
INFO  [18:45:30.697] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:45:30.697] [bbotk]  0.006939238 <list[8]>              FALSE     0.03002279        0      0
INFO  [18:45:30.697] [bbotk]  runtime_learners                                uhash
INFO  [18:45:30.697] [bbotk]           190.156 d1333e9f-3296-4ba8-8f13-edc410f263f8
INFO  [18:45:33.767] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 67 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:45:41.741] [bbotk] Evaluating 1 configuration(s)
INFO  [18:45:42.138] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:45:42.238] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -282.5939
[1] 119.7784
[1] -134.39
[1] -4.05111
[1] -63.54272
[1] 32.7766
[1] -70.70535
[1] 16.97963
[1] -70.96062
[1] 111.9931
INFO  [18:47:26.030] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -278.4203
[1] 10.20017
[1] -53.04466
[1] 138.3859
[1] -20.91982
[1] 43.90568
[1] -66.38418
[1] 43.33883
[1] -16.92591
[1] 317.1039
INFO  [18:49:06.569] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -10.66242
[1] 81.04294
[1] -48.60822
[1] 41.97969
[1] -60.69224
[1] 64.8257
[1] -100.7146
[1] 85.11059
[1] -93.95993
[1] 35.43723
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:50:38.470] [mlr3] Finished benchmark
INFO  [18:50:38.542] [bbotk] Result of batch 37:
INFO  [18:50:38.549] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:50:38.549] [bbotk]              -2.084406                         0.9813037
INFO  [18:50:38.549] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:50:38.549] [bbotk]                         0.7136131           -7.013216              -6.417128
INFO  [18:50:38.549] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:50:38.549] [bbotk]                         20                    4132                 0.5341198
INFO  [18:50:38.549] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:50:38.549] [bbotk]  0.007531528 <list[8]>              FALSE     0.03111069        0      0
INFO  [18:50:38.549] [bbotk]  runtime_learners                                uhash
INFO  [18:50:38.549] [bbotk]           295.948 2bbe1d27-34d7-4eaf-9853-67d4a542d6e5
INFO  [18:50:42.519] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 68 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:51:01.409] [bbotk] Evaluating 1 configuration(s)
INFO  [18:51:01.687] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:51:01.840] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -133.1465
[1] 15.03433
[1] -51.36834
[1] 134.3252
[1] -116.7129
[1] -3.161283
[1] -44.22384
[1] 46.89045
[1] -1593.835
[1] -35.05642
INFO  [18:52:13.345] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -7.22363
[1] 117.2329
[1] -140.5021
[1] 1.224501
[1] 100.9686
[1] 1778.185
[1] -425.4119
[1] 14.68156
[1] -43.69883
[1] 31.24667
INFO  [18:53:10.334] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -276.631
[1] 26.05611
[1] -39.71485
[1] 59.40291
[1] -31.13305
[1] 41.02571
[1] -3088.495
[1] -112.5634
[1] -214.5235
[1] 6.794029
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:53:47.796] [mlr3] Finished benchmark
INFO  [18:53:47.921] [bbotk] Result of batch 38:
INFO  [18:53:47.947] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:53:47.947] [bbotk]               -1.37325                          0.336887
INFO  [18:53:47.947] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:53:47.947] [bbotk]                         0.8781493           -4.391098              -5.186826
INFO  [18:53:47.947] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:53:47.947] [bbotk]                         14                    4717                 0.6836227
INFO  [18:53:47.947] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:53:47.947] [bbotk]  0.007824658 <list[8]>              FALSE     0.02586012        0      0
INFO  [18:53:47.947] [bbotk]  runtime_learners                                uhash
INFO  [18:53:47.947] [bbotk]           165.471 388ca597-e2c7-444b-8917-a23ecf213d52
INFO  [18:53:50.684] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 69 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:54:05.241] [bbotk] Evaluating 1 configuration(s)
INFO  [18:54:05.350] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:54:05.480] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -95.48173
[1] 106.9075
[1] -57.96881
[1] 307.0375
[1] -225.5525
[1] 17.49278
[1] -141.6505
[1] 3.006154
[1] -51.15835
[1] 220.6325
INFO  [18:54:39.843] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -130.167
[1] 58.89242
[1] -19.81213
[1] 133.0624
[1] -218.3696
[1] -4.094805
[1] -82.98747
[1] 447.705
[1] -331.4999
[1] -4.92095
INFO  [18:55:24.830] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -69.06167
[1] 48.65181
[1] -33.10213
[1] 84.71183
[1] -203.6496
[1] 42.28276
[1] -102.0926
[1] 131.3774
[1] -58.74477
[1] 85.71523
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:55:53.554] [mlr3] Finished benchmark
INFO  [18:55:53.737] [bbotk] Result of batch 39:
INFO  [18:55:53.744] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:55:53.744] [bbotk]               2.101451                         0.3018619
INFO  [18:55:53.744] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:55:53.744] [bbotk]                         0.2806026            -5.14841              -5.246556
INFO  [18:55:53.744] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:55:53.744] [bbotk]                          2                    2434                 0.9723459
INFO  [18:55:53.744] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:55:53.744] [bbotk]  0.006665279 <list[8]>              FALSE      0.0367662        0      0
INFO  [18:55:53.744] [bbotk]  runtime_learners                                uhash
INFO  [18:55:53.744] [bbotk]           107.837 ae9ace51-a1a4-4c69-bf69-2c8fdc121b5b
INFO  [18:55:58.438] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 70 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:56:12.520] [bbotk] Evaluating 1 configuration(s)
INFO  [18:56:12.712] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:56:12.818] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -164.1469
[1] -2.458303
[1] -121.5967
[1] -4.079396
[1] -61.16933
[1] 103.356
[1] -50.73479
[1] 66.19023
[1] -52.40904
[1] 22.03215
INFO  [18:57:11.620] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -116.0171
[1] -2.873253
[1] 29.40007
[1] 728.5683
[1] -321.0688
[1] -1.014305
[1] -17.58431
[1] 68.35375
[1] -38.36461
[1] 26.81766
INFO  [18:58:17.976] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -5974.177
[1] -77.65692
[1] -62.91069
[1] 134.3292
[1] -180.1187
[1] 35.87289
[1] -8.283038
[1] 56.05681
[1] -48.1135
[1] 25.61674
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:59:24.404] [mlr3] Finished benchmark
INFO  [18:59:26.604] [bbotk] Result of batch 40:
INFO  [18:59:26.736] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:59:26.736] [bbotk]              -2.436038                         0.6140166
INFO  [18:59:26.736] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:59:26.736] [bbotk]                         0.9356098           -2.416685              0.2828421
INFO  [18:59:26.736] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:59:26.736] [bbotk]                          9                    2784                 0.6624177
INFO  [18:59:26.736] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:59:26.736] [bbotk]  0.006784426 <list[8]>              FALSE     0.02826988        0      0
INFO  [18:59:26.736] [bbotk]  runtime_learners                                uhash
INFO  [18:59:26.736] [bbotk]             190.6 2e5fe9e0-3f0c-4f93-9d2b-c3289ee70f28
INFO  [18:59:38.248] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 71 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:59:47.790] [bbotk] Evaluating 1 configuration(s)
INFO  [18:59:48.045] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:59:48.173] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -55.76196
[1] 29.86393
[1] -94.79126
[1] 6.476949
[1] -61.37322
[1] 288.3461
[1] 182.0239
[1] 6323.155
[1] -194.18
[1] 1.986398
INFO  [19:00:37.662] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -69.62006
[1] 30.43394
[1] -354.3212
[1] -4.006342
[1] -42.24982
[1] 14.99648
[1] -47.11279
[1] 21.57943
[1] -32.24441
[1] 54.30601
INFO  [19:01:38.338] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 323.9717
[1] 8839.042
[1] -79.43807
[1] 141.0227
[1] -163.2453
[1] 28.67015
[1] -2450.91
[1] -65.04859
[1] -50.57874
[1] 36.95866
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:02:38.078] [mlr3] Finished benchmark
INFO  [19:02:40.276] [bbotk] Result of batch 41:
INFO  [19:02:40.347] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:02:40.347] [bbotk]             -0.9458263                         0.3175405
INFO  [19:02:40.347] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:02:40.347] [bbotk]                         0.2522817           -2.535991              -6.562472
INFO  [19:02:40.347] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:02:40.347] [bbotk]                          3                    4997                 0.9649495
INFO  [19:02:40.347] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:02:40.347] [bbotk]  0.006479255 <list[8]>              FALSE     0.02558007        0      0
INFO  [19:02:40.347] [bbotk]  runtime_learners                                uhash
INFO  [19:02:40.347] [bbotk]           169.318 b3bf3193-67c2-4877-94a1-f42d3f9cb0b6
INFO  [19:02:43.924] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 72 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:03:02.117] [bbotk] Evaluating 1 configuration(s)
INFO  [19:03:02.204] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:03:02.254] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -62.13225
[1] 10.81041
[1] -128.4447
[1] 10.45997
[1] -1446.552
[1] -45.115
[1] -148.9735
[1] -3.877216
[1] -28.58813
[1] 148.0909
INFO  [19:03:46.758] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -258.1228
[1] -3.258176
[1] -26.2915
[1] 119.8323
[1] -144.2312
[1] 13.1865
[1] -34.08486
[1] 101.109
[1] -996.3014
[1] 46.27852
INFO  [19:04:45.087] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -155.3566
[1] 44.65916
[1] 84.87764
[1] 2540.188
[1] -56.01652
[1] 15.25872
[1] -858442.6
[1] -21646.43
[1] -2914.883
[1] -37.90856
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:05:39.679] [mlr3] Finished benchmark
INFO  [19:05:40.922] [bbotk] Result of batch 42:
INFO  [19:05:40.989] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:05:40.989] [bbotk]               -2.09696                         0.5218426
INFO  [19:05:40.989] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:05:40.989] [bbotk]                         0.4742647           -5.126112               -4.22705
INFO  [19:05:40.989] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:05:40.989] [bbotk]                         14                    4365                 0.3371631
INFO  [19:05:40.989] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:05:40.989] [bbotk]  0.006678788 <list[8]>              FALSE     0.02128212        0      0
INFO  [19:05:40.989] [bbotk]  runtime_learners                                uhash
INFO  [19:05:40.989] [bbotk]           156.668 095c3c5d-df32-4acf-a3b7-6957c92c1310
INFO  [19:05:50.632] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 73 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:06:05.154] [bbotk] Evaluating 1 configuration(s)
INFO  [19:06:05.565] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:06:05.649] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -182.3632
[1] 15.8342
[1] -97.52297
[1] -3.402694
[1] -233.207
[1] 7.468132
[1] -31.49852
[1] 62.58434
[1] -29.11074
[1] 31.67651
INFO  [19:07:31.508] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -67.97807
[1] 56.78103
[1] -277.7295
[1] -3.381304
[1] -21.71167
[1] 26.4475
[1] -58.23944
[1] 102.507
[1] -81.10074
[1] 82.60371
INFO  [19:09:11.254] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 45.54854
[1] 1184.903
[1] -95.02354
[1] 49.04825
[1] -32.236
[1] 48.37289
[1] -24.69827
[1] 14.97728
[1] -57.37177
[1] 42.59911
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:10:32.492] [mlr3] Finished benchmark
INFO  [19:10:32.590] [bbotk] Result of batch 43:
INFO  [19:10:32.619] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:10:32.619] [bbotk]              -2.981325                         0.6038761
INFO  [19:10:32.619] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:10:32.619] [bbotk]                         0.3026072           -5.942476             -0.5262322
INFO  [19:10:32.619] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:10:32.619] [bbotk]                         19                    4454                 0.9941203
INFO  [19:10:32.619] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:10:32.619] [bbotk]  0.006297903 <list[8]>              FALSE     0.02598526        0      0
INFO  [19:10:32.619] [bbotk]  runtime_learners                                uhash
INFO  [19:10:32.619] [bbotk]           266.512 8e5ba990-e51b-4b58-81f1-7a155ee71e0d
INFO  [19:10:35.077] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 74 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:10:44.361] [bbotk] Evaluating 1 configuration(s)
INFO  [19:10:44.488] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:10:44.549] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -2530.246
[1] -97.76836
[1] -1326.114
[1] 869.3343
[1] -173.4339
[1] -3.635493
[1] 93.27463
[1] 2733.819
[1] -106.4868
[1] 11.99368
INFO  [19:11:49.108] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -79.99767
[1] 9.995392
[1] -9369.658
[1] -271.8332
[1] 32.80262
[1] 881.075
[1] -90.00154
[1] 51.14995
[1] -106.3449
[1] 18.71844
INFO  [19:13:09.095] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 36.80295
[1] 1150.713
[1] -110.9397
[1] 7.117913
[1] -160.9393
[1] 46.77426
[1] -1264.083
[1] 197.2623
[1] -62.95821
[1] 26.71109
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:14:22.443] [mlr3] Finished benchmark
INFO  [19:14:24.714] [bbotk] Result of batch 44:
INFO  [19:14:24.867] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:14:24.867] [bbotk]              -6.129082                         0.2013105
INFO  [19:14:24.867] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:14:24.867] [bbotk]                         0.3732691            -2.02822                2.35622
INFO  [19:14:24.867] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:14:24.867] [bbotk]                         17                    4476                 0.3583935
INFO  [19:14:24.867] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:14:24.867] [bbotk]  0.00606081 <list[8]>              FALSE     0.02055137        0      0
INFO  [19:14:24.867] [bbotk]  runtime_learners                                uhash
INFO  [19:14:24.867] [bbotk]           216.826 232dc1ea-8794-436a-b2ed-0fdb8e2c3c35
INFO  [19:14:33.807] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 75 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:14:46.872] [bbotk] Evaluating 1 configuration(s)
INFO  [19:14:47.268] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:14:47.394] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1584.002
[1] -31.40011
[1] -94.942
[1] -3.997196
[1] -113.8072
[1] 47.73929
[1] -182.0855
[1] 3.933643
[1] -364.0004
[1] -4.053204
INFO  [19:15:34.303] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -83.89944
[1] 0.5734415
[1] -244.4743
[1] 8.458797
[1] -40.37427
[1] 125.0798
[1] -40.42283
[1] 77.87687
[1] -124.8964
[1] 41.18931
INFO  [19:16:16.452] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -28.03261
[1] 101.6052
[1] -65.20094
[1] 66.13205
[1] -114897.4
[1] -5479.635
[1] -138.5857
[1] 3.074923
[1] -56.92776
[1] 57.29803
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:17:08.078] [mlr3] Finished benchmark
INFO  [19:17:08.449] [bbotk] Result of batch 45:
INFO  [19:17:08.498] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:17:08.498] [bbotk]               -4.64161                         0.1799266
INFO  [19:17:08.498] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:17:08.498] [bbotk]                         0.8818275          -0.1124563               1.706757
INFO  [19:17:08.498] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:17:08.498] [bbotk]                         18                    4107                 0.1350157
INFO  [19:17:08.498] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:17:08.498] [bbotk]  0.005590606 <list[8]>              FALSE     0.02441255        0      0
INFO  [19:17:08.498] [bbotk]  runtime_learners                                uhash
INFO  [19:17:08.498] [bbotk]           140.359 fea01f8b-94a0-4b66-bc78-00b6bd74514f
INFO  [19:17:11.221] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 76 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:17:24.315] [bbotk] Evaluating 1 configuration(s)
INFO  [19:17:24.427] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:17:24.483] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -55012.33
[1] -936.5487
[1] -317.65
[1] -4.223219
[1] -108.2203
[1] 22.81889
[1] -133.6191
[1] 20.94187
[1] 16.39691
[1] 611.8269
INFO  [19:18:09.081] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -375.0464
[1] -4.505502
[1] -75.96696
[1] 80.04909
[1] -241.9617
[1] -4.276206
[1] -76.83184
[1] 49.63831
[1] -27.36685
[1] 168.5382
INFO  [19:18:49.600] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -4628.431
[1] -75.14769
[1] -39.9
[1] 38.93887
[1] -39.64401
[1] 119.0838
[1] -266.3464
[1] 117.7846
[1] -69.05665
[1] 38.36162
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:19:37.681] [mlr3] Finished benchmark
INFO  [19:19:38.320] [bbotk] Result of batch 46:
INFO  [19:19:38.387] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:19:38.387] [bbotk]              -4.633743                         0.4735906
INFO  [19:19:38.387] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:19:38.387] [bbotk]                         0.6048974          -0.4098488               6.748915
INFO  [19:19:38.387] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:19:38.387] [bbotk]                         16                    1812                 0.1382328
INFO  [19:19:38.387] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:19:38.387] [bbotk]  0.005782847 <list[8]>              FALSE     0.03844766        0      0
INFO  [19:19:38.387] [bbotk]  runtime_learners                                uhash
INFO  [19:19:38.387] [bbotk]            132.93 2069debb-7976-47e0-864b-4e0fb336d652
INFO  [19:19:40.198] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 77 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:20:04.665] [bbotk] Evaluating 1 configuration(s)
INFO  [19:20:05.140] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:20:05.211] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -23.03109
[1] 16.08043
[1] -34.00978
[1] 43.05917
[1] -3111.032
[1] -161.1337
[1] -92.83161
[1] 27.46723
[1] -19.7356
[1] 15.266
INFO  [19:21:12.783] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -26.18862
[1] 20.01097
[1] -47.47715
[1] 2.302929
[1] -17.1272
[1] 38.23496
[1] 75.96353
[1] 1313.079
[1] -56.72565
[1] 5.415894
INFO  [19:21:48.096] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -5377.339
[1] -86.23439
[1] -15.46098
[1] 29.1505
[1] -536.3148
[1] 16.55315
[1] -29.93306
[1] 30.03452
[1] -257.8291
[1] -3.892411
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:22:26.361] [mlr3] Finished benchmark
INFO  [19:22:27.072] [bbotk] Result of batch 47:
INFO  [19:22:27.079] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:22:27.079] [bbotk]              -4.296141                         0.1922393
INFO  [19:22:27.079] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:22:27.079] [bbotk]                         0.5361048         -0.04237371               -6.89549
INFO  [19:22:27.079] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:22:27.079] [bbotk]                          6                    2862                 0.7885225
INFO  [19:22:27.079] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:22:27.079] [bbotk]  0.006680919 <list[8]>              FALSE     0.03273139        0      0
INFO  [19:22:27.079] [bbotk]  runtime_learners                                uhash
INFO  [19:22:27.079] [bbotk]           140.465 494b83fa-8be6-454a-84be-f08f8d52e1f3
INFO  [19:22:29.918] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 78 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:22:38.889] [bbotk] Evaluating 1 configuration(s)
INFO  [19:22:39.164] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:22:39.316] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -902.5101
[1] -36.50334
[1] -87.38325
[1] -3.994819
[1] -26.91188
[1] 72.84605
[1] -48.48002
[1] 27.93005
[1] -1366.765
[1] -64.17097
INFO  [19:23:46.775] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -198.33
[1] 20.39278
[1] -16.03993
[1] 145.8689
[1] -62.72991
[1] 408.3754
[1] -613.4419
[1] -3.911019
[1] -28.92078
[1] 31.10818
INFO  [19:24:44.298] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -21.00789
[1] 45.99203
[1] 34.46822
[1] 843.2276
[1] -106.7593
[1] 30.8144
[1] -14980.4
[1] -621.2313
[1] -40.46999
[1] 28.99732
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:25:44.564] [mlr3] Finished benchmark
INFO  [19:25:45.082] [bbotk] Result of batch 48:
INFO  [19:25:45.120] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:25:45.120] [bbotk]              -5.240344                         0.2854525
INFO  [19:25:45.120] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:25:45.120] [bbotk]                         0.9351058           -1.929778              -2.507721
INFO  [19:25:45.120] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:25:45.120] [bbotk]                         18                    3645                 0.4615455
INFO  [19:25:45.120] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:25:45.120] [bbotk]  0.006530216 <list[8]>              FALSE     0.02354061        0      0
INFO  [19:25:45.120] [bbotk]  runtime_learners                                uhash
INFO  [19:25:45.120] [bbotk]           184.651 3c5c3612-4224-4bf4-bae6-b1925fcb3e42
INFO  [19:25:46.714] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 79 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:25:58.209] [bbotk] Evaluating 1 configuration(s)
INFO  [19:25:58.295] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:25:58.329] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -51.84127
[1] 17.82568
[1] -1355.273
[1] -65.7827
[1] -2458.459
[1] -41.09897
[1] -275.8153
[1] 7.560327
[1] -130.5857
[1] 17.8919
INFO  [19:26:40.136] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -32.23537
[1] 49.23223
[1] -33.80524
[1] 13.32104
[1] -83.97689
[1] 14.148
[1] -90.06473
[1] 23.07247
[1] -65.8372
[1] 39.71486
INFO  [19:27:54.358] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -54.26279
[1] 27.32975
[1] -18.03143
[1] 59.37015
[1] -38.30607
[1] 58.75115
[1] -66.8095
[1] 34.83458
[1] -22.75755
[1] 62.92132
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:28:31.996] [mlr3] Finished benchmark
INFO  [19:28:32.273] [bbotk] Result of batch 49:
INFO  [19:28:32.546] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:28:32.546] [bbotk]             -0.5615356                         0.3475507
INFO  [19:28:32.546] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:28:32.546] [bbotk]                         0.2838521           -0.243394              -5.042625
INFO  [19:28:32.546] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:28:32.546] [bbotk]                          1                    4080                 0.7708114
INFO  [19:28:32.546] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:28:32.546] [bbotk]  0.005954963 <list[8]>              FALSE      0.0243475        0      0
INFO  [19:28:32.546] [bbotk]  runtime_learners                                uhash
INFO  [19:28:32.546] [bbotk]           153.185 672e6fe9-cd54-4817-be61-95d897450722
INFO  [19:28:44.345] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 80 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:29:14.336] [bbotk] Evaluating 1 configuration(s)
INFO  [19:29:15.272] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:29:15.625] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -160.9918
[1] 59.44844
[1] 9.143652e+14
[1] 6.039953e+16
[1] -188.4779
[1] -0.8288334
[1] -152.7345
[1] -3.719357
[1] -83.7228
[1] 61.7684
INFO  [19:30:10.053] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -87.38363
[1] 166.5282
[1] -111.9161
[1] 8.581475
[1] -143.1421
[1] 99.12178
[1] -377.8677
[1] -5.018786
[1] -133.8444
[1] 67.02763
INFO  [19:31:40.820] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -115.1067
[1] 148.0578
[1] -38.19278
[1] 97.93824
[1] -7169.881
[1] -128.6541
[1] -73.29678
[1] 37.80245
[1] -69.65545
[1] 53.74364
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:32:34.938] [mlr3] Finished benchmark
INFO  [19:32:36.080] [bbotk] Result of batch 50:
INFO  [19:32:36.180] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:32:36.180] [bbotk]              -4.494102                         0.4177823
INFO  [19:32:36.180] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:32:36.180] [bbotk]                         0.1471849           -4.659745               3.540011
INFO  [19:32:36.180] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:32:36.180] [bbotk]                         10                    4505                 0.3464457
INFO  [19:32:36.180] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:32:36.180] [bbotk]  0.005124344 <list[8]>              FALSE     0.03211983        0      0
INFO  [19:32:36.180] [bbotk]  runtime_learners                                uhash
INFO  [19:32:36.180] [bbotk]           198.983 afd71d49-c30b-47b3-a1da-b90c68b829c6
INFO  [19:32:42.820] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 81 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:32:57.358] [bbotk] Evaluating 1 configuration(s)
INFO  [19:32:57.825] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:32:57.936] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -88.90144
[1] 5.637923
[1] -90.32586
[1] 96.09905
[1] -48.28125
[1] 23.02781
[1] -46.19073
[1] 13.75101
[1] -4.596787
[1] 252.6437
INFO  [19:33:51.385] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -21.22953
[1] 63.11204
[1] -39.37924
[1] 21.0719
[1] -112.5733
[1] -3.510371
[1] -10.23347
[1] 178.4658
[1] -32.31494
[1] 33.90126
INFO  [19:34:47.185] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -28.01249
[1] 86.11235
[1] -4034.992
[1] -48.52688
[1] -58.38719
[1] 49.37096
[1] -40.06931
[1] 25.41649
[1] -30.90805
[1] 80.14076
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:35:57.696] [mlr3] Finished benchmark
INFO  [19:35:58.318] [bbotk] Result of batch 51:
INFO  [19:35:58.443] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:35:58.443] [bbotk]              -3.489779                         0.1033949
INFO  [19:35:58.443] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:35:58.443] [bbotk]                         0.9691774          -0.7050968              -2.603995
INFO  [19:35:58.443] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:35:58.443] [bbotk]                          2                    4382                 0.1831104
INFO  [19:35:58.443] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:35:58.443] [bbotk]  0.005152378 <list[8]>              FALSE       0.024601        0      0
INFO  [19:35:58.443] [bbotk]  runtime_learners                                uhash
INFO  [19:35:58.443] [bbotk]           179.249 0d18903b-ca3a-41a8-b8d9-0116166911a9
INFO  [19:36:01.201] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 82 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:36:25.338] [bbotk] Evaluating 1 configuration(s)
INFO  [19:36:25.479] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:36:25.578] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -78.36072
[1] 12.21868
[1] -59.03381
[1] 26.96756
[1] -239.415
[1] 67.05237
[1] -195.5812
[1] -4.013831
[1] -3821.3
[1] -57.74341
INFO  [19:36:51.091] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -121.0063
[1] -3.97713
[1] -79.468
[1] -4.206425
[1] -24.98412
[1] 80.08165
[1] -12.26215
[1] 79.86373
[1] -146.6204
[1] -3.602551
INFO  [19:37:16.646] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 62.023
[1] 1732.374
[1] -15.26812
[1] 58.2237
[1] -99.6081
[1] 20.10471
[1] -36.18582
[1] 16.63542
[1] -13.97534
[1] 33.31067
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:37:39.793] [mlr3] Finished benchmark
INFO  [19:37:41.084] [bbotk] Result of batch 52:
INFO  [19:37:41.110] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:37:41.110] [bbotk]              -4.998074                         0.4959054
INFO  [19:37:41.110] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:37:41.110] [bbotk]                         0.2751964           -3.220712             -0.2819603
INFO  [19:37:41.110] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:37:41.110] [bbotk]                         15                     432                  0.961084
INFO  [19:37:41.110] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:37:41.110] [bbotk]  0.005673571 <list[8]>              FALSE      0.0269972        0      0
INFO  [19:37:41.110] [bbotk]  runtime_learners                                uhash
INFO  [19:37:41.110] [bbotk]            74.018 0cd9f2a7-6d90-4cf6-9cd0-b0bcf8b906a6
INFO  [19:37:46.872] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 83 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:38:01.492] [bbotk] Evaluating 1 configuration(s)
INFO  [19:38:01.918] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:38:02.166] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -159.1496
[1] -3.883272
[1] 47.96284
[1] 1290.839
[1] -127.666
[1] -3.868894
[1] -60.69019
[1] 24.10271
[1] -2747.743
[1] -97.65063
INFO  [19:39:12.257] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -175.1546
[1] -3.302623
[1] -40.35544
[1] 17.2508
[1] -6971.539
[1] -191.5088
[1] -221.2796
[1] 17.22481
[1] 217.2555
[1] 4737.641
INFO  [19:40:30.955] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 23.78121
[1] 581.2621
[1] -53.91561
[1] 86.7503
[1] -20332.2
[1] -712.2667
[1] -88.65136
[1] 7.639553
[1] -6.974935
[1] 58.89882
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:41:58.288] [mlr3] Finished benchmark
INFO  [19:41:58.452] [bbotk] Result of batch 53:
INFO  [19:41:58.478] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:41:58.478] [bbotk]              -1.288877                           0.85427
INFO  [19:41:58.478] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:41:58.478] [bbotk]                         0.4046774           -3.827959             -0.7675294
INFO  [19:41:58.478] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:41:58.478] [bbotk]                         18                    4985                 0.5286469
INFO  [19:41:58.478] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:41:58.478] [bbotk]  0.005488009 <list[8]>              FALSE     0.02308964        0      0
INFO  [19:41:58.478] [bbotk]  runtime_learners                                uhash
INFO  [19:41:58.478] [bbotk]           234.076 eb46b8da-4def-47d3-aca9-ba008f711fe7
INFO  [19:41:59.819] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 84 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:42:24.242] [bbotk] Evaluating 1 configuration(s)
INFO  [19:42:24.410] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:42:24.485] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -64.05778
[1] 138.3539
[1] -30.84138
[1] 14.15456
[1] 27.82729
[1] 1070.34
[1] -36.78352
[1] 36.92516
[1] -400.3294
[1] 5.564163
INFO  [19:43:26.989] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -71.02752
[1] 2.401248
[1] -256.3737
[1] -3.902719
[1] -117.5877
[1] 153.0886
[1] -53.50378
[1] 33.91152
[1] -102.5345
[1] 30.90226
INFO  [19:44:28.268] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -119.86
[1] 226.1424
[1] -20.34671
[1] 40.5223
[1] -99.77432
[1] 78.58827
[1] -10.83393
[1] 167.4626
[1] -71.75366
[1] 24.89282
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:46:01.637] [mlr3] Finished benchmark
INFO  [19:46:04.347] [bbotk] Result of batch 54:
INFO  [19:46:04.370] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:46:04.370] [bbotk]              -4.686635                          0.338685
INFO  [19:46:04.370] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:46:04.370] [bbotk]                         0.6259283           -0.688941              0.6340077
INFO  [19:46:04.370] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:46:04.370] [bbotk]                          9                    4538                  0.500899
INFO  [19:46:04.370] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:46:04.370] [bbotk]  0.004954192 <list[8]>              FALSE     0.02667947        0      0
INFO  [19:46:04.370] [bbotk]  runtime_learners                                uhash
INFO  [19:46:04.370] [bbotk]           216.688 aeb52843-1f6e-4b9f-a226-c29aaeca29a0
INFO  [19:46:05.421] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 85 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:46:21.061] [bbotk] Evaluating 1 configuration(s)
INFO  [19:46:21.391] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:46:21.660] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -10.71134
[1] 40.2182
[1] -60.30853
[1] 113.7326
[1] -20.46281
[1] 22.93575
[1] -24.41244
[1] 6.762973
[1] -120.776
[1] 14.12391
INFO  [19:47:06.301] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 54.56515
[1] 1399.924
[1] -46.4965
[1] 36.2512
[1] -35.45433
[1] 5.635129
[1] -29.47771
[1] 25.9649
[1] -164.3997
[1] -4.069602
INFO  [19:48:24.862] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -23.12608
[1] 30.49856
[1] -12.60637
[1] 23.90578
[1] -20.02568
[1] 34.7586
[1] -19.91554
[1] 20.91864
[1] -55.18138
[1] 82.69766
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:49:19.946] [mlr3] Finished benchmark
INFO  [19:49:20.172] [bbotk] Result of batch 55:
INFO  [19:49:20.189] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:49:20.189] [bbotk]              -3.491129                         0.1381592
INFO  [19:49:20.189] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:49:20.189] [bbotk]                         0.9957352          -0.3179536              -2.796097
INFO  [19:49:20.189] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:49:20.189] [bbotk]                         17                    3675                 0.2551515
INFO  [19:49:20.189] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:49:20.189] [bbotk]  0.005544356 <list[8]>              FALSE     0.02339016        0      0
INFO  [19:49:20.189] [bbotk]  runtime_learners                                uhash
INFO  [19:49:20.189] [bbotk]           177.387 aef5222c-a516-4690-83d0-a4e73613aaf3
INFO  [19:49:21.617] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 86 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:49:44.163] [bbotk] Evaluating 1 configuration(s)
INFO  [19:49:44.269] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:49:44.519] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -117.4887
[1] -3.965965
[1] -4.378392e+16
[1] 3.449092e+15
[1] 88.7294
[1] 3595.094
[1] -1900.53
[1] -54.159
[1] -191.2184
[1] 14.79966
INFO  [19:51:06.451] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -3845.006
[1] -87.07959
[1] -401.2153
[1] 6.827407
[1] -52.17265
[1] 11.36316
[1] -3.006943e+16
[1] 2.787183e+16
[1] -1070.482
[1] -33.28189
INFO  [19:52:36.761] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -110.3401
[1] 26.70551
[1] -140.2747
[1] 60.43433
[1] -51.72911
[1] 56.06869
[1] -126.5858
[1] 35.01033
[1] -41.9292
[1] 56.40889
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:53:44.356] [mlr3] Finished benchmark
INFO  [19:53:44.715] [bbotk] Result of batch 56:
INFO  [19:53:44.732] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:53:44.732] [bbotk]              -6.878385                         0.1793412
INFO  [19:53:44.732] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:53:44.732] [bbotk]                         0.1668753           -2.614386              -2.435383
INFO  [19:53:44.732] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:53:44.732] [bbotk]                         15                    4962                 0.1889883
INFO  [19:53:44.732] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:53:44.732] [bbotk]  0.004444456 <list[8]>              FALSE     0.02106051        0      0
INFO  [19:53:44.732] [bbotk]  runtime_learners                                uhash
INFO  [19:53:44.732] [bbotk]            239.04 2cdeecb8-91c3-41ad-92fd-bf48285f4f90
INFO  [19:53:47.382] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 87 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:53:59.845] [bbotk] Evaluating 1 configuration(s)
INFO  [19:54:00.000] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:54:00.032] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -2976.116
[1] -59.90034
[1] -1984.31
[1] -45.74661
[1] 1418.504
[1] 64324.04
[1] -198.996
[1] -3.806468
[1] -37.7462
[1] 20.27545
INFO  [19:54:54.098] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -56.43888
[1] 14.82612
[1] -148.2634
[1] 3.624447
[1] -135.8148
[1] -3.798587
[1] -24.23775
[1] 155.9865
[1] -36.43079
[1] 109.8812
INFO  [19:55:31.897] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2239.181
[1] -44.04885
[1] -56.2272
[1] 70.03609
[1] -28.90165
[1] 194.8522
[1] -32.73751
[1] 34.23286
[1] -3265.223
[1] -80.41855
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:56:22.219] [mlr3] Finished benchmark
INFO  [19:56:23.072] [bbotk] Result of batch 57:
INFO  [19:56:23.137] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:56:23.137] [bbotk]               -6.55551                         0.1975705
INFO  [19:56:23.137] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:56:23.137] [bbotk]                          0.863127           -2.775916              -2.867566
INFO  [19:56:23.137] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:56:23.137] [bbotk]                         15                    3898                 0.2087144
INFO  [19:56:23.137] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:56:23.137] [bbotk]  0.004694057 <list[8]>              FALSE      0.0219208        0      0
INFO  [19:56:23.137] [bbotk]  runtime_learners                                uhash
INFO  [19:56:23.137] [bbotk]           141.626 f40f8ed9-0085-4616-8c88-7490e5a42b3b
INFO  [19:56:29.066] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 88 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:56:45.771] [bbotk] Evaluating 1 configuration(s)
INFO  [19:56:45.994] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:56:46.089] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -336.4474
[1] -3.794361
[1] -108.3627
[1] 4.114449
[1] -47.68089
[1] 81.68727
[1] -183.1416
[1] 15.37553
[1] -120.4664
[1] 63.5319
INFO  [19:57:40.918] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -88.55533
[1] 8.909155
[1] -211.5874
[1] 18.02427
[1] -67.13121
[1] 8.548737
[1] -3235.479
[1] -159.6314
[1] -2263.399
[1] -43.7809
INFO  [19:58:48.035] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -76.08963
[1] 48.11698
[1] -115.285
[1] 26.54102
[1] -25.1829
[1] 37.13983
[1] -92.51842
[1] 91.8309
[1] -31.83896
[1] 88.22169
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:00:11.902] [mlr3] Finished benchmark
INFO  [20:00:12.200] [bbotk] Result of batch 58:
INFO  [20:00:12.213] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:00:12.213] [bbotk]              -3.264304                         0.2913712
INFO  [20:00:12.213] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:00:12.213] [bbotk]                         0.3527945           -1.813192              -6.873068
INFO  [20:00:12.213] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:00:12.213] [bbotk]                         15                    4958                 0.2348039
INFO  [20:00:12.213] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:00:12.213] [bbotk]  0.004541663 <list[8]>              FALSE     0.02074814        0      0
INFO  [20:00:12.213] [bbotk]  runtime_learners                                uhash
INFO  [20:00:12.213] [bbotk]           205.295 d9a6a582-ce4f-4b2c-8802-7b881f63372b
INFO  [20:00:18.824] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 89 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:00:34.785] [bbotk] Evaluating 1 configuration(s)
INFO  [20:00:35.215] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:00:35.367] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -122.6742
[1] 85.21125
[1] -48.46382
[1] 17.2052
[1] -59.7397
[1] 18.15597
[1] -2528.802
[1] -99.3377
[1] -66.4406
[1] -3.861551
INFO  [20:01:41.969] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -20.83448
[1] 343.133
[1] -363.9741
[1] -3.815733
[1] -172.3582
[1] 32.26345
[1] -137.9343
[1] 87.44113
[1] -35.69541
[1] 19.38705
INFO  [20:03:05.622] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 110.6752
[1] 3201.138
[1] -9.824696
[1] 117.4504
[1] -89.45212
[1] 84.16358
[1] -102.4564
[1] 9.580596
[1] -28.68738
[1] 30.21594
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:04:09.750] [mlr3] Finished benchmark
INFO  [20:04:11.273] [bbotk] Result of batch 59:
INFO  [20:04:11.318] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:04:11.318] [bbotk]             -0.3046638                         0.3250073
INFO  [20:04:11.318] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:04:11.318] [bbotk]                         0.8574105           -1.264376              -6.260669
INFO  [20:04:11.318] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:04:11.318] [bbotk]                          8                    3468                 0.5389698
INFO  [20:04:11.318] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:04:11.318] [bbotk]  0.004154475 <list[8]>              FALSE     0.02509126        0      0
INFO  [20:04:11.318] [bbotk]  runtime_learners                                uhash
INFO  [20:04:11.318] [bbotk]           213.633 0d89f114-e0d2-4ae3-af04-07a843f5f950
INFO  [20:04:16.767] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 90 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:04:28.046] [bbotk] Evaluating 1 configuration(s)
INFO  [20:04:28.091] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:04:28.115] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -45.828
[1] 63.87884
[1] -238.8443
[1] 65.71036
[1] -62.301
[1] 23.39133
[1] -3251.648
[1] -104.9328
[1] -152.4784
[1] -3.780052
INFO  [20:05:52.577] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -19.01109
[1] 153.5937
[1] -1811.509
[1] -42.51212
[1] -70.88371
[1] 35.30996
[1] -250.9053
[1] 148.9071
[1] -102.6346
[1] 16.77716
INFO  [20:07:12.609] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -103.2311
[1] 75.6566
[1] -49.42046
[1] 19.7905
[1] -42.90701
[1] 70.00093
[1] -62.29995
[1] 54.55656
[1] -35.23745
[1] 125.4878
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:08:50.075] [mlr3] Finished benchmark
INFO  [20:08:51.177] [bbotk] Result of batch 60:
INFO  [20:08:51.260] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:08:51.260] [bbotk]               1.082086                         0.3904684
INFO  [20:08:51.260] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:08:51.260] [bbotk]                         0.5939189             -2.4013              -1.911699
INFO  [20:08:51.260] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:08:51.260] [bbotk]                         11                    4589                 0.5935113
INFO  [20:08:51.260] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:08:51.260] [bbotk]  0.005369249 <list[8]>              FALSE      0.0292274        0      0
INFO  [20:08:51.260] [bbotk]  runtime_learners                                uhash
INFO  [20:08:51.260] [bbotk]           260.887 5c160978-19e9-45ca-b941-1b390d7258de
INFO  [20:09:13.136] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 91 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:09:47.894] [bbotk] Evaluating 1 configuration(s)
INFO  [20:09:47.997] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:09:48.286] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -13077.41
[1] -353.922
[1] -285.377
[1] -3.497488
[1] -1569.996
[1] -39.20487
[1] -48.13842
[1] 19.44716
[1] -1.071573e+16
[1] 2.277821e+16
INFO  [20:10:33.643] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -85.61793
[1] 32.20698
[1] -19.25312
[1] 124.9434
[1] -129.2091
[1] -3.33709
[1] -331.3514
[1] 11.57425
[1] -43.81052
[1] 316.4495
INFO  [20:11:04.363] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -84.21218
[1] 34.99404
[1] -964.8746
[1] -32.20185
[1] -241.4329
[1] 178.2834
[1] 1281.964
[1] 37493.64
[1] -46.72483
[1] 178.8711
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:11:46.974] [mlr3] Finished benchmark
INFO  [20:11:49.342] [bbotk] Result of batch 61:
INFO  [20:11:49.351] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:11:49.351] [bbotk]             -0.8960226                         0.8966975
INFO  [20:11:49.351] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:11:49.351] [bbotk]                         0.9118949           -4.139421              -4.340553
INFO  [20:11:49.351] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:11:49.351] [bbotk]                         15                    4193                 0.2291926
INFO  [20:11:49.351] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:11:49.351] [bbotk]  0.004736257 <list[8]>              FALSE     0.02356984        0      0
INFO  [20:11:49.351] [bbotk]  runtime_learners                                uhash
INFO  [20:11:49.351] [bbotk]           118.195 afc736d8-4375-44bd-8dfc-72940746e4c1
INFO  [20:11:51.487] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 92 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:11:57.417] [bbotk] Evaluating 1 configuration(s)
INFO  [20:11:57.441] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:11:57.458] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -56.0425
[1] 15.67105
[1] -43.58449
[1] 20.31042
[1] -1590.532
[1] -64.31803
[1] -58.49927
[1] 35.58635
[1] -325.1283
[1] -3.9941
INFO  [20:13:14.062] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -403.294
[1] 11.00414
[1] -84.11948
[1] 5.620211
[1] -42.80194
[1] 38.57218
[1] -27.74229
[1] 66.11688
[1] -155.8562
[1] -1.798054
INFO  [20:14:12.052] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2701.009
[1] -99.38859
[1] -282.3352
[1] 6.644846
[1] -33.65012
[1] 33.76787
[1] 96.31752
[1] 3054.059
[1] -68.35116
[1] 37.27503
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:16:15.494] [mlr3] Finished benchmark
INFO  [20:16:16.127] [bbotk] Result of batch 62:
INFO  [20:16:16.137] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:16:16.137] [bbotk]              -0.440571                          0.628059
INFO  [20:16:16.137] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:16:16.137] [bbotk]                         0.9629932         -0.01699696               5.232705
INFO  [20:16:16.137] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:16:16.137] [bbotk]                         13                    3041                 0.8421179
INFO  [20:16:16.137] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:16:16.137] [bbotk]  0.004479633 <list[8]>              FALSE     0.02936619        0      0
INFO  [20:16:16.137] [bbotk]  runtime_learners                                uhash
INFO  [20:16:16.137] [bbotk]           257.454 bdd938ec-b489-4232-a050-3217c4dd7cbc
INFO  [20:16:16.873] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 93 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:16:27.844] [bbotk] Evaluating 1 configuration(s)
INFO  [20:16:27.920] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:16:27.945] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -10.03389
[1] 90.25626
[1] 50.66263
[1] 1480.431
[1] -96.54593
[1] 20.22514
[1] -70.72366
[1] 12.66149
[1] -318.4871
[1] -3.964616
INFO  [20:16:50.335] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -76.61412
[1] 16.56743
[1] -83.96032
[1] 55.99403
[1] -51.84505
[1] 14.06412
[1] -144.3995
[1] -1.280705
[1] -99.38206
[1] 38.33315
INFO  [20:17:11.828] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -256.7232
[1] 59.17048
[1] -28.34825
[1] 56.77217
[1] -3680.018
[1] -107.7517
[1] -34.64814
[1] 51.96558
[1] -35.89747
[1] 40.89069
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:18:17.496] [mlr3] Finished benchmark
INFO  [20:18:17.647] [bbotk] Result of batch 63:
INFO  [20:18:17.722] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:18:17.722] [bbotk]              -3.139019                         0.7739737
INFO  [20:18:17.722] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:18:17.722] [bbotk]                         0.1090661           -1.138063              -3.451178
INFO  [20:18:17.722] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:18:17.722] [bbotk]                          5                    3093                 0.3432296
INFO  [20:18:17.722] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:18:17.722] [bbotk]  0.004431672 <list[8]>              FALSE     0.02503508        0      0
INFO  [20:18:17.722] [bbotk]  runtime_learners                                uhash
INFO  [20:18:17.722] [bbotk]           109.238 3ff3a02c-b8fe-4962-aaa4-ababc7779d84
INFO  [20:18:18.558] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 94 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:18:31.830] [bbotk] Evaluating 1 configuration(s)
INFO  [20:18:32.296] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:18:32.313] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 75.73854
[1] 4009.621
[1] 3416.522
[1] 171315.4
[1] -1660.005
[1] -29.28333
[1] -1943.33
[1] -35.30287
[1] -1596.44
[1] -29.39484
INFO  [20:19:00.381] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1814.447
[1] -32.59377
[1] 37.94872
[1] 1971.52
[1] -2480.772
[1] -42.23843
[1] 36.1966
[1] 1854.969
[1] -5637.574
[1] -101.9771
INFO  [20:19:25.778] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 38.80559
[1] 1957.901
[1] -1688.544
[1] 64.51848
[1] -50159.8
[1] -932.9538
[1] -977.0167
[1] 631.2549
[1] 44.80275
[1] 2256.67
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:20:54.434] [mlr3] Finished benchmark
INFO  [20:20:54.696] [bbotk] Result of batch 64:
INFO  [20:20:54.706] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:20:54.706] [bbotk]              -4.730281                         0.1178433
INFO  [20:20:54.706] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:20:54.706] [bbotk]                         0.9854264           -7.077895               6.904339
INFO  [20:20:54.706] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:20:54.706] [bbotk]                          5                    4384                 0.9118293
INFO  [20:20:54.706] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:20:54.706] [bbotk]  0.004352445 <list[8]>              FALSE      0.1723003        0      0
INFO  [20:20:54.706] [bbotk]  runtime_learners                                uhash
INFO  [20:20:54.706] [bbotk]            141.74 da703030-d2bd-4f95-9c18-cd0138a3694a
INFO  [20:20:58.781] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 95 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:21:09.119] [bbotk] Evaluating 1 configuration(s)
INFO  [20:21:09.142] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:21:09.197] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -647.5532
[1] -7.631555
[1] -256.1552
[1] -3.359095
[1] -42.28218
[1] 28.34369
[1] -631.939
[1] 12.34818
[1] -224.3926
[1] -4.042867
INFO  [20:21:49.766] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -36.13659
[1] 126.0554
[1] -37.29717
[1] 58.83767
[1] -64.66799
[1] 15.6031
[1] -114.9612
[1] -3.777611
[1] -1.974569e+16
[1] 1.804611e+16
INFO  [20:23:05.190] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -40.86547
[1] 47.35266
[1] -22.32932
[1] 67.13931
[1] -43.79713
[1] 59.45825
[1] -24.33152
[1] 54.41295
[1] -112.419
[1] 22.5437
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:23:52.013] [mlr3] Finished benchmark
INFO  [20:23:52.102] [bbotk] Result of batch 65:
INFO  [20:23:52.123] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:23:52.123] [bbotk]              -3.095165                         0.1267143
INFO  [20:23:52.123] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:23:52.123] [bbotk]                         0.3000447           -2.740305              -6.687353
INFO  [20:23:52.123] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:23:52.123] [bbotk]                          6                    2906                 0.9468085
INFO  [20:23:52.123] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:23:52.123] [bbotk]  0.008424373 <list[8]>              FALSE     0.02258056        0      0
INFO  [20:23:52.123] [bbotk]  runtime_learners                                uhash
INFO  [20:23:52.123] [bbotk]           162.314 4a1d8e69-bd22-4e69-84f9-4a21b6fac776
INFO  [20:23:54.596] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 96 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:24:06.759] [bbotk] Evaluating 1 configuration(s)
INFO  [20:24:06.945] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:24:06.957] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -197.9051
[1] 21.09873
[1] -245.9022
[1] -5.152345
[1] -155.9358
[1] 166.0913
[1] -315.8369
[1] -6.477375
[1] 7.302456
[1] 334.2652
INFO  [20:24:28.571] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -151.4061
[1] 257.3056
[1] -54.04221
[1] 366.8706
[1] 5.997063
[1] 272.6648
[1] -168.6202
[1] -3.629476
[1] -133.3103
[1] 445.953
INFO  [20:24:49.565] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -144.5937
[1] 117.9449
[1] -282.2424
[1] -7.160606
[1] -58.58497
[1] 202.2514
[1] -23.21747
[1] 354.979
[1] 6.701943
[1] 268.4929
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:25:10.582] [mlr3] Finished benchmark
INFO  [20:25:10.806] [bbotk] Result of batch 66:
INFO  [20:25:10.882] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:25:10.882] [bbotk]               1.417752                         0.7234338
INFO  [20:25:10.882] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:25:10.882] [bbotk]                         0.9142184           -2.731212               1.015528
INFO  [20:25:10.882] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:25:10.882] [bbotk]                         12                      17                 0.9853789
INFO  [20:25:10.882] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:25:10.882] [bbotk]  0.008558644 <list[8]>              FALSE     0.04632032        0      0
INFO  [20:25:10.882] [bbotk]  runtime_learners                                uhash
INFO  [20:25:10.882] [bbotk]             63.34 a3bdb65b-ba8f-447f-9b2b-3e26878b916f
INFO  [20:25:12.827] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 97 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:25:22.333] [bbotk] Evaluating 1 configuration(s)
INFO  [20:25:22.562] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:25:22.596] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1623.057
[1] -32.21704
[1] -190.4752
[1] -3.245772
[1] -42.10869
[1] 84.60461
[1] -157.7924
[1] 7.718705
[1] 55.26661
[1] 1271.028
INFO  [20:25:41.054] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -2243.561
[1] -82.29868
[1] -68.51981
[1] 66.14316
[1] -115.7368
[1] 20.07954
[1] -1431.09
[1] -49.13453
[1] -224.1165
[1] -4.033074
INFO  [20:25:57.686] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -271.2776
[1] 25.43055
[1] -44.45161
[1] 85.67714
[1] -46.89691
[1] 30.11276
[1] -40.45095
[1] 146.1014
[1] 55.40064
[1] 2017.399
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:26:41.842] [mlr3] Finished benchmark
INFO  [20:26:42.029] [bbotk] Result of batch 67:
INFO  [20:26:42.039] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:26:42.039] [bbotk]              -6.551291                         0.2891369
INFO  [20:26:42.039] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:26:42.039] [bbotk]                         0.6134877           -3.588819              0.3046333
INFO  [20:26:42.039] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:26:42.039] [bbotk]                          9                    4004                  0.187547
INFO  [20:26:42.039] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:26:42.039] [bbotk]  0.008196025 <list[8]>              FALSE      0.0222736        0      0
INFO  [20:26:42.039] [bbotk]  runtime_learners                                uhash
INFO  [20:26:42.039] [bbotk]            79.133 d6416027-d8c1-4493-b9b5-767d878feb6a
INFO  [20:26:48.419] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 98 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:26:57.218] [bbotk] Evaluating 1 configuration(s)
INFO  [20:26:57.247] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:26:57.284] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -244.2529
[1] 14.59171
[1] -4650.316
[1] -55.47925
[1] -68.10174
[1] 28.63456
[1] -62.4426
[1] 118.1691
[1] -136.4854
[1] 8.469945
INFO  [20:27:51.618] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -19.47015
[1] 36.18856
[1] -23.25432
[1] 184.7443
[1] -144.2182
[1] -4.262237
[1] -95.52136
[1] 51.02849
[1] -83.04295
[1] 55.60719
INFO  [20:28:23.241] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -12.70124
[1] 76.95707
[1] -69.88946
[1] 12.62759
[1] -2739.138
[1] -60.15873
[1] -12.78408
[1] 73.19385
[1] -3722.032
[1] -83.07295
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:29:19.272] [mlr3] Finished benchmark
INFO  [20:29:19.337] [bbotk] Result of batch 68:
INFO  [20:29:19.359] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:29:19.359] [bbotk]              -4.012868                         0.1023521
INFO  [20:29:19.359] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:29:19.359] [bbotk]                         0.1618784           -4.768137              -5.464516
INFO  [20:29:19.359] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:29:19.359] [bbotk]                          7                    2581                 0.8190273
INFO  [20:29:19.359] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:29:19.359] [bbotk]  0.01107499 <list[8]>              FALSE     0.02476531        0      0
INFO  [20:29:19.359] [bbotk]  runtime_learners                                uhash
INFO  [20:29:19.359] [bbotk]           141.785 3a7143ed-a554-419f-b107-a319f7fb90e6
INFO  [20:29:21.921] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 99 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:29:31.101] [bbotk] Evaluating 1 configuration(s)
INFO  [20:29:31.166] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:29:31.209] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -752.5362
[1] -51.32581
[1] -69.95894
[1] 11.54518
[1] -956.4441
[1] -43.38521
[1] -49.79618
[1] 62.25383
[1] 71.64987
[1] 1835.39
INFO  [20:30:07.960] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -47.21579
[1] 26.49596
[1] -102.4104
[1] 7.392279
[1] -3068.982
[1] -68.71039
[1] -46.74126
[1] 60.40843
[1] -24.98783
[1] 106.1542
INFO  [20:31:06.203] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2177.401
[1] -44.4964
[1] -60.92737
[1] 62.32473
[1] -34.83371
[1] 33.34872
[1] -44.24352
[1] 146.3608
[1] -32.54585
[1] 71.33716
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:31:56.650] [mlr3] Finished benchmark
INFO  [20:31:56.724] [bbotk] Result of batch 69:
INFO  [20:31:56.755] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:31:56.755] [bbotk]              -4.213681                         0.7200497
INFO  [20:31:56.755] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:31:56.755] [bbotk]                          0.307913           -3.578477              0.8362037
INFO  [20:31:56.755] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:31:56.755] [bbotk]                         16                    3608                 0.4857948
INFO  [20:31:56.755] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:31:56.755] [bbotk]  0.007188395 <list[8]>              FALSE     0.02285384        0      0
INFO  [20:31:56.755] [bbotk]  runtime_learners                                uhash
INFO  [20:31:56.755] [bbotk]           145.261 175e8a63-3439-469d-a16f-920995e52d78
INFO  [20:31:58.860] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 100 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:31:58.987] [bbotk] Finished optimizing after 100 evaluation(s)
INFO  [20:31:58.989] [bbotk] Result:
INFO  [20:31:58.994] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:31:58.994] [bbotk]                  <num>                             <num>
INFO  [20:31:58.994] [bbotk]              -6.129082                         0.2013105
INFO  [20:31:58.994] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:31:58.994] [bbotk]                             <num>               <num>                  <num>
INFO  [20:31:58.994] [bbotk]                         0.3732691            -2.02822                2.35622
INFO  [20:31:58.994] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:31:58.994] [bbotk]                      <int>                   <int>                     <num>
INFO  [20:31:58.994] [bbotk]                         17                    4476                 0.3583935
INFO  [20:31:58.994] [bbotk]  learner_param_vals  x_domain classif.bbrier
INFO  [20:31:58.994] [bbotk]              <list>    <list>          <num>
INFO  [20:31:58.994] [bbotk]          <list[10]> <list[8]>     0.02055137
[1] -59.21448
[1] 20.20863
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] -167.9306
[1] -4.456544
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] -125.2076
[1] 86.3481
[1] -51.94548
[1] 28.9183
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] -129.0114
[1] 14.87516

### [bt]: Job terminated successfully [batchtools job.id=1414]
### [bt]: Calculation finished!
