### [bt]: This is batchtools v0.9.17
### [bt]: Starting calculation of 1 jobs
### [bt]: Setting working directory to '/content/drive/MyDrive/GitHub/Mater_Thesis_Calibration'
ece.R :
Friedmann_tasks.R :
Functions.R :
ici.R :
mse_feature_effects.R :
PipeOpCalibration_TuningExperiment.R :
PipeOpCalibration.R :
PipeOpCalibrationUnion.R :
### [bt]: Memory measurement disabled
### [bt]: Starting job [batchtools job.id=1413]
### [bt]: Generating problem instance for problem '341ee781c7d79b8f' ...
### [bt]: Applying algorithm 'run_learner' on problem '341ee781c7d79b8f' for job 1413 (seed = 1536) ...
INFO  [16:05:46.412] [mlr3] Applying learner 'xgboost TwP beta' on task 'wdbc' (iter 3/10)
INFO  [16:05:47.504] [bbotk] Starting to optimize 8 parameter(s) with '<OptimizerMbo>' and '<TerminatorEvals> [n_evals=100, k=0]'
INFO  [16:05:56.966] [bbotk] Evaluating 32 configuration(s)
INFO  [16:05:57.244] [mlr3] Running benchmark with 96 resampling iterations
INFO  [16:05:57.324] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -72.83032
[1] 7145.133
[1] -7563.638
[1] -134.3559
[1] 129.2468
[1] 6911.21
[1] 104.482
[1] 5514.703
[1] 123.9174
[1] 6508.566
INFO  [16:06:40.150] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -5005.19
[1] -90.48161
[1] -6099.33
[1] -110.5979
[1] 155.6706
[1] 8179.704
[1] -5461.97
[1] -98.71698
[1] -10519.52
[1] -190.8003
INFO  [16:07:16.194] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 144.0973
[1] 7635.348
[1] -6541.054
[1] -120.1458
[1] -5947.025
[1] -106.5376
[1] 105.9046
[1] 5596.87
[1] 218.2544
[1] 11301.72
INFO  [16:07:39.845] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -123.2545
[1] 26.11357
[1] -32.01388
[1] 137.091
[1] -86.03243
[1] 27.12857
[1] -190.716
[1] 76.89648
[1] -103.5536
[1] 36.97304
INFO  [16:08:36.660] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -383.8195
[1] -2.424223
[1] -69.50604
[1] 153.0986
[1] -117.0378
[1] -3.857497
[1] -108.4526
[1] 61.05972
[1] -276.3687
[1] 18.62676
INFO  [16:09:35.362] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -66.97053
[1] 49.05695
[1] -84.24043
[1] 61.22731
[1] -46.85625
[1] 49.67497
[1] -67.52479
[1] 30.34343
[1] -3985.115
[1] -55.94871
INFO  [16:10:27.296] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:12:14.478] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:13:27.585] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:14:35.126] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -69.68989
[1] 85.57916
[1] -133.3651
[1] 62.45535
[1] -104.9744
[1] 56.66326
[1] -66.61048
[1] 75.32037
[1] -167.5585
[1] 11.92861
INFO  [16:15:33.150] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -39.55534
[1] 100.5928
[1] -22.625
[1] 48.43031
[1] -77.08161
[1] 106.0954
[1] -83.68758
[1] 76.72515
[1] -89.49867
[1] 85.49522
INFO  [16:17:18.048] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -170.8061
[1] 184.1083
[1] -23.1698
[1] 72.37104
[1] -123.312
[1] 37.59228
[1] -28.57298
[1] 105.9209
[1] -87.92091
[1] 36.28995
INFO  [16:18:42.480] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -578.8688
[1] 159.979
[1] -345.0382
[1] 153.468
[1] -508.1075
[1] 212.6214
[1] -1281.836
[1] -21.42699
[1] -987.6554
[1] -18.50798
INFO  [16:20:26.293] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -511.3492
[1] -8.375722
[1] -587.0639
[1] -9.014526
[1] -240.8754
[1] 466.626
[1] -617.3953
[1] 320.787
[1] -208.9978
[1] 352.8253
INFO  [16:22:27.120] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 14.25731
[1] 639.1765
[1] -1258.126
[1] -14.51324
[1] -1744.966
[1] -32.15994
[1] -495.5396
[1] -8.291904
[1] -798.6233
[1] 75.75393
INFO  [16:24:11.923] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -360.6862
[1] 86.68359
[1] -234.3484
[1] 262.6499
[1] 46.53409
[1] 1688.933
[1] 32.46254
[1] 1398.914
[1] -439.7551
[1] -7.488517
INFO  [16:24:48.490] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -172.3737
[1] 369.1948
[1] -191.6521
[1] 266.9554
[1] -297.8293
[1] 452.9707
[1] -27.28158
[1] 436.6618
[1] -552.5943
[1] -7.466497
INFO  [16:25:21.189] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -384.1751
[1] 171.0036
[1] -216.7137
[1] 166.1737
[1] 13.23668
[1] 553.3103
[1] -651.9582
[1] -9.329098
[1] 11.69152
[1] 556.8556
INFO  [16:25:59.618] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:26:54.352] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:27:33.476] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:28:29.482] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -31.64038
[1] 108.3162
[1] -52.3151
[1] 26.21312
[1] -1882.487
[1] -33.14499
[1] -29.55367
[1] 56.32744
[1] -71.19272
[1] 631.4108
INFO  [16:30:04.126] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -122.1115
[1] -4.193839
[1] -113.3082
[1] -4.280754
[1] -64.11894
[1] 73.42853
[1] -40.05683
[1] 131.5856
[1] -165.4511
[1] 22.3189
INFO  [16:31:56.974] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -184.5953
[1] -4.114357
[1] -82.17112
[1] 159.523
[1] -115.3868
[1] 61.78286
[1] -29.41361
[1] 43.06065
[1] -40.8516
[1] 70.10746
INFO  [16:33:53.382] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:34:19.319] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:34:45.014] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:35:08.690] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 18.65854
[1] 952.0301
[1] 20.44994
[1] 978.5975
[1] -487.248
[1] -9.829351
[1] -40508.16
[1] -722.1155
[1] -110.4027
[1] 644.1004
INFO  [16:36:17.632] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1113.796
[1] 11.14515
[1] -675.1873
[1] -11.94407
[1] 18.9483
[1] 963.9416
[1] -614.8924
[1] -11.80903
[1] -750.607
[1] 118.1271
INFO  [16:37:11.433] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 9.077873
[1] 473.5362
[1] 13.41063
[1] 669.8243
[1] 23.42472
[1] 1128.686
[1] -505.1347
[1] -9.550489
[1] 18.98317
[1] 932.3558
INFO  [16:38:09.217] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1303.079
[1] -23.66233
[1] 25.76544
[1] 1253.826
[1] -947.6231
[1] -17.0252
[1] -513.5726
[1] 648.278
[1] 28.46271
[1] 1390.579
INFO  [16:39:31.052] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -961.6064
[1] -15.98341
[1] -1646.87
[1] 569.036
[1] 29.58227
[1] 1472.484
[1] -1098.267
[1] -19.17288
[1] 30.06393
[1] 1557.742
INFO  [16:40:45.305] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 22.86972
[1] 1207.473
[1] 19.99306
[1] 995.9612
[1] -1509.295
[1] -27.67461
[1] -913.4924
[1] 414.1654
[1] 27.40338
[1] 1355.02
INFO  [16:42:05.455] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -49.14735
[1] 12.95499
[1] -15.62899
[1] 87.69236
[1] -35.33684
[1] 89.74156
[1] -28.94929
[1] 24.09933
[1] -1647.538
[1] -31.07867
INFO  [16:42:32.837] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -37.64321
[1] 49.82406
[1] -47.82431
[1] 13.74694
[1] -91.70433
[1] 99.06794
[1] -1275.835
[1] -75.01439
[1] -87.20423
[1] 1.180504
INFO  [16:43:12.975] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -84.1271
[1] 6.162167
[1] -20589.74
[1] -1259.749
[1] -34.34782
[1] 13.30251
[1] 84.69423
[1] 2495.171
[1] -101.9983
[1] -3.990106
INFO  [16:43:45.829] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1095.719
[1] -18.27332
[1] -512.7451
[1] 414.8696
[1] -46758.2
[1] -885.9951
[1] 15.86271
[1] 804.8077
[1] 25.17832
[1] 1313.822
INFO  [16:44:20.649] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 20.40677
[1] 1005.654
[1] -2182.776
[1] -36.58999
[1] -44436.76
[1] -848.4639
[1] -1480.933
[1] -27.4715
[1] -1006.628
[1] -16.66255
INFO  [16:44:57.558] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -989.7861
[1] -16.82248
[1] -323.708
[1] 607.0452
[1] -1279.513
[1] -22.32555
[1] 19.94506
[1] 1035.437
[1] 30.13213
[1] 1646.299
INFO  [16:45:24.624] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:46:27.379] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:47:27.763] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:48:17.805] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -2.538542e+16
[1] 1.235685e+16
[1] -31.82244
[1] 18.1903
[1] -61.56641
[1] 18.30599
[1] -41.88646
[1] 35.00066
[1] -10.1572
[1] 351.3928
INFO  [16:49:46.611] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -40.15251
[1] 9.561408
[1] -133.7187
[1] -2.355688
[1] -36.64428
[1] 24.47269
[1] -2745.538
[1] -75.52822
[1] -42.78134
[1] 30.70214
INFO  [16:50:35.373] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -58.85469
[1] 7.658023
[1] -27.18945
[1] 29.04805
[1] -1521.808
[1] -37.61565
[1] -901.6899
[1] -0.2193601
[1] -70.79659
[1] 2.930034
INFO  [16:51:58.898] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -114.9891
[1] 82.25968
[1] -274.8546
[1] -5.503025
[1] -503.9674
[1] 280.8364
[1] 8.742991
[1] 395.9494
[1] -46.045
[1] 126.8465
INFO  [16:52:49.337] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -159.3652
[1] 91.85815
[1] 6.56957
[1] 262.5176
[1] -39561.49
[1] -660.6458
[1] -135.2896
[1] 44.52544
[1] -88.91536
[1] 75.02262
INFO  [16:53:38.163] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -186.9841
[1] -4.140167
[1] -99.24935
[1] 111.3898
[1] -24.63713
[1] 192.5296
[1] -8508.82
[1] -127.3702
[1] -243.7238
[1] 46.11019
INFO  [16:54:36.615] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -67.74097
[1] 25.18161
[1] -2795.121
[1] -72.21435
[1] -87.17779
[1] 51.39798
[1] -104.6231
[1] 508.7159
[1] -30532.56
[1] -602.3499
INFO  [16:55:56.747] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -79.93874
[1] -1.657987
[1] -316.8436
[1] -4.141586
[1] -11.46885
[1] 137.8437
[1] -94.60852
[1] 2.008341
[1] -53.60726
[1] 72.92296
INFO  [16:57:13.967] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -94.06894
[1] 9.019108
[1] -36.97532
[1] 103.4649
[1] -287.9889
[1] 20.23522
[1] -57.95031
[1] 45.91536
[1] -40.89001
[1] 50.62517
INFO  [16:58:05.515] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 39.05599
[1] 1713.732
[1] 28.40559
[1] 1276.222
[1] 49.80061
[1] 2270.237
[1] -1559.837
[1] -23.89057
[1] -3751.93
[1] -58.10151
INFO  [16:59:31.159] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 87.98696
[1] 3862.565
[1] 29.16459
[1] 1343.763
[1] 58.59769
[1] 2701.04
[1] -1609.298
[1] -26.34725
[1] 37.59915
[1] 1662.998
INFO  [17:00:50.554] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 23.00643
[1] 1012.681
[1] 31.81585
[1] 1396.374
[1] -1366.459
[1] -21.35198
[1] 34.34776
[1] 1654.061
[1] 28.81419
[1] 1306.27
INFO  [17:01:39.060] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -69.90985
[1] 25.67703
[1] -2226.166
[1] -91.51414
[1] -39.68621
[1] 172.8893
[1] -57.86638
[1] 40.65482
[1] -44.13076
[1] 25.09823
INFO  [17:02:19.672] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 93.52056
[1] 1424.354
[1] -90.85314
[1] 0.4365584
[1] -94.94227
[1] 19.68232
[1] -1076.144
[1] -59.49489
[1] -39.55078
[1] 51.75467
INFO  [17:03:28.824] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -57.14079
[1] 17.48305
[1] -3476.196
[1] -146.8094
[1] -209.9138
[1] 45.65595
[1] -43.14404
[1] 46.68689
[1] -287.0696
[1] 17.68452
INFO  [17:04:24.672] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:05:03.756] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:05:35.085] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:06:08.423] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -85.77152
[1] 29.11854
[1] -34.34725
[1] 68.98825
[1] -85.54104
[1] 49.27863
[1] -150.5601
[1] 5.103957
[1] -19.40672
[1] 77.10667
INFO  [17:06:54.489] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 46.75423
[1] 1739.651
[1] -94796.97
[1] -2380.513
[1] -200.7801
[1] -4.174121
[1] -132.0426
[1] 16.39984
[1] -52.88098
[1] 49.03016
INFO  [17:07:28.320] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -80.50623
[1] 11.27904
[1] 83.9469
[1] 2336.032
[1] -51.05614
[1] 72.132
[1] -58.65705
[1] 363.3273
[1] -481.1608
[1] -4.194558
INFO  [17:08:03.436] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -194.109
[1] 88.70123
[1] -89.96937
[1] 33.0252
[1] -223.0473
[1] 4.224805
[1] -24.48454
[1] 128.746
[1] -41.25413
[1] 131.3988
INFO  [17:09:07.705] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -317.355
[1] -4.273471
[1] -115.759
[1] 48.9038
[1] -881.0758
[1] -32.34698
[1] -59.78044
[1] 31.21787
[1] -49.65217
[1] 95.25879
INFO  [17:10:04.965] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -43.60035
[1] 71.96491
[1] -76.96744
[1] 159.4913
[1] -266.6679
[1] 59.89424
[1] -61.33914
[1] 25.65007
[1] -347.9995
[1] 6.550205
INFO  [17:11:10.656] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:11:38.714] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:12:25.960] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:13:09.639] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -19.02925
[1] 232.4678
[1] -72.24958
[1] 61.62956
[1] -48033.33
[1] -1107.984
[1] -103.851
[1] 44.25971
[1] -208.6798
[1] 47.80246
INFO  [17:13:24.884] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -44.23828
[1] 137.0178
[1] -50.84456
[1] 73.33586
[1] -229.0916
[1] 18.39625
[1] -267.6782
[1] -4.280432
[1] -120.8578
[1] 7.756019
INFO  [17:13:40.201] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -58.24924
[1] 27.00213
[1] -48.73396
[1] 73.79765
[1] -2478.616
[1] -36.95923
[1] -53.14974
[1] 34.70036
[1] -63.81483
[1] 98.9212
INFO  [17:14:01.048] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -197.3046
[1] 173.3388
[1] 448.349
[1] 17581.12
[1] -470.143
[1] -7.725464
[1] -345.5995
[1] 56.13706
[1] -334.3345
[1] 204.1952
INFO  [17:14:56.991] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -235.8243
[1] 750.1772
[1] -208.2723
[1] 248.9943
[1] -578.4083
[1] -8.321736
[1] 22.00355
[1] 1044.616
[1] -203.7144
[1] 129.7856
INFO  [17:15:55.700] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -264.1657
[1] 103.4526
[1] -280.0742
[1] 146.5179
[1] -12534.89
[1] -197.2936
[1] 8.475706
[1] 394.4052
[1] -516.0549
[1] -8.30629
INFO  [17:17:03.681] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -168.7055
[1] 49.82592
[1] -173.1017
[1] 36.7232
[1] -42.68299
[1] 66.72874
[1] -153.5843
[1] 106.6679
[1] -3197.401
[1] -52.32288
INFO  [17:17:39.976] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -180.2453
[1] 45.94995
[1] -10504.97
[1] -174.4683
[1] -179.0436
[1] -3.635168
[1] -56.25915
[1] 160.8664
[1] -42.92838
[1] 75.44995
INFO  [17:18:15.589] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -59.54611
[1] 97.51514
[1] -112.163
[1] 56.56753
[1] -261.4203
[1] 96.37496
[1] -84.14923
[1] 26.75553
[1] -119.6288
[1] 100.9411
INFO  [17:18:50.602] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -39.34236
[1] 31.13383
[1] -4082.587
[1] -85.55291
[1] 32.08587
[1] 677.9723
[1] -54.51567
[1] 27.79924
[1] -100.6047
[1] 153.4003
INFO  [17:19:37.278] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -62.88021
[1] 20.43003
[1] 158.6595
[1] 4266.495
[1] -93.7923
[1] -3.975865
[1] -56.66411
[1] 44.43496
[1] -68.83818
[1] 31.06428
INFO  [17:20:33.106] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -76.42475
[1] 47.81353
[1] -27.94324
[1] 28.85401
[1] -21.42039
[1] 126.983
[1] -70.96151
[1] 97.73427
[1] -3796.074
[1] -155.0219
INFO  [17:21:14.502] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:21:45.215] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:22:24.769] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:23:09.878] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -818.9638
[1] -30.41029
[1] -16.3784
[1] 77.80345
[1] -89.61082
[1] 12.61274
[1] -73.81191
[1] 20.63515
[1] -35.37637
[1] 44.19481
INFO  [17:23:52.258] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -33324.3
[1] -659.6307
[1] 11.29662
[1] 507.066
[1] -66.53682
[1] 24.85591
[1] -403.1122
[1] 2.699689
[1] -53.94385
[1] 18.5174
INFO  [17:24:29.033] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -99.23458
[1] 1.116526
[1] -175.1269
[1] 3.901945
[1] -64.48756
[1] 111.3006
[1] -90.12403
[1] 8.404625
[1] 80.03236
[1] 2058.552
INFO  [17:25:07.076] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -482.1558
[1] 654.747
[1] -566.1636
[1] -10.75048
[1] -1358.872
[1] 862.1434
[1] -809.1485
[1] -15.5579
[1] 28.22624
[1] 1405.217
INFO  [17:25:33.574] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -536.3763
[1] -10.18563
[1] 13.88397
[1] 687.2837
[1] -110.0245
[1] 371.6512
[1] -1534.184
[1] -26.38248
[1] 17.70059
[1] 916.191
INFO  [17:26:02.649] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 14.36707
[1] 808.3354
[1] -494.3302
[1] 189.9116
[1] -479.298
[1] 145.2133
[1] -834.2207
[1] -15.05543
[1] -778.8976
[1] -14.81769
INFO  [17:26:21.966] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -2383.352
[1] -40.21443
[1] -3147.9
[1] -55.25934
[1] 7740.816
[1] 368464.5
[1] 45.16734
[1] 2249.731
[1] 46.85053
[1] 2287.834
INFO  [17:26:46.760] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 66.34258
[1] 3360.438
[1] 60.43962
[1] 2952.721
[1] -1682491
[1] -29894.9
[1] -3872.828
[1] -68.36866
[1] 85.9056
[1] 4375.491
INFO  [17:27:08.511] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 78.70817
[1] 3948.834
[1] -2275.463
[1] -39.06534
[1] -3603.395
[1] -61.97188
[1] 72.29853
[1] 3559.151
[1] 44.31648
[1] 2237.065
INFO  [17:27:36.584] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -26086.33
[1] -321.4766
[1] -35.28165
[1] 90.02566
[1] -48.05094
[1] 105.7641
[1] -252.8749
[1] -4.196473
[1] -189.9526
[1] 31.41012
INFO  [17:28:18.338] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -55.80802
[1] 41.97435
[1] -85.44334
[1] 68.35592
[1] -101.9514
[1] 125.2877
[1] -15870.13
[1] -256.2596
[1] -106.0982
[1] 10.82524
INFO  [17:28:48.832] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2049.077
[1] -34.36473
[1] -116.3816
[1] 15.28803
[1] -44.95209
[1] 172.6472
[1] -33.7646
[1] 37.71755
[1] -30849.5
[1] -540.2183
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:29:53.366] [mlr3] Finished benchmark
INFO  [17:29:54.817] [bbotk] Result of batch 1:
INFO  [17:29:54.954] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:29:54.954] [bbotk]              1.6234560                         0.2161734
INFO  [17:29:54.954] [bbotk]             -5.2842995                         0.6661734
INFO  [17:29:54.954] [bbotk]              5.0773336                         0.8911734
INFO  [17:29:54.954] [bbotk]             -1.8304216                         0.4411734
INFO  [17:29:54.954] [bbotk]              3.3503948                         0.5536734
INFO  [17:29:54.954] [bbotk]             -3.5573607                         0.1036734
INFO  [17:29:54.954] [bbotk]              6.8042725                         0.3286734
INFO  [17:29:54.954] [bbotk]             -0.1034828                         0.7786734
INFO  [17:29:54.954] [bbotk]              4.2138642                         0.1599234
INFO  [17:29:54.954] [bbotk]             -2.6938911                         0.6099234
INFO  [17:29:54.954] [bbotk]              0.7599866                         0.8349234
INFO  [17:29:54.954] [bbotk]             -6.1477689                         0.3849234
INFO  [17:29:54.954] [bbotk]             -0.9669522                         0.2724234
INFO  [17:29:54.954] [bbotk]              5.9408030                         0.7224234
INFO  [17:29:54.954] [bbotk]             -4.4208301                         0.9474234
INFO  [17:29:54.954] [bbotk]              2.4869254                         0.4974234
INFO  [17:29:54.954] [bbotk]             -3.9890954                         0.5817984
INFO  [17:29:54.954] [bbotk]              2.9186601                         0.1317984
INFO  [17:29:54.954] [bbotk]             -0.5352175                         0.3567984
INFO  [17:29:54.954] [bbotk]              6.3725377                         0.8067984
INFO  [17:29:54.954] [bbotk]              1.1917213                         0.6942984
INFO  [17:29:54.954] [bbotk]             -5.7160342                         0.2442984
INFO  [17:29:54.954] [bbotk]              4.6455989                         0.4692984
INFO  [17:29:54.954] [bbotk]             -2.2621564                         0.9192984
INFO  [17:29:54.954] [bbotk]             -4.8525648                         0.5255484
INFO  [17:29:54.954] [bbotk]              2.0551907                         0.9755484
INFO  [17:29:54.954] [bbotk]             -1.3986869                         0.7505484
INFO  [17:29:54.954] [bbotk]              5.5090683                         0.3005484
INFO  [17:29:54.954] [bbotk]              0.3282519                         0.4130484
INFO  [17:29:54.954] [bbotk]             -6.5795036                         0.8630484
INFO  [17:29:54.954] [bbotk]              3.7821295                         0.6380484
INFO  [17:29:54.954] [bbotk]             -3.1256258                         0.1880484
INFO  [17:29:54.954] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:29:54.954] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:29:54.954] [bbotk]                         0.7406948         -8.41827516            -2.09275980
INFO  [17:29:54.954] [bbotk]                         0.2906948         -3.81310484             4.81499547
INFO  [17:29:54.954] [bbotk]                         0.5156948         -1.51051974            -5.54663724
INFO  [17:29:54.954] [bbotk]                         0.9656948         -6.11569020             1.36111784
INFO  [17:29:54.954] [bbotk]                         0.8531948         -7.26698261            -0.36582098
INFO  [17:29:54.954] [bbotk]                         0.4031948         -2.66181229             6.54193429
INFO  [17:29:54.954] [bbotk]                         0.1781948         -0.35922720            -3.81969842
INFO  [17:29:54.954] [bbotk]                         0.6281948         -4.96439766             3.08805666
INFO  [17:29:54.954] [bbotk]                         0.9094448         -4.38875111             2.22458725
INFO  [17:29:54.954] [bbotk]                         0.4594448         -8.99392145            -4.68316783
INFO  [17:29:54.954] [bbotk]                         0.2344448         -6.69133648             5.67846488
INFO  [17:29:54.954] [bbotk]                         0.6844448         -2.08616602            -1.22929039
INFO  [17:29:54.954] [bbotk]                         0.1219448         -7.84262889            -6.41010665
INFO  [17:29:54.954] [bbotk]                         0.5719448         -3.23745856             0.49764843
INFO  [17:29:54.954] [bbotk]                         0.7969448         -0.93487347            -2.95622921
INFO  [17:29:54.954] [bbotk]                         0.3469448         -5.54004393             3.95152606
INFO  [17:29:54.954] [bbotk]                         0.7688198         -6.40351334            -6.84184138
INFO  [17:29:54.954] [bbotk]                         0.3188198         -1.79834288             0.06591372
INFO  [17:29:54.954] [bbotk]                         0.5438198         -4.10092797            -3.38796392
INFO  [17:29:54.954] [bbotk]                         0.9938198         -8.70609830             3.51979136
INFO  [17:29:54.954] [bbotk]                         0.4313198         -0.64705033             1.79285254
INFO  [17:29:54.954] [bbotk]                         0.8813198         -5.25222079            -5.11490253
INFO  [17:29:54.954] [bbotk]                         0.6563198         -7.55480575             5.24673018
INFO  [17:29:54.954] [bbotk]                         0.2063198         -2.94963543            -1.66102510
INFO  [17:29:54.954] [bbotk]                         0.2625698         -8.13045202             2.65632195
INFO  [17:29:54.954] [bbotk]                         0.7125698         -3.52528170            -4.25143312
INFO  [17:29:54.954] [bbotk]                         0.9375698         -1.22269661             6.11019959
INFO  [17:29:54.954] [bbotk]                         0.4875698         -5.82786707            -0.79755569
INFO  [17:29:54.954] [bbotk]                         0.8250698         -2.37398915            -5.97837194
INFO  [17:29:54.954] [bbotk]                         0.3750698         -6.97915948             0.92938313
INFO  [17:29:54.954] [bbotk]                         0.1500698         -4.67657452            -2.52449451
INFO  [17:29:54.954] [bbotk]                         0.6000698         -0.07140406             4.38326077
INFO  [17:29:54.954] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:29:54.954] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:29:54.954] [bbotk]                         20                     573                 0.1330423
INFO  [17:29:54.954] [bbotk]                         10                    3073                 0.5830423
INFO  [17:29:54.954] [bbotk]                         15                    4323                 0.3580423
INFO  [17:29:54.954] [bbotk]                          5                    1823                 0.8080423
INFO  [17:29:54.954] [bbotk]                         13                    3698                 0.6955423
INFO  [17:29:54.954] [bbotk]                          3                    1198                 0.2455423
INFO  [17:29:54.954] [bbotk]                         18                    2448                 0.9205423
INFO  [17:29:54.954] [bbotk]                          8                    4948                 0.4705423
INFO  [17:29:54.954] [bbotk]                         11                     261                 0.1892923
INFO  [17:29:54.954] [bbotk]                          1                    2761                 0.6392923
INFO  [17:29:54.954] [bbotk]                         16                    4011                 0.4142923
INFO  [17:29:54.954] [bbotk]                          6                    1511                 0.8642923
INFO  [17:29:54.954] [bbotk]                          9                     886                 0.3017923
INFO  [17:29:54.954] [bbotk]                         19                    3386                 0.7517923
INFO  [17:29:54.954] [bbotk]                          4                    4636                 0.5267923
INFO  [17:29:54.954] [bbotk]                         14                    2136                 0.9767923
INFO  [17:29:54.954] [bbotk]                         17                    1980                 0.6674173
INFO  [17:29:54.954] [bbotk]                          7                    4480                 0.2174173
INFO  [17:29:54.954] [bbotk]                         12                    3230                 0.8924173
INFO  [17:29:54.954] [bbotk]                          2                     730                 0.4424173
INFO  [17:29:54.954] [bbotk]                          4                    1355                 0.5549173
INFO  [17:29:54.954] [bbotk]                         14                    3855                 0.1049173
INFO  [17:29:54.954] [bbotk]                          9                    2605                 0.7799173
INFO  [17:29:54.954] [bbotk]                         19                     105                 0.3299173
INFO  [17:29:54.954] [bbotk]                         18                    3542                 0.9486673
INFO  [17:29:54.954] [bbotk]                          8                    1042                 0.4986673
INFO  [17:29:54.954] [bbotk]                         13                    2292                 0.7236673
INFO  [17:29:54.954] [bbotk]                          3                    4792                 0.2736673
INFO  [17:29:54.954] [bbotk]                          1                    2917                 0.8361673
INFO  [17:29:54.954] [bbotk]                         11                     417                 0.3861673
INFO  [17:29:54.954] [bbotk]                          6                    1667                 0.6111673
INFO  [17:29:54.954] [bbotk]                         16                    4167                 0.1611673
INFO  [17:29:54.954] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:29:54.954] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:29:54.954] [bbotk]      0.03991168        0      0          102.029
INFO  [17:29:54.954] [bbotk]      0.03399899        0      0          166.545
INFO  [17:29:54.954] [bbotk]      0.55121821        0      0          245.926
INFO  [17:29:54.954] [bbotk]      0.03272983        0      0          246.142
INFO  [17:29:54.954] [bbotk]      0.05274917        0      0          328.759
INFO  [17:29:54.954] [bbotk]      0.06540728        0      0          107.394
INFO  [17:29:54.954] [bbotk]      0.55121821        0      0          149.377
INFO  [17:29:54.954] [bbotk]      0.02809244        0      0          323.386
INFO  [17:29:54.954] [bbotk]      0.55121821        0      0           74.216
INFO  [17:29:54.954] [bbotk]      0.05770524        0      0          179.915
INFO  [17:29:54.954] [bbotk]      0.05147680        0      0          235.844
INFO  [17:29:54.954] [bbotk]      0.02552912        0      0           99.936
INFO  [17:29:54.954] [bbotk]      0.04361297        0      0           98.480
INFO  [17:29:54.954] [bbotk]      0.55121821        0      0          172.935
INFO  [17:29:54.954] [bbotk]      0.02284007        0      0          220.826
INFO  [17:29:54.954] [bbotk]      0.04532832        0      0          157.260
INFO  [17:29:54.954] [bbotk]      0.03093537        0      0          207.808
INFO  [17:29:54.954] [bbotk]      0.14729565        0      0          211.650
INFO  [17:29:54.954] [bbotk]      0.02693992        0      0          164.344
INFO  [17:29:54.954] [bbotk]      0.55121821        0      0          102.370
INFO  [17:29:54.954] [bbotk]      0.02695641        0      0          113.802
INFO  [17:29:54.954] [bbotk]      0.02781223        0      0          185.591
INFO  [17:29:54.954] [bbotk]      0.55121821        0      0          118.233
INFO  [17:29:54.954] [bbotk]      0.02830389        0      0           51.050
INFO  [17:29:54.954] [bbotk]      0.04179805        0      0          182.176
INFO  [17:29:54.954] [bbotk]      0.04160992        0      0          106.512
INFO  [17:29:54.954] [bbotk]      0.02671528        0      0          143.568
INFO  [17:29:54.954] [bbotk]      0.55121821        0      0          114.891
INFO  [17:29:54.954] [bbotk]      0.02905774        0      0          116.882
INFO  [17:29:54.954] [bbotk]      0.04077226        0      0           74.161
INFO  [17:29:54.954] [bbotk]      0.07955221        0      0           74.235
INFO  [17:29:54.954] [bbotk]      0.02326728        0      0          127.486
INFO  [17:29:54.954] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:29:54.954] [bbotk]                                 uhash
INFO  [17:29:54.954] [bbotk]  3a5e13f8-0738-411e-988c-32be90928b86
INFO  [17:29:54.954] [bbotk]  451bfb98-12d0-4b68-a9c8-3ebf9d71b132
INFO  [17:29:54.954] [bbotk]  2c0744ff-a108-4671-8ee1-1b614c5230c5
INFO  [17:29:54.954] [bbotk]  3a0488d3-8e8e-4747-b2c1-cffb084a75d2
INFO  [17:29:54.954] [bbotk]  2a904105-0233-4827-90aa-473754ab4c1e
INFO  [17:29:54.954] [bbotk]  808b4cab-48f2-4c5a-b252-feba5e5a57dc
INFO  [17:29:54.954] [bbotk]  a3325bd2-60da-4122-8575-0022afa3f217
INFO  [17:29:54.954] [bbotk]  d4292479-b9a2-4ad8-9b9b-2aea23aa6e82
INFO  [17:29:54.954] [bbotk]  3f5210c1-3a97-493d-90af-892e39977a03
INFO  [17:29:54.954] [bbotk]  f5b857fb-a332-4838-80e5-6102261b0133
INFO  [17:29:54.954] [bbotk]  fbcb69ee-19c2-4d13-8ccd-b9e9b578cb5d
INFO  [17:29:54.954] [bbotk]  9d38798b-c0a8-4bee-b9ce-d0c91d1ef296
INFO  [17:29:54.954] [bbotk]  95662ca3-2844-4c35-a899-202942a65bc0
INFO  [17:29:54.954] [bbotk]  029fb35f-3b16-44b1-943e-eabdc7122aea
INFO  [17:29:54.954] [bbotk]  984c8908-9794-4e43-852f-0b8dbe8da399
INFO  [17:29:54.954] [bbotk]  8545ccdd-8869-4809-8b8b-c633e92b8f73
INFO  [17:29:54.954] [bbotk]  3e20abfd-38fd-4445-9752-1f957d84e70f
INFO  [17:29:54.954] [bbotk]  7c3be380-5d93-42fe-8db5-3e0cd8a3c5b0
INFO  [17:29:54.954] [bbotk]  23e54ee9-ba62-4479-ab55-83e183e35330
INFO  [17:29:54.954] [bbotk]  d03dfd24-61ae-4d46-9f75-8aa41c805005
INFO  [17:29:54.954] [bbotk]  a7912648-d56f-4725-9948-e9cdc9483f5e
INFO  [17:29:54.954] [bbotk]  dd499366-2228-4ad0-8ae8-00731f9aaeff
INFO  [17:29:54.954] [bbotk]  401dd776-7066-4995-b7c1-f85cb8271d8a
INFO  [17:29:54.954] [bbotk]  01ba76ec-cbae-4a06-99c6-e06896831267
INFO  [17:29:54.954] [bbotk]  732ee89e-ac9a-4c0b-b7aa-544d144020b4
INFO  [17:29:54.954] [bbotk]  f3271b29-5003-4692-aae2-c15b0b4d8495
INFO  [17:29:54.954] [bbotk]  d38fad82-1ccf-4570-bcab-22a039638ae3
INFO  [17:29:54.954] [bbotk]  0a4c3351-0e4d-4da0-b100-0231801c4f8e
INFO  [17:29:54.954] [bbotk]  0704b05c-f591-4f57-b7af-21425085e921
INFO  [17:29:54.954] [bbotk]  b584a248-3358-4259-b86b-757ea4d0e122
INFO  [17:29:54.954] [bbotk]  ae85044a-f701-4a11-95cf-28f37f365275
INFO  [17:29:54.954] [bbotk]  9fb0de6e-c01d-4329-91e8-86398e427a08
INFO  [17:29:54.954] [bbotk]                                 uhash
INFO  [17:30:04.023] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 32 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:30:10.007] [bbotk] Evaluating 1 configuration(s)
INFO  [17:30:10.163] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:30:10.204] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1375.472
[1] -26.58795
[1] 23.93628
[1] 1213.478
[1] -250166.8
[1] -4381.553
[1] -1079.631
[1] -18.38928
[1] -1240.192
[1] -21.76095
INFO  [17:30:43.151] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1097.252
[1] -19.34061
[1] -892.7732
[1] -15.34324
[1] -1032.396
[1] -18.83567
[1] 16.72702
[1] 866.27
[1] -151.5134
[1] 2057.794
INFO  [17:31:25.789] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1071.102
[1] -18.13214
[1] 19.74146
[1] 973.766
[1] 36.48519
[1] 1890.316
[1] -950.444
[1] -17.51758
[1] -937.6097
[1] -17.10524
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:32:18.848] [mlr3] Finished benchmark
INFO  [17:32:19.148] [bbotk] Result of batch 2:
INFO  [17:32:19.277] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:32:19.277] [bbotk]               3.115715                         0.7007793
INFO  [17:32:19.277] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:32:19.277] [bbotk]                         0.5198155            -8.93004              -5.529263
INFO  [17:32:19.277] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:32:19.277] [bbotk]                         11                    3225                 0.7665535
INFO  [17:32:19.277] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:32:19.277] [bbotk]  0.06987298 <list[8]>              FALSE     0.04411904        0      0
INFO  [17:32:19.277] [bbotk]  runtime_learners                                uhash
INFO  [17:32:19.277] [bbotk]           128.146 47913166-bf4f-4051-849c-a34ebf804c05
INFO  [17:32:21.383] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 33 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:32:26.464] [bbotk] Evaluating 1 configuration(s)
INFO  [17:32:26.712] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:32:26.824] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 14.03521
[1] 680.3377
[1] -542.55
[1] 20.00013
[1] -150.1665
[1] 308.735
[1] -21.57404
[1] 405.5437
[1] -627.6987
[1] -8.610091
INFO  [17:33:16.850] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -559.9048
[1] -8.573334
[1] -181.1477
[1] 380.2321
[1] -775.2006
[1] -9.085804
[1] -8.031317
[1] 430.0073
[1] -772.8442
[1] -14.06901
INFO  [17:34:07.803] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -181.4639
[1] 241.0122
[1] -202.9642
[1] 201.8626
[1] 8.351697
[1] 395.7278
[1] -431.9434
[1] -6.710552
[1] 10.66448
[1] 481.9003
INFO  [17:35:00.248] [mlr3] Finished benchmark
INFO  [17:35:00.458] [bbotk] Result of batch 3:
INFO  [17:35:00.492] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:35:00.492] [bbotk]               3.229782                          0.723935
INFO  [17:35:00.492] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:35:00.492] [bbotk]                         0.1313115           -7.187042              -3.290759
INFO  [17:35:00.492] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:35:00.492] [bbotk]                          3                    3276                  0.994547
INFO  [17:35:00.492] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:35:00.492] [bbotk]  0.03954202 <list[8]>              FALSE     0.06404066        0      0
INFO  [17:35:00.492] [bbotk]  runtime_learners                                uhash
INFO  [17:35:00.492] [bbotk]           153.018 8d93d3c6-d481-4d88-a255-b744382007a7
INFO  [17:35:01.287] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 34 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:35:06.196] [bbotk] Evaluating 1 configuration(s)
INFO  [17:35:06.323] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:35:07.116] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -14281.4
[1] -261.8449
[1] 247.8126
[1] 13369.82
[1] -58787.47
[1] -1084.739
[1] -17952.4
[1] -330.7043
[1] -19211.34
[1] -354.4951
INFO  [17:36:04.691] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -12143.49
[1] -223.4963
[1] 399.959
[1] 21662.49
[1] -12177.63
[1] -224.2841
[1] -15069.25
[1] -277.3074
[1] 297.5981
[1] 16026.99
INFO  [17:37:01.464] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -69463.24
[1] -1280.172
[1] -6523254
[1] -120564
[1] 247.6079
[1] 13321.65
[1] -14992.51
[1] -275.4988
[1] -8023.931
[1] -147.9285
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:37:33.363] [mlr3] Finished benchmark
INFO  [17:37:33.493] [bbotk] Result of batch 4:
INFO  [17:37:33.521] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:37:33.521] [bbotk]               1.383964                         0.5252211
INFO  [17:37:33.521] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:37:33.521] [bbotk]                         0.9530628           -8.376369               6.809842
INFO  [17:37:33.521] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:37:33.521] [bbotk]                         12                    1550                 0.9611116
INFO  [17:37:33.521] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:37:33.521] [bbotk]  0.03668561 <list[8]>              FALSE      0.2960368        0      0
INFO  [17:37:33.521] [bbotk]  runtime_learners                                uhash
INFO  [17:37:33.521] [bbotk]            145.61 0e486bbc-f285-4fda-8f36-06b49c782efd
INFO  [17:37:35.994] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 35 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:37:41.469] [bbotk] Evaluating 1 configuration(s)
INFO  [17:37:41.612] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:37:41.725] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -37.13281
[1] 30.64762
[1] -65.59328
[1] 23.32161
[1] -967.9073
[1] -28.92356
[1] -41.04266
[1] 59.97106
[1] -4.119583e+16
[1] 3.640673e+14
INFO  [17:38:17.532] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -126.2219
[1] -3.301547
[1] -40.97581
[1] 74.52016
[1] -133.1775
[1] 49.78144
[1] -52.54655
[1] 25.06601
[1] -174.8319
[1] 45.36672
INFO  [17:38:55.070] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -82.29726
[1] 15.76663
[1] -2756.245
[1] -70.05735
[1] 70.43902
[1] 1803.566
[1] -4419.657
[1] -107.549
[1] -79449.82
[1] -1775.05
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:39:25.168] [mlr3] Finished benchmark
INFO  [17:39:25.295] [bbotk] Result of batch 5:
INFO  [17:39:25.334] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:39:25.334] [bbotk]              0.4378358                         0.8970028
INFO  [17:39:25.334] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:39:25.334] [bbotk]                          0.353948          -0.7213833              -5.184945
INFO  [17:39:25.334] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:39:25.334] [bbotk]                         18                    3779                 0.1508428
INFO  [17:39:25.334] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:39:25.334] [bbotk]  0.05912899 <list[8]>              FALSE      0.0260179        0      0
INFO  [17:39:25.334] [bbotk]  runtime_learners                                uhash
INFO  [17:39:25.334] [bbotk]           102.594 0900c67a-aabb-498f-8aa9-f7cb8c07fdf0
WARN  [17:39:26.342] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:39:26.447] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 36 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:39:31.929] [bbotk] Evaluating 1 configuration(s)
INFO  [17:39:32.071] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:39:32.467] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 25.54439
[1] 1222.505
[1] -2119.145
[1] -36.21944
[1] 22.579
[1] 953.241
[1] -1298.749
[1] -18.91278
[1] -989.6768
[1] 264.8788
INFO  [17:40:17.610] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 30.67603
[1] 1405.937
[1] 17.89863
[1] 787.3457
[1] -949.6588
[1] -15.42139
[1] -1158.823
[1] -18.00642
[1] 41.45639
[1] 1996.76
INFO  [17:41:01.279] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 43.01038
[1] 1939.213
[1] -1278.141
[1] -19.28547
[1] 18.00037
[1] 830.6174
[1] -894.8413
[1] 248.8746
[1] -1314.555
[1] -21.10286
INFO  [17:41:53.151] [mlr3] Finished benchmark
INFO  [17:41:53.513] [bbotk] Result of batch 6:
INFO  [17:41:53.594] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:41:53.594] [bbotk]               2.536977                         0.7775262
INFO  [17:41:53.594] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:41:53.594] [bbotk]                         0.1580493           -7.482641              -4.206836
INFO  [17:41:53.594] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:41:53.594] [bbotk]                         17                    3285                 0.2860805
INFO  [17:41:53.594] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:41:53.594] [bbotk]  0.05145055 <list[8]>              FALSE     0.09365822        0      0
INFO  [17:41:53.594] [bbotk]  runtime_learners                                uhash
INFO  [17:41:53.594] [bbotk]           140.403 3d532375-ce22-44f5-99ba-7fd9fdf6dc20
INFO  [17:41:55.145] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 37 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:42:01.203] [bbotk] Evaluating 1 configuration(s)
INFO  [17:42:01.355] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:42:01.671] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -75.58048
[1] 133.9357
[1] -247.0362
[1] -4.127853
[1] -34.58042
[1] 118.4841
[1] -79.03352
[1] 110.9247
[1] -15501.18
[1] -381.8799
INFO  [17:42:10.188] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -117.628
[1] 42.72785
[1] -221.201
[1] -3.989661
[1] 3.076106
[1] 132.0055
[1] -50.74799
[1] 166.1553
[1] -62.88786
[1] 129.183
INFO  [17:42:19.283] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 3.557981
[1] 158.312
[1] -94.68342
[1] 162.7143
[1] -211.1347
[1] -4.5858
[1] -153.7158
[1] 34.03697
[1] -304.6153
[1] -4.710567
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:42:37.424] [mlr3] Finished benchmark
INFO  [17:42:37.752] [bbotk] Result of batch 7:
INFO  [17:42:38.066] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:42:38.066] [bbotk]               2.862222                         0.7521377
INFO  [17:42:38.066] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:42:38.066] [bbotk]                         0.3487977          -0.2623598              -1.795118
INFO  [17:42:38.066] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:42:38.066] [bbotk]                         16                     983                 0.8090849
INFO  [17:42:38.066] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:42:38.066] [bbotk]  0.05829501 <list[8]>              FALSE     0.04591396        0      0
INFO  [17:42:38.066] [bbotk]  runtime_learners                                uhash
INFO  [17:42:38.066] [bbotk]            35.292 895e9b7e-45ae-44a3-b213-762bff132bc5
INFO  [17:42:41.595] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 38 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:42:47.505] [bbotk] Evaluating 1 configuration(s)
INFO  [17:42:48.208] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:42:48.754] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -37.99677
[1] 83.3608
[1] -95.37984
[1] 37.30871
[1] -814.8116
[1] -20.23784
[1] -41.55428
[1] 110.3278
[1] -198.0981
[1] 24.8393
INFO  [17:43:02.840] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -78.04848
[1] 115.0065
[1] -132.8817
[1] 85.37767
[1] -310.3101
[1] 2.560524
[1] -124.3787
[1] 42.80941
[1] -302.0948
[1] -4.665078
INFO  [17:43:21.126] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -209.2066
[1] -3.988408
[1] -282.6858
[1] 20.96208
[1] -68.56963
[1] 50.51163
[1] 447.2754
[1] 10398.24
[1] -45.92074
[1] 125.7653
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:43:40.635] [mlr3] Finished benchmark
INFO  [17:43:40.959] [bbotk] Result of batch 8:
INFO  [17:43:41.288] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:43:41.288] [bbotk]              0.5985624                         0.1940112
INFO  [17:43:41.288] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:43:41.288] [bbotk]                         0.3688245           -2.657716                -1.8407
INFO  [17:43:41.288] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:43:41.288] [bbotk]                          4                     600                 0.1248202
INFO  [17:43:41.288] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:43:41.288] [bbotk]  0.0539473 <list[8]>              FALSE     0.03815495        0      0
INFO  [17:43:41.288] [bbotk]  runtime_learners                                uhash
INFO  [17:43:41.288] [bbotk]            50.843 d9d97c96-4f23-4d88-9a53-562eedb6c6fd
WARN  [17:43:49.337] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:43:49.356] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 39 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:43:55.109] [bbotk] Evaluating 1 configuration(s)
INFO  [17:43:55.193] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:43:55.298] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -36.92949
[1] 20.69438
[1] -24.54586
[1] 28.18366
[1] -19.40009
[1] 173.1825
[1] -297.4637
[1] 1.249525
[1] -1565.285
[1] -55.22465
INFO  [17:44:21.750] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -93.25853
[1] -3.872891
[1] -43.13369
[1] 20.02727
[1] -275.47
[1] 33.01148
[1] -40.61783
[1] 33.79846
[1] -43.46231
[1] 6.604493
INFO  [17:44:49.552] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -40.26485
[1] 32.20253
[1] -120.2658
[1] 84.94315
[1] -10.80573
[1] 24.95849
[1] -80.28412
[1] -3.524709
[1] -13.30519
[1] 24.14094
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:45:32.534] [mlr3] Finished benchmark
INFO  [17:45:32.723] [bbotk] Result of batch 9:
INFO  [17:45:32.746] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:45:32.746] [bbotk]              -1.441797                          0.820361
INFO  [17:45:32.746] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:45:32.746] [bbotk]                         0.6310589          -0.6099863              -4.073861
INFO  [17:45:32.746] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:45:32.746] [bbotk]                          4                    3333                 0.3250838
INFO  [17:45:32.746] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:45:32.746] [bbotk]  0.04040289 <list[8]>              FALSE     0.02432104        0      0
INFO  [17:45:32.746] [bbotk]  runtime_learners                                uhash
INFO  [17:45:32.746] [bbotk]            96.717 64931774-d202-45d7-87b1-46c18af5f553
INFO  [17:45:33.471] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 40 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:45:39.257] [bbotk] Evaluating 1 configuration(s)
INFO  [17:45:39.452] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:45:39.520] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -212.7996
[1] 48.58145
[1] -1327.444
[1] -18.31588
[1] -10680.45
[1] -155.8411
[1] -165.1093
[1] 47.14481
[1] -165.5885
[1] 104.7217
INFO  [17:45:58.501] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -144.744
[1] 247.9765
[1] -228.5105
[1] 108.2483
[1] -62.95001
[1] 242.7772
[1] -225.4515
[1] 35.86906
[1] -159.6971
[1] 131.2923
INFO  [17:46:13.551] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 138.5011
[1] 3718.801
[1] -144.5101
[1] 101.5761
[1] -251.7726
[1] -4.974446
[1] -178.5317
[1] 52.05566
[1] -95.84018
[1] 261.9615
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:46:28.733] [mlr3] Finished benchmark
INFO  [17:46:28.938] [bbotk] Result of batch 10:
INFO  [17:46:28.975] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:46:28.975] [bbotk]               1.602274                         0.5970398
INFO  [17:46:28.975] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:46:28.975] [bbotk]                         0.3874246           -4.356081              -5.259031
INFO  [17:46:28.975] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:46:28.975] [bbotk]                         20                     216                 0.2554157
INFO  [17:46:28.975] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:46:28.975] [bbotk]  0.04189635 <list[8]>              FALSE     0.04797199        0      0
INFO  [17:46:28.975] [bbotk]  runtime_learners                                uhash
INFO  [17:46:28.975] [bbotk]            48.021 c325be0f-f04e-49d3-ab71-1e27ac196ff2
INFO  [17:46:29.817] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 41 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:46:46.967] [bbotk] Evaluating 1 configuration(s)
INFO  [17:46:47.065] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:46:47.290] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -91.90753
[1] 31.98334
[1] 115.2572
[1] 4810.741
[1] -25.2824
[1] 179.8388
[1] -138.6452
[1] 10.92334
[1] -52.77873
[1] 60.0113
INFO  [17:47:17.666] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -250.7663
[1] 8.074008
[1] -50.17449
[1] 59.97281
[1] -36.35548
[1] 111.3598
[1] -127.3683
[1] 27.85817
[1] -142.5693
[1] -4.145374
INFO  [17:47:52.264] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -53.70238
[1] 42.21625
[1] -79.88148
[1] 23.85962
[1] -5330.732
[1] -108.7809
[1] -89.18572
[1] 54.15519
[1] 36.19544
[1] 1302.954
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:48:30.197] [mlr3] Finished benchmark
INFO  [17:48:30.396] [bbotk] Result of batch 11:
INFO  [17:48:30.427] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:48:30.427] [bbotk]              -1.769431                         0.2710112
INFO  [17:48:30.427] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:48:30.427] [bbotk]                         0.5676837           -3.708168               3.415669
INFO  [17:48:30.427] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:48:30.427] [bbotk]                         20                    1783                 0.3956591
INFO  [17:48:30.427] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:48:30.427] [bbotk]  0.03765053 <list[8]>              FALSE     0.02931842        0      0
INFO  [17:48:30.427] [bbotk]  runtime_learners                                uhash
INFO  [17:48:30.427] [bbotk]           101.995 7b9f99ea-cba2-4138-ad47-118ba9a0671e
INFO  [17:48:32.616] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 42 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:48:38.396] [bbotk] Evaluating 1 configuration(s)
INFO  [17:48:38.786] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:48:38.936] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -193.5946
[1] 14.14104
[1] -34.85342
[1] 80.25911
[1] -166.9871
[1] 43.57252
[1] -21.1229
[1] 43.07187
[1] -32.5375
[1] 40.85315
INFO  [17:49:19.814] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -21.81734
[1] 65.13189
[1] -113.5418
[1] -2.919045
[1] -26.18342
[1] 38.38563
[1] -230.6852
[1] 40.82405
[1] -30.45181
[1] 25.22526
INFO  [17:50:09.347] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -54.27503
[1] 13.76613
[1] 71.29244
[1] 2495.229
[1] -1243.419
[1] -38.04564
[1] -23.20334
[1] 98.48535
[1] -36.35233
[1] 17.80526
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:50:44.212] [mlr3] Finished benchmark
INFO  [17:50:44.485] [bbotk] Result of batch 12:
INFO  [17:50:44.576] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:50:44.576] [bbotk]              0.5155906                         0.5447156
INFO  [17:50:44.576] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:50:44.576] [bbotk]                         0.1040253          -0.3995185              -4.980501
INFO  [17:50:44.576] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:50:44.576] [bbotk]                          8                    4397                 0.6199767
INFO  [17:50:44.576] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:50:44.576] [bbotk]  0.03939033 <list[8]>              FALSE     0.02628035        0      0
INFO  [17:50:44.576] [bbotk]  runtime_learners                                uhash
INFO  [17:50:44.576] [bbotk]           123.792 ad101c74-5eb0-4a01-9356-c1015bd11e66
INFO  [17:50:48.368] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 43 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:50:56.503] [bbotk] Evaluating 1 configuration(s)
INFO  [17:50:56.758] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:50:56.987] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -43.71168
[1] 40.81855
[1] -5775.283
[1] -138.0776
[1] -135.9045
[1] 13.9606
[1] -1171.912
[1] -86.06374
[1] -127.0938
[1] 11.64641
INFO  [17:51:04.627] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -38.63835
[1] 24.90126
[1] -995.7476
[1] -29.09227
[1] -36.73576
[1] 37.63373
[1] -265.6023
[1] -2.938891
[1] -35.02679
[1] 39.21659
INFO  [17:51:26.417] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -24.86596
[1] 231.8955
[1] -24.01295
[1] 29.94085
[1] -28.40925
[1] 22.60955
[1] -1211.284
[1] -66.74438
[1] -1071.771
[1] -44.85268
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:51:48.966] [mlr3] Finished benchmark
INFO  [17:51:50.938] [bbotk] Result of batch 13:
INFO  [17:51:51.074] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:51:51.074] [bbotk]             -0.2922998                         0.9236944
INFO  [17:51:51.074] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:51:51.074] [bbotk]                         0.8432751          -0.6562507             -0.1469484
INFO  [17:51:51.074] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:51:51.074] [bbotk]                          2                     379                 0.5259188
INFO  [17:51:51.074] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:51:51.074] [bbotk]  0.03293387 <list[8]>              FALSE     0.02091131        0      0
INFO  [17:51:51.074] [bbotk]  runtime_learners                                uhash
INFO  [17:51:51.074] [bbotk]            45.741 f4bd3bf8-5256-4c65-8bf6-2ecab54d6fa1
INFO  [17:51:54.938] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 44 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:52:02.834] [bbotk] Evaluating 1 configuration(s)
INFO  [17:52:02.920] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:52:03.477] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -34.85754
[1] 94.79074
[1] -36.27647
[1] 104.2929
[1] -2625.439
[1] -83.11578
[1] -50.93466
[1] 17.09552
[1] -193.1397
[1] 12.09327
INFO  [17:52:42.304] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1137.366
[1] -28.79461
[1] -45.18085
[1] 23.54385
[1] -140.8455
[1] 18.13743
[1] -36.28739
[1] 34.1041
[1] -59.46937
[1] 7.296934
INFO  [17:53:39.026] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -27.69744
[1] 78.90691
[1] -54.91242
[1] 23.8187
[1] -75.40186
[1] 56.06066
[1] -114.1838
[1] 3.667434
[1] -137.614
[1] -3.067301
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:54:35.537] [mlr3] Finished benchmark
INFO  [17:54:35.841] [bbotk] Result of batch 14:
INFO  [17:54:35.950] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:54:35.950] [bbotk]              -5.824839                         0.9939789
INFO  [17:54:35.950] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:54:35.950] [bbotk]                         0.7678303           -4.744388              -4.997538
INFO  [17:54:35.950] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:54:35.950] [bbotk]                         15                    4262                 0.6019085
INFO  [17:54:35.950] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:54:35.950] [bbotk]  0.03078586 <list[8]>              FALSE     0.02503067        0      0
INFO  [17:54:35.950] [bbotk]  runtime_learners                                uhash
INFO  [17:54:35.950] [bbotk]           150.869 31331a21-6c96-48a0-872b-6a4b24146149
INFO  [17:54:37.391] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 45 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:54:45.975] [bbotk] Evaluating 1 configuration(s)
INFO  [17:54:46.447] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:54:46.536] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -54.2904
[1] 19.88509
[1] -155.7018
[1] 37.5733
[1] -2012.913
[1] -43.48778
[1] -63.57818
[1] 81.59185
[1] -162.9543
[1] 42.6592
INFO  [17:55:22.568] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1.385549e+16
[1] 3.241605e+16
[1] -1931.098
[1] -73.01955
[1] -80.9553
[1] 21.85148
[1] -4257.146
[1] -95.32162
[1] -109.3366
[1] -1.884971
INFO  [17:55:56.064] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -3102.192
[1] -67.75959
[1] -33.92499
[1] 25.94029
[1] -1897.527
[1] -35.18496
[1] -1317.469
[1] -42.35541
[1] -78.30663
[1] 20.43735
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:56:33.501] [mlr3] Finished benchmark
INFO  [17:56:33.597] [bbotk] Result of batch 15:
INFO  [17:56:33.643] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:56:33.643] [bbotk]              0.5080825                          0.895929
INFO  [17:56:33.643] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:56:33.643] [bbotk]                         0.3593547           -1.726359              -2.968555
INFO  [17:56:33.643] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:56:33.643] [bbotk]                          3                    2762                 0.3459181
INFO  [17:56:33.643] [bbotk]    acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:56:33.643] [bbotk]  0.032802 <list[8]>              FALSE     0.02701839        0      0
INFO  [17:56:33.643] [bbotk]  runtime_learners                                uhash
INFO  [17:56:33.643] [bbotk]            102.25 e9f60311-4345-412d-83e0-92bbc7171bd0
INFO  [17:56:34.623] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 46 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:56:41.236] [bbotk] Evaluating 1 configuration(s)
INFO  [17:56:41.363] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:56:41.714] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -191.4661
[1] 73.60746
[1] -70.34715
[1] 54.28947
[1] -7.809101
[1] 167.3736
[1] -76.50542
[1] 20.84629
[1] -62.63614
[1] 57.32265
INFO  [17:57:14.758] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -45.31242
[1] 29.69689
[1] -76.09013
[1] 8.812701
[1] -1001.799
[1] -37.87337
[1] -58.56197
[1] 19.19338
[1] -30.46426
[1] 33.80838
INFO  [17:57:37.083] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2109.937
[1] -52.04961
[1] -240.0789
[1] -0.7505588
[1] -49.91958
[1] 35.87397
[1] -88.7637
[1] 1.9361
[1] -28.45417
[1] 24.50079
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:58:02.484] [mlr3] Finished benchmark
INFO  [17:58:02.778] [bbotk] Result of batch 16:
INFO  [17:58:02.905] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:58:02.905] [bbotk]             -0.2425388                         0.2218519
INFO  [17:58:02.905] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:58:02.905] [bbotk]                         0.9512267           -1.360556              -6.377267
INFO  [17:58:02.905] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:58:02.905] [bbotk]                         11                    2241                 0.4255788
INFO  [17:58:02.905] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:58:02.905] [bbotk]  0.03393747 <list[8]>              FALSE     0.02149368        0      0
INFO  [17:58:02.905] [bbotk]  runtime_learners                                uhash
INFO  [17:58:02.905] [bbotk]            79.072 55f365b4-0229-458f-8f0c-e89f2562483d
INFO  [17:58:05.893] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 47 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:58:13.307] [bbotk] Evaluating 1 configuration(s)
INFO  [17:58:13.524] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:58:13.670] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -6565.137
[1] -224.5897
[1] -68.3966
[1] 56.68886
[1] -899.5551
[1] -68.62288
[1] -95.79383
[1] 17.33857
[1] -19467.6
[1] -299.2813
INFO  [17:58:29.432] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -19.07066
[1] 57.44464
[1] -50.6973
[1] 10.27491
[1] -1291.387
[1] -50.00069
[1] -390.1149
[1] 22.04595
[1] -49.58073
[1] 58.03077
INFO  [17:58:48.316] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -61.48815
[1] 11.34631
[1] -34.43452
[1] 22.30941
[1] -1613.818
[1] -76.08962
[1] 55.16667
[1] 1254.208
[1] -114.5221
[1] 5.193181
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:59:11.496] [mlr3] Finished benchmark
INFO  [17:59:11.897] [bbotk] Result of batch 17:
INFO  [17:59:11.952] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:59:11.952] [bbotk]              -5.199647                         0.8708728
INFO  [17:59:11.952] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:59:11.952] [bbotk]                          0.755135           -3.586739              -5.054181
INFO  [17:59:11.952] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:59:11.952] [bbotk]                         17                     383                 0.5463118
INFO  [17:59:11.952] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:59:11.952] [bbotk]  0.02919458 <list[8]>              FALSE     0.02473685        0      0
INFO  [17:59:11.952] [bbotk]  runtime_learners                                uhash
INFO  [17:59:11.952] [bbotk]            55.498 4cfdbceb-025b-443c-8d0a-a66c2359f447
INFO  [17:59:12.902] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 48 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:59:19.362] [bbotk] Evaluating 1 configuration(s)
INFO  [17:59:19.457] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:59:19.543] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -212.9481
[1] 410.0901
[1] -378.4245
[1] -7.412559
[1] -397.3443
[1] 64.34485
[1] -18995.4
[1] -372.458
[1] -185.0582
[1] 136.3636
INFO  [18:00:16.712] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -198.3401
[1] 131.5321
[1] -302.2714
[1] -6.59665
[1] -460.0357
[1] -7.218059
[1] -481.9959
[1] -7.772995
[1] 10.52646
[1] 498.0358
INFO  [18:01:14.625] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -161.7681
[1] 46.34901
[1] -72.49318
[1] 250.8247
[1] -167.3941
[1] 337.3152
[1] -9869.691
[1] -168.2412
[1] -357.7522
[1] -7.237323
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:02:26.228] [mlr3] Finished benchmark
INFO  [18:02:26.381] [bbotk] Result of batch 18:
INFO  [18:02:26.432] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:02:26.432] [bbotk]               2.086775                         0.4782731
INFO  [18:02:26.432] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:02:26.432] [bbotk]                         0.9683142           -8.300854              -2.515831
INFO  [18:02:26.432] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:02:26.432] [bbotk]                         16                    3220                 0.9221503
INFO  [18:02:26.432] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:02:26.432] [bbotk]  0.06036869 <list[8]>              FALSE     0.04918273        0      0
INFO  [18:02:26.432] [bbotk]  runtime_learners                                uhash
INFO  [18:02:26.432] [bbotk]            185.59 0b5d6591-9f32-493c-8af6-6e5b202836d4
INFO  [18:02:28.565] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 49 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:02:37.348] [bbotk] Evaluating 1 configuration(s)
INFO  [18:02:37.437] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:02:37.561] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 255.1449
[1] 6101.369
[1] -44.76774
[1] 17.56605
[1] -37.72873
[1] 49.20204
[1] -17.50085
[1] 25.53786
[1] -2.407559
[1] 299.3717
INFO  [18:03:04.862] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -224.9627
[1] -3.823856
[1] -33.1051
[1] 40.43544
[1] -881.2401
[1] -3.934709
[1] -65.3256
[1] 5.505012
[1] -1233.293
[1] -70.39746
INFO  [18:03:35.611] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1037.651
[1] -42.12687
[1] -35.58181
[1] 144.716
[1] -35.26864
[1] 40.43662
[1] -94.14129
[1] -0.9417454
[1] -54.95889
[1] 5.705995
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:03:59.624] [mlr3] Finished benchmark
INFO  [18:03:59.923] [bbotk] Result of batch 19:
INFO  [18:04:00.079] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:04:00.079] [bbotk]               -3.06606                          0.791913
INFO  [18:04:00.079] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:04:00.079] [bbotk]                         0.8079884          -0.6952863               1.750898
INFO  [18:04:00.079] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:04:00.079] [bbotk]                         14                    2100                 0.7717745
INFO  [18:04:00.079] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:04:00.079] [bbotk]  0.03183655 <list[8]>              FALSE     0.02522722        0      0
INFO  [18:04:00.079] [bbotk]  runtime_learners                                uhash
INFO  [18:04:00.079] [bbotk]            80.929 fdc33b47-7478-4cad-a076-2f9612f1651c
WARN  [18:04:02.601] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:04:02.773] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 50 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:04:10.256] [bbotk] Evaluating 1 configuration(s)
INFO  [18:04:10.484] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:04:10.735] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -3633.239
[1] -67.05697
[1] -50.33159
[1] 17.53668
[1] -5157.56
[1] -92.96138
[1] 47.23908
[1] 1733.427
[1] -73.31482
[1] 99.37112
INFO  [18:04:51.471] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -32.20002
[1] 80.68608
[1] -1171.878
[1] -38.58835
[1] -5185.426
[1] -79.56624
[1] -71.11557
[1] 14.37339
[1] -64.95777
[1] 13.71283
INFO  [18:05:33.581] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -88.92143
[1] 115.4953
[1] -130.4296
[1] -4.12235
[1] -118.0757
[1] 7.917375
[1] -146.8068
[1] 16.24887
[1] -771.683
[1] -44.75454
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:06:22.795] [mlr3] Finished benchmark
INFO  [18:06:23.088] [bbotk] Result of batch 20:
INFO  [18:06:23.119] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:06:23.119] [bbotk]              -4.386885                         0.3545052
INFO  [18:06:23.119] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:06:23.119] [bbotk]                         0.8110543           -2.786478               2.718849
INFO  [18:06:23.119] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:06:23.119] [bbotk]                         16                    3090                 0.3502197
INFO  [18:06:23.119] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:06:23.119] [bbotk]  0.02861117 <list[8]>              FALSE     0.02449194        0      0
INFO  [18:06:23.119] [bbotk]  runtime_learners                                uhash
INFO  [18:06:23.119] [bbotk]           131.286 f7c36c5e-62bc-4063-b368-d40328faaf8f
INFO  [18:06:25.288] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 51 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:06:30.300] [bbotk] Evaluating 1 configuration(s)
INFO  [18:06:30.461] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:06:30.589] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -127.1535
[1] 70.68351
[1] 32.98763
[1] 567.2654
[1] -33.32281
[1] 93.02202
[1] -83.56356
[1] 18.03237
[1] -32.04776
[1] 30.17215
INFO  [18:07:12.096] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -64.16415
[1] 30.23088
[1] -29.03705
[1] 75.36663
[1] -58.19714
[1] 13.25162
[1] -4359.534
[1] -137.6946
[1] -2815.773
[1] -60.54903
INFO  [18:07:47.690] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 51.22786
[1] 1501.665
[1] -268.4776
[1] 10.56921
[1] -49.81989
[1] 73.07021
[1] -77.76642
[1] 6.219379
[1] -98.58182
[1] 5.846522
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:08:36.703] [mlr3] Finished benchmark
INFO  [18:08:36.800] [bbotk] Result of batch 21:
INFO  [18:08:36.867] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:08:36.867] [bbotk]             -0.1581616                         0.6780907
INFO  [18:08:36.867] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:08:36.867] [bbotk]                         0.2814582         -0.02146937                2.95474
INFO  [18:08:36.867] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:08:36.867] [bbotk]                         16                    3479                 0.4010753
INFO  [18:08:36.867] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:08:36.867] [bbotk]  0.03105875 <list[8]>              FALSE     0.02469389        0      0
INFO  [18:08:36.867] [bbotk]  runtime_learners                                uhash
INFO  [18:08:36.867] [bbotk]           125.112 0fc2da9a-64b9-430c-94ce-19091695399e
INFO  [18:08:38.292] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 52 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:08:43.774] [bbotk] Evaluating 1 configuration(s)
INFO  [18:08:44.127] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:08:44.407] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -243.3225
[1] -4.648063
[1] -113.6444
[1] 79.8552
[1] -221876.2
[1] -4380.014
[1] -166.7371
[1] 207.253
[1] -83.51546
[1] 64.57221
INFO  [18:09:08.801] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -77.00048
[1] 51.3984
[1] -173.7441
[1] -5.296307
[1] -110.1209
[1] 102.2177
[1] -15.32149
[1] 248.0464
[1] -510.0502
[1] 136.4592
INFO  [18:10:13.985] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -177.1767
[1] 3.095417
[1] -36.78531
[1] 244.5355
[1] -43.40637
[1] 87.26501
[1] -20.56351
[1] 120.0522
[1] -295.8824
[1] 44.68593
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:10:59.691] [mlr3] Finished benchmark
INFO  [18:10:59.799] [bbotk] Result of batch 22:
INFO  [18:10:59.822] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:10:59.822] [bbotk]               2.366677                         0.6708442
INFO  [18:10:59.822] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:10:59.822] [bbotk]                          0.918008            -2.76118              -4.063122
INFO  [18:10:59.822] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:10:59.822] [bbotk]                         16                    4549                 0.6154499
INFO  [18:10:59.822] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:10:59.822] [bbotk]  0.05119594 <list[8]>              FALSE     0.04262258        0      0
INFO  [18:10:59.822] [bbotk]  runtime_learners                                uhash
INFO  [18:10:59.822] [bbotk]           134.919 25e3fe28-117a-450d-86ae-a77252968f64
WARN  [18:11:01.651] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:11:01.665] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 53 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:11:07.991] [bbotk] Evaluating 1 configuration(s)
INFO  [18:11:08.245] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:11:08.423] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -989.7701
[1] 544.6165
[1] -1148.1
[1] -17.82542
[1] 32.69578
[1] 1425.301
[1] -2795.215
[1] -52.38266
[1] -342506.2
[1] -5759.243
INFO  [18:11:29.128] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -459.9229
[1] 1140.714
[1] -424434.7
[1] -6920.145
[1] -953.5674
[1] -15.748
[1] -1236.097
[1] -20.37035
[1] -727.2058
[1] 380.762
INFO  [18:11:52.390] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1009.902
[1] -16.0504
[1] 7.545222
[1] 1217.395
[1] 29.11725
[1] 1428.165
[1] 22.51583
[1] 1120.019
[1] -2302.53
[1] -37.11693
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:12:14.345] [mlr3] Finished benchmark
INFO  [18:12:14.460] [bbotk] Result of batch 23:
INFO  [18:12:14.546] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:12:14.546] [bbotk]               2.751847                         0.4240372
INFO  [18:12:14.546] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:12:14.546] [bbotk]                         0.1096542           -7.376423              -2.593231
INFO  [18:12:14.546] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:12:14.546] [bbotk]                          7                    1304                 0.6615901
INFO  [18:12:14.546] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:12:14.546] [bbotk]  0.04117707 <list[8]>              FALSE     0.07162353        0      0
INFO  [18:12:14.546] [bbotk]  runtime_learners                                uhash
INFO  [18:12:14.546] [bbotk]            64.467 ba88215a-470c-4a3e-8388-b19e41557528
INFO  [18:12:15.913] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 54 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:12:22.506] [bbotk] Evaluating 1 configuration(s)
INFO  [18:12:22.684] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:12:22.779] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -26.80859
[1] 32.41229
[1] -107.0855
[1] 55.53642
[1] 43.99883
[1] 1708.998
[1] -60.95106
[1] 19.60818
[1] 78.53718
[1] 2392.487
INFO  [18:12:44.615] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -68.57151
[1] 37.37701
[1] -193.163
[1] 33.56606
[1] -69.96885
[1] 136.8191
[1] -278.8862
[1] -4.215192
[1] -149.3717
[1] 83.17786
INFO  [18:13:45.893] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -13.82705
[1] 210.6209
[1] -61.10341
[1] 51.3906
[1] -4165.639
[1] -108.566
[1] -125.7
[1] 12.8768
[1] -55.51107
[1] 26.80458
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:14:20.745] [mlr3] Finished benchmark
INFO  [18:14:20.898] [bbotk] Result of batch 24:
INFO  [18:14:20.918] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:14:20.918] [bbotk]              -3.661352                         0.7391731
INFO  [18:14:20.918] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:14:20.918] [bbotk]                         0.4470812           -3.296754              -0.505545
INFO  [18:14:20.918] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:14:20.918] [bbotk]                         20                    4163                 0.2202277
INFO  [18:14:20.918] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:14:20.918] [bbotk]  0.02763998 <list[8]>              FALSE     0.02071026        0      0
INFO  [18:14:20.918] [bbotk]  runtime_learners                                uhash
INFO  [18:14:20.918] [bbotk]           117.314 264b70c2-f9ff-4387-8707-af4df1d37b44
INFO  [18:14:22.192] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 55 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:14:28.581] [bbotk] Evaluating 1 configuration(s)
INFO  [18:14:28.715] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:14:28.822] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -135.3159
[1] 34.33974
[1] -36.54266
[1] 353.4574
[1] -105.9374
[1] 260.2079
[1] -78.73655
[1] 33.68993
[1] -30.98169
[1] 104.4282
INFO  [18:14:52.195] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -203.7621
[1] 30.28715
[1] -93.2898
[1] 13.11485
[1] -150.1509
[1] 77.60656
[1] 70.99428
[1] 2112.776
[1] -117.5614
[1] 39.83884
INFO  [18:15:50.695] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -211.4528
[1] 52.47263
[1] -71.49104
[1] 34.1314
[1] -340.1213
[1] -11.17653
[1] -60256.42
[1] -975.749
[1] -29.16181
[1] 91.50974
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:16:46.821] [mlr3] Finished benchmark
INFO  [18:16:47.047] [bbotk] Result of batch 25:
INFO  [18:16:47.225] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:16:47.225] [bbotk]              -5.037593                         0.3453519
INFO  [18:16:47.225] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:16:47.225] [bbotk]                          0.667095           -7.060353              -2.178682
INFO  [18:16:47.225] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:16:47.225] [bbotk]                          8                    3327                 0.3680839
INFO  [18:16:47.225] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:16:47.225] [bbotk]  0.02591013 <list[8]>              FALSE     0.02971048        0      0
INFO  [18:16:47.225] [bbotk]  runtime_learners                                uhash
INFO  [18:16:47.225] [bbotk]           137.254 0c8c91cc-e50b-4b4b-9134-38dc43f6af6f
INFO  [18:16:49.032] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 56 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:16:54.527] [bbotk] Evaluating 1 configuration(s)
INFO  [18:16:54.731] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:16:55.023] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -96.89859
[1] 73.68797
[1] -35.62545
[1] 317.2734
[1] -8238.835
[1] -137.4001
[1] -41.36907
[1] 40.84968
[1] -70.65049
[1] 68.89232
INFO  [18:17:13.052] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -95.70977
[1] 228.7174
[1] -63.91495
[1] 103.3209
[1] -102.9376
[1] -3.838725
[1] -88.81631
[1] 116.3182
[1] -134.1846
[1] 36.30721
INFO  [18:17:33.865] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -30.00976
[1] 55.74308
[1] -47.62543
[1] 105.7384
[1] -79.95408
[1] 95.18785
[1] -192.6775
[1] -4.347961
[1] -40.56949
[1] 200.5882
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:17:50.888] [mlr3] Finished benchmark
INFO  [18:17:51.260] [bbotk] Result of batch 26:
INFO  [18:17:51.423] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:17:51.423] [bbotk]              -1.304631                         0.8788169
INFO  [18:17:51.423] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:17:51.423] [bbotk]                         0.8881404           -4.115183              0.5447909
INFO  [18:17:51.423] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:17:51.423] [bbotk]                          9                     292                 0.1924927
INFO  [18:17:51.423] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:17:51.423] [bbotk]  0.02706306 <list[8]>              FALSE     0.03467644        0      0
INFO  [18:17:51.423] [bbotk]  runtime_learners                                uhash
INFO  [18:17:51.423] [bbotk]            55.185 dbeb49ef-57e4-40ee-bbf0-dc75318c3f83
INFO  [18:17:53.392] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 57 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:17:58.857] [bbotk] Evaluating 1 configuration(s)
INFO  [18:17:58.917] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:17:58.991] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -5682.022
[1] -101.227
[1] -36.54249
[1] 46.78205
[1] -85.78413
[1] 144.7773
[1] -91.02221
[1] 9.803363
[1] -113.9167
[1] 2.216214
INFO  [18:18:27.864] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -59.18023
[1] 10.15206
[1] 62.58295
[1] 2180.526
[1] -21.598
[1] 53.16073
[1] -115.0613
[1] -3.90556
[1] -215.83
[1] 28.27958
INFO  [18:19:27.656] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -39.62407
[1] 49.89559
[1] -3270.574
[1] -121.4235
[1] -19.21445
[1] 37.46853
[1] -57.4774
[1] 8.801675
[1] -1081.983
[1] -28.4601
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:20:30.962] [mlr3] Finished benchmark
INFO  [18:20:31.537] [bbotk] Result of batch 27:
INFO  [18:20:31.840] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:20:31.840] [bbotk]              -2.155135                         0.7971291
INFO  [18:20:31.840] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:20:31.840] [bbotk]                          0.699372           -1.949862               3.132963
INFO  [18:20:31.840] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:20:31.840] [bbotk]                         11                    4001                 0.5468108
INFO  [18:20:31.840] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:20:31.840] [bbotk]  0.02422659 <list[8]>              FALSE     0.02200433        0      0
INFO  [18:20:31.840] [bbotk]  runtime_learners                                uhash
INFO  [18:20:31.840] [bbotk]           150.364 794aea47-98d2-436f-9f10-0521b93c0ddd
WARN  [18:20:36.885] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:20:37.222] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 58 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:20:45.469] [bbotk] Evaluating 1 configuration(s)
INFO  [18:20:45.915] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:20:46.741] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -40.27947
[1] 42.26161
[1] -50.39015
[1] 25.84884
[1] -65.06997
[1] 18.91708
[1] -37.10123
[1] 211.3162
[1] -6389.893
[1] -77.80351
INFO  [18:21:23.620] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -26.608
[1] 45.74621
[1] 553.1635
[1] 12364.16
[1] -20.30572
[1] 45.61539
[1] -81.71009
[1] 8.720546
[1] -601.273
[1] -15.10379
INFO  [18:22:05.890] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2.148879
[1] 92.73824
[1] -22.94043
[1] 34.75354
[1] -18.29659
[1] 45.37059
[1] -48.80908
[1] 78.93144
[1] -104.0451
[1] 6.853581
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:22:55.207] [mlr3] Finished benchmark
INFO  [18:22:55.338] [bbotk] Result of batch 28:
INFO  [18:22:55.483] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:22:55.483] [bbotk]              0.7335182                          0.313164
INFO  [18:22:55.483] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:22:55.483] [bbotk]                         0.6240107            -0.48865              -3.019751
INFO  [18:22:55.483] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:22:55.483] [bbotk]                         17                    4195                 0.4947665
INFO  [18:22:55.483] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:22:55.483] [bbotk]  0.02588623 <list[8]>              FALSE     0.02977006        0      0
INFO  [18:22:55.483] [bbotk]  runtime_learners                                uhash
INFO  [18:22:55.483] [bbotk]           126.027 cf7451c8-a020-4232-957b-efd40d040d16
INFO  [18:22:57.632] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 59 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:23:03.006] [bbotk] Evaluating 1 configuration(s)
INFO  [18:23:03.273] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:23:03.338] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 60.82866
[1] 1170.844
[1] -32.31038
[1] 115.9051
[1] -1256.251
[1] -30.03408
[1] -313.338
[1] 22.71783
[1] -27.95935
[1] 15.6291
INFO  [18:23:30.769] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -44.30698
[1] 20.37243
[1] -46.92231
[1] 49.93186
[1] 81.85207
[1] 3295.334
[1] -89.17936
[1] 15.48079
[1] -231.0198
[1] 19.52834
INFO  [18:24:09.683] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -65.02271
[1] 5.810507
[1] -99.84705
[1] 373.0645
[1] -30.001
[1] 74.69943
[1] -119.5368
[1] 18.47878
[1] -97.93783
[1] 32.33052
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:24:43.098] [mlr3] Finished benchmark
INFO  [18:24:43.198] [bbotk] Result of batch 29:
INFO  [18:24:43.226] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:24:43.226] [bbotk]              -5.766583                         0.4434165
INFO  [18:24:43.226] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:24:43.226] [bbotk]                         0.2715851           -2.951945              -2.145287
INFO  [18:24:43.226] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:24:43.226] [bbotk]                         20                    2262                 0.3426168
INFO  [18:24:43.226] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:24:43.226] [bbotk]  0.02337053 <list[8]>              FALSE     0.02282222        0      0
INFO  [18:24:43.226] [bbotk]  runtime_learners                                uhash
INFO  [18:24:43.226] [bbotk]             98.37 d52097d7-7948-4594-b32d-b3223d07c496
INFO  [18:24:44.836] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 60 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:24:49.466] [bbotk] Evaluating 1 configuration(s)
INFO  [18:24:49.530] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:24:49.599] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -54.17557
[1] 21.02034
[1] -52.88751
[1] 66.85762
[1] -93.43786
[1] 14.81298
[1] -943.7344
[1] -85.22145
[1] -13.84813
[1] 25.70441
INFO  [18:25:09.617] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -431.24
[1] 12.02305
[1] -78.34444
[1] 99.29856
[1] 38.44738
[1] 1499.353
[1] -46.1626
[1] 0.7748063
[1] -35.71333
[1] 19.29261
INFO  [18:25:44.107] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1411.441
[1] -42.30227
[1] -29.99984
[1] 81.83025
[1] -64.91216
[1] 17.20634
[1] -650.6314
[1] -3.765087
[1] -86.54513
[1] 4.376708
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:26:13.300] [mlr3] Finished benchmark
INFO  [18:26:13.488] [bbotk] Result of batch 30:
INFO  [18:26:13.769] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:26:13.769] [bbotk]              -2.624261                         0.2815588
INFO  [18:26:13.769] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:26:13.769] [bbotk]                         0.8013415          -0.6647173              -4.557624
INFO  [18:26:13.769] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:26:13.769] [bbotk]                         18                    2330                 0.2512336
INFO  [18:26:13.769] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:26:13.769] [bbotk]  0.02178515 <list[8]>              FALSE     0.02207646        0      0
INFO  [18:26:13.769] [bbotk]  runtime_learners                                uhash
INFO  [18:26:13.769] [bbotk]            81.698 58b32cfa-3609-4e67-a132-d068b6719cae
INFO  [18:26:16.896] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 61 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:26:25.227] [bbotk] Evaluating 1 configuration(s)
INFO  [18:26:25.392] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:26:25.514] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -77.57891
[1] 57.43983
[1] -26.09444
[1] 22.8682
[1] 52.90509
[1] 764.6858
[1] -68.59187
[1] 15.328
[1] -23.72251
[1] 123.4534
INFO  [18:27:02.825] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -56.31511
[1] 100.6882
[1] -914.9484
[1] -64.05018
[1] -60.51268
[1] 79.3796
[1] -42.43464
[1] 16.65336
[1] -5008.954
[1] -219.3834
INFO  [18:27:24.179] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -94.58273
[1] -0.2068772
[1] -78.89789
[1] 9.008016
[1] -22.29583
[1] 43.12318
[1] -3587.501
[1] -46.64441
[1] -106.456
[1] 7.816249
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:27:55.076] [mlr3] Finished benchmark
INFO  [18:27:55.445] [bbotk] Result of batch 31:
INFO  [18:27:55.523] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:27:55.523] [bbotk]              -4.338625                         0.4614736
INFO  [18:27:55.523] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:27:55.523] [bbotk]                         0.4731876          -0.6762858               -2.71267
INFO  [18:27:55.523] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:27:55.523] [bbotk]                         17                    2219                 0.5598134
INFO  [18:27:55.523] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:27:55.523] [bbotk]  0.0220425 <list[8]>              FALSE     0.02587013        0      0
INFO  [18:27:55.523] [bbotk]  runtime_learners                                uhash
INFO  [18:27:55.523] [bbotk]            87.316 13968339-a1ef-4df5-813d-94f996bd430a
WARN  [18:27:58.020] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:27:58.141] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 62 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:28:03.834] [bbotk] Evaluating 1 configuration(s)
INFO  [18:28:03.966] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:28:04.258] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 34.45548
[1] 2015.926
[1] -516.9499
[1] 212.2283
[1] -2288.028
[1] -43.01039
[1] 13.38171
[1] 660.2631
[1] -110363.9
[1] -2094.156
INFO  [18:28:29.627] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -659.2752
[1] -12.16226
[1] -1722.409
[1] -32.03593
[1] -780.5744
[1] -14.04335
[1] 14.08902
[1] 701.9893
[1] -544.4664
[1] 535.6471
INFO  [18:28:54.364] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 15.17982
[1] 774.4607
[1] -847.9959
[1] -15.21019
[1] -707.5101
[1] -13.10813
[1] -1122.451
[1] 353.3047
[1] -919.7146
[1] 7.597681
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:29:14.590] [mlr3] Finished benchmark
INFO  [18:29:14.683] [bbotk] Result of batch 32:
INFO  [18:29:14.783] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:29:14.783] [bbotk]              -5.984933                         0.3484167
INFO  [18:29:14.783] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:29:14.783] [bbotk]                         0.6571306           -7.753858              0.8419752
INFO  [18:29:14.783] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:29:14.783] [bbotk]                         20                     636                 0.8493052
INFO  [18:29:14.783] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:29:14.783] [bbotk]  0.01998161 <list[8]>              FALSE     0.04162185        0      0
INFO  [18:29:14.783] [bbotk]  runtime_learners                                uhash
INFO  [18:29:14.783] [bbotk]            69.739 f9e5ee7d-2eb6-4d46-a954-f2dfe29b454f
WARN  [18:29:16.574] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:29:16.631] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 63 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:29:23.249] [bbotk] Evaluating 1 configuration(s)
INFO  [18:29:23.308] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:29:23.351] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -687.8171
[1] -15.45369
[1] -509.6982
[1] -8.314948
[1] 15.06714
[1] 660.8386
[1] -541.8234
[1] 10.87131
[1] -852.6143
[1] 187.8533
INFO  [18:31:21.676] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -336.528
[1] -6.813081
[1] -286.0213
[1] 349.8846
[1] 12.35915
[1] 566.9677
[1] -266.4164
[1] -5.139503
[1] -583.9274
[1] -9.568384
INFO  [18:32:32.963] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -487.1825
[1] -9.479437
[1] -1326.65
[1] -25.4656
[1] -135.6341
[1] 344.4374
[1] -407.9784
[1] -7.425667
[1] -398.9981
[1] 74.34704
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:34:21.288] [mlr3] Finished benchmark
INFO  [18:34:21.467] [bbotk] Result of batch 33:
INFO  [18:34:21.533] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:34:21.533] [bbotk]               2.974325                           0.88407
INFO  [18:34:21.533] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:34:21.533] [bbotk]                         0.9539046           -8.450976              -3.708858
INFO  [18:34:21.533] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:34:21.533] [bbotk]                         16                    3754                 0.9536814
INFO  [18:34:21.533] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:34:21.533] [bbotk]  0.03394599 <list[8]>              FALSE     0.04728401        0      0
INFO  [18:34:21.533] [bbotk]  runtime_learners                                uhash
INFO  [18:34:21.533] [bbotk]           297.621 2946e33b-26c4-44f4-85ad-b1867b773b96
INFO  [18:34:22.719] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 64 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:34:30.494] [bbotk] Evaluating 1 configuration(s)
INFO  [18:34:30.596] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:34:30.656] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -291.1857
[1] 5.041813
[1] -24.47553
[1] 160.5137
[1] -82.46597
[1] 78.57695
[1] -4.453873
[1] 164.5499
[1] -52.56197
[1] 182.999
INFO  [18:34:58.283] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1707.14
[1] -47.52727
[1] -3.797807e+16
[1] 1.521692e+15
[1] -102.5845
[1] 18.19534
[1] -24.21388
[1] 106.6094
[1] -94.4096
[1] 16.99765
INFO  [18:35:32.771] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -81.07183
[1] 32.88358
[1] -801.8239
[1] -44.02809
[1] -71.32712
[1] 16.73286
[1] -240.1009
[1] -1.875453
[1] -14.36539
[1] 151.886
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:35:59.905] [mlr3] Finished benchmark
INFO  [18:36:00.104] [bbotk] Result of batch 34:
INFO  [18:36:00.182] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:36:00.182] [bbotk]             -0.8083591                         0.3164111
INFO  [18:36:00.182] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:36:00.182] [bbotk]                         0.8179508           -2.220056               1.069837
INFO  [18:36:00.182] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:36:00.182] [bbotk]                          1                    1837                 0.2603525
INFO  [18:36:00.182] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:36:00.182] [bbotk]  0.02008619 <list[8]>              FALSE     0.02165464        0      0
INFO  [18:36:00.182] [bbotk]  runtime_learners                                uhash
INFO  [18:36:00.182] [bbotk]            88.423 f676ae0e-4093-407d-8376-14154375cb86
INFO  [18:36:03.637] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 65 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:36:11.077] [bbotk] Evaluating 1 configuration(s)
INFO  [18:36:11.370] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:36:11.720] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -58.50918
[1] 51.46696
[1] -483.958
[1] 25.91763
[1] -68.28791
[1] 65.70237
[1] -43.55447
[1] 51.35206
[1] -112.5523
[1] 40.75685
INFO  [18:37:03.095] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -68.0842
[1] 33.45386
[1] -52.2254
[1] 52.02981
[1] -71.87309
[1] 94.5353
[1] 7.242877
[1] 369.7689
[1] -133.768
[1] 36.94397
INFO  [18:37:42.061] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -250.4333
[1] -3.625212
[1] 330.9577
[1] 9202.167
[1] -82.07723
[1] 30.29088
[1] -74.25658
[1] 233.2475
[1] -11.97522
[1] 130.099
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:38:30.072] [mlr3] Finished benchmark
INFO  [18:38:30.384] [bbotk] Result of batch 35:
INFO  [18:38:30.455] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:38:30.455] [bbotk]               1.272368                         0.4647862
INFO  [18:38:30.455] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:38:30.455] [bbotk]                         0.1817382           -0.598338              0.8938697
INFO  [18:38:30.455] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:38:30.455] [bbotk]                          8                    4401                 0.2542594
INFO  [18:38:30.455] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:38:30.455] [bbotk]  0.01979816 <list[8]>              FALSE     0.03323967        0      0
INFO  [18:38:30.455] [bbotk]  runtime_learners                                uhash
INFO  [18:38:30.455] [bbotk]           137.825 c23737ad-937a-402a-a469-a9082ed65be9
WARN  [18:38:32.221] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:38:32.252] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 66 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:38:36.018] [bbotk] Evaluating 1 configuration(s)
INFO  [18:38:36.113] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:38:36.166] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -40.00156
[1] 40.67427
[1] -119.0456
[1] 12.05891
[1] -30.10848
[1] 153.2494
[1] -32.04025
[1] 29.09695
[1] -31.58226
[1] 18.79988
INFO  [18:39:20.508] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -18.36703
[1] 77.50678
[1] -36.65717
[1] 23.82508
[1] -30.68617
[1] 68.26413
[1] -78.99283
[1] 28.47206
[1] -72.40858
[1] 7.208683
INFO  [18:40:04.508] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -19.5738
[1] 337.0578
[1] -35.66906
[1] 65.86195
[1] -112.88
[1] -2.561581
[1] -54.82035
[1] 21.92672
[1] -266.5012
[1] 11.00255
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:40:58.357] [mlr3] Finished benchmark
INFO  [18:40:58.504] [bbotk] Result of batch 36:
INFO  [18:40:58.563] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:40:58.563] [bbotk]             -0.3488411                         0.9244412
INFO  [18:40:58.563] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:40:58.563] [bbotk]                         0.8193546          -0.6676321              -5.883399
INFO  [18:40:58.563] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:40:58.563] [bbotk]                          2                    3839                 0.8238003
INFO  [18:40:58.563] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:40:58.563] [bbotk]  0.01951642 <list[8]>              FALSE     0.02431215        0      0
INFO  [18:40:58.563] [bbotk]  runtime_learners                                uhash
INFO  [18:40:58.563] [bbotk]           141.698 df0652d6-0a99-4801-a2d9-d72d2d0a63b2
INFO  [18:41:00.139] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 67 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:41:06.441] [bbotk] Evaluating 1 configuration(s)
INFO  [18:41:06.578] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:41:06.663] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -75.4063
[1] 8.798381
[1] -31.40547
[1] 46.445
[1] -3159.226
[1] -53.32134
[1] -107.9836
[1] -2.657294
[1] -8566.827
[1] -116.6041
INFO  [18:41:19.865] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -39.50757
[1] 37.58262
[1] -2365.94
[1] -69.99435
[1] -74.10733
[1] -3.119478
[1] -37.12642
[1] 48.08794
[1] -22.58227
[1] 74.50989
INFO  [18:41:34.648] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -39.03022
[1] 55.93072
[1] -60.21513
[1] 13.99207
[1] -111.2654
[1] 73.90044
[1] -58.12567
[1] 11.62198
[1] -826.719
[1] -61.23267
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:42:02.662] [mlr3] Finished benchmark
INFO  [18:42:02.926] [bbotk] Result of batch 37:
INFO  [18:42:02.998] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:42:02.998] [bbotk]               -5.85763                         0.7461077
INFO  [18:42:02.998] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:42:02.998] [bbotk]                         0.7729294           -1.236473              0.2547351
INFO  [18:42:02.998] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:42:02.998] [bbotk]                         10                     673                  0.315791
INFO  [18:42:02.998] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:42:02.998] [bbotk]  0.01940747 <list[8]>              FALSE     0.02062513        0      0
INFO  [18:42:02.998] [bbotk]  runtime_learners                                uhash
INFO  [18:42:02.998] [bbotk]            53.648 ba5123fc-f1a2-4eec-a2de-b8f48ab9aac6
INFO  [18:42:12.182] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 68 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:42:20.449] [bbotk] Evaluating 1 configuration(s)
INFO  [18:42:20.917] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:42:21.389] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -35.79272
[1] 20.35765
[1] -49.70815
[1] 23.44663
[1] -13.69024
[1] 41.4538
[1] -57.83315
[1] 15.4242
[1] -599.7102
[1] -33.76128
INFO  [18:42:37.045] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -77.26929
[1] -3.908511
[1] -77.09906
[1] 18.68578
[1] -74.3382
[1] 27.2489
[1] -103.5955
[1] 13.68271
[1] -41.33412
[1] 200.3222
INFO  [18:42:52.030] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -21.29351
[1] 50.47548
[1] -89.74337
[1] 9.676217
[1] -80.95791
[1] 13.1024
[1] -1164.07
[1] -41.49484
[1] -40.86705
[1] 40.19926
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:43:09.892] [mlr3] Finished benchmark
INFO  [18:43:10.415] [bbotk] Result of batch 38:
INFO  [18:43:10.512] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:43:10.512] [bbotk]              -1.439674                         0.2581752
INFO  [18:43:10.512] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:43:10.512] [bbotk]                          0.864978           -0.437468              -5.564993
INFO  [18:43:10.512] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:43:10.512] [bbotk]                          8                     546                 0.8279483
INFO  [18:43:10.512] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:43:10.512] [bbotk]  0.01752622 <list[8]>              FALSE     0.02356795        0      0
INFO  [18:43:10.512] [bbotk]  runtime_learners                                uhash
INFO  [18:43:10.512] [bbotk]            47.443 913cd70f-9508-401d-9ca7-b5ca7fac5214
INFO  [18:43:12.513] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 69 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:43:19.842] [bbotk] Evaluating 1 configuration(s)
INFO  [18:43:20.149] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:43:20.347] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -2461.597
[1] -72.67448
[1] -78.2791
[1] 69.01169
[1] -26.21652
[1] 20.40251
[1] -47.13398
[1] 13.42197
[1] -62.87175
[1] 23.65738
INFO  [18:44:09.785] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -50.86739
[1] 68.25976
[1] -45.14916
[1] 13.68058
[1] -295.9847
[1] 21.36761
[1] -33.88101
[1] 26.024
[1] -32.62355
[1] 11.72401
INFO  [18:45:13.277] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -42.8227
[1] 23.38787
[1] -18.11241
[1] 58.07084
[1] -62.22963
[1] 7.633857
[1] -62.47699
[1] 46.66291
[1] -93.18758
[1] 1.897944
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:45:42.235] [mlr3] Finished benchmark
INFO  [18:45:42.691] [bbotk] Result of batch 39:
INFO  [18:45:42.758] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:45:42.758] [bbotk]              -5.456085                         0.5438765
INFO  [18:45:42.758] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:45:42.758] [bbotk]                         0.8111552          -0.6493553              0.2129969
INFO  [18:45:42.758] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:45:42.758] [bbotk]                         15                    4362                 0.6957486
INFO  [18:45:42.758] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:45:42.758] [bbotk]  0.01777538 <list[8]>              FALSE     0.02098019        0      0
INFO  [18:45:42.758] [bbotk]  runtime_learners                                uhash
INFO  [18:45:42.758] [bbotk]           140.991 16e03d75-3602-4585-8395-6d9630067166
INFO  [18:45:45.493] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 70 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:45:50.974] [bbotk] Evaluating 1 configuration(s)
INFO  [18:45:51.006] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:45:51.072] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -41.03489
[1] 20.42393
[1] -95.96601
[1] 17.40136
[1] -28.47429
[1] 117.1004
[1] -58.09011
[1] 308.2479
[1] 75.35381
[1] 3285.333
INFO  [18:46:40.233] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1040.847
[1] -38.36235
[1] -45.21855
[1] 16.09561
[1] -52.71214
[1] 11.41908
[1] -74.94619
[1] 15.00855
[1] -16.73914
[1] 182.5163
INFO  [18:47:28.757] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -50.92203
[1] 32.26251
[1] -662.9417
[1] -7.893429
[1] -25.15223
[1] 31.20953
[1] -134.6069
[1] 0.3509559
[1] -533.4393
[1] 3.281127
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:48:26.052] [mlr3] Finished benchmark
INFO  [18:48:26.536] [bbotk] Result of batch 40:
INFO  [18:48:26.652] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:48:26.652] [bbotk]              -3.718267                          0.538017
INFO  [18:48:26.652] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:48:26.652] [bbotk]                         0.7973659           -2.531066             -0.9488996
INFO  [18:48:26.652] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:48:26.652] [bbotk]                         15                    4761                 0.7656216
INFO  [18:48:26.652] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:48:26.652] [bbotk]  0.01687547 <list[8]>              FALSE     0.02240883        0      0
INFO  [18:48:26.652] [bbotk]  runtime_learners                                uhash
INFO  [18:48:26.652] [bbotk]           153.957 9c990c23-e501-4d1d-acf8-b6f651c4b789
INFO  [18:48:29.950] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 71 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:48:39.671] [bbotk] Evaluating 1 configuration(s)
INFO  [18:48:39.797] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:48:39.840] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -81.19629
[1] 42.70174
[1] -99.1996
[1] 4.420017
[1] -85.04334
[1] 191.8416
[1] -98.12928
[1] 7.671958
[1] -3605.996
[1] -90.93664
INFO  [18:48:51.843] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -221.5965
[1] 2.91061
[1] -66.53145
[1] 116.1276
[1] 45.35193
[1] 1420.189
[1] -44.12597
[1] 89.54028
[1] -60.78499
[1] 15.82273
INFO  [18:49:06.275] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -131.3084
[1] 31.39018
[1] -217.3924
[1] 4.30712
[1] -87.41459
[1] 5.560817
[1] -49.20544
[1] 19.58792
[1] -4520.426
[1] -68.55224
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:49:20.405] [mlr3] Finished benchmark
INFO  [18:49:20.611] [bbotk] Result of batch 41:
INFO  [18:49:20.676] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:49:20.676] [bbotk]              -1.387526                         0.6318825
INFO  [18:49:20.676] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:49:20.676] [bbotk]                         0.4719602          -0.3797171               3.431513
INFO  [18:49:20.676] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:49:20.676] [bbotk]                          5                     210                 0.6959508
INFO  [18:49:20.676] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:49:20.676] [bbotk]  0.01832594 <list[8]>              FALSE     0.02775689        0      0
INFO  [18:49:20.676] [bbotk]  runtime_learners                                uhash
INFO  [18:49:20.676] [bbotk]            39.398 2a8180eb-e58b-4ac5-8e3c-e9871e658bcd
INFO  [18:49:24.147] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 72 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:49:31.781] [bbotk] Evaluating 1 configuration(s)
INFO  [18:49:32.015] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:49:32.225] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -1002.953
[1] -16.1326
[1] -127.0623
[1] 429.3078
[1] -555.0666
[1] -9.204852
[1] -75.02628
[1] 439.5722
[1] -191.9671
[1] 446.0545
INFO  [18:50:13.322] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -555.5978
[1] -10.8842
[1] 2055.464
[1] 96190.32
[1] -605.4389
[1] -9.736095
[1] 13.356
[1] 669.8067
[1] -596.8143
[1] -10.75162
INFO  [18:51:05.197] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -51187.01
[1] -992.8191
[1] -974.9588
[1] -15.89413
[1] -163.7594
[1] 297.2112
[1] -610.4866
[1] -10.52897
[1] 13.0432
[1] 593.3112
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:51:58.866] [mlr3] Finished benchmark
INFO  [18:51:59.328] [bbotk] Result of batch 42:
INFO  [18:51:59.438] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:51:59.438] [bbotk]             -0.1030883                          0.685751
INFO  [18:51:59.438] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:51:59.438] [bbotk]                         0.1031001           -8.784883              -2.887835
INFO  [18:51:59.438] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:51:59.438] [bbotk]                         20                    4168                 0.3152343
INFO  [18:51:59.438] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:51:59.438] [bbotk]  0.01526557 <list[8]>              FALSE     0.04464954        0      0
INFO  [18:51:59.438] [bbotk]  runtime_learners                                uhash
INFO  [18:51:59.438] [bbotk]           146.215 4880b35e-db46-4710-bc47-21dae8da68c8
WARN  [18:52:03.693] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:52:03.719] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 73 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:52:10.480] [bbotk] Evaluating 1 configuration(s)
INFO  [18:52:10.754] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:52:11.042] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -33.85512
[1] 203.7385
[1] -56.54001
[1] 373.8601
[1] -193.3834
[1] 103.7444
[1] -403.9131
[1] -6.651953
[1] -37.18731
[1] 259.6802
INFO  [18:52:40.425] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -12.97618
[1] 463.8611
[1] -225.3158
[1] 85.91539
[1] -275.6637
[1] 385.1333
[1] -299.7668
[1] -0.3275713
[1] -589.0694
[1] 433.5635
INFO  [18:53:10.496] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -145.377
[1] 260.716
[1] -98.45523
[1] 161.2655
[1] -454.3735
[1] -6.922697
[1] -84.26982
[1] 225.1294
[1] -224.1803
[1] 395.042
INFO  [18:53:50.442] [mlr3] Finished benchmark
INFO  [18:53:50.551] [bbotk] Result of batch 43:
INFO  [18:53:50.561] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:53:50.561] [bbotk]               2.182323                         0.1293294
INFO  [18:53:50.561] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:53:50.561] [bbotk]                         0.6454627           -6.807409              -5.698974
INFO  [18:53:50.561] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:53:50.561] [bbotk]                         16                    1758                 0.5413842
INFO  [18:53:50.561] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:53:50.561] [bbotk]  0.01945166 <list[8]>              FALSE      0.0475942        0      0
INFO  [18:53:50.561] [bbotk]  runtime_learners                                uhash
INFO  [18:53:50.561] [bbotk]            98.985 5d8c5478-9a36-4d6b-b142-3eba427f3c88
INFO  [18:53:54.577] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 74 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:54:14.295] [bbotk] Evaluating 1 configuration(s)
INFO  [18:54:14.629] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:54:14.836] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 44.62896
[1] 1523.005
[1] -3929.709
[1] -188.3186
[1] -22.73291
[1] 22.51016
[1] -77.51907
[1] 52.98433
[1] -3.464312e+16
[1] 1.301413e+14
INFO  [18:54:46.714] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -58.63474
[1] 40.11712
[1] -70.5903
[1] 13.1129
[1] -1092.17
[1] 130.3685
[1] -83.42523
[1] 9.808407
[1] -306729.5
[1] -8654.815
INFO  [18:55:21.152] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2.267071e+16
[1] 4.997928e+15
[1] -506.8479
[1] 9.278823
[1] -96.173
[1] 45.89092
[1] -112.6636
[1] 6.875133
[1] -3416.483
[1] -190.0151
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:56:03.174] [mlr3] Finished benchmark
INFO  [18:56:03.664] [bbotk] Result of batch 44:
INFO  [18:56:03.715] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:56:03.715] [bbotk]             -0.8277815                         0.7320105
INFO  [18:56:03.715] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:56:03.715] [bbotk]                         0.7755921           -2.185805              0.2322068
INFO  [18:56:03.715] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:56:03.715] [bbotk]                          7                    1733                 0.5442244
INFO  [18:56:03.715] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:56:03.715] [bbotk]  0.01675169 <list[8]>              FALSE     0.02407324        0      0
INFO  [18:56:03.715] [bbotk]  runtime_learners                                uhash
INFO  [18:56:03.715] [bbotk]           108.064 01e0443d-fc01-4ad3-9e3e-99c52eaaa003
INFO  [18:56:09.480] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 75 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:56:25.914] [bbotk] Evaluating 1 configuration(s)
INFO  [18:56:26.409] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:56:26.544] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -8.310434
[1] 91.91028
[1] -2094.195
[1] -82.77711
[1] -6.847252
[1] 169.1317
[1] -31.69073
[1] 62.78113
[1] -736.8758
[1] 5.2279
INFO  [18:56:51.003] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -80.48432
[1] 7.749855
[1] -79.13828
[1] 9.884372
[1] -115.589
[1] 33.10974
[1] -39.14618
[1] 16.59152
[1] -48.93195
[1] 76.01767
INFO  [18:57:11.266] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -89.52441
[1] 12.13259
[1] -54.11837
[1] 125.9789
[1] -129.2691
[1] 5.172635
[1] -35.58818
[1] 30.72617
[1] -3263.069
[1] -94.83828
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:57:37.685] [mlr3] Finished benchmark
INFO  [18:57:38.368] [bbotk] Result of batch 45:
INFO  [18:57:38.440] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:57:38.440] [bbotk]               -1.97354                         0.4612968
INFO  [18:57:38.440] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:57:38.440] [bbotk]                         0.8118451          -0.5980968               1.802498
INFO  [18:57:38.440] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:57:38.440] [bbotk]                         10                    1278                 0.2925756
INFO  [18:57:38.440] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:57:38.440] [bbotk]  0.01647508 <list[8]>              FALSE     0.02449479        0      0
INFO  [18:57:38.440] [bbotk]  runtime_learners                                uhash
INFO  [18:57:38.440] [bbotk]            70.784 f860ea6e-d7b6-468e-ba2f-cd9ccb45067b
INFO  [18:57:40.959] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 76 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:57:50.650] [bbotk] Evaluating 1 configuration(s)
INFO  [18:57:50.816] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:57:50.851] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -63.46257
[1] 20.26664
[1] -68.37824
[1] 78.68832
[1] -26.15137
[1] 82.71286
[1] -2986.735
[1] -58.5184
[1] -7.369405
[1] 81.6178
INFO  [18:58:27.601] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -19.58231
[1] 40.51796
[1] -128.3707
[1] -0.2529466
[1] -903.374
[1] 157.2286
[1] -66.11718
[1] 15.10335
[1] -3412.524
[1] -172.4018
INFO  [18:59:47.089] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -68.24687
[1] 56.3316
[1] -3139.147
[1] -144.6785
[1] -81.91726
[1] 30.19095
[1] -21.85302
[1] 54.72612
[1] -63.69713
[1] 25.80255
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:00:43.827] [mlr3] Finished benchmark
INFO  [19:00:43.902] [bbotk] Result of batch 46:
INFO  [19:00:43.909] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:00:43.909] [bbotk]              -1.790584                         0.5572008
INFO  [19:00:43.909] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:00:43.909] [bbotk]                         0.3373729           -2.703286               -6.64557
INFO  [19:00:43.909] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:00:43.909] [bbotk]                         18                    4401                 0.6550854
INFO  [19:00:43.909] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:00:43.909] [bbotk]  0.01568208 <list[8]>              FALSE     0.02303262        0      0
INFO  [19:00:43.909] [bbotk]  runtime_learners                                uhash
INFO  [19:00:43.909] [bbotk]           172.438 7aeae206-9e64-40ba-879e-4e0f896fd7a6
INFO  [19:01:02.055] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 77 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:01:22.149] [bbotk] Evaluating 1 configuration(s)
INFO  [19:01:23.030] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:01:23.091] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 128.427
[1] 6788.267
[1] 120.4617
[1] 6327.61
[1] -6788.446
[1] -122.1833
[1] 297.82
[1] 15778.99
[1] -7575.473
[1] -136.752
INFO  [19:01:48.354] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -18821.78
[1] -339.0086
[1] -10266.61
[1] -183.4588
[1] -6033.472
[1] -108.2492
[1] 133.1919
[1] 7040.774
[1] -521612.8
[1] -9499.207
INFO  [19:02:18.021] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 137.6388
[1] 7242.977
[1] -6007.066
[1] -107.5153
[1] -6554.61
[1] -117.3317
[1] -11366.88
[1] -206.2748
[1] -11723.86
[1] -212.7665
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:02:39.186] [mlr3] Finished benchmark
INFO  [19:02:39.678] [bbotk] Result of batch 47:
INFO  [19:02:39.717] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:02:39.717] [bbotk]               3.319342                         0.7396814
INFO  [19:02:39.717] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:02:39.717] [bbotk]                         0.2271915           -8.853418              0.7427478
INFO  [19:02:39.717] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:02:39.717] [bbotk]                         19                    1003                 0.6325033
INFO  [19:02:39.717] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:02:39.717] [bbotk]  0.01626759 <list[8]>              FALSE     0.04059417        0      0
INFO  [19:02:39.717] [bbotk]  runtime_learners                                uhash
INFO  [19:02:39.717] [bbotk]            75.069 4d6a4e0c-3ea2-496f-a79d-3adcb515c5b0
INFO  [19:02:45.145] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 78 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:02:53.916] [bbotk] Evaluating 1 configuration(s)
INFO  [19:02:54.011] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:02:54.190] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -84.78683
[1] 27.56319
[1] -9.082291
[1] 41.9249
[1] -43.39068
[1] 22.28914
[1] -86.06171
[1] 13.04084
[1] -34.50171
[1] 92.31929
INFO  [19:03:51.772] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -43.06617
[1] 14.70053
[1] -55.87298
[1] 2.758421
[1] -3462.856
[1] -60.92611
[1] -41.50235
[1] 43.44319
[1] -57.92141
[1] 66.67636
INFO  [19:04:41.523] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -64.3957
[1] 60.05359
[1] -18.86432
[1] 86.5971
[1] -72.90191
[1] 24.65442
[1] -104.7258
[1] -3.967947
[1] -15.36102
[1] 26.90385
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:05:22.260] [mlr3] Finished benchmark
INFO  [19:05:22.448] [bbotk] Result of batch 48:
INFO  [19:05:22.471] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:05:22.471] [bbotk]             -0.0328294                         0.5126455
INFO  [19:05:22.471] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:05:22.471] [bbotk]                         0.6082883          -0.2674877              -4.059189
INFO  [19:05:22.471] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:05:22.471] [bbotk]                         10                    4812                  0.372004
INFO  [19:05:22.471] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:05:22.471] [bbotk]  0.01496907 <list[8]>              FALSE     0.02686337        0      0
INFO  [19:05:22.471] [bbotk]  runtime_learners                                uhash
INFO  [19:05:22.471] [bbotk]           147.851 aa8ee732-c07e-49e3-a21c-7e2a8f6a21c6
INFO  [19:05:27.696] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 79 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:05:50.690] [bbotk] Evaluating 1 configuration(s)
INFO  [19:05:50.782] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:05:50.816] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -48.09402
[1] 33.37117
[1] -25.12343
[1] 69.60578
[1] -31.29861
[1] 201.1455
[1] -383.9553
[1] -4.011108
[1] -681.4719
[1] -30.20929
INFO  [19:06:15.426] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -69.32416
[1] 21.84376
[1] -38.80919
[1] 104.8324
[1] -76.19784
[1] 42.1342
[1] -14.13147
[1] 204.8239
[1] -41.78133
[1] 29.3681
INFO  [19:06:51.234] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -3510.837
[1] -82.36001
[1] 87.60159
[1] 2841.158
[1] -291.7835
[1] 3.186869
[1] -34.49081
[1] 24.05591
[1] -13322.5
[1] -458.8159
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:07:29.353] [mlr3] Finished benchmark
INFO  [19:07:29.800] [bbotk] Result of batch 49:
INFO  [19:07:29.837] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:07:29.837] [bbotk]              0.4918281                         0.9394191
INFO  [19:07:29.837] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:07:29.837] [bbotk]                         0.1076428          -0.5763184              0.7257212
INFO  [19:07:29.837] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:07:29.837] [bbotk]                         13                    2057                 0.4922757
INFO  [19:07:29.837] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:07:29.837] [bbotk]  0.0175546 <list[8]>              FALSE       0.025897        0      0
INFO  [19:07:29.837] [bbotk]  runtime_learners                                uhash
INFO  [19:07:29.837] [bbotk]            98.206 bfe91504-1212-41c0-aec1-94f06671981d
INFO  [19:07:31.840] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 80 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:07:48.178] [bbotk] Evaluating 1 configuration(s)
INFO  [19:07:48.415] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:07:48.646] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 133.8894
[1] 3907.671
[1] -29.72976
[1] 66.75084
[1] -98.46117
[1] 100.8367
[1] -22.07161
[1] 73.63113
[1] -33.83278
[1] 25.57969
INFO  [19:08:47.242] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -51.46898
[1] 40.30307
[1] -37.3963
[1] 47.33969
[1] -35961.88
[1] -755.7664
[1] -3246.669
[1] -134.6518
[1] -56.75826
[1] 18.08119
INFO  [19:09:53.688] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -23.70138
[1] 56.87657
[1] -73.57778
[1] 17.36722
[1] -68.64205
[1] 70.40833
[1] -63.43023
[1] 3.599957
[1] -38.80643
[1] 52.84983
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:10:44.946] [mlr3] Finished benchmark
INFO  [19:10:45.411] [bbotk] Result of batch 50:
INFO  [19:10:45.453] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:10:45.453] [bbotk]              -4.815449                         0.9073665
INFO  [19:10:45.453] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:10:45.453] [bbotk]                         0.9195497           -2.362016              -1.960518
INFO  [19:10:45.453] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:10:45.453] [bbotk]                         17                    3507                 0.3644025
INFO  [19:10:45.453] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:10:45.453] [bbotk]  0.01432102 <list[8]>              FALSE     0.02116346        0      0
INFO  [19:10:45.453] [bbotk]  runtime_learners                                uhash
INFO  [19:10:45.453] [bbotk]           175.951 17677160-1c7b-4ae6-b676-6165740935d7
INFO  [19:10:49.162] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 81 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:10:59.067] [bbotk] Evaluating 1 configuration(s)
INFO  [19:10:59.087] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:10:59.130] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -9237.857
[1] -116.0304
[1] -118.4812
[1] 14.86024
[1] -3.292918e+16
[1] 8.593155e+15
[1] -208.3204
[1] 35.23152
[1] -40.39696
[1] 19.9179
INFO  [19:12:07.111] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -106.704
[1] 36.27152
[1] -122.733
[1] 19.0776
[1] -61.24513
[1] 93.57333
[1] -78.29357
[1] 20.65693
[1] -237.3374
[1] -2.073645
INFO  [19:13:04.076] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -95.08949
[1] 29.24013
[1] -2526.942
[1] -47.50403
[1] -54.44123
[1] 52.8084
[1] -1782.302
[1] -61.00753
[1] -91.12305
[1] 11.66038
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:14:02.579] [mlr3] Finished benchmark
INFO  [19:14:02.651] [bbotk] Result of batch 51:
INFO  [19:14:02.700] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:14:02.700] [bbotk]              -3.166579                         0.7763484
INFO  [19:14:02.700] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:14:02.700] [bbotk]                          0.944395           -1.992242               1.524771
INFO  [19:14:02.700] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:14:02.700] [bbotk]                         16                    3799                 0.1835789
INFO  [19:14:02.700] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:14:02.700] [bbotk]  0.01645102 <list[8]>              FALSE     0.02276528        0      0
INFO  [19:14:02.700] [bbotk]  runtime_learners                                uhash
INFO  [19:14:02.700] [bbotk]           183.152 2861c320-9b5a-4efc-b730-3533bc149088
INFO  [19:14:06.485] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 82 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:14:13.506] [bbotk] Evaluating 1 configuration(s)
INFO  [19:14:13.652] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:14:13.704] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -25.72594
[1] 22.24054
[1] -132.7258
[1] 31.06149
[1] -147.0593
[1] 9.17467
[1] -1750.06
[1] -29.46537
[1] -52.05583
[1] 104.6598
INFO  [19:14:42.498] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -103.0562
[1] 102.5887
[1] -117.9884
[1] 6.416018
[1] -39.53409
[1] 18.6216
[1] -53.30644
[1] 31.69315
[1] -79.99496
[1] 54.71113
INFO  [19:15:17.810] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -46.2271
[1] 34.44589
[1] -113.0867
[1] 3.49279
[1] -95.0595
[1] 17.96718
[1] -8034.262
[1] -290.7772
[1] -80.04701
[1] 12.50791
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:15:47.655] [mlr3] Finished benchmark
INFO  [19:15:47.907] [bbotk] Result of batch 52:
INFO  [19:15:47.966] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:15:47.966] [bbotk]              -5.708828                         0.7175752
INFO  [19:15:47.966] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:15:47.966] [bbotk]                         0.5205731           -4.008248              -1.650138
INFO  [19:15:47.966] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:15:47.966] [bbotk]                         12                    1847                 0.5394226
INFO  [19:15:47.966] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:15:47.966] [bbotk]  0.01440942 <list[8]>              FALSE     0.02281719        0      0
INFO  [19:15:47.966] [bbotk]  runtime_learners                                uhash
INFO  [19:15:47.966] [bbotk]            93.233 48a7133e-26e7-4bc0-b087-afac9b3838d3
WARN  [19:15:52.523] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:15:52.528] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 83 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:16:02.212] [bbotk] Evaluating 1 configuration(s)
INFO  [19:16:02.326] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:16:02.356] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -57.16802
[1] 41.99867
[1] -99.46831
[1] 59.93808
[1] -39.38058
[1] 22.07943
[1] -17.14111
[1] 38.68857
[1] -126.8008
[1] 110.1359
INFO  [19:16:47.799] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -198.4418
[1] 13.01421
[1] -52.66065
[1] 71.46149
[1] -22.94298
[1] 34.26459
[1] -27.56611
[1] 59.98204
[1] -37.47956
[1] 15.97844
INFO  [19:17:26.092] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2342.717
[1] -43.95165
[1] -37.49218
[1] 21.62706
[1] -20.96042
[1] 37.95749
[1] 35.16067
[1] 926.8148
[1] -46.21814
[1] 4.168491
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:18:07.132] [mlr3] Finished benchmark
INFO  [19:18:08.249] [bbotk] Result of batch 53:
INFO  [19:18:08.356] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:18:08.356] [bbotk]              -6.407797                         0.4993967
INFO  [19:18:08.356] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:18:08.356] [bbotk]                         0.7397478           -1.309955              -4.775408
INFO  [19:18:08.356] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:18:08.356] [bbotk]                         19                    1707                 0.4639833
INFO  [19:18:08.356] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:18:08.356] [bbotk]  0.01868562 <list[8]>              FALSE     0.02074639        0      0
INFO  [19:18:08.356] [bbotk]  runtime_learners                                uhash
INFO  [19:18:08.356] [bbotk]           124.105 a5465cf1-f7a4-42bd-83d8-3e4fa5e08369
INFO  [19:18:18.391] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 84 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:18:31.460] [bbotk] Evaluating 1 configuration(s)
INFO  [19:18:31.851] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:18:32.001] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -54.49149
[1] 21.75706
[1] -31.95233
[1] 29.98994
[1] -11.16539
[1] 37.80019
[1] -0.5817149
[1] 52.23803
[1] -82.86071
[1] 13.22425
INFO  [19:19:31.338] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -68.65271
[1] 8.413958
[1] -90.61933
[1] 89.63799
[1] -115.5473
[1] 93.13012
[1] -4619.603
[1] -150.5882
[1] -133.7313
[1] 5.504558
INFO  [19:20:28.800] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -156.2919
[1] 10.26075
[1] -22.57504
[1] 11.85054
[1] -2.26082e+16
[1] 1.219997e+16
[1] -63.82547
[1] 58.78788
[1] -23.80785
[1] 15.27671
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:21:52.755] [mlr3] Finished benchmark
INFO  [19:21:53.058] [bbotk] Result of batch 54:
INFO  [19:21:53.127] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:21:53.127] [bbotk]              -6.415272                         0.4822867
INFO  [19:21:53.127] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:21:53.127] [bbotk]                          0.669919          -0.4674962              -1.070532
INFO  [19:21:53.127] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:21:53.127] [bbotk]                          3                    4851                 0.2322909
INFO  [19:21:53.127] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:21:53.127] [bbotk]  0.01596394 <list[8]>              FALSE     0.02111216        0      0
INFO  [19:21:53.127] [bbotk]  runtime_learners                                uhash
INFO  [19:21:53.127] [bbotk]            200.22 e86feeb5-c972-44ad-b9d4-3af69bbde4b2
INFO  [19:22:01.009] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 85 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:22:22.616] [bbotk] Evaluating 1 configuration(s)
INFO  [19:22:24.466] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:22:24.694] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 4.381442
[1] 117.8871
[1] -114.527
[1] 79.30727
[1] -94.54486
[1] 53.24145
[1] -35.40977
[1] 57.34723
[1] -57.45101
[1] 31.1645
INFO  [19:22:43.752] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -55.42054
[1] 54.61904
[1] -99.11776
[1] 27.22931
[1] -94.48952
[1] 79.51209
[1] -173.0567
[1] 48.0341
[1] -78.45438
[1] 274.8493
INFO  [19:23:08.423] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -119.1261
[1] -1.494042
[1] 88.48439
[1] 2563.717
[1] -91.17534
[1] 56.67349
[1] -12.86118
[1] 78.85193
[1] -79.49854
[1] 24.26449
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:23:46.711] [mlr3] Finished benchmark
INFO  [19:23:47.441] [bbotk] Result of batch 55:
INFO  [19:23:47.575] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:23:47.575] [bbotk]               1.264045                         0.9829013
INFO  [19:23:47.575] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:23:47.575] [bbotk]                         0.6877059         -0.05269441              -1.677714
INFO  [19:23:47.575] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:23:47.575] [bbotk]                          3                     466                 0.1994144
INFO  [19:23:47.575] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:23:47.575] [bbotk]  0.01547436 <list[8]>              FALSE     0.02763747        0      0
INFO  [19:23:47.575] [bbotk]  runtime_learners                                uhash
INFO  [19:23:47.575] [bbotk]            81.708 64c1bb06-fffc-4f94-973a-52634ca9b7dc
INFO  [19:23:51.742] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 86 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:24:23.111] [bbotk] Evaluating 1 configuration(s)
INFO  [19:24:23.241] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:24:23.328] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -25.06541
[1] 313.9571
[1] -72.68039
[1] 29.74474
[1] -83.87354
[1] 60.65437
[1] -36.0042
[1] 27.62395
[1] -3882.779
[1] -58.88526
INFO  [19:25:22.076] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 197.3488
[1] 7283.692
[1] 17.42847
[1] 390.8546
[1] -73.80235
[1] 15.69905
[1] -77.33128
[1] 11.69584
[1] -204.165
[1] 2.970253
INFO  [19:26:38.635] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -26.36117
[1] 72.41242
[1] -2103.063
[1] -87.92444
[1] -160.9113
[1] 4.909705
[1] -4274.429
[1] -114.7276
[1] -55.6765
[1] 18.73465
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:27:58.851] [mlr3] Finished benchmark
INFO  [19:28:02.245] [bbotk] Result of batch 56:
INFO  [19:28:02.449] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:28:02.449] [bbotk]              -6.318938                         0.5278724
INFO  [19:28:02.449] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:28:02.449] [bbotk]                         0.6137897           -3.032455               1.477546
INFO  [19:28:02.449] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:28:02.449] [bbotk]                         13                    3664                 0.2617894
INFO  [19:28:02.449] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:28:02.449] [bbotk]  0.01602465 <list[8]>              FALSE     0.02189627        0      0
INFO  [19:28:02.449] [bbotk]  runtime_learners                                uhash
INFO  [19:28:02.449] [bbotk]           215.127 47aa6206-e37b-44f3-8e87-bceaa71077de
WARN  [19:28:13.187] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:28:13.262] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 87 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:28:29.081] [bbotk] Evaluating 1 configuration(s)
INFO  [19:28:29.598] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:28:29.851] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -76.36169
[1] 8.225887
[1] -38.45563
[1] 88.72809
[1] -182.1314
[1] 11.92342
[1] -574.2527
[1] -19.12541
[1] -26.56473
[1] 76.96252
INFO  [19:29:07.346] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -6390.955
[1] -74.4298
[1] -44.00591
[1] 56.49132
[1] -1017.509
[1] -0.9020263
[1] -2253.722
[1] -47.29325
[1] -78.49133
[1] 9.708051
INFO  [19:29:42.682] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -610.194
[1] -31.80465
[1] -221.8636
[1] -0.4832753
[1] -89.50528
[1] 10.66379
[1] -89.5225
[1] 2.859225
[1] 143.0065
[1] 3076.464
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:30:30.788] [mlr3] Finished benchmark
INFO  [19:30:32.528] [bbotk] Result of batch 57:
INFO  [19:30:32.542] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:30:32.542] [bbotk]             -0.2813691                         0.3168295
INFO  [19:30:32.542] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:30:32.542] [bbotk]                         0.4845024           -4.049211              -5.033094
INFO  [19:30:32.542] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:30:32.542] [bbotk]                          2                    1815                 0.6831152
INFO  [19:30:32.542] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:30:32.542] [bbotk]  0.01491523 <list[8]>              FALSE     0.02492856        0      0
INFO  [19:30:32.542] [bbotk]  runtime_learners                                uhash
INFO  [19:30:32.542] [bbotk]           120.508 7b5b57a3-6f7c-4c04-8a4a-757c1dd3f055
INFO  [19:30:35.005] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 88 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:31:02.964] [bbotk] Evaluating 1 configuration(s)
INFO  [19:31:03.151] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:31:03.252] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -17.48713
[1] 54.16184
[1] -500.6704
[1] -33.93754
[1] -112.9574
[1] 62.78136
[1] -19.22105
[1] 55.69418
[1] -17.39027
[1] 19.28464
INFO  [19:31:48.749] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -78.65616
[1] 11.79597
[1] -40.60862
[1] 11.76049
[1] -38.98436
[1] 31.9147
[1] -30.94311
[1] 18.77434
[1] -21.70902
[1] 14.10965
INFO  [19:32:43.640] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -37.2914
[1] 0.9650327
[1] -9.546666
[1] 34.18686
[1] -12.18111
[1] 84.18517
[1] -32.17753
[1] 7.397448
[1] -77.37806
[1] -0.6992951
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:33:28.772] [mlr3] Finished benchmark
INFO  [19:33:30.197] [bbotk] Result of batch 58:
INFO  [19:33:30.230] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:33:30.230] [bbotk]              -3.060116                          0.666947
INFO  [19:33:30.230] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:33:30.230] [bbotk]                         0.1714666          -0.3860603              -5.164427
INFO  [19:33:30.230] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:33:30.230] [bbotk]                         20                    4135                 0.2145764
INFO  [19:33:30.230] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:33:30.230] [bbotk]  0.01367385 <list[8]>              FALSE     0.02522273        0      0
INFO  [19:33:30.230] [bbotk]  runtime_learners                                uhash
INFO  [19:33:30.230] [bbotk]            145.22 7dc4f9d9-abae-489c-9ee5-6d5adf005a80
INFO  [19:33:36.285] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 89 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:34:02.626] [bbotk] Evaluating 1 configuration(s)
INFO  [19:34:02.817] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:34:03.105] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -45.03349
[1] 32.97433
[1] -106.7174
[1] 11.16897
[1] -17727.1
[1] -500.5436
[1] -150.8111
[1] 18.08408
[1] -39.15011
[1] 82.39165
INFO  [19:35:04.010] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -81.61911
[1] 9.192804
[1] -49.34334
[1] 49.29429
[1] -71.36826
[1] 17.97082
[1] -40.01976
[1] 71.47101
[1] -65.76107
[1] 86.87922
INFO  [19:35:38.964] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -41.93799
[1] 23.7718
[1] 28.51842
[1] 519.0113
[1] -1400.587
[1] -36.56388
[1] -58.82702
[1] 15.4013
[1] -78.28981
[1] 180.99
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:36:18.506] [mlr3] Finished benchmark
INFO  [19:36:18.582] [bbotk] Result of batch 59:
INFO  [19:36:18.592] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:36:18.592] [bbotk]              -1.312663                         0.5421984
INFO  [19:36:18.592] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:36:18.592] [bbotk]                         0.5640595           -1.013487               5.398197
INFO  [19:36:18.592] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:36:18.592] [bbotk]                          2                    4311                 0.6973236
INFO  [19:36:18.592] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:36:18.592] [bbotk]  0.01319562 <list[8]>              FALSE      0.0249431        0      0
INFO  [19:36:18.592] [bbotk]  runtime_learners                                uhash
INFO  [19:36:18.592] [bbotk]             135.2 1bb06149-f052-49bb-955d-6c53e238367c
INFO  [19:36:20.398] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 90 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:36:29.622] [bbotk] Evaluating 1 configuration(s)
INFO  [19:36:29.740] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:36:29.844] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -34.66307
[1] 36.75371
[1] -9.459831
[1] 52.87694
[1] -63.23189
[1] 6.418628
[1] -52.38818
[1] 45.73976
[1] -12.95269
[1] 48.50388
INFO  [19:37:24.983] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -33.48268
[1] 20.60933
[1] -18.78234
[1] 24.58915
[1] -46.37352
[1] 14.36899
[1] -711.4057
[1] -38.7014
[1] -19.82849
[1] 23.95654
INFO  [19:38:29.296] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -37.21938
[1] 18.25943
[1] -65.9695
[1] 41.13115
[1] -71.83594
[1] 10.8646
[1] -26.68023
[1] 81.77286
[1] -45.76252
[1] 25.70473
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:39:26.677] [mlr3] Finished benchmark
INFO  [19:39:27.368] [bbotk] Result of batch 60:
INFO  [19:39:27.398] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:39:27.398] [bbotk]              -4.956845                         0.6815229
INFO  [19:39:27.398] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:39:27.398] [bbotk]                         0.5653728          -0.4078162              -4.979491
INFO  [19:39:27.398] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:39:27.398] [bbotk]                         12                    4598                 0.1616873
INFO  [19:39:27.398] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:39:27.398] [bbotk]  0.01354644 <list[8]>              FALSE     0.02700661        0      0
INFO  [19:39:27.398] [bbotk]  runtime_learners                                uhash
INFO  [19:39:27.398] [bbotk]           176.401 0948d40d-88ee-49c2-b960-aca9faf9b457
INFO  [19:39:33.247] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 91 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:39:44.982] [bbotk] Evaluating 1 configuration(s)
INFO  [19:39:45.136] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:39:45.190] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -66.6401
[1] 19.46986
[1] -3316.837
[1] -64.40169
[1] -24.17979
[1] 181.8224
[1] -130.4731
[1] 106.4464
[1] -65.36386
[1] 12.27545
INFO  [19:41:05.820] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -70.49499
[1] 44.87555
[1] -107.5764
[1] -3.137018
[1] -22.84097
[1] 42.45032
[1] -20.20521
[1] 79.06572
[1] -1711.285
[1] -3.880048
INFO  [19:42:03.379] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -6.421249
[1] 34.74203
[1] -49.67823
[1] 18.32388
[1] -1438.627
[1] -52.87925
[1] -21.58711
[1] 89.18241
[1] -64.20155
[1] 11.33867
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:42:55.872] [mlr3] Finished benchmark
INFO  [19:42:58.238] [bbotk] Result of batch 61:
INFO  [19:42:58.306] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:42:58.306] [bbotk]              -6.182933                         0.7773354
INFO  [19:42:58.306] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:42:58.306] [bbotk]                         0.9587019           -1.668326              -6.795964
INFO  [19:42:58.306] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:42:58.306] [bbotk]                          2                    2526                 0.6010776
INFO  [19:42:58.306] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:42:58.306] [bbotk]  0.0120184 <list[8]>              FALSE     0.02202844        0      0
INFO  [19:42:58.306] [bbotk]  runtime_learners                                uhash
INFO  [19:42:58.306] [bbotk]           189.632 c53ed421-15d1-453b-b432-769a4c0f6c06
INFO  [19:43:10.444] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 92 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:43:22.570] [bbotk] Evaluating 1 configuration(s)
INFO  [19:43:22.603] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:43:22.615] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -54.04035
[1] 154.624
[1] -109.2296
[1] 11.14432
[1] -137.9332
[1] 8.723749
[1] -18.72372
[1] 131.177
[1] -290.424
[1] 1129.931
INFO  [19:44:28.737] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -2279.482
[1] -57.19827
[1] -57.05319
[1] 51.68834
[1] -84.67891
[1] -3.834776
[1] -70.25439
[1] 81.42978
[1] -18.00361
[1] 33.50154
INFO  [19:46:11.209] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -64.03823
[1] 11.85347
[1] -35.22214
[1] 42.18128
[1] -152.177
[1] -0.1814591
[1] -129.5741
[1] 37.74049
[1] -33.28277
[1] 206.9764
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:47:41.021] [mlr3] Finished benchmark
INFO  [19:47:41.096] [bbotk] Result of batch 62:
INFO  [19:47:41.104] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:47:41.104] [bbotk]              -1.195304                           0.23711
INFO  [19:47:41.104] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:47:41.104] [bbotk]                          0.971946           -3.708404              -6.558671
INFO  [19:47:41.104] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:47:41.104] [bbotk]                          7                    4440                 0.3799423
INFO  [19:47:41.104] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:47:41.104] [bbotk]  0.01225564 <list[8]>              FALSE     0.02311906        0      0
INFO  [19:47:41.104] [bbotk]  runtime_learners                                uhash
INFO  [19:47:41.104] [bbotk]           258.088 075625fa-2a5b-47b3-b735-57fe2bd703d9
INFO  [19:47:43.867] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 93 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:48:05.467] [bbotk] Evaluating 1 configuration(s)
INFO  [19:48:06.652] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:48:06.831] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -81.84415
[1] 48.46587
[1] -31.2066
[1] 141.4054
[1] -163.4137
[1] 30.49792
[1] -49.07107
[1] 71.7552
[1] -23.02189
[1] 125.529
INFO  [19:49:28.336] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -46.55853
[1] 16.98531
[1] -86.0011
[1] 7.513318
[1] -361.4336
[1] 16.94969
[1] -11.6122
[1] 76.95406
[1] -1255.862
[1] -39.83836
INFO  [19:51:10.873] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -131.6824
[1] 25.53804
[1] -16.2705
[1] 102.1998
[1] -1809.132
[1] -46.40496
[1] -22024.43
[1] -564.4634
[1] -71.65218
[1] -4.192894
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:52:41.061] [mlr3] Finished benchmark
INFO  [19:52:41.875] [bbotk] Result of batch 63:
INFO  [19:52:42.008] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:52:42.008] [bbotk]              -6.000004                         0.1056373
INFO  [19:52:42.008] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:52:42.008] [bbotk]                         0.2874667           -1.847973              -6.128862
INFO  [19:52:42.008] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:52:42.008] [bbotk]                          7                    4640                 0.4691381
INFO  [19:52:42.008] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:52:42.008] [bbotk]  0.01296809 <list[8]>              FALSE     0.02164812        0      0
INFO  [19:52:42.008] [bbotk]  runtime_learners                                uhash
INFO  [19:52:42.008] [bbotk]           273.705 0f62e1ef-3676-4056-bb78-c82a1742add4
INFO  [19:52:46.765] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 94 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:53:00.616] [bbotk] Evaluating 1 configuration(s)
INFO  [19:53:00.679] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:53:00.926] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -3.084705e+16
[1] 6.511099e+15
[1] 76.57995
[1] 2207.048
[1] -3.105897e+16
[1] 6.932253e+13
[1] -116.9817
[1] 32.27089
[1] -51.46538
[1] 8.863942
INFO  [19:53:32.870] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -13772.03
[1] -331.4474
[1] -71.934
[1] 20.04937
[1] -41.93503
[1] 36.13471
[1] -36.51569
[1] 71.45272
[1] -150.9602
[1] 29.45658
INFO  [19:53:57.492] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -295.7468
[1] 7.29688
[1] -38.03015
[1] 23.15304
[1] -152.157
[1] -1.624842
[1] -30.49233
[1] 97.83585
[1] -104.7547
[1] 21.50468
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:54:35.897] [mlr3] Finished benchmark
INFO  [19:54:37.191] [bbotk] Result of batch 64:
INFO  [19:54:37.296] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:54:37.296] [bbotk]              -6.180747                         0.2849555
INFO  [19:54:37.296] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:54:37.296] [bbotk]                         0.6217064           -2.628205              -4.431598
INFO  [19:54:37.296] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:54:37.296] [bbotk]                          8                     778                 0.3781187
INFO  [19:54:37.296] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:54:37.296] [bbotk]  0.01214339 <list[8]>              FALSE     0.02426107        0      0
INFO  [19:54:37.296] [bbotk]  runtime_learners                                uhash
INFO  [19:54:37.296] [bbotk]             94.48 0cc91a29-af90-4a48-b2bb-8b08263d95ee
INFO  [19:54:44.371] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 95 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:54:55.901] [bbotk] Evaluating 1 configuration(s)
INFO  [19:54:55.959] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:54:56.131] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -38.70481
[1] 174.6474
[1] -25.28281
[1] 63.41715
[1] -2533.852
[1] -62.66631
[1] -67.75422
[1] 12.94467
[1] -40.57899
[1] 13.95159
INFO  [19:55:58.634] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -740.9797
[1] -27.62419
[1] -33.43092
[1] 12.9334
[1] -161.8001
[1] 41.42366
[1] 73.15918
[1] 1330.388
[1] -1171.59
[1] -80.25303
INFO  [19:57:18.603] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -57.54919
[1] 9.435088
[1] -28.75749
[1] 40.8849
[1] -40.16717
[1] 74.30756
[1] -43.83689
[1] 43.80638
[1] -44.11124
[1] 45.53693
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:58:38.665] [mlr3] Finished benchmark
INFO  [19:58:38.795] [bbotk] Result of batch 65:
INFO  [19:58:38.820] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:58:38.820] [bbotk]              -2.701583                         0.4035072
INFO  [19:58:38.820] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:58:38.820] [bbotk]                         0.4560249           -2.157281              -1.293493
INFO  [19:58:38.820] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:58:38.820] [bbotk]                         19                    4871                 0.6310035
INFO  [19:58:38.820] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:58:38.820] [bbotk]  0.0109208 <list[8]>              FALSE     0.02266893        0      0
INFO  [19:58:38.820] [bbotk]  runtime_learners                                uhash
INFO  [19:58:38.820] [bbotk]           222.274 3f28a033-fa4b-4a3f-b7b7-2c699a701fca
INFO  [19:58:41.555] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 96 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:58:59.772] [bbotk] Evaluating 1 configuration(s)
INFO  [19:58:59.827] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:58:59.882] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -65.68042
[1] 186.4651
[1] -75.63794
[1] 194.9992
[1] 1902.213
[1] 74547.69
[1] -69.16566
[1] 119.8958
[1] -151.3011
[1] 54.91926
INFO  [20:00:05.390] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -436.5303
[1] 70.18839
[1] -96.38575
[1] 151.7877
[1] -187.4068
[1] 41.93151
[1] -273.6365
[1] -5.369492
[1] -123.5118
[1] 99.40999
INFO  [20:01:05.971] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -33.07656
[1] 269.7359
[1] -379.3739
[1] 304.8655
[1] -219.7929
[1] 18.11303
[1] -71.0229
[1] 88.2622
[1] -23.4339
[1] 163.1792
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:02:15.607] [mlr3] Finished benchmark
INFO  [20:02:16.032] [bbotk] Result of batch 66:
INFO  [20:02:16.086] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:02:16.086] [bbotk]              0.8061962                         0.4643564
INFO  [20:02:16.086] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:02:16.086] [bbotk]                         0.5631098           -6.925937               -4.29333
INFO  [20:02:16.086] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:02:16.086] [bbotk]                         20                    3766                 0.1216818
INFO  [20:02:16.086] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:02:16.086] [bbotk]  0.01083784 <list[8]>              FALSE     0.05303255        0      0
INFO  [20:02:16.086] [bbotk]  runtime_learners                                uhash
INFO  [20:02:16.086] [bbotk]           194.711 a9e1a4de-2ff3-40d1-83d1-8db3a469f9c3
INFO  [20:02:24.355] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 97 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:02:33.266] [bbotk] Evaluating 1 configuration(s)
INFO  [20:02:33.352] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:02:33.401] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -29.38182
[1] 40.00042
[1] -180.1013
[1] 2.682326
[1] -222.6441
[1] 57.02994
[1] -782.3689
[1] -50.38899
[1] -227.406
[1] 53.50436
INFO  [20:03:38.814] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -40.36181
[1] 18.16245
[1] -120.0005
[1] 3.130931
[1] -27.60929
[1] 126.414
[1] -1163.68
[1] -61.90121
[1] 115.1749
[1] 2926.13
INFO  [20:04:27.979] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 120.0584
[1] 3556.775
[1] -67.06948
[1] 16.88791
[1] -37.74446
[1] 22.23076
[1] -33.78812
[1] 42.69267
[1] -102.7171
[1] 6.284004
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:05:21.248] [mlr3] Finished benchmark
INFO  [20:05:21.341] [bbotk] Result of batch 67:
INFO  [20:05:21.371] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:05:21.371] [bbotk]             0.06518621                         0.4497601
INFO  [20:05:21.371] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:05:21.371] [bbotk]                         0.8601704          -0.4043228              -1.208665
INFO  [20:05:21.371] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:05:21.371] [bbotk]                          3                    2218                 0.5780397
INFO  [20:05:21.371] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:05:21.371] [bbotk]  0.01272562 <list[8]>              FALSE     0.02355379        0      0
INFO  [20:05:21.371] [bbotk]  runtime_learners                                uhash
INFO  [20:05:21.371] [bbotk]           167.526 e5a56f25-0f0b-43b4-b909-1af876510b42
INFO  [20:05:25.711] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 98 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:05:37.368] [bbotk] Evaluating 1 configuration(s)
INFO  [20:05:37.421] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:05:37.448] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -76.04102
[1] 29.86442
[1] -64.18104
[1] 22.84162
[1] -4364.956
[1] -86.30857
[1] -5470.517
[1] -104.0721
[1] -8240.141
[1] -278.8341
INFO  [20:06:15.360] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -108.9557
[1] 16.83944
[1] -64.7795
[1] 2.953912
[1] -8264.867
[1] -554.6858
[1] -38.41923
[1] 46.37895
[1] -43.76179
[1] 76.28091
INFO  [20:07:17.098] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -118.6643
[1] 29.24247
[1] -64.09269
[1] 101.9905
[1] -46.00512
[1] 11.35264
[1] -1449.458
[1] -35.53124
[1] -90.31147
[1] 36.09524
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:08:58.935] [mlr3] Finished benchmark
INFO  [20:09:00.148] [bbotk] Result of batch 68:
INFO  [20:09:00.198] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:09:00.198] [bbotk]              0.5582388                         0.7188694
INFO  [20:09:00.198] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:09:00.198] [bbotk]                         0.1355641           -1.157115              -1.893541
INFO  [20:09:00.198] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:09:00.198] [bbotk]                         20                    4826                  0.771388
INFO  [20:09:00.198] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:09:00.198] [bbotk]  0.01079241 <list[8]>              FALSE     0.02451589        0      0
INFO  [20:09:00.198] [bbotk]  runtime_learners                                uhash
INFO  [20:09:00.198] [bbotk]           200.965 87221daf-cca1-4349-aada-5f9189e1a093
INFO  [20:09:13.233] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 99 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:09:29.689] [bbotk] Evaluating 1 configuration(s)
INFO  [20:09:30.062] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:09:30.242] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -98.54512
[1] 34.67582
[1] -50.67927
[1] 8.774403
[1] -72.82401
[1] 24.8931
[1] -47.52835
[1] 72.631
[1] -92.23656
[1] 58.10799
INFO  [20:10:48.331] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -103.4743
[1] 39.84099
[1] -1805.604
[1] -72.4573
[1] -2166.622
[1] -111.3821
[1] -47.25811
[1] 24.87206
[1] -284.0107
[1] 5.405393
INFO  [20:11:53.814] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -42.16336
[1] 14.22373
[1] -179.0204
[1] 6.524184
[1] -826.4814
[1] -63.90273
[1] -6538.067
[1] -102.5854
[1] -38.7916
[1] 18.93161
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:12:55.318] [mlr3] Finished benchmark
INFO  [20:12:55.397] [bbotk] Result of batch 69:
INFO  [20:12:55.403] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:12:55.403] [bbotk]              -6.564502                         0.7658608
INFO  [20:12:55.403] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:12:55.403] [bbotk]                         0.2211123           -1.301375              -4.989525
INFO  [20:12:55.403] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:12:55.403] [bbotk]                          9                    3760                  0.500965
INFO  [20:12:55.403] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:12:55.403] [bbotk]  0.01082462 <list[8]>              FALSE     0.01971081        0      0
INFO  [20:12:55.403] [bbotk]  runtime_learners                                uhash
INFO  [20:12:55.403] [bbotk]           204.641 b8201449-a3a9-4cb1-a945-4efa9c85aa0f
WARN  [20:13:03.043] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [20:13:03.058] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 100 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:13:03.246] [bbotk] Finished optimizing after 100 evaluation(s)
INFO  [20:13:03.251] [bbotk] Result:
INFO  [20:13:03.735] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:13:03.735] [bbotk]                  <num>                             <num>
INFO  [20:13:03.735] [bbotk]              -6.564502                         0.7658608
INFO  [20:13:03.735] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:13:03.735] [bbotk]                             <num>               <num>                  <num>
INFO  [20:13:03.735] [bbotk]                         0.2211123           -1.301375              -4.989525
INFO  [20:13:03.735] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:13:03.735] [bbotk]                      <int>                   <int>                     <num>
INFO  [20:13:03.735] [bbotk]                          9                    3760                  0.500965
INFO  [20:13:03.735] [bbotk]  learner_param_vals  x_domain classif.bbrier
INFO  [20:13:03.735] [bbotk]              <list>    <list>          <num>
INFO  [20:13:03.735] [bbotk]          <list[10]> <list[8]>     0.01971081
[1] -82.33917
[1] 10.65862
[1] -14.74888
[1] 95.97749
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] -41.15619
[1] 103.4052
[1] -40.64628
[1] 24.89981
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] -126.4236
[1] 12.83001

### [bt]: Job terminated successfully [batchtools job.id=1413]
### [bt]: Calculation finished!
