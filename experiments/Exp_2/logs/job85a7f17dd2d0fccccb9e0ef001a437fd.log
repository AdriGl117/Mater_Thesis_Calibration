### [bt]: This is batchtools v0.9.17
### [bt]: Starting calculation of 1 jobs
### [bt]: Setting working directory to '/content/drive/MyDrive/GitHub/Mater_Thesis_Calibration'
ece.R :
Friedmann_tasks.R :
Functions.R :
ici.R :
mse_feature_effects.R :
PipeOpCalibration_TuningExperiment.R :
PipeOpCalibration.R :
PipeOpCalibrationUnion.R :
### [bt]: Memory measurement disabled
### [bt]: Starting job [batchtools job.id=1415]
### [bt]: Generating problem instance for problem '341ee781c7d79b8f' ...
### [bt]: Applying algorithm 'run_learner' on problem '341ee781c7d79b8f' for job 1415 (seed = 1538) ...
INFO  [16:05:57.072] [mlr3] Applying learner 'xgboost TwP beta' on task 'wdbc' (iter 5/10)
INFO  [16:05:58.386] [bbotk] Starting to optimize 8 parameter(s) with '<OptimizerMbo>' and '<TerminatorEvals> [n_evals=100, k=0]'
INFO  [16:06:09.078] [bbotk] Evaluating 32 configuration(s)
INFO  [16:06:09.784] [mlr3] Running benchmark with 96 resampling iterations
INFO  [16:06:09.932] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -40.21383
[1] 51.92881
[1] -267.7499
[1] 29.52719
[1] -76.63538
[1] 15.96938
[1] -51.74264
[1] 34.07845
[1] -10791.26
[1] -205.9065
INFO  [16:07:05.965] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -97.02083
[1] 23.41249
[1] -43.64901
[1] 101.656
[1] -99.51705
[1] 25.90895
[1] -55.49031
[1] 10.33689
[1] 68.17958
[1] 2878.689
INFO  [16:07:22.279] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -30.81118
[1] 56.26254
[1] -99.76193
[1] -4.014562
[1] -39.16013
[1] 135.3288
[1] -28.86352
[1] 66.45146
[1] 50.05616
[1] 1886.654
INFO  [16:07:38.999] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 9.957998
[1] 476.8912
[1] -270.7687
[1] -4.330826
[1] 8.817945
[1] 416.3354
[1] 6.101826
[1] 309.1153
[1] -28.43747
[1] 292.9772
INFO  [16:08:17.269] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -262.9497
[1] -0.6572609
[1] -302.7429
[1] -5.864758
[1] 4.137769
[1] 193.0055
[1] 5.733106
[1] 310.6989
[1] -102.4692
[1] 331.77
INFO  [16:09:19.248] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 13.48487
[1] 565.868
[1] -10788.16
[1] -239.2312
[1] -156.3271
[1] 129.2684
[1] -340.6923
[1] -7.002264
[1] -425.4997
[1] -6.629848
INFO  [16:10:57.987] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 46.01852
[1] 2043.243
[1] -1422.999
[1] -23.18081
[1] -1202.719
[1] -20.14222
[1] 29.7745
[1] 1314.873
[1] -2447.302
[1] -39.86768
INFO  [16:11:29.370] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -2975.271
[1] -51.93824
[1] -1691.274
[1] -28.37645
[1] 53.7507
[1] 2695.441
[1] 39.00638
[1] 1991.824
[1] 66.35556
[1] 3427.721
INFO  [16:12:03.944] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2257.554
[1] -35.31944
[1] -1637.983
[1] -26.5647
[1] -2003.945
[1] -32.30501
[1] -1804.738
[1] -29.41026
[1] -1779.822
[1] 967.2236
INFO  [16:12:42.966] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 75.62605
[1] 3908.567
[1] -2958.443
[1] -52.60879
[1] -3719.189
[1] -67.68453
[1] -2566.171
[1] -46.01544
[1] 44.50428
[1] 2309.014
INFO  [16:14:00.903] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1564.292
[1] -28.24491
[1] 75.40126
[1] 3950.393
[1] 52.46826
[1] 2774.92
[1] -2765.035
[1] -51.23152
[1] 69.3023
[1] 3692.542
INFO  [16:15:16.030] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 110.1376
[1] 5702.297
[1] 123.5275
[1] 6508.989
[1] -1749.315
[1] -31.81028
[1] 160.9273
[1] 8253.713
[1] -78909.45
[1] -1419.515
INFO  [16:16:21.532] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -410.9464
[1] -7.489209
[1] 17.71919
[1] 731.305
[1] -759.169
[1] -15.80512
[1] -87.55905
[1] 441.6177
[1] -318.597
[1] -5.676096
INFO  [16:17:13.785] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -439.1124
[1] -9.314643
[1] -402.7419
[1] -7.376581
[1] -872.0671
[1] -18.69932
[1] -342.6869
[1] 45.56806
[1] 13.17317
[1] 649.3617
INFO  [16:18:37.024] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -484.342
[1] -8.775726
[1] -72.2856
[1] 302.7465
[1] -84.79996
[1] 529.8414
[1] -1192.993
[1] -26.10283
[1] -203.8113
[1] 183.6389
INFO  [16:19:30.918] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -34.20972
[1] 25.10798
[1] -47.0024
[1] 34.04528
[1] -34.0067
[1] 15.36297
[1] -3459.301
[1] -132.3683
[1] -8.814586
[1] 76.92622
INFO  [16:20:32.196] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -43.78788
[1] 68.33276
[1] -393.0018
[1] 20.00225
[1] -142.3184
[1] -3.722962
[1] -2156.019
[1] -48.85775
[1] -99.8087
[1] 7.390861
INFO  [16:22:15.225] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -35.87081
[1] 40.8253
[1] 193.3187
[1] 2762.589
[1] -97.34705
[1] 6.604359
[1] -30.8978
[1] 47.64031
[1] -2405.632
[1] -136.4045
INFO  [16:23:52.561] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -357.864
[1] 40.47058
[1] -151.5289
[1] 344.935
[1] 2.05263
[1] 469.0223
[1] -435.7266
[1] 67.77401
[1] -359.953
[1] 70.71422
INFO  [16:24:19.937] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -479.2751
[1] -9.755332
[1] -278.0199
[1] 69.76744
[1] -82.11085
[1] 309.0131
[1] 30.23559
[1] 1521.499
[1] -592.6748
[1] -9.479382
INFO  [16:24:50.686] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -588.3705
[1] -9.620865
[1] 10.00495
[1] 436.2885
[1] -431.1061
[1] -7.843053
[1] -401.7651
[1] 270.7276
[1] -770.437
[1] -11.32963
INFO  [16:25:27.095] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:26:08.040] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:26:56.627] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:27:56.526] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:28:34.763] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:29:17.767] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:30:17.086] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -22.03192
[1] 95.43728
[1] -101.9258
[1] 120.2491
[1] -70.08085
[1] 56.27012
[1] -35.84903
[1] 44.23362
[1] -144.5715
[1] 410.2116
INFO  [16:31:49.681] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -42.19777
[1] 84.21065
[1] -57.86699
[1] 40.2193
[1] -28.78282
[1] 158.8419
[1] -141.4958
[1] 1.1236
[1] -232.2995
[1] -4.483204
INFO  [16:33:31.377] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 374.8948
[1] 13270.05
[1] -56.42561
[1] 70.06635
[1] -64.4017
[1] 87.5378
[1] -79.85728
[1] 28.96215
[1] -223.7477
[1] 214.9182
INFO  [16:34:45.113] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 23.62013
[1] 983.5617
[1] -680.1078
[1] 675.434
[1] -1423.444
[1] -22.51514
[1] -780.2073
[1] -11.36218
[1] 16.12873
[1] 664.1003
INFO  [16:35:43.045] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 17.99785
[1] 858.1041
[1] 26.68586
[1] 1214.101
[1] -1147.144
[1] -18.29708
[1] -646.9312
[1] 380.1717
[1] -1225.03
[1] -18.39252
INFO  [16:36:54.733] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -976.3988
[1] -14.64485
[1] 28.49185
[1] 1204.036
[1] 22.15487
[1] 921.308
[1] -1748.952
[1] -12.32419
[1] -11.43416
[1] 802.6352
INFO  [16:37:35.973] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -12.24689
[1] 23.59372
[1] -59.28848
[1] 3.80967
[1] -65.19615
[1] 23.83429
[1] -48.3776
[1] 7.200044
[1] -82.68186
[1] 25.62483
INFO  [16:37:55.262] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -29.48323
[1] 78.00763
[1] -52.31431
[1] 27.09523
[1] -111.4863
[1] 33.14532
[1] -26.20537
[1] 18.2882
[1] -44.60557
[1] 34.11188
INFO  [16:38:16.566] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -8.730658e+15
[1] 1.68029e+16
[1] 38.44206
[1] 1171.62
[1] -39.27701
[1] 10.14411
[1] -17.852
[1] 154.9051
[1] -4820.215
[1] -303.235
INFO  [16:38:36.383] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -308.0705
[1] -6.53198
[1] -7.675316
[1] 239.7686
[1] 8.204511
[1] 363.8564
[1] -333.0828
[1] -0.7025562
[1] -9.754124
[1] 257.952
INFO  [16:39:03.794] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -92.74596
[1] 198.435
[1] -289.9219
[1] 23.26027
[1] -312.5932
[1] -5.85929
[1] -43.0062
[1] 381.6181
[1] -291.1379
[1] -5.903894
INFO  [16:39:35.809] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -257.7475
[1] 192.3584
[1] -446.558
[1] -6.922059
[1] -90.62931
[1] 204.9653
[1] -2.089893
[1] 294.6531
[1] -766.5608
[1] -0.647444
INFO  [16:39:58.679] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -33.76714
[1] 16.32223
[1] -30.27945
[1] 38.15907
[1] -35.59106
[1] 13.63877
[1] -3119.969
[1] -74.5167
[1] -22.70214
[1] 55.04829
INFO  [16:40:40.549] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -77.76891
[1] 4.3757
[1] -32.92027
[1] 116.8587
[1] -349.5914
[1] 6.567112
[1] -46.59716
[1] 52.70436
[1] -18.81004
[1] 92.70542
INFO  [16:41:37.152] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -36.29367
[1] 76.66203
[1] -168.8869
[1] -2.948156
[1] -74.71089
[1] 53.01587
[1] -160.9564
[1] 23.46747
[1] -32.35111
[1] 78.03225
INFO  [16:42:50.256] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -22.51824
[1] 479.9831
[1] 9.931676
[1] 512.8909
[1] -225.4601
[1] 106.2919
[1] -358.4003
[1] -5.695278
[1] -356.5998
[1] 34.99452
INFO  [16:43:42.318] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -456.6152
[1] 380.6307
[1] -276.69
[1] 132.8748
[1] 12.06201
[1] 761.8087
[1] 10.70265
[1] 541.7485
[1] -394.0934
[1] -7.460878
INFO  [16:44:33.035] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -446.5879
[1] 252.6605
[1] -460.0622
[1] -7.862044
[1] 15.66172
[1] 692.3625
[1] -243.4182
[1] 152.1911
[1] -63531.79
[1] -1057.754
INFO  [16:45:31.858] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:47:16.953] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:48:35.574] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [16:49:50.649] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -283.515
[1] -4.030937
[1] -32.90382
[1] 54.89867
[1] 58.45809
[1] 1852.311
[1] -64.81149
[1] 14.83058
[1] -138.0395
[1] 267.7086
INFO  [16:50:23.431] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -67.36954
[1] 20.72662
[1] 95.50691
[1] 2369.615
[1] -57.21987
[1] 144.6282
[1] -61.4496
[1] 42.2718
[1] -8985.996
[1] -353.2186
INFO  [16:51:16.377] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -73.10615
[1] 94.801
[1] -76.42434
[1] 29.37785
[1] -49.09545
[1] 61.0874
[1] -474.8372
[1] -4.22964
[1] 64.39045
[1] 1982.96
INFO  [16:52:20.702] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -36.09587
[1] 21.52649
[1] -20.3332
[1] 38.63857
[1] 43.97012
[1] 1052.183
[1] -40.50559
[1] 46.33768
[1] -56.99986
[1] 24.61594
INFO  [16:53:16.467] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -39.15986
[1] 43.17708
[1] -28.21325
[1] 87.20901
[1] -251.7242
[1] 0.7297348
[1] -41.5652
[1] 86.62967
[1] -156.7283
[1] -4.226804
INFO  [16:53:58.745] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -6342.671
[1] -240.2731
[1] -53.02294
[1] 19.42827
[1] 49.88316
[1] 1309.025
[1] 17.34035
[1] 305.533
[1] -49.4744
[1] 11.88179
INFO  [16:54:40.076] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -99.9242
[1] 8.89604
[1] -34.96665
[1] 104.3905
[1] -86.32915
[1] 31.25449
[1] -2943.006
[1] -104.6156
[1] -78.29396
[1] 14.02299
INFO  [16:55:49.711] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -25.86468
[1] 22.4239
[1] -126.9214
[1] 50.3955
[1] -20.67272
[1] 60.51446
[1] 31.12529
[1] 924.7605
[1] -39.73922
[1] 13.5555
INFO  [16:56:45.215] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -731.3348
[1] -32.00293
[1] -31.65086
[1] 89.13154
[1] -310.8462
[1] 7.477342
[1] -3140.918
[1] -80.76308
[1] -19.36893
[1] 36.31772
INFO  [16:57:39.091] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [16:58:22.828] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [16:59:16.491] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:00:10.757] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -133.865
[1] -3.631082
[1] -62.51884
[1] 30.04047
[1] -74.98933
[1] 24.41034
[1] -27.24779
[1] 87.58575
[1] -194.4025
[1] 4.830618
INFO  [17:00:59.153] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -202.4667
[1] -3.778631
[1] -54.22392
[1] 142.9631
[1] -35.36059
[1] 41.73277
[1] -131.8195
[1] 66.18707
[1] -168.193
[1] -2.988138
INFO  [17:01:38.773] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -17.17165
[1] 88.78257
[1] -122.0715
[1] 4.695726
[1] -74.25793
[1] 74.3191
[1] -72.11329
[1] 100.5799
[1] -224.5018
[1] 9.618513
INFO  [17:02:09.269] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:03:16.879] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:04:24.848] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:05:20.427] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -67.73631
[1] 11.06911
[1] -145.7328
[1] 86.66649
[1] -62.04751
[1] 22.5077
[1] -395.8749
[1] 15.11221
[1] -241.5114
[1] 172.8465
INFO  [17:06:47.657] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -116.1128
[1] -3.854149
[1] -58.02563
[1] 121.3104
[1] -41.29436
[1] 41.70597
[1] -40.78295
[1] 30.31783
[1] -76.59522
[1] 52.90786
INFO  [17:08:01.546] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -67.1111
[1] 24.97114
[1] -1337.103
[1] -32.4877
[1] -460.6701
[1] 3.952779
[1] -38.79612
[1] 87.66694
[1] 38.6579
[1] 954.5317
INFO  [17:09:07.907] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -205.0618
[1] 8.156483
[1] -275.1493
[1] 72.86856
[1] -14.36988
[1] 249.3967
[1] -63.73533
[1] 171.1637
[1] -214.6547
[1] -4.543437
INFO  [17:09:37.551] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -287.4676
[1] -4.508319
[1] -285.4418
[1] -5.194311
[1] 8.550178
[1] 431.4334
[1] -108.7237
[1] 143.1865
[1] -188.6665
[1] -0.9812505
INFO  [17:09:59.457] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -512.5076
[1] -5.630824
[1] 517.5876
[1] 17784.42
[1] -178.0141
[1] 49.75175
[1] -310.6839
[1] 47.58695
[1] -90.99903
[1] 95.38597
INFO  [17:10:25.745] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -31.69445
[1] 75.52591
[1] -3265.499
[1] -64.53172
[1] -32.31532
[1] 11.18405
[1] -28.8458
[1] 74.32495
[1] -58.6411
[1] 38.31916
INFO  [17:11:17.552] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -51.50546
[1] 15.72994
[1] -66.83401
[1] 162.5527
[1] -2004.07
[1] -67.7045
[1] -54.91435
[1] 6.467735
[1] -568.2022
[1] -3.777427
INFO  [17:11:56.079] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 57.35483
[1] 1173.39
[1] -1483.71
[1] -35.87284
[1] -2996.322
[1] -151.9222
[1] -48.19181
[1] 21.7883
[1] -140.6494
[1] 0.8577146
INFO  [17:12:44.930] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:13:07.644] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:13:25.760] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:13:49.611] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -535.5714
[1] -7.843479
[1] 8.225812
[1] 326.0759
[1] -187.1183
[1] 401.7611
[1] -493.2394
[1] -7.135109
[1] -90.12202
[1] 332.6281
INFO  [17:14:53.808] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -12.46635
[1] 316.4738
[1] -221.5423
[1] 200.5672
[1] -409.8687
[1] -5.831597
[1] -467.2139
[1] -8.226702
[1] -18685.92
[1] -326.5548
INFO  [17:15:56.349] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -460.8845
[1] -6.635247
[1] -15757.27
[1] -256.2192
[1] 19.5184
[1] 873.1877
[1] -570.6775
[1] -9.332311
[1] -8.407857
[1] 477.5542
INFO  [17:16:53.155] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 94.65338
[1] 5054.695
[1] 121.9887
[1] 6499.62
[1] -6324.561
[1] -115.3385
[1] -11938.09
[1] -212.7796
[1] 112.0909
[1] 5981.791
INFO  [17:17:24.674] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -7372.817
[1] -134.9541
[1] -5902.304
[1] -108.3564
[1] 116.6986
[1] 6230.45
[1] -5084.904
[1] -92.92668
[1] 146.3894
[1] 7858.392
INFO  [17:17:54.946] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -33702.99
[1] -605.5255
[1] -7298.807
[1] -132.5274
[1] 136.3027
[1] 7219.436
[1] 158.0276
[1] 8388.407
[1] -7409.745
[1] -136.2494
INFO  [17:18:23.834] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
INFO  [17:19:17.563] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
INFO  [17:19:47.535] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
INFO  [17:20:20.066] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -49.07595
[1] 13.0687
[1] -18.79684
[1] 150.3618
[1] -29.00604
[1] 67.70957
[1] -1805.511
[1] -57.24334
[1] -24.8053
[1] 42.6479
INFO  [17:20:52.428] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -85.27864
[1] 9.198458
[1] -40.78206
[1] 55.25421
[1] -83.93442
[1] 10.25482
[1] -48.48989
[1] 32.33759
[1] -1660.986
[1] -48.10072
INFO  [17:21:20.260] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 160.4624
[1] 2842.107
[1] -24.89011
[1] 68.02177
[1] -55.71223
[1] 61.84042
[1] -45.97935
[1] 43.43787
[1] -97.58121
[1] 2.862866
INFO  [17:21:49.177] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -3250.48
[1] -55.17842
[1] -2441.535
[1] -43.05952
[1] -364.4948
[1] 1097.795
[1] -1404.812
[1] -24.61174
[1] -129.4782
[1] 1789.989
INFO  [17:22:27.376] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 45.07665
[1] 2350.392
[1] -2555.238
[1] -46.79762
[1] -2697.816
[1] -46.13274
[1] -2946.01
[1] -53.32928
[1] -1420.282
[1] -25.44013
INFO  [17:23:12.071] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 36.107
[1] 1851.805
[1] 42.90702
[1] 2185.725
[1] 53.76996
[1] 2710.584
[1] -1941.231
[1] -33.55518
[1] -1991.09
[1] -35.48877
INFO  [17:24:05.524] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -82.13214
[1] 103.1652
[1] -183.4327
[1] 19.62239
[1] -49.12062
[1] 159.0109
[1] -155.748
[1] 71.50852
[1] -119.9229
[1] 49.51966
INFO  [17:24:52.732] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -222.7489
[1] 8.75359
[1] -58.58494
[1] 124.9421
[1] -132.0984
[1] 38.28213
[1] 5.515166
[1] 219.6863
[1] -239.9535
[1] -3.869299
INFO  [17:25:20.117] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -82.47584
[1] 131.3623
[1] -77.07036
[1] 215.2642
[1] -69.90239
[1] 113.6005
[1] -46105.2
[1] -1459.41
[1] -257.7738
[1] -4.251596
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:26:01.880] [mlr3] Finished benchmark
INFO  [17:26:02.821] [bbotk] Result of batch 1:
INFO  [17:26:02.883] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:26:02.883] [bbotk]             -6.5837390                         0.3918902
INFO  [17:26:02.883] [bbotk]              0.3240160                         0.8418902
INFO  [17:26:02.883] [bbotk]              3.7778936                         0.1668902
INFO  [17:26:02.883] [bbotk]             -3.1298613                         0.6168902
INFO  [17:26:02.883] [bbotk]              2.0509548                         0.5043902
INFO  [17:26:02.883] [bbotk]             -4.8568001                         0.9543902
INFO  [17:26:02.883] [bbotk]             -1.4029225                         0.2793902
INFO  [17:26:02.883] [bbotk]              5.5048324                         0.7293902
INFO  [17:26:02.883] [bbotk]              6.3683018                         0.3356402
INFO  [17:26:02.883] [bbotk]             -0.5394530                         0.7856402
INFO  [17:26:02.883] [bbotk]              2.9144242                         0.5606402
INFO  [17:26:02.883] [bbotk]             -3.9933307                         0.1106402
INFO  [17:26:02.883] [bbotk]              1.1874854                         0.2231402
INFO  [17:26:02.883] [bbotk]             -5.7202696                         0.6731402
INFO  [17:26:02.883] [bbotk]             -2.2663919                         0.4481402
INFO  [17:26:02.883] [bbotk]              4.6413630                         0.8981402
INFO  [17:26:02.883] [bbotk]              0.7557507                         0.4200152
INFO  [17:26:02.883] [bbotk]             -6.1520043                         0.8700152
INFO  [17:26:02.883] [bbotk]             -2.6981266                         0.1950152
INFO  [17:26:02.883] [bbotk]              4.2096283                         0.6450152
INFO  [17:26:02.883] [bbotk]             -0.9711877                         0.7575152
INFO  [17:26:02.883] [bbotk]              5.9365671                         0.3075152
INFO  [17:26:02.883] [bbotk]             -4.4250654                         0.5325152
INFO  [17:26:02.883] [bbotk]              2.4826895                         0.9825152
INFO  [17:26:02.883] [bbotk]             -0.1077183                         0.3637652
INFO  [17:26:02.883] [bbotk]              6.8000365                         0.8137652
INFO  [17:26:02.883] [bbotk]              3.3461589                         0.1387652
INFO  [17:26:02.883] [bbotk]             -3.5615960                         0.5887652
INFO  [17:26:02.883] [bbotk]              5.0730977                         0.4762652
INFO  [17:26:02.883] [bbotk]             -1.8346572                         0.9262652
INFO  [17:26:02.883] [bbotk]             -5.2885349                         0.2512652
INFO  [17:26:02.883] [bbotk]              1.6192201                         0.7012652
INFO  [17:26:02.883] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:26:02.883] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:26:02.883] [bbotk]                         0.3130857         -4.12913397             2.54167700
INFO  [17:26:02.883] [bbotk]                         0.7630857         -8.73430436            -4.36607807
INFO  [17:26:02.883] [bbotk]                         0.5380857         -1.82654888            -0.91220022
INFO  [17:26:02.883] [bbotk]                         0.9880857         -6.43171934             5.99555464
INFO  [17:26:02.883] [bbotk]                         0.8755857         -7.58301175            -6.09301679
INFO  [17:26:02.883] [bbotk]                         0.4255857         -2.97784142             0.81473819
INFO  [17:26:02.883] [bbotk]                         0.6505857         -5.28042679             4.26861582
INFO  [17:26:02.883] [bbotk]                         0.2005857         -0.67525633            -2.63913904
INFO  [17:26:02.883] [bbotk]                         0.5943357         -2.40219515             6.85902405
INFO  [17:26:02.883] [bbotk]                         0.1443357         -7.00736547            -0.04873081
INFO  [17:26:02.883] [bbotk]                         0.3693357         -4.70478052             3.40514641
INFO  [17:26:02.883] [bbotk]                         0.8193357         -0.09961006            -3.50260866
INFO  [17:26:02.883] [bbotk]                         0.2568357         -5.85607306             1.67820759
INFO  [17:26:02.883] [bbotk]                         0.7068357         -1.25090260            -5.22954738
INFO  [17:26:02.883] [bbotk]                         0.4818357         -8.15865809            -1.77566963
INFO  [17:26:02.883] [bbotk]                         0.9318357         -3.55348770             5.13208523
INFO  [17:26:02.883] [bbotk]                         0.3974607         -0.38743319             4.70035053
INFO  [17:26:02.883] [bbotk]                         0.8474607         -4.99260365            -2.20740434
INFO  [17:26:02.883] [bbotk]                         0.1724607         -2.69001829            -5.66128208
INFO  [17:26:02.883] [bbotk]                         0.6224607         -7.29518861             1.24647289
INFO  [17:26:02.883] [bbotk]                         0.5099607         -3.84131083            -3.93434336
INFO  [17:26:02.883] [bbotk]                         0.9599607         -8.44648122             2.97341171
INFO  [17:26:02.883] [bbotk]                         0.7349607         -6.14389620            -0.48046552
INFO  [17:26:02.883] [bbotk]                         0.2849607         -1.53872574             6.42728935
INFO  [17:26:02.883] [bbotk]                         0.9037107         -2.11437201             0.38300348
INFO  [17:26:02.883] [bbotk]                         0.4537107         -6.71954247            -6.52475152
INFO  [17:26:02.883] [bbotk]                         0.6787107         -4.41695710            -3.07087375
INFO  [17:26:02.883] [bbotk]                         0.2287107         -9.02212748             3.83688112
INFO  [17:26:02.883] [bbotk]                         0.1162107         -5.56824993            -4.79781277
INFO  [17:26:02.883] [bbotk]                         0.5662107         -0.96307947             2.10994230
INFO  [17:26:02.883] [bbotk]                         0.3412107         -7.87083488             5.56381994
INFO  [17:26:02.883] [bbotk]                         0.7912107         -3.26566456            -1.34393493
INFO  [17:26:02.883] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:26:02.883] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:26:02.883] [bbotk]                         11                    2292                 0.3777686
INFO  [17:26:02.883] [bbotk]                          1                    4792                 0.8277685
INFO  [17:26:02.883] [bbotk]                          6                    1042                 0.6027685
INFO  [17:26:02.883] [bbotk]                         16                    3542                 0.1527686
INFO  [17:26:02.883] [bbotk]                          9                    1667                 0.4902686
INFO  [17:26:02.883] [bbotk]                         19                    4167                 0.9402685
INFO  [17:26:02.883] [bbotk]                         14                     417                 0.7152685
INFO  [17:26:02.883] [bbotk]                          4                    2917                 0.2652686
INFO  [17:26:02.883] [bbotk]                          2                    1355                 0.5465186
INFO  [17:26:02.883] [bbotk]                         12                    3855                 0.9965185
INFO  [17:26:02.883] [bbotk]                          7                    2605                 0.3215186
INFO  [17:26:02.883] [bbotk]                         17                     105                 0.7715185
INFO  [17:26:02.883] [bbotk]                          5                     730                 0.6590185
INFO  [17:26:02.883] [bbotk]                         15                    3230                 0.2090186
INFO  [17:26:02.883] [bbotk]                         20                    1980                 0.4340186
INFO  [17:26:02.883] [bbotk]                         10                    4480                 0.8840185
INFO  [17:26:02.883] [bbotk]                         16                    3386                 0.3496436
INFO  [17:26:02.883] [bbotk]                          6                     886                 0.7996435
INFO  [17:26:02.883] [bbotk]                          1                    4636                 0.5746435
INFO  [17:26:02.883] [bbotk]                         11                    2136                 0.1246436
INFO  [17:26:02.883] [bbotk]                          8                    1511                 0.2371436
INFO  [17:26:02.883] [bbotk]                         18                    4011                 0.6871435
INFO  [17:26:02.883] [bbotk]                          3                    2761                 0.4621436
INFO  [17:26:02.883] [bbotk]                         13                     261                 0.9121435
INFO  [17:26:02.883] [bbotk]                          7                    3073                 0.5183936
INFO  [17:26:02.883] [bbotk]                         17                     573                 0.9683935
INFO  [17:26:02.883] [bbotk]                         12                    4323                 0.7433935
INFO  [17:26:02.883] [bbotk]                          2                    1823                 0.2933936
INFO  [17:26:02.883] [bbotk]                         14                    3698                 0.4058936
INFO  [17:26:02.883] [bbotk]                          4                    1198                 0.8558935
INFO  [17:26:02.883] [bbotk]                          9                    4948                 0.6308935
INFO  [17:26:02.883] [bbotk]                         19                    2448                 0.1808936
INFO  [17:26:02.883] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:26:02.883] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:26:02.883] [bbotk]      0.03177394        0      0           88.258
INFO  [17:26:02.883] [bbotk]      0.10098693        0      0          198.579
INFO  [17:26:02.883] [bbotk]      0.21734304        0      0          104.250
INFO  [17:26:02.883] [bbotk]      0.17120340        0      0          218.145
INFO  [17:26:02.883] [bbotk]      0.10384873        0      0          188.185
INFO  [17:26:02.883] [bbotk]      0.02820290        0      0          258.098
INFO  [17:26:02.883] [bbotk]      0.11237985        0      0           94.294
INFO  [17:26:02.883] [bbotk]      0.23510440        0      0          148.549
INFO  [17:26:02.883] [bbotk]      0.23510440        0      0          138.698
INFO  [17:26:02.883] [bbotk]      0.03677900        0      0          267.482
INFO  [17:26:02.883] [bbotk]      0.19987945        0      0          170.454
INFO  [17:26:02.883] [bbotk]      0.03097888        0      0           59.985
INFO  [17:26:02.883] [bbotk]      0.07994799        0      0           82.194
INFO  [17:26:02.883] [bbotk]      0.03169744        0      0          170.820
INFO  [17:26:02.883] [bbotk]      0.10034631        0      0          161.221
INFO  [17:26:02.883] [bbotk]      0.23510440        0      0          258.527
INFO  [17:26:02.883] [bbotk]      0.03088737        0      0          149.642
INFO  [17:26:02.883] [bbotk]      0.03050519        0      0          139.085
INFO  [17:26:02.883] [bbotk]      0.02567698        0      0          178.416
INFO  [17:26:02.883] [bbotk]      0.23510440        0      0          149.548
INFO  [17:26:02.883] [bbotk]      0.02685782        0      0          118.063
INFO  [17:26:02.883] [bbotk]      0.23510440        0      0          188.774
INFO  [17:26:02.883] [bbotk]      0.03104210        0      0          226.456
INFO  [17:26:02.883] [bbotk]      0.06771285        0      0           77.020
INFO  [17:26:02.883] [bbotk]      0.02579792        0      0          138.429
INFO  [17:26:02.883] [bbotk]      0.23510440        0      0           63.276
INFO  [17:26:02.883] [bbotk]      0.11470456        0      0          182.871
INFO  [17:26:02.883] [bbotk]      0.20972945        0      0           90.311
INFO  [17:26:02.883] [bbotk]      0.23510440        0      0          115.781
INFO  [17:26:02.883] [bbotk]      0.02977077        0      0           88.785
INFO  [17:26:02.883] [bbotk]      0.16187630        0      0          135.939
INFO  [17:26:02.883] [bbotk]      0.05577676        0      0          108.048
INFO  [17:26:02.883] [bbotk]  classif.bbrier warnings errors runtime_learners
INFO  [17:26:02.883] [bbotk]                                 uhash
INFO  [17:26:02.883] [bbotk]  7bedda72-9ecb-4f3b-a74e-157fe8afb031
INFO  [17:26:02.883] [bbotk]  e1aa005c-cc6d-4344-bb2c-a99c7223e448
INFO  [17:26:02.883] [bbotk]  8bc24010-0daf-4735-b206-9b73d99c4a29
INFO  [17:26:02.883] [bbotk]  0597114a-df01-49b5-82c1-f0d6ff5d84c1
INFO  [17:26:02.883] [bbotk]  ba75ba3c-c841-4f76-97ae-a426adeb53a2
INFO  [17:26:02.883] [bbotk]  ec10a4d4-b6bc-4282-bf78-d9229e55b34e
INFO  [17:26:02.883] [bbotk]  3c196e77-aadf-4a14-b085-fb5ffc136fdf
INFO  [17:26:02.883] [bbotk]  60b91891-0e82-48e1-a8ad-bfc1e3c94e81
INFO  [17:26:02.883] [bbotk]  e1f03ee6-e566-4c78-8b49-010289e020fc
INFO  [17:26:02.883] [bbotk]  85df2520-c7a4-4e86-8839-db163c8cb860
INFO  [17:26:02.883] [bbotk]  c49fe354-ac2e-4e0b-808e-854e38602a6b
INFO  [17:26:02.883] [bbotk]  cfa3d9db-6260-42a7-944e-5e43e8d4c677
INFO  [17:26:02.883] [bbotk]  16167e93-6fb2-4c05-9467-cdab976726f4
INFO  [17:26:02.883] [bbotk]  2b736687-7a66-4621-9219-8786fa8ea973
INFO  [17:26:02.883] [bbotk]  c065466c-7b68-4476-9ed8-0170cceb22d3
INFO  [17:26:02.883] [bbotk]  10da4093-8138-4326-830b-aa449991d9a3
INFO  [17:26:02.883] [bbotk]  34684d96-6750-4b20-ba31-01fe390ebb10
INFO  [17:26:02.883] [bbotk]  3c8a726b-64b8-4b0c-9e1b-a3931cdfd3b3
INFO  [17:26:02.883] [bbotk]  6e63c59a-7285-4deb-83a3-b1829a45b25a
INFO  [17:26:02.883] [bbotk]  31d9ac8e-1f12-4bc0-9d4b-71a94bb8616b
INFO  [17:26:02.883] [bbotk]  5885e346-f967-41cd-a9a4-3962846b9eb0
INFO  [17:26:02.883] [bbotk]  542dbd87-76b9-4529-879c-7ed74481d7ea
INFO  [17:26:02.883] [bbotk]  5c91f0db-90c3-43b5-abf2-d868f3b1fb30
INFO  [17:26:02.883] [bbotk]  3c911ed1-69a1-4fcf-81f3-66581bf658f9
INFO  [17:26:02.883] [bbotk]  618cd379-db96-455b-8135-b745b81c102c
INFO  [17:26:02.883] [bbotk]  26675fef-12b2-41bb-bf34-b958f23e722f
INFO  [17:26:02.883] [bbotk]  3237f097-c40b-453f-b0f6-47453166b4b7
INFO  [17:26:02.883] [bbotk]  2bc0cbb1-578a-40a5-ad6c-66f9f24c9bda
INFO  [17:26:02.883] [bbotk]  95497cb2-a120-4264-9c70-c806e2783d99
INFO  [17:26:02.883] [bbotk]  60279834-e580-4074-a3b6-2b3b67d2d4d4
INFO  [17:26:02.883] [bbotk]  a5db3a9c-ca80-4c53-b37b-107f80643d64
INFO  [17:26:02.883] [bbotk]  2ef877b7-69f9-4bd3-9ee2-92f1120977e9
INFO  [17:26:02.883] [bbotk]                                 uhash
INFO  [17:26:10.988] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 32 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:26:17.814] [bbotk] Evaluating 1 configuration(s)
INFO  [17:26:17.981] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:26:18.059] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -68.62157
[1] 16.17771
[1] -38.94978
[1] 17.70095
[1] -306.0295
[1] -4.127721
[1] 335.7187
[1] 7020.036
[1] -21.63835
[1] 37.1266
INFO  [17:26:45.242] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -70.97628
[1] 4.034052
[1] -22.85874
[1] 124.3459
[1] -31.44279
[1] 23.79336
[1] -150.6367
[1] 24.13033
[1] -66.16
[1] 19.55137
INFO  [17:27:22.804] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -4253.054
[1] -90.9413
[1] 42.03476
[1] 872.1724
[1] -406.8388
[1] 34.01353
[1] -34.73554
[1] 35.89678
[1] -62.96729
[1] 19.04473
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:28:13.422] [mlr3] Finished benchmark
INFO  [17:28:13.574] [bbotk] Result of batch 2:
INFO  [17:28:13.621] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:28:13.621] [bbotk]              -4.699302                         0.5030351
INFO  [17:28:13.621] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:28:13.621] [bbotk]                         0.5286114           -2.427404              -1.728184
INFO  [17:28:13.621] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:28:13.621] [bbotk]                          8                    3081                 0.5512745
INFO  [17:28:13.621] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:28:13.621] [bbotk]  0.03686181 <list[8]>              FALSE     0.02760849        0      0
INFO  [17:28:13.621] [bbotk]  runtime_learners                                uhash
INFO  [17:28:13.621] [bbotk]           114.532 66cd13e1-7cbb-4234-8cdd-012a3c727eaf
INFO  [17:28:14.258] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 33 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:28:20.594] [bbotk] Evaluating 1 configuration(s)
INFO  [17:28:20.856] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:28:21.015] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 3.362138e+14
[1] 3.868082e+16
[1] -111.798
[1] 1.079741
[1] -61.43039
[1] 41.602
[1] -57.98109
[1] 27.73667
[1] -27.90144
[1] 36.63826
INFO  [17:28:48.768] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -60.73929
[1] -1.491072
[1] 17.05042
[1] 447.701
[1] -36.4576
[1] 90.50354
[1] -43.73912
[1] 85.20515
[1] -95.75104
[1] 29.67121
INFO  [17:29:19.174] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -62.64892
[1] 34.50236
[1] -99.19892
[1] 20.764
[1] 92.7007
[1] 2540.598
[1] -18.83151
[1] 81.99831
[1] -586.3368
[1] -3.028198
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:29:46.432] [mlr3] Finished benchmark
INFO  [17:29:46.647] [bbotk] Result of batch 3:
INFO  [17:29:46.672] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:29:46.672] [bbotk]             -0.1671489                         0.5936599
INFO  [17:29:46.672] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:29:46.672] [bbotk]                         0.1424017           -2.757214              -2.327302
INFO  [17:29:46.672] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:29:46.672] [bbotk]                         16                    2356                 0.8477602
INFO  [17:29:46.672] [bbotk]     acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:29:46.672] [bbotk]  0.0329948 <list[8]>              FALSE     0.02865067        0      0
INFO  [17:29:46.672] [bbotk]  runtime_learners                                uhash
INFO  [17:29:46.672] [bbotk]            84.961 c190d045-eef0-4d09-ba91-7a483e4b7814
INFO  [17:29:47.504] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 34 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:29:53.403] [bbotk] Evaluating 1 configuration(s)
INFO  [17:29:53.614] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:29:53.658] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -54.66765
[1] 24.13774
[1] -53.62124
[1] 5.42341
[1] -38.71387
[1] 25.42366
[1] -11.79626
[1] 44.01745
[1] -22.01335
[1] 59.90004
INFO  [17:30:41.961] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -188.7255
[1] -3.872999
[1] -32.9731
[1] 12.27293
[1] -101.2502
[1] 5.408309
[1] 59.13395
[1] 1961.062
[1] -63.71942
[1] 26.15334
INFO  [17:31:21.781] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -37.77666
[1] 88.59017
[1] -81.1867
[1] 8.27897
[1] -26.23412
[1] 31.38947
[1] -18.39416
[1] 57.79511
[1] 37.26506
[1] 770.9433
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:32:03.107] [mlr3] Finished benchmark
INFO  [17:32:03.361] [bbotk] Result of batch 4:
INFO  [17:32:03.444] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:32:03.444] [bbotk]              -2.265662                         0.8289948
INFO  [17:32:03.444] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:32:03.444] [bbotk]                         0.7028209           -1.637407              -2.069849
INFO  [17:32:03.444] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:32:03.444] [bbotk]                         15                    3520                 0.8340465
INFO  [17:32:03.444] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:32:03.444] [bbotk]  0.02055244 <list[8]>              FALSE     0.02799294        0      0
INFO  [17:32:03.444] [bbotk]  runtime_learners                                uhash
INFO  [17:32:03.444] [bbotk]           128.687 baaaf2ef-91ff-43d1-a1c3-64016a747bd6
INFO  [17:32:04.305] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 35 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:32:12.837] [bbotk] Evaluating 1 configuration(s)
INFO  [17:32:13.056] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:32:13.297] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -19.68611
[1] 48.02389
[1] -89.18369
[1] 10.92047
[1] -18.74641
[1] 53.73316
[1] -92.44701
[1] 2.66253
[1] -3435.366
[1] -108.3978
INFO  [17:33:13.205] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -166.3738
[1] -4.115186
[1] -22.34141
[1] 55.52361
[1] -138.3399
[1] 5.500422
[1] -46.66087
[1] 56.2263
[1] -156.8649
[1] 22.78642
INFO  [17:34:10.761] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 118.1861
[1] 2038.138
[1] -38.624
[1] 18.93888
[1] -816.238
[1] 46.84634
[1] -35.64536
[1] 65.37262
[1] -88.60441
[1] 17.71863
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:35:14.266] [mlr3] Finished benchmark
INFO  [17:35:14.965] [bbotk] Result of batch 5:
INFO  [17:35:15.136] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:35:15.136] [bbotk]             -0.5350073                          0.256861
INFO  [17:35:15.136] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:35:15.136] [bbotk]                         0.5474045           -4.249541              -1.734436
INFO  [17:35:15.136] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:35:15.136] [bbotk]                         17                    4619                 0.7235146
INFO  [17:35:15.136] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:35:15.136] [bbotk]  0.02460529 <list[8]>              FALSE     0.02650619        0      0
INFO  [17:35:15.136] [bbotk]  runtime_learners                                uhash
INFO  [17:35:15.136] [bbotk]           178.249 2f8913b8-6f98-4295-a6ed-2785c059c652
WARN  [17:35:17.742] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [17:35:18.065] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 36 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:35:27.095] [bbotk] Evaluating 1 configuration(s)
INFO  [17:35:27.260] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:35:27.413] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -32.52669
[1] 33.10611
[1] -28.21465
[1] 87.91992
[1] -66.09175
[1] 50.49522
[1] -2505.141
[1] -55.60041
[1] -34.59893
[1] 22.43066
INFO  [17:35:49.675] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -304.4332
[1] -3.897939
[1] -54.72866
[1] 12.18506
[1] -34.09916
[1] 56.56835
[1] -268.4432
[1] -3.760002
[1] -2696.404
[1] -54.05965
INFO  [17:36:12.508] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -76.01626
[1] 16.41393
[1] -202.3804
[1] -0.5293694
[1] -22.92716
[1] 58.37461
[1] -2914.875
[1] -68.11119
[1] 14.96209
[1] 343.4929
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:36:37.843] [mlr3] Finished benchmark
INFO  [17:36:37.973] [bbotk] Result of batch 6:
INFO  [17:36:38.010] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:36:38.010] [bbotk]              0.2993208                         0.8688518
INFO  [17:36:38.010] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:36:38.010] [bbotk]                         0.1094532          -0.1675991               3.183519
INFO  [17:36:38.010] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:36:38.010] [bbotk]                         11                     957                  0.727283
INFO  [17:36:38.010] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:36:38.010] [bbotk]  0.01629036 <list[8]>              FALSE     0.02661437        0      0
INFO  [17:36:38.010] [bbotk]  runtime_learners                                uhash
INFO  [17:36:38.010] [bbotk]            69.847 1caed4fe-dcc2-49d8-b22d-07b2802fec94
INFO  [17:36:39.337] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 37 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:36:46.741] [bbotk] Evaluating 1 configuration(s)
INFO  [17:36:46.829] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:36:46.969] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -66.4429
[1] 74.83505
[1] -313.2334
[1] 36.02924
[1] -32.45554
[1] 26.13985
[1] -8.537709e+15
[1] 2.313181e+16
[1] -38.29601
[1] 10.13601
INFO  [17:37:39.314] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -5.772376e+15
[1] 2.650762e+16
[1] -111.2604
[1] 15.55841
[1] -33.57461
[1] 29.05429
[1] -130.1879
[1] -3.611579
[1] -247.7416
[1] 9.939492
INFO  [17:38:18.052] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1086.684
[1] -67.9921
[1] -57.79852
[1] 88.56005
[1] -8668.007
[1] -161.5206
[1] -41.19939
[1] 30.59556
[1] -205.8672
[1] 19.52987
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:39:07.226] [mlr3] Finished benchmark
INFO  [17:39:07.357] [bbotk] Result of batch 7:
INFO  [17:39:07.436] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:39:07.436] [bbotk]              -4.168104                         0.6360107
INFO  [17:39:07.436] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:39:07.436] [bbotk]                         0.7978257           -4.386197              -5.276058
INFO  [17:39:07.436] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:39:07.436] [bbotk]                          1                    3323                  0.520555
INFO  [17:39:07.436] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:39:07.436] [bbotk]  0.01654758 <list[8]>              FALSE     0.02567293        0      0
INFO  [17:39:07.436] [bbotk]  runtime_learners                                uhash
INFO  [17:39:07.436] [bbotk]           138.556 ff271e69-8488-4b1f-9464-ebba73ab817e
INFO  [17:39:08.708] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 38 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:39:17.747] [bbotk] Evaluating 1 configuration(s)
INFO  [17:39:18.023] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:39:18.160] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -41.0926
[1] 29.89911
[1] -50.2105
[1] 21.05137
[1] -33.8906
[1] 85.12334
[1] -202.2902
[1] 8.773764
[1] -2452.796
[1] -120.4688
INFO  [17:39:54.225] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1581.941
[1] -31.91649
[1] -38.17926
[1] 14.06482
[1] -40.93407
[1] 43.59999
[1] 376.3675
[1] 10893.06
[1] -37.31834
[1] 12.19456
INFO  [17:40:23.018] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -19.24271
[1] 46.68534
[1] -28.29633
[1] 19.86717
[1] -135.978
[1] 16.9814
[1] 79.69829
[1] 2337.106
[1] -35.74449
[1] 58.39688
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:40:53.801] [mlr3] Finished benchmark
INFO  [17:40:53.907] [bbotk] Result of batch 8:
INFO  [17:40:53.937] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:40:53.937] [bbotk]              -6.603301                         0.3704356
INFO  [17:40:53.937] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:40:53.937] [bbotk]                         0.8087241           -3.223844              -1.011499
INFO  [17:40:53.937] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:40:53.937] [bbotk]                         17                    2300                 0.6615086
INFO  [17:40:53.937] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:40:53.937] [bbotk]  0.01547982 <list[8]>              FALSE     0.02615137        0      0
INFO  [17:40:53.937] [bbotk]  runtime_learners                                uhash
INFO  [17:40:53.937] [bbotk]            94.578 0dc10f7b-5a60-4e89-82b3-4bf8bae66265
INFO  [17:40:54.681] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 39 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:41:03.391] [bbotk] Evaluating 1 configuration(s)
INFO  [17:41:04.525] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:41:05.878] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -47.32388
[1] 49.15751
[1] -270.0982
[1] 17.06525
[1] -34.25535
[1] 30.61283
[1] -2876.59
[1] -52.79211
[1] -87.92581
[1] -3.229973
INFO  [17:41:41.332] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -74.08994
[1] 7.160128
[1] -59.9579
[1] 11.27304
[1] 43.00682
[1] 1614.03
[1] -45.42478
[1] 26.78847
[1] -329.1413
[1] 12.1813
INFO  [17:42:28.198] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1023.252
[1] -44.92812
[1] -58.08185
[1] 30.45979
[1] -17.97481
[1] 70.64514
[1] -61.55196
[1] 20.33617
[1] -42.71198
[1] 44.12863
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:42:56.801] [mlr3] Finished benchmark
INFO  [17:42:57.048] [bbotk] Result of batch 9:
INFO  [17:42:57.121] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:42:57.121] [bbotk]              0.1097706                         0.6795595
INFO  [17:42:57.121] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:42:57.121] [bbotk]                         0.6131373          -0.1351453               4.862343
INFO  [17:42:57.121] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:42:57.121] [bbotk]                         19                    1393                 0.8788271
INFO  [17:42:57.121] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:42:57.121] [bbotk]  0.01456707 <list[8]>              FALSE      0.0295659        0      0
INFO  [17:42:57.121] [bbotk]  runtime_learners                                uhash
INFO  [17:42:57.121] [bbotk]           109.774 ff848bec-9f50-4d49-80bc-4f81638e4491
INFO  [17:42:58.783] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 40 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:43:05.768] [bbotk] Evaluating 1 configuration(s)
INFO  [17:43:05.861] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:43:05.907] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -36.29371
[1] 27.34212
[1] -59.66033
[1] 31.13195
[1] -34.76126
[1] 19.8116
[1] -66.50237
[1] 52.21811
[1] -397.7667
[1] -3.157556
INFO  [17:44:06.062] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -106.1619
[1] 45.75547
[1] -18.10707
[1] 70.41762
[1] -55.60819
[1] 20.07715
[1] -85.28552
[1] 6.433727
[1] -74.27649
[1] 4.33714
INFO  [17:44:57.506] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -90.07088
[1] -3.889271
[1] -53.77651
[1] 74.72747
[1] -21.34783
[1] 61.89797
[1] -35.47473
[1] 42.78323
[1] -458.1957
[1] 9.654761
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:45:30.732] [mlr3] Finished benchmark
INFO  [17:45:30.831] [bbotk] Result of batch 10:
INFO  [17:45:30.875] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:45:30.875] [bbotk]             -0.7822042                         0.8564545
INFO  [17:45:30.875] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:45:30.875] [bbotk]                         0.5276455           -4.729868             -0.4709211
INFO  [17:45:30.875] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:45:30.875] [bbotk]                          2                    4704                 0.8403273
INFO  [17:45:30.875] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:45:30.875] [bbotk]  0.01370934 <list[8]>              FALSE     0.02830953        0      0
INFO  [17:45:30.875] [bbotk]  runtime_learners                                uhash
INFO  [17:45:30.875] [bbotk]           144.544 448d159e-3be8-4b68-8eb0-d5d253753cf2
INFO  [17:45:32.430] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 41 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:45:38.251] [bbotk] Evaluating 1 configuration(s)
INFO  [17:45:38.384] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:45:38.468] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -63.22178
[1] 82.98019
[1] -105.4152
[1] 27.47767
[1] -259.3887
[1] -3.912254
[1] -50.03181
[1] 22.15239
[1] -222.7524
[1] 17.55588
INFO  [17:46:14.701] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 22.41155
[1] 758.6929
[1] -41.06175
[1] 30.03463
[1] -67.72028
[1] 13.07568
[1] -1933.662
[1] -38.78599
[1] -50.08818
[1] 21.10086
INFO  [17:47:08.320] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -5923.59
[1] -111.7139
[1] -1389.561
[1] -32.23798
[1] -56.28115
[1] 40.93409
[1] -28.47668
[1] 29.30992
[1] -355.8999
[1] 16.73462
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:48:04.596] [mlr3] Finished benchmark
INFO  [17:48:04.783] [bbotk] Result of batch 11:
INFO  [17:48:04.796] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:48:04.796] [bbotk]              -5.855822                         0.5756589
INFO  [17:48:04.796] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:48:04.796] [bbotk]                         0.9788863           -3.981067            -0.03111629
INFO  [17:48:04.796] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:48:04.796] [bbotk]                         17                    3783                 0.3079987
INFO  [17:48:04.796] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:48:04.796] [bbotk]  0.01306125 <list[8]>              FALSE     0.02676278        0      0
INFO  [17:48:04.796] [bbotk]  runtime_learners                                uhash
INFO  [17:48:04.796] [bbotk]            144.99 316ab752-2f80-42b1-a60a-a4e525f32a4b
INFO  [17:48:05.978] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 42 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:48:14.315] [bbotk] Evaluating 1 configuration(s)
INFO  [17:48:14.377] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:48:14.434] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -19.23641
[1] 31.94483
[1] -8.597799
[1] 53.03726
[1] -1093.836
[1] -28.58901
[1] -127.4432
[1] 23.5944
[1] -55.30752
[1] 1.45797
INFO  [17:48:30.392] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -891.7994
[1] -3.738232
[1] -8.418416
[1] 54.89227
[1] 108.8382
[1] 4518.935
[1] -40.87304
[1] 21.98081
[1] -80.07207
[1] 80.15221
INFO  [17:48:46.600] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -30.72629
[1] 32.86314
[1] -153.4025
[1] 16.03078
[1] -71.37963
[1] 54.09348
[1] -74.17375
[1] 59.00059
[1] -277.2236
[1] 6.005063
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:49:00.080] [mlr3] Finished benchmark
INFO  [17:49:00.217] [bbotk] Result of batch 12:
INFO  [17:49:00.240] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:49:00.240] [bbotk]              -2.489913                         0.1349159
INFO  [17:49:00.240] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:49:00.240] [bbotk]                         0.8643886            -1.43457              -4.863239
INFO  [17:49:00.240] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:49:00.240] [bbotk]                          2                    3079                 0.4184379
INFO  [17:49:00.240] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:49:00.240] [bbotk]  0.01250075 <list[8]>              FALSE     0.02621898        0      0
INFO  [17:49:00.240] [bbotk]  runtime_learners                                uhash
INFO  [17:49:00.240] [bbotk]            45.187 8a6d21dc-0416-4d9c-9939-cb04458c1c63
INFO  [17:49:01.534] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 43 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:49:07.216] [bbotk] Evaluating 1 configuration(s)
INFO  [17:49:07.464] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:49:07.580] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -43.29008
[1] 17.02151
[1] -43.38649
[1] 19.29624
[1] -88.57447
[1] 72.44722
[1] 515.3473
[1] 15749.88
[1] -34.55097
[1] 18.47302
INFO  [17:49:51.836] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -45.78156
[1] 75.07172
[1] -52.57813
[1] 3.431929
[1] -45.40598
[1] 73.94422
[1] -922.5012
[1] 71.4624
[1] -73.54483
[1] 11.33205
INFO  [17:50:40.664] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -540.7591
[1] -2.711449
[1] -38.15329
[1] 47.52605
[1] -56.60183
[1] 18.77456
[1] -44.28591
[1] 98.64556
[1] -41.66449
[1] 84.04654
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:51:50.464] [mlr3] Finished benchmark
INFO  [17:51:50.542] [bbotk] Result of batch 13:
INFO  [17:51:50.689] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:51:50.689] [bbotk]              -5.588889                         0.7613089
INFO  [17:51:50.689] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:51:50.689] [bbotk]                         0.3300294           -5.187311              -2.104299
INFO  [17:51:50.689] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:51:50.689] [bbotk]                          7                    4033                 0.6439648
INFO  [17:51:50.689] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:51:50.689] [bbotk]  0.01187679 <list[8]>              FALSE     0.02574234        0      0
INFO  [17:51:50.689] [bbotk]  runtime_learners                                uhash
INFO  [17:51:50.689] [bbotk]           161.108 f4a86dc2-f9af-4edc-a069-4465624def7f
INFO  [17:51:53.077] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 44 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:52:04.617] [bbotk] Evaluating 1 configuration(s)
INFO  [17:52:05.001] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:52:05.324] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -122.3755
[1] 29.85012
[1] -65.37404
[1] 87.52383
[1] -53.35888
[1] 12.60043
[1] -41.57961
[1] 27.39366
[1] -98.38878
[1] 35.85659
INFO  [17:52:24.292] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -34.46734
[1] 22.19731
[1] -991.4687
[1] -40.85655
[1] -45777.26
[1] -969.6339
[1] -43.16731
[1] 26.85549
[1] -221.2554
[1] 50.63869
INFO  [17:52:40.136] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -4155.266
[1] -106.1983
[1] -4348.485
[1] -85.03652
[1] -307.5706
[1] 6.933377
[1] -3651.505
[1] -136.1738
[1] -76.34145
[1] 34.40769
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:53:17.808] [mlr3] Finished benchmark
INFO  [17:53:18.082] [bbotk] Result of batch 14:
INFO  [17:53:18.106] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:53:18.106] [bbotk]              -3.473051                         0.3100816
INFO  [17:53:18.106] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:53:18.106] [bbotk]                         0.5791465           -2.511528              -5.888715
INFO  [17:53:18.106] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:53:18.106] [bbotk]                         16                    1044                 0.1773562
INFO  [17:53:18.106] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:53:18.106] [bbotk]  0.01110047 <list[8]>              FALSE     0.02767158        0      0
INFO  [17:53:18.106] [bbotk]  runtime_learners                                uhash
INFO  [17:53:18.106] [bbotk]            70.879 816fdbba-11a5-43c5-aa78-2eed16228291
INFO  [17:53:19.753] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 45 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:53:26.777] [bbotk] Evaluating 1 configuration(s)
INFO  [17:53:27.083] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:53:27.227] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -40.86534
[1] 32.46835
[1] -902.6088
[1] -39.58856
[1] -49.03341
[1] 0.8129554
[1] -303.867
[1] 97.24002
[1] -85.59845
[1] 26.46342
INFO  [17:54:05.677] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -93.77776
[1] 4.970631
[1] -15.03463
[1] 68.45689
[1] -39.26026
[1] 28.42403
[1] -45.72519
[1] 18.11639
[1] -195.7934
[1] -3.747089
INFO  [17:54:38.171] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -116.6685
[1] 0.3736809
[1] -76.02517
[1] 18.16197
[1] -18.36068
[1] 79.28846
[1] -964.9189
[1] 71.36508
[1] 614.2621
[1] 11126.03
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:55:09.752] [mlr3] Finished benchmark
INFO  [17:55:09.922] [bbotk] Result of batch 15:
INFO  [17:55:09.956] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:55:09.956] [bbotk]              -1.022915                         0.8542482
INFO  [17:55:09.956] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:55:09.956] [bbotk]                         0.4105387           -1.776976             -0.4716063
INFO  [17:55:09.956] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:55:09.956] [bbotk]                         14                    3121                 0.3203955
INFO  [17:55:09.956] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:55:09.956] [bbotk]  0.01066183 <list[8]>              FALSE     0.02459184        0      0
INFO  [17:55:09.956] [bbotk]  runtime_learners                                uhash
INFO  [17:55:09.956] [bbotk]           101.501 6f64eada-1348-4a6f-b62f-f096ada43f19
INFO  [17:55:11.463] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 46 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:55:17.486] [bbotk] Evaluating 1 configuration(s)
INFO  [17:55:17.702] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:55:17.845] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -45.36471
[1] 11.29601
[1] -71.15908
[1] 15.60295
[1] -44.15428
[1] 45.31724
[1] -71.25733
[1] 39.38303
[1] -1924.238
[1] -55.7664
INFO  [17:55:45.189] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -196.969
[1] 30.80493
[1] -595.4228
[1] 11.21758
[1] -237.5583
[1] -0.6969145
[1] -136.8038
[1] -3.962987
[1] -88.54706
[1] -3.899034
INFO  [17:56:14.332] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -59.84421
[1] 8.433458
[1] -39.85125
[1] 49.82627
[1] -192.5921
[1] 68.01198
[1] -46.39145
[1] 40.72502
[1] -501.8933
[1] -4.011781
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:56:46.119] [mlr3] Finished benchmark
INFO  [17:56:46.292] [bbotk] Result of batch 16:
INFO  [17:56:46.443] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:56:46.443] [bbotk]              -4.526398                         0.7022729
INFO  [17:56:46.443] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:56:46.443] [bbotk]                         0.5728483           -4.395131              -1.173544
INFO  [17:56:46.443] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:56:46.443] [bbotk]                         10                    1583                 0.9910647
INFO  [17:56:46.443] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:56:46.443] [bbotk]  0.009788198 <list[8]>              FALSE     0.03128807        0      0
INFO  [17:56:46.443] [bbotk]  runtime_learners                                uhash
INFO  [17:56:46.443] [bbotk]            87.788 c538e112-daa0-45f8-b652-4c25c47518f4
INFO  [17:56:48.948] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 47 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:56:55.073] [bbotk] Evaluating 1 configuration(s)
INFO  [17:56:55.408] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:56:55.567] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -35.62603
[1] 17.087
[1] -27.74481
[1] 48.44601
[1] -99.89787
[1] 4.93782
[1] -34.12116
[1] 33.67687
[1] -108.7118
[1] 55.11735
INFO  [17:57:43.810] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -2251.766
[1] -27.0257
[1] -29.30587
[1] 45.12942
[1] -41.84777
[1] 8.192517
[1] -73.34703
[1] 40.79376
[1] -29.34535
[1] 24.31055
INFO  [17:58:24.951] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1441.667
[1] -14.99406
[1] -38.44852
[1] 40.57724
[1] -148.1542
[1] 4.277153
[1] -25.22657
[1] 27.95496
[1] -22.29118
[1] 59.39764
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [17:59:10.394] [mlr3] Finished benchmark
INFO  [17:59:10.919] [bbotk] Result of batch 17:
INFO  [17:59:11.010] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [17:59:11.010] [bbotk]              -6.071665                         0.9269756
INFO  [17:59:11.010] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [17:59:11.010] [bbotk]                         0.9959498           -3.291298              0.3334822
INFO  [17:59:11.010] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [17:59:11.010] [bbotk]                          2                    2926                 0.7650095
INFO  [17:59:11.010] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [17:59:11.010] [bbotk]  0.009662599 <list[8]>              FALSE     0.02973323        0      0
INFO  [17:59:11.010] [bbotk]  runtime_learners                                uhash
INFO  [17:59:11.010] [bbotk]           133.752 1397be97-c48a-4164-9234-3bc1984b049e
INFO  [17:59:13.654] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 48 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [17:59:19.571] [bbotk] Evaluating 1 configuration(s)
INFO  [17:59:19.691] [mlr3] Running benchmark with 3 resampling iterations
INFO  [17:59:19.864] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -213.3912
[1] 41.38205
[1] -60.58504
[1] 34.47144
[1] -185.6351
[1] -4.064147
[1] -34.26518
[1] 64.52643
[1] -46.09348
[1] 45.24143
INFO  [17:59:47.606] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -202.9006
[1] -1.267472
[1] -101.3986
[1] 31.74917
[1] -90.87987
[1] 164.9027
[1] -96.36015
[1] 32.11183
[1] -147.7661
[1] 33.55993
INFO  [18:00:21.277] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -44.94979
[1] 124.6237
[1] -216.8365
[1] 68.08451
[1] 68.01768
[1] 1832.385
[1] -44.05197
[1] 46.62007
[1] -85.84946
[1] 3.126748
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:00:49.083] [mlr3] Finished benchmark
INFO  [18:00:49.265] [bbotk] Result of batch 18:
INFO  [18:00:49.298] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:00:49.298] [bbotk]              -6.811187                         0.1009082
INFO  [18:00:49.298] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:00:49.298] [bbotk]                         0.6991283           -5.661822             -0.9740699
INFO  [18:00:49.298] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:00:49.298] [bbotk]                          1                    2436                 0.5292434
INFO  [18:00:49.298] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:00:49.298] [bbotk]  0.009435368 <list[8]>              FALSE     0.03648313        0      0
INFO  [18:00:49.298] [bbotk]  runtime_learners                                uhash
INFO  [18:00:49.298] [bbotk]            88.496 ccb7dce4-27c1-4e6e-970b-fd9f05ad3512
INFO  [18:00:50.387] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 49 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:00:56.055] [bbotk] Evaluating 1 configuration(s)
INFO  [18:00:56.309] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:00:56.568] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -29.07088
[1] 471.2708
[1] -218.1633
[1] 4.031983
[1] -17.06253
[1] 72.65796
[1] -3225.41
[1] -91.25012
[1] -33.43538
[1] 11.22231
INFO  [18:01:11.406] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -269.0516
[1] -0.5351009
[1] -18.66127
[1] 33.02123
[1] -22.70038
[1] 12.33691
[1] -110.0724
[1] -1.07639
[1] -81535.61
[1] -2558.649
INFO  [18:01:39.896] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -34.92178
[1] 21.39785
[1] -207.0896
[1] 13.18825
[1] -40.24424
[1] 21.31147
[1] 303.9874
[1] 4157.668
[1] -57.23477
[1] 53.66085
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:02:14.425] [mlr3] Finished benchmark
INFO  [18:02:14.680] [bbotk] Result of batch 19:
INFO  [18:02:14.792] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:02:14.792] [bbotk]              -6.295635                         0.8421792
INFO  [18:02:14.792] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:02:14.792] [bbotk]                         0.4489468          -0.1379002               1.438922
INFO  [18:02:14.792] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:02:14.792] [bbotk]                         19                    2647                 0.7558129
INFO  [18:02:14.792] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:02:14.792] [bbotk]  0.01006374 <list[8]>              FALSE     0.02809985        0      0
INFO  [18:02:14.792] [bbotk]  runtime_learners                                uhash
INFO  [18:02:14.792] [bbotk]            76.602 b58ae291-b3e0-4f00-b697-b44353297a99
INFO  [18:02:17.442] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 50 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:02:23.361] [bbotk] Evaluating 1 configuration(s)
INFO  [18:02:23.520] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:02:23.720] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -40.0269
[1] 24.81472
[1] -6397.387
[1] -199.3479
[1] -28.86983
[1] 20.10169
[1] -280.2642
[1] -4.052381
[1] -91.66585
[1] 56.29669
INFO  [18:03:01.938] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 54.82147
[1] 1327.467
[1] -72.97998
[1] 19.63842
[1] -44.19188
[1] 106.6402
[1] -96.30679
[1] 34.40937
[1] -135.5447
[1] 8.548655
INFO  [18:03:31.629] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 118.8089
[1] 2987.63
[1] -34.58148
[1] 43.9115
[1] -275.4715
[1] 20.26952
[1] -94.28356
[1] 48.53001
[1] -4631.466
[1] -151.0815
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:04:05.672] [mlr3] Finished benchmark
INFO  [18:04:05.902] [bbotk] Result of batch 20:
INFO  [18:04:06.008] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:04:06.008] [bbotk]              -6.318972                         0.8806941
INFO  [18:04:06.008] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:04:06.008] [bbotk]                         0.6759554           -4.357853             -0.6418156
INFO  [18:04:06.008] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:04:06.008] [bbotk]                         11                    1968                  0.272945
INFO  [18:04:06.008] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:04:06.008] [bbotk]  0.01056817 <list[8]>              FALSE     0.02858945        0      0
INFO  [18:04:06.008] [bbotk]  runtime_learners                                uhash
INFO  [18:04:06.008] [bbotk]            99.735 980e917b-24b2-496e-8d30-4f8f7c0e2b3b
INFO  [18:04:09.163] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 51 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:04:13.314] [bbotk] Evaluating 1 configuration(s)
INFO  [18:04:13.387] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:04:13.445] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -61.95809
[1] 40.54236
[1] -158.7607
[1] 32.50462
[1] -232.1639
[1] -4.130937
[1] -106.4416
[1] 14.53964
[1] -10.29477
[1] 124.3204
INFO  [18:04:48.498] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -3097.681
[1] -52.09594
[1] -113.2353
[1] 16.14804
[1] -34.29913
[1] 54.31725
[1] -17.88058
[1] 377.535
[1] -100.6951
[1] 10.94055
INFO  [18:05:25.468] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 203.8468
[1] 7230.206
[1] -50.27755
[1] 80.89517
[1] -94.57027
[1] -3.709609
[1] -503.1229
[1] -4.473564
[1] -41.86715
[1] 91.51718
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:06:08.332] [mlr3] Finished benchmark
INFO  [18:06:08.423] [bbotk] Result of batch 21:
INFO  [18:06:08.455] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:06:08.455] [bbotk]               1.206991                         0.8904961
INFO  [18:06:08.455] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:06:08.455] [bbotk]                         0.1057072          -0.1258451               6.281305
INFO  [18:06:08.455] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:06:08.455] [bbotk]                         19                    3200                 0.9095983
INFO  [18:06:08.455] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:06:08.455] [bbotk]  0.009141694 <list[8]>              FALSE     0.03631078        0      0
INFO  [18:06:08.455] [bbotk]  runtime_learners                                uhash
INFO  [18:06:08.455] [bbotk]           114.339 ba38c2c7-8aa9-4657-8a08-09277f52cb3c
INFO  [18:06:09.853] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 52 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:06:16.439] [bbotk] Evaluating 1 configuration(s)
INFO  [18:06:16.539] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:06:16.717] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -33.27719
[1] 18.1186
[1] -43.3788
[1] 29.68549
[1] -93.67093
[1] -1.692628
[1] -40.82345
[1] 36.21207
[1] -67.87916
[1] 23.45628
INFO  [18:06:46.064] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -98.43484
[1] -3.694017
[1] -84.92217
[1] 101.1103
[1] -29.83117
[1] 30.4331
[1] -349.9787
[1] -3.933562
[1] -23.96142
[1] 90.62135
INFO  [18:07:35.425] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -9.060609
[1] 66.15349
[1] -92.94524
[1] 5.973623
[1] -31.04457
[1] 956.3134
[1] -756.8413
[1] -29.44979
[1] -1075.99
[1] -29.20397
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:08:20.558] [mlr3] Finished benchmark
INFO  [18:08:20.728] [bbotk] Result of batch 22:
INFO  [18:08:20.768] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:08:20.768] [bbotk]             -0.1271759                         0.9689319
INFO  [18:08:20.768] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:08:20.768] [bbotk]                          0.763706          -0.5657981              0.9936183
INFO  [18:08:20.768] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:08:20.768] [bbotk]                         10                    4205                 0.8825058
INFO  [18:08:20.768] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:08:20.768] [bbotk]  0.007833104 <list[8]>              FALSE      0.0312497        0      0
INFO  [18:08:20.768] [bbotk]  runtime_learners                                uhash
INFO  [18:08:20.768] [bbotk]           123.294 ce9ec968-e192-45f4-a06c-b8507ae6e7c2
INFO  [18:08:22.207] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 53 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:08:29.007] [bbotk] Evaluating 1 configuration(s)
INFO  [18:08:29.175] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:08:29.295] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -11.49498
[1] 37.60711
[1] -146.9037
[1] 7.393786
[1] 123.23
[1] 2205.999
[1] -52.86358
[1] 7.013684
[1] -403.5388
[1] -4.002877
INFO  [18:09:02.737] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -163.3448
[1] 18.55417
[1] -38.62969
[1] 75.81055
[1] -54.80086
[1] 14.47855
[1] -206.8188
[1] -3.965145
[1] -39.39685
[1] 48.78098
INFO  [18:09:39.903] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -43.37159
[1] 65.86924
[1] -90.50146
[1] 18.7897
[1] -45.21196
[1] 14.98545
[1] -123.699
[1] 65.73062
[1] -48.1448
[1] 56.93296
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:10:14.376] [mlr3] Finished benchmark
INFO  [18:10:14.694] [bbotk] Result of batch 23:
INFO  [18:10:14.823] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:10:14.823] [bbotk]              -2.291946                         0.4967645
INFO  [18:10:14.823] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:10:14.823] [bbotk]                         0.3716017           -3.733733              -3.560682
INFO  [18:10:14.823] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:10:14.823] [bbotk]                          6                    3261                 0.4854971
INFO  [18:10:14.823] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:10:14.823] [bbotk]  0.008352496 <list[8]>              FALSE     0.02454312        0      0
INFO  [18:10:14.823] [bbotk]  runtime_learners                                uhash
INFO  [18:10:14.823] [bbotk]           104.235 5de70582-9fae-48da-8843-e1ac2fadda20
INFO  [18:10:16.707] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 54 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:10:23.670] [bbotk] Evaluating 1 configuration(s)
INFO  [18:10:23.714] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:10:23.790] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -78.57457
[1] 59.19358
[1] -46.77014
[1] 30.70369
[1] -50.48524
[1] 21.17813
[1] -72.61426
[1] 36.59928
[1] -73.3993
[1] 28.86346
INFO  [18:11:03.983] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -26.7083
[1] 41.82212
[1] -2394.825
[1] -34.58811
[1] -25.08806
[1] 38.10549
[1] -98.98227
[1] -3.281773
[1] -49.57083
[1] 31.29599
INFO  [18:11:55.349] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2849.816
[1] -111.9413
[1] -1087.548
[1] 75.988
[1] -921.334
[1] 332.8147
[1] -43.79874
[1] 91.80688
[1] -63.63825
[1] 0.3957697
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:12:31.824] [mlr3] Finished benchmark
INFO  [18:12:31.931] [bbotk] Result of batch 24:
INFO  [18:12:31.964] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:12:31.964] [bbotk]             -0.3261249                         0.2635868
INFO  [18:12:31.964] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:12:31.964] [bbotk]                         0.6766722           -2.917369              -5.220719
INFO  [18:12:31.964] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:12:31.964] [bbotk]                         14                    3647                 0.3095761
INFO  [18:12:31.964] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:12:31.964] [bbotk]  0.007961343 <list[8]>              FALSE     0.02600895        0      0
INFO  [18:12:31.964] [bbotk]  runtime_learners                                uhash
INFO  [18:12:31.964] [bbotk]           127.385 7cb3525d-c61e-4a5b-b1e5-902c5e27da0d
INFO  [18:12:33.288] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 55 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:12:40.813] [bbotk] Evaluating 1 configuration(s)
INFO  [18:12:41.035] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:12:41.067] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -36.76652
[1] 36.02712
[1] -23.78022
[1] 6.923759
[1] -34.20516
[1] 19.59502
[1] -12.83017
[1] 15.59607
[1] -71.33394
[1] 9.91699
INFO  [18:12:59.708] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -19.68881
[1] 24.21286
[1] -218.2305
[1] 35.44822
[1] -13708.44
[1] -1096.555
[1] -58.04385
[1] 7.417336
[1] -24.22177
[1] 12.22384
INFO  [18:13:31.384] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -30.26075
[1] 39.30555
[1] -26.83687
[1] 55.53492
[1] -65.84735
[1] 13.00645
[1] -110.3631
[1] 23.84616
[1] -83.26406
[1] 26.68131
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:13:50.600] [mlr3] Finished benchmark
INFO  [18:13:50.824] [bbotk] Result of batch 25:
INFO  [18:13:50.860] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:13:50.860] [bbotk]              -3.043799                         0.6955367
INFO  [18:13:50.860] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:13:50.860] [bbotk]                         0.2641762          -0.1485842              -6.598926
INFO  [18:13:50.860] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:13:50.860] [bbotk]                         14                     738                 0.4923333
INFO  [18:13:50.860] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:13:50.860] [bbotk]  0.007744876 <list[8]>              FALSE     0.02890866        0      0
INFO  [18:13:50.860] [bbotk]  runtime_learners                                uhash
INFO  [18:13:50.860] [bbotk]             68.37 3a3a71a5-1d92-496b-a780-b73008e6fc78
WARN  [18:13:54.485] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:13:54.626] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 56 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:14:03.738] [bbotk] Evaluating 1 configuration(s)
INFO  [18:14:03.899] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:14:04.334] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -64.80366
[1] 34.64346
[1] -75.27702
[1] 7.100122
[1] -214.8057
[1] 29.96957
[1] -30.43836
[1] 50.05803
[1] -153.883
[1] -3.773841
INFO  [18:14:47.025] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -119.6795
[1] -3.153653
[1] -380.0805
[1] -3.82497
[1] -38.0182
[1] 40.10083
[1] -38.17453
[1] 95.57134
[1] -65.254
[1] 88.30155
INFO  [18:15:49.818] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -46.31125
[1] 19.53917
[1] -123.9578
[1] 8.978162
[1] -27.61146
[1] 47.95095
[1] 108.7164
[1] 2292.601
[1] -2365.248
[1] -40.95248
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:16:34.116] [mlr3] Finished benchmark
INFO  [18:16:34.375] [bbotk] Result of batch 26:
INFO  [18:16:34.459] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:16:34.459] [bbotk]              0.2061215                         0.1361678
INFO  [18:16:34.459] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:16:34.459] [bbotk]                         0.8717847           -4.073335              -3.007974
INFO  [18:16:34.459] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:16:34.459] [bbotk]                          5                    4137                 0.7942435
INFO  [18:16:34.459] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:16:34.459] [bbotk]  0.007310129 <list[8]>              FALSE     0.02895468        0      0
INFO  [18:16:34.459] [bbotk]  runtime_learners                                uhash
INFO  [18:16:34.459] [bbotk]           147.764 e0c3398d-6e7f-4743-b950-fcb068da9fad
INFO  [18:16:38.323] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 57 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:16:45.783] [bbotk] Evaluating 1 configuration(s)
INFO  [18:16:46.041] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:16:46.340] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -64.44145
[1] 18.1613
[1] -1622.036
[1] -66.39652
[1] -20.47063
[1] 21.36827
[1] -9587.101
[1] -178.0516
[1] -31.49779
[1] 69.98606
INFO  [18:17:22.627] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -4544.575
[1] -196.59
[1] -12.09074
[1] 44.84168
[1] -35.26463
[1] 8.100504
[1] -1692.826
[1] -33.96383
[1] -630.9728
[1] -3.614952
INFO  [18:18:24.510] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -36.21997
[1] 132.2489
[1] -25.31068
[1] 61.37182
[1] -55.23744
[1] 22.8299
[1] -3820.418
[1] -170.5366
[1] -365.2978
[1] 11.89552
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:19:12.299] [mlr3] Finished benchmark
INFO  [18:19:12.827] [bbotk] Result of batch 27:
INFO  [18:19:13.028] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:19:13.028] [bbotk]              -5.545198                         0.5328019
INFO  [18:19:13.028] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:19:13.028] [bbotk]                         0.9233637           -4.719287              -1.111948
INFO  [18:19:13.028] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:19:13.028] [bbotk]                          7                    2810                 0.7329749
INFO  [18:19:13.028] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:19:13.028] [bbotk]  0.008934039 <list[8]>              FALSE      0.0274347        0      0
INFO  [18:19:13.028] [bbotk]  runtime_learners                                uhash
INFO  [18:19:13.028] [bbotk]           143.641 c74af9ff-ee4f-4b7a-9075-c45b54968cf2
INFO  [18:19:16.642] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 58 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:19:27.675] [bbotk] Evaluating 1 configuration(s)
INFO  [18:19:27.878] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:19:28.022] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -21.52233
[1] 37.58355
[1] -56.31417
[1] 35.03814
[1] -33631.41
[1] -777.3091
[1] -178.9005
[1] -3.963405
[1] -21.128
[1] 63.69233
INFO  [18:19:42.073] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -33.36699
[1] 35.36024
[1] -155.4934
[1] -3.2341
[1] -5833.852
[1] -122.9862
[1] -42.01457
[1] 17.30705
[1] -7.848621
[1] 128.9401
INFO  [18:19:56.482] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -96.93011
[1] 4.826013
[1] -49.02989
[1] 61.99952
[1] -91.53581
[1] 203.2275
[1] -172.28
[1] 31.26619
[1] 54.17036
[1] 2207.366
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:20:10.475] [mlr3] Finished benchmark
INFO  [18:20:10.556] [bbotk] Result of batch 28:
INFO  [18:20:10.588] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:20:10.588] [bbotk]               -6.44618                         0.2773492
INFO  [18:20:10.588] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:20:10.588] [bbotk]                         0.3652349           -1.887278               2.474282
INFO  [18:20:10.588] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:20:10.588] [bbotk]                         19                    2977                 0.3210775
INFO  [18:20:10.588] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:20:10.588] [bbotk]  0.007495303 <list[8]>              FALSE     0.02781208        0      0
INFO  [18:20:10.588] [bbotk]  runtime_learners                                uhash
INFO  [18:20:10.588] [bbotk]            41.149 0431651a-707a-4a0e-afe4-7c15987f8135
WARN  [18:20:12.963] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:20:13.011] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 59 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:20:17.212] [bbotk] Evaluating 1 configuration(s)
INFO  [18:20:17.327] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:20:17.631] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -68.24054
[1] 8.202165
[1] -59.0777
[1] 20.8654
[1] -14.2039
[1] 28.07399
[1] -25.28344
[1] 15.27429
[1] -11.79151
[1] 61.14304
INFO  [18:20:46.746] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -924.1877
[1] -3.448771
[1] -11.30474
[1] 39.09195
[1] 192.4617
[1] 6507.034
[1] -33.1425
[1] 3.93317
[1] -9.964393
[1] 52.08269
INFO  [18:21:26.148] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -27.63401
[1] 28.98902
[1] -32.52697
[1] 20.18899
[1] -100.1497
[1] 23.40264
[1] -40.38733
[1] 46.56393
[1] -1835.811
[1] -75.8489
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:21:56.748] [mlr3] Finished benchmark
INFO  [18:21:56.984] [bbotk] Result of batch 29:
INFO  [18:21:57.104] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:21:57.104] [bbotk]              -3.605576                         0.2373518
INFO  [18:21:57.104] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:21:57.104] [bbotk]                         0.6150674        -0.001961099              -6.020689
INFO  [18:21:57.104] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:21:57.104] [bbotk]                         19                    3829                 0.8297628
INFO  [18:21:57.104] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:21:57.104] [bbotk]  0.006790167 <list[8]>              FALSE     0.03703561        0      0
INFO  [18:21:57.104] [bbotk]  runtime_learners                                uhash
INFO  [18:21:57.104] [bbotk]            97.941 034f3c5f-461a-47af-b4f5-1f9b3e980493
WARN  [18:21:58.405] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:21:58.567] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 60 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:22:05.986] [bbotk] Evaluating 1 configuration(s)
INFO  [18:22:06.158] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:22:06.273] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -6519.802
[1] -102.0604
[1] -74.41626
[1] -4.110706
[1] -35.07658
[1] 10.29061
[1] -26.00642
[1] 29.81658
[1] -19.28854
[1] 26.44249
INFO  [18:22:25.230] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -89.21495
[1] -3.10938
[1] -20.88882
[1] 21.98166
[1] -25.91056
[1] 165.0943
[1] -70.04286
[1] 34.02834
[1] -39.92395
[1] 24.62528
INFO  [18:22:45.246] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2403.799
[1] -74.26032
[1] -83.21117
[1] 13.62062
[1] -42.62525
[1] 18.71069
[1] -290.1171
[1] 26.80584
[1] -27.14025
[1] 60.66348
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:23:05.775] [mlr3] Finished benchmark
INFO  [18:23:05.939] [bbotk] Result of batch 30:
INFO  [18:23:06.129] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:23:06.129] [bbotk]              -3.494304                          0.722574
INFO  [18:23:06.129] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:23:06.129] [bbotk]                         0.9533003          -0.6499697             -0.2311833
INFO  [18:23:06.129] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:23:06.129] [bbotk]                         10                    1067                 0.4042717
INFO  [18:23:06.129] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:23:06.129] [bbotk]  0.007021981 <list[8]>              FALSE     0.02815958        0      0
INFO  [18:23:06.129] [bbotk]  runtime_learners                                uhash
INFO  [18:23:06.129] [bbotk]            58.862 97b52f2d-35dc-4191-98ed-8da90cd8d746
INFO  [18:23:08.975] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 61 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:23:18.974] [bbotk] Evaluating 1 configuration(s)
INFO  [18:23:19.176] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:23:19.257] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -90.95219
[1] 25.43789
[1] -30.59099
[1] 66.76641
[1] -26.82077
[1] 20.0167
[1] -35.21837
[1] 24.71487
[1] -47.09791
[1] 8.94186
INFO  [18:23:36.085] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -42.27886
[1] 17.66858
[1] 37.75673
[1] 1405.91
[1] -11.84839
[1] 69.61928
[1] -23.78179
[1] 25.28903
[1] -76.80438
[1] 5.304791
INFO  [18:23:58.791] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -683.7604
[1] -24.58214
[1] -77.75388
[1] 16.05178
[1] -23.72866
[1] 123.7013
[1] -60.58591
[1] 68.95594
[1] -314.918
[1] 13.74846
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:24:22.482] [mlr3] Finished benchmark
INFO  [18:24:23.223] [bbotk] Result of batch 31:
INFO  [18:24:23.404] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:24:23.404] [bbotk]              -1.242798                         0.8153093
INFO  [18:24:23.404] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:24:23.404] [bbotk]                         0.8408624          -0.9862877              -2.712616
INFO  [18:24:23.404] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:24:23.404] [bbotk]                          8                     577                 0.4636657
INFO  [18:24:23.404] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:24:23.404] [bbotk]  0.006239725 <list[8]>              FALSE     0.02850149        0      0
INFO  [18:24:23.404] [bbotk]  runtime_learners                                uhash
INFO  [18:24:23.404] [bbotk]            62.262 ad4173fb-524e-4cfc-b899-3537f31947bc
INFO  [18:24:30.385] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 62 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:24:45.344] [bbotk] Evaluating 1 configuration(s)
INFO  [18:24:45.439] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:24:45.490] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -76.15714
[1] 47.85206
[1] -172.4028
[1] 4.07113
[1] -50.7636
[1] 90.77299
[1] -42.73503
[1] 21.58373
[1] -162.8669
[1] 24.48651
INFO  [18:25:00.632] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -59.73712
[1] 45.69058
[1] -69.76891
[1] -3.565208
[1] -91.56507
[1] -1.399423
[1] -47.52943
[1] 112.6273
[1] -48.68467
[1] 15.48341
INFO  [18:25:15.001] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -84.79658
[1] 0.5949107
[1] 143.2299
[1] 2827.205
[1] -41.38533
[1] 15.18279
[1] 269.3902
[1] 4061.865
[1] -124.7336
[1] 52.48438
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:25:33.035] [mlr3] Finished benchmark
INFO  [18:25:33.335] [bbotk] Result of batch 32:
INFO  [18:25:33.479] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:25:33.479] [bbotk]              -6.548987                          0.562971
INFO  [18:25:33.479] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:25:33.479] [bbotk]                         0.5481327           -1.565519               2.050749
INFO  [18:25:33.479] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:25:33.479] [bbotk]                         13                     356                 0.8260225
INFO  [18:25:33.479] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:25:33.479] [bbotk]  0.005921528 <list[8]>              FALSE      0.0278687        0      0
INFO  [18:25:33.479] [bbotk]  runtime_learners                                uhash
INFO  [18:25:33.479] [bbotk]            46.535 42ab5954-099c-48c1-9da7-05c53345b87d
INFO  [18:25:35.225] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 63 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:25:43.250] [bbotk] Evaluating 1 configuration(s)
INFO  [18:25:43.451] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:25:43.691] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -16.11068
[1] 30.10763
[1] -66.70453
[1] 15.56662
[1] -30.06989
[1] 29.76876
[1] -68.28721
[1] 4.685371
[1] -20.64598
[1] 24.43801
INFO  [18:26:15.719] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -0.6120809
[1] 56.02166
[1] -92.41248
[1] 4.541535
[1] -28.47372
[1] 70.0038
[1] -120.8591
[1] 35.39298
[1] -171.3683
[1] 15.94595
INFO  [18:26:49.365] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -168.4084
[1] 3.728065
[1] -47.11415
[1] 72.97319
[1] -54.47332
[1] 21.60326
[1] 1.128715
[1] 75.51141
[1] -96.16362
[1] 12.59919
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:27:43.336] [mlr3] Finished benchmark
INFO  [18:27:43.595] [bbotk] Result of batch 33:
INFO  [18:27:43.695] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:27:43.695] [bbotk]             -0.8891583                         0.1107645
INFO  [18:27:43.695] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:27:43.695] [bbotk]                         0.5470983          -0.0312736              0.2859286
INFO  [18:27:43.695] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:27:43.695] [bbotk]                         13                    3412                 0.6327948
INFO  [18:27:43.695] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:27:43.695] [bbotk]  0.006324111 <list[8]>              FALSE     0.02521549        0      0
INFO  [18:27:43.695] [bbotk]  runtime_learners                                uhash
INFO  [18:27:43.695] [bbotk]           119.116 c9f24688-e2cc-4590-bcad-7a804c1cac8b
INFO  [18:27:46.822] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 64 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:27:53.511] [bbotk] Evaluating 1 configuration(s)
INFO  [18:27:53.603] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:27:53.688] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -33.63211
[1] 91.14959
[1] -74.02166
[1] 17.61245
[1] -49.13897
[1] 27.37733
[1] -47.57961
[1] 24.85055
[1] -22.54469
[1] 21.81859
INFO  [18:28:25.704] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -33.99552
[1] 22.56828
[1] -57.45564
[1] 22.04289
[1] 41.22751
[1] 1408.776
[1] -32.56812
[1] 117.7128
[1] -149.036
[1] -3.122611
INFO  [18:29:08.442] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -18.93476
[1] 65.16814
[1] -32.01127
[1] 18.16351
[1] -887.4671
[1] -26.98351
[1] -1.904457e+16
[1] 3.092411e+16
[1] -80.21599
[1] 462.986
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:29:41.381] [mlr3] Finished benchmark
INFO  [18:29:41.676] [bbotk] Result of batch 34:
INFO  [18:29:41.773] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:29:41.773] [bbotk]              -6.797193                         0.8431152
INFO  [18:29:41.773] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:29:41.773] [bbotk]                         0.3943206           -2.416249               1.139157
INFO  [18:29:41.773] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:29:41.773] [bbotk]                         19                    3528                 0.4613647
INFO  [18:29:41.773] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:29:41.773] [bbotk]  0.006481524 <list[8]>              FALSE     0.02434283        0      0
INFO  [18:29:41.773] [bbotk]  runtime_learners                                uhash
INFO  [18:29:41.773] [bbotk]           106.833 ad20e926-de4e-4c49-b587-5f9c2899352f
WARN  [18:29:43.801] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:29:44.007] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 65 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:29:53.842] [bbotk] Evaluating 1 configuration(s)
INFO  [18:29:54.324] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:29:54.733] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -301.2962
[1] 13.28495
[1] -68.62439
[1] 67.31117
[1] -40.81088
[1] 155.1553
[1] -51.39091
[1] 155.221
[1] -688.3667
[1] -12.04994
INFO  [18:30:12.962] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -74.24633
[1] 88.56868
[1] -94695.98
[1] -1577.51
[1] -269.9318
[1] 12.64
[1] -133.3345
[1] 88.74522
[1] -302.9954
[1] -4.832556
INFO  [18:30:33.544] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -143.1918
[1] 71.05443
[1] -36.84536
[1] 174.1009
[1] -142.4194
[1] 91.91001
[1] -3778.553
[1] -71.43549
[1] -61.3888
[1] 263.0724
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:30:59.050] [mlr3] Finished benchmark
INFO  [18:31:00.311] [bbotk] Result of batch 35:
INFO  [18:31:00.369] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:31:00.369] [bbotk]              0.3609386                         0.9227003
INFO  [18:31:00.369] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:31:00.369] [bbotk]                         0.1476799         -0.09655446               6.719255
INFO  [18:31:00.369] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:31:00.369] [bbotk]                          6                     298                 0.2604113
INFO  [18:31:00.369] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:31:00.369] [bbotk]  0.006006025 <list[8]>              FALSE     0.06043959        0      0
INFO  [18:31:00.369] [bbotk]  runtime_learners                                uhash
INFO  [18:31:00.369] [bbotk]            63.206 df76c3b1-3caa-4510-85f4-456b4e1099fc
INFO  [18:31:05.501] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 66 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:31:12.988] [bbotk] Evaluating 1 configuration(s)
INFO  [18:31:13.037] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:31:13.110] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -197.3923
[1] -3.828629
[1] 426.5815
[1] 9307.582
[1] -62.57686
[1] 495.3277
[1] -92.15878
[1] 55.45556
[1] -41.45322
[1] 12.29628
INFO  [18:32:12.477] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -49.70846
[1] 202.6437
[1] -1314.782
[1] -48.50035
[1] -92.96171
[1] 81.64419
[1] -102.5404
[1] 27.19179
[1] -75.2892
[1] 0.5145054
INFO  [18:33:06.380] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -26.41175
[1] 71.7154
[1] -24.167
[1] 78.05864
[1] -25.33574
[1] 63.08372
[1] -49.76324
[1] 13.84095
[1] -44.09282
[1] 22.83568
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:33:54.664] [mlr3] Finished benchmark
INFO  [18:33:54.778] [bbotk] Result of batch 36:
INFO  [18:33:54.795] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:33:54.795] [bbotk]             0.02671614                         0.5112544
INFO  [18:33:54.795] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:33:54.795] [bbotk]                         0.4964079           -3.870956              -0.501248
INFO  [18:33:54.795] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:33:54.795] [bbotk]                         15                    4078                 0.9173742
INFO  [18:33:54.795] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:33:54.795] [bbotk]  0.006701944 <list[8]>              FALSE     0.02952822        0      0
INFO  [18:33:54.795] [bbotk]  runtime_learners                                uhash
INFO  [18:33:54.795] [bbotk]           161.111 6826f8ad-c260-4713-9d33-5cdb74e0d9d0
WARN  [18:33:57.720] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:33:57.778] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 67 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:34:02.093] [bbotk] Evaluating 1 configuration(s)
INFO  [18:34:02.176] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:34:02.261] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -78.6133
[1] 138.6064
[1] -101.1439
[1] 10.13085
[1] -29.06274
[1] 11.97561
[1] -50.39402
[1] 28.34271
[1] -18.21534
[1] 30.53771
INFO  [18:34:36.653] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -55.49835
[1] 15.48357
[1] -38.59547
[1] 49.9496
[1] -81.48152
[1] 6.171397
[1] -35.3458
[1] 25.16038
[1] -43.41674
[1] 80.79456
INFO  [18:35:19.963] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 670.5703
[1] 17922.21
[1] -53.6531
[1] 13.77294
[1] -18.82657
[1] 93.95009
[1] -44.21271
[1] 214.432
[1] -101.2118
[1] -4.052903
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:36:19.231] [mlr3] Finished benchmark
INFO  [18:36:19.338] [bbotk] Result of batch 37:
INFO  [18:36:19.440] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:36:19.440] [bbotk]             0.08823443                         0.4053592
INFO  [18:36:19.440] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:36:19.440] [bbotk]                         0.7660341          -0.3880737             -0.4860397
INFO  [18:36:19.440] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:36:19.440] [bbotk]                         18                    4831                 0.3273381
INFO  [18:36:19.440] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:36:19.440] [bbotk]  0.00650051 <list[8]>              FALSE     0.02442762        0      0
INFO  [18:36:19.440] [bbotk]  runtime_learners                                uhash
INFO  [18:36:19.440] [bbotk]           136.236 7290a32e-7253-414a-999a-7e47e0e47f2e
INFO  [18:36:22.133] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 68 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:36:28.726] [bbotk] Evaluating 1 configuration(s)
INFO  [18:36:28.917] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:36:29.150] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -115.4536
[1] 11.98972
[1] -120.7417
[1] 23.88488
[1] -125.877
[1] -1.540985
[1] -62.56039
[1] 21.351
[1] -75.91052
[1] 39.30486
INFO  [18:37:03.222] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -33.83997
[1] 128.3425
[1] 42.17448
[1] 1181.119
[1] -525.4159
[1] 18.69146
[1] -238.4042
[1] 32.96924
[1] -47.52249
[1] 6.770387
INFO  [18:37:32.047] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -330.7062
[1] 30.10869
[1] -1134.764
[1] -34.09707
[1] -59.56677
[1] 23.21445
[1] -62.88858
[1] 21.49499
[1] -129.8359
[1] -1.523525
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:37:50.698] [mlr3] Finished benchmark
INFO  [18:37:50.810] [bbotk] Result of batch 38:
INFO  [18:37:50.893] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:37:50.893] [bbotk]              0.2807358                         0.3917747
INFO  [18:37:50.893] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:37:50.893] [bbotk]                         0.6691324          -0.6123442               1.454356
INFO  [18:37:50.893] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:37:50.893] [bbotk]                         19                    1489                 0.3349974
INFO  [18:37:50.893] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:37:50.893] [bbotk]  0.00587162 <list[8]>              FALSE     0.02834191        0      0
INFO  [18:37:50.893] [bbotk]  runtime_learners                                uhash
INFO  [18:37:50.893] [bbotk]            80.237 b1cc8b88-56a0-4b93-adef-03abc89d8c9f
INFO  [18:37:52.017] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 69 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:37:58.812] [bbotk] Evaluating 1 configuration(s)
INFO  [18:37:58.896] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:37:59.024] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -51.59704
[1] 28.48679
[1] -268.0362
[1] -3.146884
[1] -52.38122
[1] 35.97074
[1] -127.8969
[1] 44.71462
[1] -26.14954
[1] 61.89932
INFO  [18:38:51.736] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -21.17788
[1] 53.10114
[1] -91.45968
[1] 2.088543
[1] -19.37616
[1] 150.5561
[1] -61.52172
[1] 57.69069
[1] -41.28045
[1] 51.27396
INFO  [18:39:43.383] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -120.6209
[1] 6.518118
[1] -4479.145
[1] -186.4459
[1] -90.69206
[1] 6.295762
[1] 10.03126
[1] 261.5136
[1] -4962.981
[1] -66.92248
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:40:31.735] [mlr3] Finished benchmark
INFO  [18:40:32.068] [bbotk] Result of batch 39:
INFO  [18:40:32.247] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:40:32.247] [bbotk]              -3.976628                         0.8863727
INFO  [18:40:32.247] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:40:32.247] [bbotk]                         0.7019606           -4.642637              -2.623121
INFO  [18:40:32.247] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:40:32.247] [bbotk]                          1                    3771                 0.2293151
INFO  [18:40:32.247] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:40:32.247] [bbotk]  0.00609118 <list[8]>              FALSE     0.02961866        0      0
INFO  [18:40:32.247] [bbotk]  runtime_learners                                uhash
INFO  [18:40:32.247] [bbotk]           151.352 b2caef2e-34d9-4488-a2ab-b98245bc76a5
WARN  [18:40:34.654] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:40:34.720] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 70 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:40:44.306] [bbotk] Evaluating 1 configuration(s)
INFO  [18:40:44.586] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:40:44.681] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] 45.72249
[1] 1170.113
[1] -60.61018
[1] -3.038676
[1] -32.7702
[1] 27.37318
[1] -2.939041e+16
[1] 5.301785e+15
[1] -30.56845
[1] 22.3528
INFO  [18:41:27.569] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -31.32792
[1] 104.7608
[1] -24.63563
[1] 108.6738
[1] -6.116343
[1] 304.9298
[1] -141.2308
[1] 23.47251
[1] -66.05452
[1] 11.4841
INFO  [18:42:23.796] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -5586.459
[1] -215.2695
[1] -29.30868
[1] 66.33525
[1] -208.0381
[1] 28.50248
[1] -2874.416
[1] -108.546
[1] -68.77976
[1] 33.60614
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:43:11.679] [mlr3] Finished benchmark
INFO  [18:43:12.197] [bbotk] Result of batch 40:
INFO  [18:43:12.321] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:43:12.321] [bbotk]             -0.6944603                         0.5285815
INFO  [18:43:12.321] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:43:12.321] [bbotk]                         0.3411811           -1.337535              0.1367955
INFO  [18:43:12.321] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:43:12.321] [bbotk]                         10                    4835                 0.4856745
INFO  [18:43:12.321] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:43:12.321] [bbotk]  0.005284691 <list[8]>              FALSE     0.02580549        0      0
INFO  [18:43:12.321] [bbotk]  runtime_learners                                uhash
INFO  [18:43:12.321] [bbotk]           145.693 87261870-2853-4cb4-9f5f-22951eef9a1e
INFO  [18:43:15.371] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 71 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:43:22.674] [bbotk] Evaluating 1 configuration(s)
INFO  [18:43:22.992] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:43:23.153] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -60.49999
[1] 63.02815
[1] -124.0431
[1] 59.7455
[1] -77.79851
[1] 14.12019
[1] -238.4988
[1] 28.08475
[1] -19.18114
[1] 85.92204
INFO  [18:43:47.716] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -62.33022
[1] 51.7459
[1] -188.0147
[1] 142.6615
[1] -60.9006
[1] 48.93173
[1] -62.51751
[1] 70.94183
[1] -293.8572
[1] -4.438364
INFO  [18:44:09.611] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -65.90818
[1] 80.99988
[1] 43.01992
[1] 1591.132
[1] -294.1984
[1] 159.6067
[1] -59.97936
[1] 49.58748
[1] -45.46653
[1] 67.59931
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:44:37.722] [mlr3] Finished benchmark
INFO  [18:44:37.937] [bbotk] Result of batch 41:
INFO  [18:44:38.011] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:44:38.011] [bbotk]               -5.06663                         0.5313812
INFO  [18:44:38.011] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:44:38.011] [bbotk]                          0.259588            -5.58382               -6.49519
INFO  [18:44:38.011] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:44:38.011] [bbotk]                          1                    1225                 0.5767947
INFO  [18:44:38.011] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:44:38.011] [bbotk]  0.005475021 <list[8]>              FALSE      0.0404112        0      0
INFO  [18:44:38.011] [bbotk]  runtime_learners                                uhash
INFO  [18:44:38.011] [bbotk]             74.01 59aab54a-0995-4671-81a9-e4c49fbd0ecd
INFO  [18:44:41.691] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 72 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:44:48.714] [bbotk] Evaluating 1 configuration(s)
INFO  [18:44:48.886] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:44:48.950] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -59.50402
[1] 9.648233
[1] -147.5465
[1] 37.57521
[1] -3586.199
[1] -86.33314
[1] -46.36297
[1] 20.60391
[1] -17.36095
[1] 75.63212
INFO  [18:45:23.904] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -40.55769
[1] 88.35097
[1] -28.40877
[1] 74.65336
[1] -123.046
[1] 16.38665
[1] -245.2936
[1] -3.970849
[1] -131.7753
[1] 13.25743
INFO  [18:46:08.566] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -4639.089
[1] -200.3491
[1] -96.11451
[1] 25.11014
[1] 34.91185
[1] 873.9178
[1] -90.81727
[1] -3.342743
[1] -527.5667
[1] -10.99333
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:46:46.448] [mlr3] Finished benchmark
INFO  [18:46:47.283] [bbotk] Result of batch 42:
INFO  [18:46:47.310] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:46:47.310] [bbotk]              -6.408476                         0.6420517
INFO  [18:46:47.310] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:46:47.310] [bbotk]                         0.5340204           -3.357461              0.1466739
INFO  [18:46:47.310] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:46:47.310] [bbotk]                         16                    3382                 0.7221467
INFO  [18:46:47.310] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:46:47.310] [bbotk]  0.005124688 <list[8]>              FALSE     0.02688038        0      0
INFO  [18:46:47.310] [bbotk]  runtime_learners                                uhash
INFO  [18:46:47.310] [bbotk]           114.327 6d89ac41-4b6e-4810-82ef-dab82db56907
INFO  [18:46:48.498] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 73 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:46:57.007] [bbotk] Evaluating 1 configuration(s)
INFO  [18:46:57.140] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:46:57.381] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -2982.135
[1] -158.1728
[1] -23.86958
[1] 51.75834
[1] -55.17596
[1] 18.18643
[1] -124.9827
[1] 1.864856
[1] -27.62126
[1] 66.85516
INFO  [18:47:49.781] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -61.58089
[1] 21.17227
[1] -1520.851
[1] 84.82081
[1] -71.29072
[1] 1.334131
[1] -75.33876
[1] 13.02489
[1] 755.1443
[1] 19652.66
INFO  [18:48:28.231] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -27.90782
[1] 76.50158
[1] -32.15895
[1] 47.09641
[1] -33.17213
[1] 30.30792
[1] -519.6492
[1] 6.502777
[1] 60.25935
[1] 995.6772
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:49:04.673] [mlr3] Finished benchmark
INFO  [18:49:05.370] [bbotk] Result of batch 43:
INFO  [18:49:05.476] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:49:05.476] [bbotk]              -3.392537                         0.8649593
INFO  [18:49:05.476] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:49:05.476] [bbotk]                         0.2300361           -4.929736              -2.347631
INFO  [18:49:05.476] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:49:05.476] [bbotk]                          4                    4039                 0.9201439
INFO  [18:49:05.476] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:49:05.476] [bbotk]  0.005527892 <list[8]>              FALSE     0.02826403        0      0
INFO  [18:49:05.476] [bbotk]  runtime_learners                                uhash
INFO  [18:49:05.476] [bbotk]           126.057 371f6146-530c-4c0e-8223-63c43ec34bcf
INFO  [18:49:13.393] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 74 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:49:31.839] [bbotk] Evaluating 1 configuration(s)
INFO  [18:49:32.022] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:49:32.240] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -178.2424
[1] 10.39159
[1] -81.68024
[1] 51.87134
[1] -116.4238
[1] 105.5746
[1] -69.87967
[1] 55.60487
[1] -38.2977
[1] 62.67937
INFO  [18:49:45.283] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -278.2133
[1] -4.276944
[1] -33.83294
[1] 77.36082
[1] -77.77465
[1] 34.19961
[1] -296.68
[1] 46.73477
[1] -63.61539
[1] 46.42403
INFO  [18:50:03.592] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -74.67908
[1] 78.27692
[1] -169.822
[1] 0.07224589
[1] -7.776622
[1] 160.2091
[1] -45.27675
[1] 251.052
[1] -469.0186
[1] 45.98333
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:50:17.197] [mlr3] Finished benchmark
INFO  [18:50:17.503] [bbotk] Result of batch 44:
INFO  [18:50:17.525] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:50:17.525] [bbotk]              -6.622413                          0.483453
INFO  [18:50:17.525] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:50:17.525] [bbotk]                          0.791893           -2.786908              0.9660782
INFO  [18:50:17.525] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:50:17.525] [bbotk]                         20                     103                 0.1066078
INFO  [18:50:17.525] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:50:17.525] [bbotk]  0.005090692 <list[8]>              FALSE     0.04385126        0      0
INFO  [18:50:17.525] [bbotk]  runtime_learners                                uhash
INFO  [18:50:17.525] [bbotk]            44.679 75007e92-553f-4d87-9083-dc8a5de33b7b
INFO  [18:50:21.406] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 75 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:50:31.838] [bbotk] Evaluating 1 configuration(s)
INFO  [18:50:31.999] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:50:32.155] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -181.1539
[1] 94.4674
[1] -30.30819
[1] 67.21587
[1] -58.29979
[1] 30.20612
[1] -46.28218
[1] 70.52221
[1] -40.35697
[1] 25.62854
INFO  [18:50:58.755] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -58.97003
[1] 43.98177
[1] -84.90203
[1] 38.31118
[1] -175.057
[1] -3.872651
[1] -84.7858
[1] 12.32664
[1] -44.37489
[1] 105.3819
INFO  [18:51:26.886] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -30.36056
[1] 32.08314
[1] -50.61577
[1] 96.94808
[1] -310.0065
[1] -3.974711
[1] 114.8372
[1] 3344.615
[1] 34.24379
[1] 1115.711
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:52:10.721] [mlr3] Finished benchmark
INFO  [18:52:10.873] [bbotk] Result of batch 45:
INFO  [18:52:10.960] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:52:10.960] [bbotk]              -0.227855                         0.9432488
INFO  [18:52:10.960] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:52:10.960] [bbotk]                         0.1494516           -4.429843             -0.8454649
INFO  [18:52:10.960] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:52:10.960] [bbotk]                          7                    1721                 0.9142936
INFO  [18:52:10.960] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:52:10.960] [bbotk]  0.005346342 <list[8]>              FALSE     0.02876781        0      0
INFO  [18:52:10.960] [bbotk]  runtime_learners                                uhash
INFO  [18:52:10.960] [bbotk]            97.679 ab0cf791-036e-44f8-a05a-612a05e0a411
INFO  [18:52:17.618] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 76 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:52:25.216] [bbotk] Evaluating 1 configuration(s)
INFO  [18:52:25.514] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:52:25.786] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -19.72818
[1] 63.9978
[1] -28.36931
[1] 117.1279
[1] -42.47918
[1] 44.78487
[1] -54.82694
[1] 10.67517
[1] -16.34384
[1] 26.29386
INFO  [18:52:58.227] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -19.22472
[1] 11.68177
[1] -575.4149
[1] -28.55915
[1] -27.32192
[1] 29.19571
[1] -248.9888
[1] 6.870386
[1] -123.9769
[1] 147.1628
INFO  [18:53:30.874] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -32.05255
[1] 16.71817
[1] -37.98809
[1] 109.7092
[1] -55.21571
[1] 70.60481
[1] -3123.08
[1] -75.75119
[1] 28.33495
[1] 756.1176
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:53:56.944] [mlr3] Finished benchmark
INFO  [18:53:57.007] [bbotk] Result of batch 46:
INFO  [18:53:57.015] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:53:57.015] [bbotk]              -4.637178                         0.9900566
INFO  [18:53:57.015] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:53:57.015] [bbotk]                         0.4017257           -1.222429               1.168842
INFO  [18:53:57.015] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:53:57.015] [bbotk]                         15                    1938                  0.802461
INFO  [18:53:57.015] [bbotk]    acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:53:57.015] [bbotk]  0.005481 <list[8]>              FALSE     0.02823671        0      0
INFO  [18:53:57.015] [bbotk]  runtime_learners                                uhash
INFO  [18:53:57.015] [bbotk]            90.572 3c2d62de-4251-45c0-8457-f6103a710d0b
INFO  [18:54:02.036] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 77 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:54:13.422] [bbotk] Evaluating 1 configuration(s)
INFO  [18:54:13.524] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:54:13.577] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -20.02534
[1] 24.60679
[1] -50.4803
[1] 7.299696
[1] -17263.09
[1] -356.9386
[1] -62.04955
[1] 25.41204
[1] -39.71994
[1] 36.99143
INFO  [18:55:21.170] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -3873.581
[1] -118.5375
[1] -58.49005
[1] -3.684637
[1] -30.13059
[1] 26.30259
[1] -2118.14
[1] -35.56955
[1] -46.93332
[1] 27.62833
INFO  [18:56:33.206] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -1442.124
[1] -32.19692
[1] -75.03803
[1] 19.39382
[1] -45.76344
[1] 7.758085
[1] -572.599
[1] 24.47291
[1] -38.1822
[1] 719.2632
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [18:57:51.360] [mlr3] Finished benchmark
INFO  [18:57:51.749] [bbotk] Result of batch 47:
INFO  [18:57:51.759] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [18:57:51.759] [bbotk]               -6.45647                         0.8065288
INFO  [18:57:51.759] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [18:57:51.759] [bbotk]                          0.992901           -1.116326               2.388306
INFO  [18:57:51.759] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [18:57:51.759] [bbotk]                         10                    4918                 0.7197439
INFO  [18:57:51.759] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [18:57:51.759] [bbotk]  0.005299507 <list[8]>              FALSE     0.03021747        0      0
INFO  [18:57:51.759] [bbotk]  runtime_learners                                uhash
INFO  [18:57:51.759] [bbotk]           217.552 3a7cf1a9-caa9-4435-8467-18b68d473745
WARN  [18:57:57.836] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [18:57:57.841] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 78 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [18:58:14.799] [bbotk] Evaluating 1 configuration(s)
INFO  [18:58:14.829] [mlr3] Running benchmark with 3 resampling iterations
INFO  [18:58:14.843] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -34.24261
[1] 33.69045
[1] -151.9235
[1] 10.64335
[1] -112.5393
[1] 18.31529
[1] -34.11226
[1] 14.11352
[1] -186.4135
[1] -4.011441
INFO  [18:59:03.053] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -12.07225
[1] 122.84
[1] -2382.922
[1] -45.19932
[1] -123.8545
[1] -3.556027
[1] -412.9988
[1] 22.19473
[1] -53.02608
[1] 13.15047
INFO  [18:59:55.692] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -74.52576
[1] 12.45552
[1] -80.2388
[1] 18.33367
[1] -53.07906
[1] 13.83334
[1] -39.91321
[1] 65.04027
[1] -101.939
[1] 43.41824
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:00:50.470] [mlr3] Finished benchmark
INFO  [19:00:51.291] [bbotk] Result of batch 48:
INFO  [19:00:51.316] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:00:51.316] [bbotk]              -1.044956                         0.5462602
INFO  [19:00:51.316] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:00:51.316] [bbotk]                         0.8269736           -0.865112              0.6606568
INFO  [19:00:51.316] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:00:51.316] [bbotk]                         13                    3402                  0.476058
INFO  [19:00:51.316] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:00:51.316] [bbotk]  0.005485994 <list[8]>              FALSE      0.0273551        0      0
INFO  [19:00:51.316] [bbotk]  runtime_learners                                uhash
INFO  [19:00:51.316] [bbotk]           155.139 6302594c-06da-4c21-8f56-a47e57f8ccf4
WARN  [19:00:56.598] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:00:56.633] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 79 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:01:15.655] [bbotk] Evaluating 1 configuration(s)
INFO  [19:01:15.741] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:01:15.878] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -33.04018
[1] 20.88058
[1] -75.64649
[1] -0.345093
[1] -27.68327
[1] 84.94988
[1] -30.27804
[1] 44.10496
[1] -9.753558
[1] 50.54777
INFO  [19:01:43.546] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -10958.01
[1] -345.3324
[1] -76.93913
[1] 12.37388
[1] -71.83286
[1] 18.99919
[1] -121.8566
[1] -3.30241
[1] -11.43447
[1] 50.67074
INFO  [19:02:08.043] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -89.03081
[1] 13.34935
[1] -34800.31
[1] -1243.217
[1] -22.81462
[1] 32.01257
[1] -6430.216
[1] -134.7665
[1] -37.46243
[1] 47.74303
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:02:42.786] [mlr3] Finished benchmark
INFO  [19:02:43.704] [bbotk] Result of batch 49:
INFO  [19:02:43.822] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:02:43.822] [bbotk]              -3.876197                         0.9199926
INFO  [19:02:43.822] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:02:43.822] [bbotk]                         0.9459019           -1.736128              -4.231018
INFO  [19:02:43.822] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:02:43.822] [bbotk]                         15                     757                 0.6904741
INFO  [19:02:43.822] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:02:43.822] [bbotk]  0.005556981 <list[8]>              FALSE     0.03023531        0      0
INFO  [19:02:43.822] [bbotk]  runtime_learners                                uhash
INFO  [19:02:43.822] [bbotk]            86.402 d970289a-1bd6-492e-8c4d-ef08130fe3a6
INFO  [19:02:46.882] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 80 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:03:02.281] [bbotk] Evaluating 1 configuration(s)
INFO  [19:03:02.344] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:03:02.523] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -40.86191
[1] 18.4419
[1] -21.63808
[1] 88.64217
[1] -45.59662
[1] 9.053186
[1] -25.96578
[1] 15.43694
[1] -29.80549
[1] 62.18687
INFO  [19:03:41.991] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -16.94556
[1] 60.45283
[1] -32.50626
[1] 65.29398
[1] -67.67203
[1] 38.31859
[1] -397.8628
[1] 10.32815
[1] -32.89587
[1] 4.150534
INFO  [19:04:32.292] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -86.42928
[1] 29.13174
[1] -28.0899
[1] 28.30164
[1] -42.10534
[1] 42.32695
[1] -19.65467
[1] 87.00502
[1] -448.7926
[1] -3.922526
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:05:19.480] [mlr3] Finished benchmark
INFO  [19:05:19.670] [bbotk] Result of batch 50:
INFO  [19:05:19.681] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:05:19.681] [bbotk]              -1.910546                         0.2739638
INFO  [19:05:19.681] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:05:19.681] [bbotk]                         0.2194765          -0.5508169              -4.252779
INFO  [19:05:19.681] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:05:19.681] [bbotk]                          7                    2582                 0.1107245
INFO  [19:05:19.681] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:05:19.681] [bbotk]  0.004877893 <list[8]>              FALSE     0.03948709        0      0
INFO  [19:05:19.681] [bbotk]  runtime_learners                                uhash
INFO  [19:05:19.681] [bbotk]            135.72 b8caddeb-1e74-4a96-81e4-435638941c8a
INFO  [19:05:21.517] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 81 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:05:46.224] [bbotk] Evaluating 1 configuration(s)
INFO  [19:05:46.794] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:05:47.489] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -55.82981
[1] 55.57944
[1] -34.10546
[1] 21.36642
[1] -28.27083
[1] 24.92069
[1] -63.43179
[1] 11.23428
[1] -138.8125
[1] 46.01777
INFO  [19:06:13.316] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -26.58343
[1] 23.09738
[1] -27.64832
[1] 38.73885
[1] -230.3732
[1] 3.877877
[1] -1280.496
[1] -39.70652
[1] 38.56419
[1] 922.8339
INFO  [19:06:35.221] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -114.0544
[1] 15.04584
[1] -313.9628
[1] 5.045427
[1] -1449.032
[1] -74.00904
[1] -37.15479
[1] 29.50024
[1] 149.9561
[1] 3099.582
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:07:10.006] [mlr3] Finished benchmark
INFO  [19:07:10.113] [bbotk] Result of batch 51:
INFO  [19:07:10.138] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:07:10.138] [bbotk]              -2.602548                         0.5594196
INFO  [19:07:10.138] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:07:10.138] [bbotk]                         0.3740203           -2.512451              -6.231974
INFO  [19:07:10.138] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:07:10.138] [bbotk]                          8                    1139                  0.529642
INFO  [19:07:10.138] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:07:10.138] [bbotk]  0.004875409 <list[8]>              FALSE     0.02580405        0      0
INFO  [19:07:10.138] [bbotk]  runtime_learners                                uhash
INFO  [19:07:10.138] [bbotk]            82.053 dde622cc-0418-4d52-934e-e0cd1f2e48a6
INFO  [19:07:27.916] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 82 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:07:46.109] [bbotk] Evaluating 1 configuration(s)
INFO  [19:07:46.296] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:07:46.397] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -41.36041
[1] 83.73249
[1] -114.0122
[1] 23.29261
[1] -52.5551
[1] 29.70817
[1] -171.9869
[1] 66.51473
[1] -33.14092
[1] 21.9495
INFO  [19:08:31.259] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -234.6095
[1] -3.973945
[1] -46.43026
[1] 33.58644
[1] -30.22664
[1] 108.1674
[1] -292.9196
[1] 6.657801
[1] -26.92497
[1] 57.97349
INFO  [19:09:35.276] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -37.06189
[1] 103.474
[1] -24.40957
[1] 61.74082
[1] -84.12391
[1] 21.35192
[1] -480.4139
[1] -1.159685
[1] -1533.43
[1] -30.35375
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:10:44.367] [mlr3] Finished benchmark
INFO  [19:10:44.866] [bbotk] Result of batch 52:
INFO  [19:10:44.875] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:10:44.875] [bbotk]              -4.297299                         0.1750228
INFO  [19:10:44.875] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:10:44.875] [bbotk]                         0.4761137           -5.136888              -2.689266
INFO  [19:10:44.875] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:10:44.875] [bbotk]                          8                    4331                 0.5186893
INFO  [19:10:44.875] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:10:44.875] [bbotk]  0.004631991 <list[8]>              FALSE     0.02474036        0      0
INFO  [19:10:44.875] [bbotk]  runtime_learners                                uhash
INFO  [19:10:44.875] [bbotk]            177.61 6e87bf89-0d95-43cb-bc92-59e017335a61
WARN  [19:10:50.675] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:10:50.685] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 83 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:10:59.489] [bbotk] Evaluating 1 configuration(s)
INFO  [19:10:59.648] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:10:59.727] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -60.77987
[1] 74.65647
[1] -67.78145
[1] 99.18802
[1] -247.0813
[1] 34.23732
[1] -88.34572
[1] 3.034437
[1] -22.7017
[1] 63.69324
INFO  [19:11:33.129] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -276.6478
[1] 38.71333
[1] -62.20862
[1] 11.38377
[1] -4277.897
[1] -177.2857
[1] 31.6457
[1] 656.9251
[1] -100.8317
[1] 0.4590975
INFO  [19:12:03.194] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -144.729
[1] 51.74589
[1] -27.9631
[1] 26.72132
[1] -62.14231
[1] 44.41783
[1] -81.70645
[1] 9.840778
[1] 1.165903e+15
[1] 3.659325e+16
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:12:54.391] [mlr3] Finished benchmark
INFO  [19:12:55.431] [bbotk] Result of batch 53:
INFO  [19:12:55.474] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:12:55.474] [bbotk]              -6.859777                         0.2772403
INFO  [19:12:55.474] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:12:55.474] [bbotk]                         0.1504783           -1.016377               2.264023
INFO  [19:12:55.474] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:12:55.474] [bbotk]                          6                    2091                 0.3481377
INFO  [19:12:55.474] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:12:55.474] [bbotk]  0.00471402 <list[8]>              FALSE      0.0252111        0      0
INFO  [19:12:55.474] [bbotk]  runtime_learners                                uhash
INFO  [19:12:55.474] [bbotk]           114.455 e39b0306-bf5d-4df8-bde2-37e8409d186e
INFO  [19:13:03.366] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 84 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:13:10.460] [bbotk] Evaluating 1 configuration(s)
INFO  [19:13:10.561] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:13:10.623] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -32.7318
[1] 53.57289
[1] -134.3916
[1] -4.004085
[1] -26.74212
[1] 26.25368
[1] -26.57355
[1] 72.2047
[1] -9.414232
[1] 63.90956
INFO  [19:13:47.333] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -67.96613
[1] 3.81619
[1] -44.47163
[1] 26.72078
[1] -177.0669
[1] -4.072928
[1] -22.02938
[1] 44.39034
[1] -2.861437e+16
[1] 1.863312e+15
INFO  [19:14:43.049] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -962.4214
[1] -17.63661
[1] -78.92468
[1] -4.095049
[1] -2632.492
[1] 2759.452
[1] -37.46734
[1] 61.99066
[1] -70.09075
[1] 25.65015
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:15:24.770] [mlr3] Finished benchmark
INFO  [19:15:24.866] [bbotk] Result of batch 54:
INFO  [19:15:24.878] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:15:24.878] [bbotk]              -6.536568                         0.6338103
INFO  [19:15:24.878] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:15:24.878] [bbotk]                          0.815325           -1.237339               2.021016
INFO  [19:15:24.878] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:15:24.878] [bbotk]                          7                    2338                 0.4527806
INFO  [19:15:24.878] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:15:24.878] [bbotk]  0.006350391 <list[8]>              FALSE     0.02619359        0      0
INFO  [19:15:24.878] [bbotk]  runtime_learners                                uhash
INFO  [19:15:24.878] [bbotk]           133.022 8faa019c-4504-4fc7-8ba4-565d1a39e135
INFO  [19:15:27.517] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 85 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:15:43.677] [bbotk] Evaluating 1 configuration(s)
INFO  [19:15:43.927] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:15:43.980] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -21.77187
[1] 35.62363
[1] -60.62258
[1] 134.002
[1] -47.51917
[1] 102.9681
[1] -514.6198
[1] -4.102247
[1] -51.90414
[1] 23.182
INFO  [19:16:44.619] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -30.30198
[1] 64.51837
[1] -59.85976
[1] 56.90171
[1] -291.7803
[1] 22.9164
[1] -219.5429
[1] -3.853872
[1] -58.80053
[1] 30.6783
INFO  [19:17:52.524] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -24.43862
[1] 125.4082
[1] -1526.31
[1] -31.62641
[1] -111.7821
[1] 19.57393
[1] -99.14808
[1] 13.73421
[1] -18.06321
[1] 60.58743
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:18:55.827] [mlr3] Finished benchmark
INFO  [19:18:56.473] [bbotk] Result of batch 55:
INFO  [19:18:56.479] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:18:56.479] [bbotk]              -0.560407                         0.1140778
INFO  [19:18:56.479] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:18:56.479] [bbotk]                         0.6324555            -3.44764              -2.147916
INFO  [19:18:56.479] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:18:56.479] [bbotk]                          7                    3690                 0.5597381
INFO  [19:18:56.479] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:18:56.479] [bbotk]  0.004746652 <list[8]>              FALSE     0.02664463        0      0
INFO  [19:18:56.479] [bbotk]  runtime_learners                                uhash
INFO  [19:18:56.479] [bbotk]           191.435 096f60a1-4bc6-470e-aa01-dd6f74e9013a
INFO  [19:19:17.836] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 86 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:19:36.701] [bbotk] Evaluating 1 configuration(s)
INFO  [19:19:36.922] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:19:37.674] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -60.72966
[1] 96.39142
[1] -40.14922
[1] 33.31056
[1] -34.60768
[1] 91.62343
[1] -34.17881
[1] 20.44199
[1] -47.86155
[1] 16.07218
INFO  [19:20:12.746] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1.84949e+15
[1] 2.844906e+16
[1] -82.4957
[1] 71.81886
[1] -17.11085
[1] 113.2121
[1] -85.67942
[1] 9.928741
[1] -112.8734
[1] 21.0451
INFO  [19:20:50.749] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -53.98736
[1] 149.7736
[1] -99.11503
[1] -1.164005
[1] -48.84842
[1] 15.94072
[1] -257.7863
[1] 24.0665
[1] -7.680134
[1] 87.21648
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:21:18.039] [mlr3] Finished benchmark
INFO  [19:21:18.140] [bbotk] Result of batch 56:
INFO  [19:21:18.172] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:21:18.172] [bbotk]              0.4319208                         0.1256955
INFO  [19:21:18.172] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:21:18.172] [bbotk]                          0.208988          -0.2067452               2.415583
INFO  [19:21:18.172] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:21:18.172] [bbotk]                         19                    3911                 0.7115228
INFO  [19:21:18.172] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:21:18.172] [bbotk]  0.00659902 <list[8]>              FALSE     0.02806844        0      0
INFO  [19:21:18.172] [bbotk]  runtime_learners                                uhash
INFO  [19:21:18.172] [bbotk]           100.169 05d40502-9a9c-43f9-9094-0938fa9bb3f1
INFO  [19:21:30.012] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 87 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:21:59.938] [bbotk] Evaluating 1 configuration(s)
INFO  [19:22:00.208] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:22:01.017] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -54.83189
[1] 73.70086
[1] -303.2773
[1] -0.6323437
[1] -40.40372
[1] 43.62973
[1] -4345.482
[1] -58.86482
[1] -21.30716
[1] 30.40716
INFO  [19:23:01.154] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -21.63657
[1] 38.05861
[1] -72.92427
[1] 19.3248
[1] -54.29029
[1] 163.565
[1] -52.35185
[1] 15.11734
[1] -57.49925
[1] 45.67039
INFO  [19:24:01.822] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -36.65516
[1] 25.03494
[1] -4625.76
[1] -207.8293
[1] -844.807
[1] -32.20608
[1] 238.2366
[1] 3551.167
[1] -185.1784
[1] 14.85316
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:24:43.099] [mlr3] Finished benchmark
INFO  [19:24:44.998] [bbotk] Result of batch 57:
INFO  [19:24:45.261] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:24:45.261] [bbotk]              -1.628209                         0.8367552
INFO  [19:24:45.261] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:24:45.261] [bbotk]                         0.2005716           -3.962548              -5.674403
INFO  [19:24:45.261] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:24:45.261] [bbotk]                         15                    3978                 0.7468559
INFO  [19:24:45.261] [bbotk]      acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:24:45.261] [bbotk]  0.00534539 <list[8]>              FALSE     0.02585409        0      0
INFO  [19:24:45.261] [bbotk]  runtime_learners                                uhash
INFO  [19:24:45.261] [bbotk]           161.214 69b04fd1-f0b3-483c-ad4c-8fdd57d5375f
WARN  [19:24:48.631] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:24:48.643] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 88 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:24:56.115] [bbotk] Evaluating 1 configuration(s)
INFO  [19:24:56.285] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:24:56.299] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -31.50746
[1] 18.41633
[1] -25.72462
[1] 93.29801
[1] -65.16485
[1] 20.97103
[1] -57.38685
[1] 35.89701
[1] -55.64147
[1] 110.7412
INFO  [19:26:05.554] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -17.82587
[1] 69.78486
[1] -105.4574
[1] 0.7806196
[1] -43.19018
[1] 65.10892
[1] -168.579
[1] 22.21278
[1] -309.6314
[1] -2.576929
INFO  [19:27:39.269] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -30.25542
[1] 45.0481
[1] -80.46578
[1] 10.93758
[1] -42.77101
[1] 62.78233
[1] -78016.74
[1] -2392.548
[1] -154.5394
[1] 13.04584
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:28:37.735] [mlr3] Finished benchmark
INFO  [19:28:38.090] [bbotk] Result of batch 58:
INFO  [19:28:38.178] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:28:38.178] [bbotk]              -4.307756                         0.5740891
INFO  [19:28:38.178] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:28:38.178] [bbotk]                         0.4910749            -4.39032              -6.368047
INFO  [19:28:38.178] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:28:38.178] [bbotk]                         18                    4428                 0.3598753
INFO  [19:28:38.178] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:28:38.178] [bbotk]  0.004683124 <list[8]>              FALSE      0.0253855        0      0
INFO  [19:28:38.178] [bbotk]  runtime_learners                                uhash
INFO  [19:28:38.178] [bbotk]           220.926 abf64af6-452a-4421-88f4-3704df96b2b4
INFO  [19:28:49.206] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 89 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:28:57.860] [bbotk] Evaluating 1 configuration(s)
INFO  [19:28:58.136] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:28:58.208] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -63.90699
[1] 48.22709
[1] -4136.565
[1] -101.0036
[1] -65.35037
[1] 16.73281
[1] -15.73865
[1] 30.8677
[1] -8.21255
[1] 50.84238
INFO  [19:30:13.094] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -2900.052
[1] -71.60975
[1] -28.61308
[1] 22.081
[1] -44.88141
[1] 54.09104
[1] -45.43919
[1] 8.058434
[1] 79.58787
[1] 2934.857
INFO  [19:31:30.082] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -86.62585
[1] 3.966939
[1] -2477.037
[1] -50.24298
[1] -107.1103
[1] -3.241445
[1] -3242.039
[1] -76.46855
[1] -284.531
[1] 31.94884
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:32:23.932] [mlr3] Finished benchmark
INFO  [19:32:24.196] [bbotk] Result of batch 59:
INFO  [19:32:24.209] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:32:24.209] [bbotk]              -5.982807                         0.7370455
INFO  [19:32:24.209] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:32:24.209] [bbotk]                         0.3314092           -1.249032               1.297597
INFO  [19:32:24.209] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:32:24.209] [bbotk]                         18                    4985                 0.2805426
INFO  [19:32:24.209] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:32:24.209] [bbotk]  0.004856342 <list[8]>              FALSE     0.02596094        0      0
INFO  [19:32:24.209] [bbotk]  runtime_learners                                uhash
INFO  [19:32:24.209] [bbotk]           205.442 edae6520-9342-4764-83bd-2600c7427477
WARN  [19:32:28.550] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:32:28.615] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 90 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:32:50.567] [bbotk] Evaluating 1 configuration(s)
INFO  [19:32:51.203] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:32:51.276] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -39.77847
[1] 56.53795
[1] -53.68561
[1] 7.019158
[1] -1.873458e+16
[1] 2.281634e+16
[1] -93.22691
[1] 22.60729
[1] -24.91587
[1] 28.32956
INFO  [19:33:46.436] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -145.6422
[1] 3.69776
[1] -40.85756
[1] 58.51125
[1] -5076.45
[1] -97.11344
[1] -52.99015
[1] 542.7204
[1] -209.2626
[1] 5.663267
INFO  [19:35:08.851] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -162.0602
[1] 69.23485
[1] 89.39271
[1] 2911.776
[1] -125.6365
[1] 10.35715
[1] -47.40436
[1] 24.8501
[1] -62.61116
[1] 136.5505
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:37:08.511] [mlr3] Finished benchmark
INFO  [19:37:08.670] [bbotk] Result of batch 60:
INFO  [19:37:08.701] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:37:08.701] [bbotk]              0.1283231                         0.9638832
INFO  [19:37:08.701] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:37:08.701] [bbotk]                         0.7885441           -2.845958              -2.863854
INFO  [19:37:08.701] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:37:08.701] [bbotk]                         17                    4090                 0.3088282
INFO  [19:37:08.701] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:37:08.701] [bbotk]  0.004419342 <list[8]>              FALSE     0.02735574        0      0
INFO  [19:37:08.701] [bbotk]  runtime_learners                                uhash
INFO  [19:37:08.701] [bbotk]           255.923 44963444-a3dc-4f8c-a1ec-e76f99e6fb0b
WARN  [19:37:14.907] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:37:14.914] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 91 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:37:22.842] [bbotk] Evaluating 1 configuration(s)
INFO  [19:37:22.940] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:37:22.989] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -26.20987
[1] 35.10618
[1] -171.0011
[1] 6.395923
[1] -31.88643
[1] 24.42291
[1] -64.14983
[1] 43.94975
[1] -29200.33
[1] -523.4936
INFO  [19:38:57.804] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -1636.897
[1] -64.96455
[1] -198.2174
[1] 2.573454
[1] -6.945816
[1] 197.4535
[1] -65.56365
[1] 11.07647
[1] -77.25004
[1] 96.6819
INFO  [19:40:16.900] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -156.7112
[1] 99.9822
[1] -41.87172
[1] 41.08434
[1] -43.99447
[1] 158.7076
[1] -42.0646
[1] 56.73822
[1] -78.85343
[1] 9.894578
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:41:15.653] [mlr3] Finished benchmark
INFO  [19:41:15.730] [bbotk] Result of batch 61:
INFO  [19:41:16.070] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:41:16.070] [bbotk]              -5.313867                         0.7131427
INFO  [19:41:16.070] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:41:16.070] [bbotk]                         0.9735432           -5.792193              -3.187622
INFO  [19:41:16.070] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:41:16.070] [bbotk]                         20                    4855                 0.4312247
INFO  [19:41:16.070] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:41:16.070] [bbotk]  0.004206106 <list[8]>              FALSE     0.02663205        0      0
INFO  [19:41:16.070] [bbotk]  runtime_learners                                uhash
INFO  [19:41:16.070] [bbotk]            232.29 8b6eca00-ab4b-49df-a387-ef980d2c051c
WARN  [19:41:26.587] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:41:26.624] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 92 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:41:39.992] [bbotk] Evaluating 1 configuration(s)
INFO  [19:41:40.083] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:41:40.733] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -21.47985
[1] 41.9771
[1] -36.70959
[1] 50.5896
[1] -2.178935e+16
[1] 2.115333e+16
[1] -41.37011
[1] 2.246375
[1] -17913.73
[1] -220.3195
INFO  [19:43:03.750] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -35.05846
[1] 40.22272
[1] 60.65998
[1] 2037.208
[1] -40.83063
[1] 45.42336
[1] -168.8372
[1] 5.531998
[1] -73.20144
[1] -3.236172
INFO  [19:44:07.107] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -33.75712
[1] 33.4853
[1] -176.2084
[1] 10.242
[1] -197.1443
[1] 23.10732
[1] 148.6408
[1] 3397.962
[1] -22.44946
[1] 57.60247
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:45:20.731] [mlr3] Finished benchmark
INFO  [19:45:20.842] [bbotk] Result of batch 62:
INFO  [19:45:20.853] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:45:20.853] [bbotk]              -1.231538                         0.7633915
INFO  [19:45:20.853] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:45:20.853] [bbotk]                         0.2579262           -5.415182              -2.693771
INFO  [19:45:20.853] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:45:20.853] [bbotk]                         14                    4469                 0.7122472
INFO  [19:45:20.853] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:45:20.853] [bbotk]  0.004629542 <list[8]>              FALSE     0.02692379        0      0
INFO  [19:45:20.853] [bbotk]  runtime_learners                                uhash
INFO  [19:45:20.853] [bbotk]           218.516 3dd38d53-698b-4486-a97a-0fed7210e82b
WARN  [19:45:29.259] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:45:29.279] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 93 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:45:40.762] [bbotk] Evaluating 1 configuration(s)
INFO  [19:45:40.979] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:45:41.188] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -93.93865
[1] 61.7961
[1] -225.9312
[1] 0.4452792
[1] -83.96141
[1] 23.52003
[1] -54.35141
[1] 28.28635
[1] -1536.468
[1] -33.00452
INFO  [19:46:46.234] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -171.0122
[1] 6.053593
[1] -20.19685
[1] 99.31756
[1] -121.2215
[1] 8.462491
[1] -27.19878
[1] 30.38328
[1] 133.6761
[1] 2686.752
INFO  [19:47:55.380] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -74.74862
[1] 25.26085
[1] -476.6224
[1] 60.54776
[1] -767.428
[1] 93.93143
[1] -50.01463
[1] 23.40758
[1] -6546.96
[1] -120.3643
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:49:04.120] [mlr3] Finished benchmark
INFO  [19:49:06.792] [bbotk] Result of batch 63:
INFO  [19:49:06.829] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:49:06.829] [bbotk]              -3.269362                         0.9499157
INFO  [19:49:06.829] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:49:06.829] [bbotk]                         0.1104079           -2.218199              -4.929707
INFO  [19:49:06.829] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:49:06.829] [bbotk]                         18                    4775                 0.4087201
INFO  [19:49:06.829] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:49:06.829] [bbotk]  0.004512008 <list[8]>              FALSE     0.02574676        0      0
INFO  [19:49:06.829] [bbotk]  runtime_learners                                uhash
INFO  [19:49:06.829] [bbotk]           202.155 8d00278e-dc8c-494f-9485-f495ad49feb3
INFO  [19:49:18.149] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 94 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:49:45.305] [bbotk] Evaluating 1 configuration(s)
INFO  [19:49:45.757] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:49:45.920] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -157.2718
[1] -3.842896
[1] -30.15027
[1] 100.5373
[1] -110.5758
[1] 10.06401
[1] 464.7488
[1] 16029.2
[1] -21.65152
[1] 60.42517
INFO  [19:51:05.384] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -217.7397
[1] -4.097554
[1] -72.51632
[1] 19.41037
[1] -118.2932
[1] 31.7719
[1] -89.89813
[1] 46.43984
[1] -56.44016
[1] 47.92738
INFO  [19:52:47.101] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -69.88003
[1] 8.610409
[1] 75.02427
[1] 2711.336
[1] 13.83028
[1] 206.8486
[1] -7198.92
[1] -118.2911
[1] -2410.779
[1] -102.6063
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:53:56.952] [mlr3] Finished benchmark
INFO  [19:53:57.064] [bbotk] Result of batch 64:
INFO  [19:53:57.073] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:53:57.073] [bbotk]              0.6798999                         0.1026777
INFO  [19:53:57.073] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:53:57.073] [bbotk]                         0.8620244            -2.41224              -4.746903
INFO  [19:53:57.073] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:53:57.073] [bbotk]                         20                    4600                 0.3352299
INFO  [19:53:57.073] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:53:57.073] [bbotk]  0.004351549 <list[8]>              FALSE     0.02928384        0      0
INFO  [19:53:57.073] [bbotk]  runtime_learners                                uhash
INFO  [19:53:57.073] [bbotk]           250.824 6874f1f8-be54-437a-a66d-7940d0eba434
WARN  [19:54:07.085] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:54:07.344] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 95 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:54:32.201] [bbotk] Evaluating 1 configuration(s)
INFO  [19:54:32.343] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:54:32.400] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -45.34847
[1] 37.21185
[1] -25.20901
[1] 32.21515
[1] -70.1376
[1] 111.4028
[1] -172.0673
[1] 20.08636
[1] -57.39699
[1] 1.415807
INFO  [19:55:11.395] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -42.08022
[1] 45.32792
[1] -33.86579
[1] 23.56664
[1] 62.594
[1] 2097.62
[1] -61.45049
[1] 150.274
[1] -74.64022
[1] 4.548437
INFO  [19:55:50.366] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -53.88247
[1] 25.32556
[1] -67.20444
[1] 0.3870774
[1] -31.26632
[1] 101.6568
[1] 87.33376
[1] 2420.317
[1] -1.773696e+16
[1] 2.085311e+16
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:56:30.906] [mlr3] Finished benchmark
INFO  [19:56:31.400] [bbotk] Result of batch 65:
INFO  [19:56:31.466] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:56:31.466] [bbotk]              -5.591972                         0.3100997
INFO  [19:56:31.466] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:56:31.466] [bbotk]                         0.4551942           -2.227282             -0.2566816
INFO  [19:56:31.466] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:56:31.466] [bbotk]                          8                    1101                 0.5339038
INFO  [19:56:31.466] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:56:31.466] [bbotk]  0.006520836 <list[8]>              FALSE     0.02420776        0      0
INFO  [19:56:31.466] [bbotk]  runtime_learners                                uhash
INFO  [19:56:31.466] [bbotk]           118.062 9118a5f8-cc83-4222-a144-1c5ee579d384
WARN  [19:56:51.445] [mlr3] train: Stopped because hard maximum generation limit was hit.
INFO  [19:56:51.478] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 96 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:57:13.094] [bbotk] Evaluating 1 configuration(s)
INFO  [19:57:13.503] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:57:13.586] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -18.5212
[1] 85.67593
[1] -89.734
[1] 113.211
[1] -47.52887
[1] 14.06326
[1] -117.625
[1] 18.93215
[1] -29.49026
[1] 43.84827
INFO  [19:58:09.186] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] 1552.062
[1] 43077.52
[1] -33.11477
[1] 28.0009
[1] -85.46325
[1] 28.20426
[1] -69.30331
[1] -3.152577
[1] -89.3023
[1] 46.14105
INFO  [19:58:42.158] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -127.496
[1] 55.14933
[1] 57.45456
[1] 1132.946
[1] -48.59716
[1] 11.94598
[1] -208.7854
[1] 25.36889
[1] -806.2154
[1] -36.55259
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [19:59:23.067] [mlr3] Finished benchmark
INFO  [19:59:23.356] [bbotk] Result of batch 66:
INFO  [19:59:23.391] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [19:59:23.391] [bbotk]              -6.718346                         0.1560765
INFO  [19:59:23.391] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [19:59:23.391] [bbotk]                         0.2910128           -1.900863              -3.395605
INFO  [19:59:23.391] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [19:59:23.391] [bbotk]                         19                    1532                 0.4958175
INFO  [19:59:23.391] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [19:59:23.391] [bbotk]  0.004063967 <list[8]>              FALSE     0.02620489        0      0
INFO  [19:59:23.391] [bbotk]  runtime_learners                                uhash
INFO  [19:59:23.391] [bbotk]           126.462 7eef2ae6-bb5b-4747-b807-c90acb21b1e5
INFO  [19:59:34.979] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 97 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [19:59:51.408] [bbotk] Evaluating 1 configuration(s)
INFO  [19:59:52.152] [mlr3] Running benchmark with 3 resampling iterations
INFO  [19:59:52.552] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -66.87081
[1] 29.26952
[1] -79.15142
[1] 29.95122
[1] -30.18427
[1] 39.39236
[1] -60.29432
[1] 24.47129
[1] -61.28031
[1] 8.196919
INFO  [20:00:29.770] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -275.2205
[1] 7.828523
[1] -65.94419
[1] -3.957063
[1] -57.4789
[1] 8.58244
[1] -155.0132
[1] 65.63745
[1] -680.6975
[1] -29.23937
INFO  [20:01:12.738] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] 657.7688
[1] 12728.97
[1] -3688.806
[1] -148.5682
[1] -41.88074
[1] 25.30466
[1] -19.72724
[1] 104.1978
[1] -430.0139
[1] 1.630146
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:02:06.746] [mlr3] Finished benchmark
INFO  [20:02:08.032] [bbotk] Result of batch 67:
INFO  [20:02:08.241] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:02:08.241] [bbotk]              -2.677017                         0.1100618
INFO  [20:02:08.241] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:02:08.241] [bbotk]                         0.8505387           -1.249244             -0.2838404
INFO  [20:02:08.241] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:02:08.241] [bbotk]                          1                    1086                 0.7281487
INFO  [20:02:08.241] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:02:08.241] [bbotk]  0.004352094 <list[8]>              FALSE     0.02680422        0      0
INFO  [20:02:08.241] [bbotk]  runtime_learners                                uhash
INFO  [20:02:08.241] [bbotk]            133.79 4eb351b3-6749-438f-beb1-c74762fe73f0
INFO  [20:02:13.886] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 98 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:02:37.635] [bbotk] Evaluating 1 configuration(s)
INFO  [20:02:38.026] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:02:38.074] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -66.22491
[1] 14.68128
[1] -27.84712
[1] 96.79224
[1] -39.51893
[1] 45.55658
[1] -125.2182
[1] -3.878983
[1] -45.23362
[1] 75.00644
INFO  [20:03:25.591] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -195.5176
[1] -3.874211
[1] -43.30321
[1] 66.3043
[1] -47.73683
[1] 1.794508
[1] -140.1249
[1] 45.27338
[1] 76.26435
[1] 3053.923
INFO  [20:04:08.033] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -558.861
[1] 4.938223
[1] -43.06191
[1] 67.73591
[1] -1575.846
[1] -42.11598
[1] -47.69323
[1] 88.54227
[1] -54.84502
[1] 14.63705
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:05:33.822] [mlr3] Finished benchmark
INFO  [20:05:34.797] [bbotk] Result of batch 68:
INFO  [20:05:34.879] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:05:34.879] [bbotk]              -4.411148                         0.4659397
INFO  [20:05:34.879] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:05:34.879] [bbotk]                         0.9943714           -5.541809              -4.324557
INFO  [20:05:34.879] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:05:34.879] [bbotk]                          9                    3879                 0.3319082
INFO  [20:05:34.879] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:05:34.879] [bbotk]  0.004028993 <list[8]>              FALSE     0.02814213        0      0
INFO  [20:05:34.879] [bbotk]  runtime_learners                                uhash
INFO  [20:05:34.879] [bbotk]           175.636 078ab5ef-57c5-4cf6-9010-e1e20660022a
INFO  [20:05:54.287] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 99 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:06:05.252] [bbotk] Evaluating 1 configuration(s)
INFO  [20:06:05.643] [mlr3] Running benchmark with 3 resampling iterations
INFO  [20:06:05.768] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 1/3)
[1] -54.57803
[1] 49.91579
[1] -36.29534
[1] 44.63428
[1] -59.31239
[1] 7.468628
[1] -74.36657
[1] 14.26558
[1] -60.02931
[1] 93.10213
INFO  [20:07:29.543] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 2/3)
[1] -114.4991
[1] 8.192923
[1] -75.5716
[1] 22.09372
[1] -94.77639
[1] 32.55844
[1] -185.3491
[1] 3.375121
[1] -19.38864
[1] 71.12473
INFO  [20:08:38.942] [mlr3] Applying learner 'classif.xgboost' on task 'wdbc' (iter 3/3)
[1] -2416.266
[1] -75.63608
[1] -81.68525
[1] 2.804811
[1] -5387.148
[1] -172.6929
[1] 623.7793
[1] 13979.46
[1] 31.37116
[1] 692.2997
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
INFO  [20:10:25.837] [mlr3] Finished benchmark
INFO  [20:10:26.604] [bbotk] Result of batch 69:
INFO  [20:10:26.679] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:10:26.679] [bbotk]              -5.881252                          0.264249
INFO  [20:10:26.679] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:10:26.679] [bbotk]                         0.1450989           -3.015082              -1.426502
INFO  [20:10:26.679] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:10:26.679] [bbotk]                         19                    4313                 0.3696574
INFO  [20:10:26.679] [bbotk]       acq_ei  x_domain .already_evaluated classif.bbrier warnings errors
INFO  [20:10:26.679] [bbotk]  0.003843762 <list[8]>              FALSE     0.02460844        0      0
INFO  [20:10:26.679] [bbotk]  runtime_learners                                uhash
INFO  [20:10:26.679] [bbotk]           258.987 bc36bcfe-df2a-4cda-912a-4ad399b9aa64
INFO  [20:10:31.957] [mlr3] Calling train method of fallback 'regr.ranger' on task 'surrogate_task' with 100 observations {learner: <LearnerRegrRanger/LearnerRegr/Learner/R6>}
INFO  [20:10:32.006] [bbotk] Finished optimizing after 100 evaluation(s)
INFO  [20:10:32.102] [bbotk] Result:
INFO  [20:10:32.109] [bbotk]  classif.xgboost.alpha classif.xgboost.colsample_bylevel
INFO  [20:10:32.109] [bbotk]                  <num>                             <num>
INFO  [20:10:32.109] [bbotk]              -5.591972                         0.3100997
INFO  [20:10:32.109] [bbotk]  classif.xgboost.colsample_bytree classif.xgboost.eta classif.xgboost.lambda
INFO  [20:10:32.109] [bbotk]                             <num>               <num>                  <num>
INFO  [20:10:32.109] [bbotk]                         0.4551942           -2.227282             -0.2566816
INFO  [20:10:32.109] [bbotk]  classif.xgboost.max_depth classif.xgboost.nrounds classif.xgboost.subsample
INFO  [20:10:32.109] [bbotk]                      <int>                   <int>                     <num>
INFO  [20:10:32.109] [bbotk]                          8                    1101                 0.5339038
INFO  [20:10:32.109] [bbotk]  learner_param_vals  x_domain classif.bbrier
INFO  [20:10:32.109] [bbotk]              <list>    <list>          <num>
INFO  [20:10:32.109] [bbotk]          <list[10]> <list[8]>     0.02420776
[1] -48.51287
[1] 8.003238
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] -964.2702
[1] -14.80444
[1] -38.2048
[1] 27.72587
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: algorithm did not converge
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] 41.35632
[1] 1192.474
Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
This happened PipeOp classif.xgboost's $train()
This happened PipeOp classif.xgboost.tuned's $train()
[1] -300.1074
[1] 3.436944

### [bt]: Job terminated successfully [batchtools job.id=1415]
### [bt]: Calculation finished!
